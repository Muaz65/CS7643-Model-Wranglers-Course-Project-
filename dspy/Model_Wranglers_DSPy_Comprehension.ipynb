{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tqgkJdlqp17D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dspy-ai in /opt/conda/lib/python3.10/site-packages (2.0.7)\n",
      "Requirement already satisfied: requests<=2.31.0 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (2.31.0)\n",
      "Requirement already satisfied: ujson<=5.8.0 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (5.8.0)\n",
      "Requirement already satisfied: optuna<=3.4.0 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (3.4.0)\n",
      "Requirement already satisfied: regex<=2023.10.3 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (2023.10.3)\n",
      "Requirement already satisfied: backoff<=2.2.1 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (2.2.1)\n",
      "Requirement already satisfied: datasets<=2.14.6 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (2.14.6)\n",
      "Requirement already satisfied: tqdm<=4.66.1 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (4.65.0)\n",
      "Requirement already satisfied: openai<=0.28.1 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (0.28.1)\n",
      "Requirement already satisfied: joblib<=1.3.2 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (1.3.2)\n",
      "Requirement already satisfied: pandas<=2.1.1 in /opt/conda/lib/python3.10/site-packages (from dspy-ai) (2.1.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (3.9.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (0.19.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (0.70.15)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (0.3.7)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (2023.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (14.0.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets<=2.14.6->dspy-ai) (23.0)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna<=3.4.0->dspy-ai) (6.8.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna<=3.4.0->dspy-ai) (1.13.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna<=3.4.0->dspy-ai) (2.0.23)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<=2.1.1->dspy-ai) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<=2.1.1->dspy-ai) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<=2.1.1->dspy-ai) (2022.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<=2.31.0->dspy-ai) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<=2.31.0->dspy-ai) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<=2.31.0->dspy-ai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<=2.31.0->dspy-ai) (3.4)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna<=3.4.0->dspy-ai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna<=3.4.0->dspy-ai) (4.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.14.6->dspy-ai) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.14.6->dspy-ai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.14.6->dspy-ai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.14.6->dspy-ai) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.14.6->dspy-ai) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.14.6->dspy-ai) (6.0.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets<=2.14.6->dspy-ai) (3.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<=2.1.1->dspy-ai) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna<=3.4.0->dspy-ai) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna<=3.4.0->dspy-ai) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install dspy-ai\n",
    "! pip install transformers\n",
    "! pip install accelerate\n",
    "# !pip install \"openai<1.0.0\"\n",
    "# # !pip install azure-keyvault-secrets azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "L2XSJ3guqcRf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fd737b9982400eb5ee9f65e5e8233b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import dspy\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dsp.utils.utils import deduplicate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, BootstrapFinetune\n",
    "\n",
    "lm = dspy.HFModel(model='mistralai/Mistral-7B-Instruct-v0.1')\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkbqdYhQrVH0"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zde416GDrCep",
    "outputId": "65491076-1f8b-4369-a139-fdf2a5f85bf3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c014736bea430ea91407fd7eeb6bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236d15c6ae68451799c9bfadca53841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a873e141d9497eb36d000d680da4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/346k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892a3cc2c09b47c88fbaab3c728f5fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/344k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ef88a763f942118498fabfde3e3272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d84bb4e37649008a9a2a78b0811186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cf06f335224be0a6cad9e9ec42a109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bb2a007a424d49a2e6fa47dc2de6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'answer': 'A', 'word': 'prophet', 'scrambled': 'prohept', 'question': \"Rearrange the letters in 'prohept' to form the correct word.\\nA: prophet\\nB: jessica\\nC: child\\nD: respected\"}) (input_keys={'question'})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "hf_dataset = load_dataset(\"kurtn718/scrambled_words_multiple_choice\")\n",
    "\n",
    "# Function to convert a Huggingface dataset row to DSPy format\n",
    "def convert_to_dspy_format(item):\n",
    "    return dspy.Example(\n",
    "        answer=item[\"correct_answer\"],\n",
    "        word=item[\"word\"],\n",
    "        scrambled=item[\"scrambled\"],\n",
    "        question=item[\"question\"]\n",
    "    )\n",
    "\n",
    "# Convert and combine all splits\n",
    "dspy_dataset = defaultdict(list)\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for item in hf_dataset[split]:\n",
    "        dspy_example = convert_to_dspy_format(item)\n",
    "        dspy_dataset[split].append(dspy_example)\n",
    "\n",
    "train_set = dspy_dataset[\"train\"]\n",
    "validation_set = dspy_dataset[\"validation\"]\n",
    "test_set = dspy_dataset[\"test\"]\n",
    "\n",
    "train_set = [x.with_inputs('question') for x in train_set]\n",
    "validation_set = [x.with_inputs('question') for x in validation_set]\n",
    "test_set = [x.with_inputs('question') for x in test_set]\n",
    "\n",
    "# Check the first element of the training set\n",
    "example = train_set[0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWPytOuVxnBQ",
    "outputId": "69f92d00-bd2b-4e98-c66b-0846448a879d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Rearrange the letters in 'prohept' to form the correct word.\n",
      "A: prophet\n",
      "B: jessica\n",
      "C: child\n",
      "D: respected\n",
      "Predicted Answer: Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prohept' to form the correct word. A: prophet B: jessica C: child D: respected\n",
      "Answer: B\n"
     ]
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer multiple choice questions from the given options A,B,C,D\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"1 letter from A,B,C,D\")\n",
    "\n",
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Call the predictor on a particular input.\n",
    "pred = generate_answer(question=example.question)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuKUbGJ05f9h",
    "outputId": "be80ac6b-47a9-4484-a4ec-6f7d0b38da68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prohept' to form the correct word. A: prophet B: jessica C: child D: respected\n",
      "Answer:\u001b[32mAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prohept' to form the correct word. A: prophet B: jessica C: child D: respected\n",
      "Answer: B\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "HMzCJ48z8fJ3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'scuks'. A: structures B: avalon C: sucks D: polyester\n",
      "Answer: C: sucks\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'spueospd'. A: muslim B: supposed C: desired D: offices\n",
      "Answer: D: offices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hbndaags'? A: whose B: handbags C: jerusalem D: bidders\n",
      "Answer: D: bidders\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ptnemerhine' represent when unscrambled? A: phentermine B: chaos C: killing D: tion\n",
      "Answer: A: phentermine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'taht'. A: that B: gamma C: parcel D: drawer\n",
      "Answer: A: that\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'guatir'. A: guitar B: chemicals C: variation D: pounds\n",
      "Answer: A: guitar\n"
     ]
    }
   ],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(BasicQA)\n",
    "    def postprocess(self, prediction):\n",
    "        # print(\"_______\")\n",
    "        # print(prediction)\n",
    "        # print(\"_______\")\n",
    "        return prediction.split(\"Answer: \")[-1][0]\n",
    "    \n",
    "    def forward(self, question):\n",
    "        prediction = self.generate_answer(question=question)\n",
    "        prediction.answer = self.postprocess(prediction.answer)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S99nssb35o9I",
    "outputId": "6d2db15a-695f-444c-9f8b-57aeba5a4dce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'clel' represent when unscrambled? A: productivity B: flux C: edges D: cell\n",
      "Answer: D: cell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sopt' to form the correct word. A: scratch B: spot C: periodic D: pension\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wkpsorohs'. A: workshops B: alexander C: brazil D: coastal\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nlrtaaus'? A: legislation B: drawing C: naturals D: proc\n",
      "Answer: D: proc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'elldrey' to form the correct word. A: sincerely B: boulder C: textile D: elderly\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'reomval'. A: ballet B: removal C: invision D: proceedings\n",
      "Answer: D: proceedings\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'barsets'? A: belle B: approved C: breasts D: deployment\n",
      "Answer: D: deployment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'auosticc'? A: powerseller B: golf C: apparatus D: acoustic\n",
      "Answer: A: powerseller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pcath'? A: patch B: smallest C: mali D: monitored\n",
      "Answer: D: monitored\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'varbneulle'. A: corners B: allah C: vulnerable D: cartridge\n",
      "Answer: D: cartridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'queiotsn' represent when unscrambled? A: bracelet B: butterfly C: question D: carrier\n",
      "Answer: C: question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wnrappig'? A: extend B: estimation C: wrapping D: scoring\n",
      "Answer: D: scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rosevleot'. A: premises B: roosevelt C: striking D: freshwater\n",
      "Answer: A: premises\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'etreira' represent when unscrambled? A: emacs B: auburn C: offerings D: eritrea\n",
      "Answer: D: eritrea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cuslter' to form the correct word. A: tuning B: tiles C: cluster D: forthcoming\n",
      "Answer: C\n",
      "Question: Rearrange the letters in 'prohept' to form the correct word.\n",
      "A: prophet\n",
      "B: jessica\n",
      "C: child\n",
      "D: respected\n",
      "Predicted Answer: B\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\n",
    "generate_answer_with_chain_of_thought = CoT()\n",
    "\n",
    "# Call the predictor on the same input.\n",
    "pred = generate_answer_with_chain_of_thought(question=example.question)\n",
    "\n",
    "# Print the input, the chain of thought, and the prediction.\n",
    "print(f\"Question: {example.question}\")\n",
    "# print(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lmiited' to form the correct word. A: physiology B: space C: wherever D: limited\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ceczh'. A: promotions B: supply C: tissues D: czech\n",
      "Answer: D: czech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hoetl'. A: cream B: hotel C: portrait D: religion\n",
      "Answer: C: portrait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'webhstos'? A: burial B: frontier C: portuguese D: webshots\n",
      "Answer: B: frontier\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aotrbion' to form the correct word. A: lightning B: number C: abortion D: pointer\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ceeland'. A: cleaned B: organizing C: commitments D: households\n",
      "Answer: B: organizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'naillvshe' represent when unscrambled? A: nashville B: wrist C: challenge D: forces\n",
      "Answer: D: forces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'croe' represent when unscrambled? A: publication B: participate C: core D: receipt\n",
      "Answer: D: receipt\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tihng'. A: situated B: concurrent C: thing D: lotus\n",
      "Answer: C: thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oavl'? A: quarterly B: john C: oval D: antivirus\n",
      "Answer: oval\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wlid' to form the correct word. A: finger B: wild C: plates D: furniture\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 0/2000 [00:11<?, ?it/s]\u001b[A\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 1/2000 [00:12<6:40:21, 12.02s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 2  (50.0):   0%|          | 1/2000 [00:12<6:40:21, 12.02s/it] \u001b[A\n",
      "Average Metric: 1 / 2  (50.0):   0%|          | 2/2000 [00:12<2:47:28,  5.03s/it]\u001b[A\n",
      "Average Metric: 1 / 3  (33.3):   0%|          | 2/2000 [00:12<2:47:28,  5.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 4  (25.0):   0%|          | 3/2000 [00:12<2:47:23,  5.03s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 5  (20.0):   0%|          | 4/2000 [00:12<2:47:18,  5.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 1 / 5  (20.0):   0%|          | 5/2000 [00:12<48:48,  1.47s/it]  \u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 6  (16.7):   0%|          | 5/2000 [00:12<48:48,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 7  (14.3):   0%|          | 6/2000 [00:12<48:47,  1.47s/it]\u001b[A\n",
      "Average Metric: 1 / 7  (14.3):   0%|          | 7/2000 [00:12<29:59,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'daigtil' to form the correct word. A: digital B: orthodox C: themselves D: determination\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 8  (25.0):   0%|          | 7/2000 [00:12<29:59,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aalts' represent when unscrambled? A: atlas B: norman C: magnetic D: const\n",
      "Answer: A: atlas\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hlpeed'? A: badge B: hotels C: helped D: tech\n",
      "Answer: D: tech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dniiclspie'. A: discipline B: better C: fault D: spain\n",
      "Answer: D: spainAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ptniaing'? A: genetic B: compressed C: properties D: painting\n",
      "Answer: D: painting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oedslt'? A: dirty B: oldest C: climate D: baking\n",
      "Answer: D: baking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'luagh'? A: keywords B: counted C: laugh D: provinces\n",
      "Answer: D: provinces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'barihan' to form the correct word. A: bahrain B: polished C: milfhunter D: interested\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vtoes'? A: votes B: download C: scotia D: rates\n",
      "Answer: A: votes\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'niiamonton'? A: feature B: filename C: nomination D: horny\n",
      "Answer: D: horny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sgavae'. A: saudi B: editorial C: savage D: dynamics\n",
      "Answer: A: saudi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'deoelpyd'. A: feet B: muscle C: deployed D: character\n",
      "Answer: D: character\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'crcoeninng' represent when unscrambled? A: supplied B: teachers C: voyeur D: concerning\n",
      "Answer: D: concerning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sihft' to form the correct word. A: continued B: streaming C: pools D: shift\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cnateirg'. A: mainly B: disputes C: hour D: catering\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'agtens'. A: prayer B: wheel C: agents D: hamburg\n",
      "Answer: D: hamburg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 8  (25.0):   0%|          | 8/2000 [00:22<29:58,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dalals' represent when unscrambled? A: dallas B: seeds C: casting D: ideas\n",
      "Answer: A: dallas\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'arnuod' to form the correct word. A: obligations B: defence C: honors D: around\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 9  (33.3):   0%|          | 8/2000 [00:23<29:58,  1.11it/s]\u001b[A\n",
      "Average Metric: 3 / 9  (33.3):   0%|          | 9/2000 [00:23<1:24:06,  2.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 3 / 10  (30.0):   0%|          | 9/2000 [00:23<1:24:06,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 3 / 10  (30.0):   0%|          | 10/2000 [00:23<1:09:12,  2.09s/it]\u001b[A\n",
      "Average Metric: 3 / 11  (27.3):   0%|          | 10/2000 [00:23<1:09:12,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sawn' represent when unscrambled? A: swan B: refurbished C: shoes D: prompt\n",
      "Answer: A: swan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 12  (25.0):   1%|          | 11/2000 [00:23<1:09:10,  2.09s/it]\u001b[A\n",
      "Average Metric: 3 / 12  (25.0):   1%|          | 12/2000 [00:23<44:57,  1.36s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 13  (30.8):   1%|          | 12/2000 [00:23<44:57,  1.36s/it]\u001b[A\n",
      "Average Metric: 4 / 13  (30.8):   1%|          | 13/2000 [00:23<36:19,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 14  (28.6):   1%|          | 13/2000 [00:23<36:19,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 15  (26.7):   1%|          | 14/2000 [00:24<36:18,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 15  (26.7):   1%|          | 15/2000 [00:24<23:31,  1.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snivag'. A: humor B: intimate C: saving D: belts\n",
      "Answer: D: belts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4 / 16  (25.0):   1%|          | 15/2000 [00:24<23:31,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 5 / 17  (29.4):   1%|          | 16/2000 [00:24<23:31,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 18  (33.3):   1%|          | 17/2000 [00:24<23:30,  1.41it/s]\u001b[A\n",
      "Average Metric: 6 / 18  (33.3):   1%|          | 18/2000 [00:24<13:34,  2.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 6 / 19  (31.6):   1%|          | 18/2000 [00:24<13:34,  2.43it/s]\u001b[A\n",
      "Average Metric: 7 / 20  (35.0):   1%|          | 19/2000 [00:24<13:34,  2.43it/s]\u001b[A\n",
      "Average Metric: 7 / 20  (35.0):   1%|          | 20/2000 [00:24<10:02,  3.29it/s]\u001b[A\n",
      "Average Metric: 7 / 21  (33.3):   1%|          | 20/2000 [00:24<10:02,  3.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 22  (36.4):   1%|          | 21/2000 [00:24<10:02,  3.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 23  (39.1):   1%|          | 22/2000 [00:24<10:01,  3.29it/s]\u001b[A\n",
      "Average Metric: 9 / 23  (39.1):   1%|          | 23/2000 [00:24<06:44,  4.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pisrah' represent when unscrambled? A: warcraft B: alphabetical C: parish D: lately\n",
      "Answer: D: lately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'shecems'. A: begun B: posters C: schemes D: motorola\n",
      "Answer: D: motorola\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'nnoe' represent when unscrambled? A: conclusion B: none C: jane D: globalization\n",
      "Answer: B: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sinetag'? A: paperback B: cylinder C: seating D: leadership\n",
      "Answer: B: cylinder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 24  (37.5):   1%|          | 23/2000 [00:29<06:44,  4.89it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 25  (36.0):   1%|          | 24/2000 [00:29<06:44,  4.89it/s]\u001b[A\n",
      "Average Metric: 9 / 25  (36.0):   1%|         | 25/2000 [00:29<29:38,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 10 / 26  (38.5):   1%|         | 25/2000 [00:30<29:38,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 27  (40.7):   1%|         | 26/2000 [00:30<29:37,  1.11it/s]\u001b[A\n",
      "Average Metric: 11 / 27  (40.7):   1%|         | 27/2000 [00:30<21:55,  1.50it/s]\u001b[A\n",
      "Average Metric: 11 / 28  (39.3):   1%|         | 27/2000 [00:30<21:55,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 11 / 29  (37.9):   1%|         | 28/2000 [00:30<21:55,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 11 / 29  (37.9):   1%|         | 29/2000 [00:30<16:55,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 12 / 30  (40.0):   1%|         | 29/2000 [00:30<16:55,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mclaaticpre' to form the correct word. A: table B: malpractice C: oscar D: grounds\n",
      "Answer: C: oscar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'xobx' to form the correct word. A: xbox B: vegetation C: families D: dependence\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sttnaig' represent when unscrambled? A: stating B: trace C: benz D: traffic\n",
      "Answer: A: stating\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'polos' to form the correct word. A: subdivision B: minimum C: subscriber D: pools\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mcexio' to form the correct word. A: hood B: consideration C: mexico D: name\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cshet' represent when unscrambled? A: dressing B: faces C: protecting D: chest\n",
      "Answer: D: chest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 31  (41.9):   2%|         | 30/2000 [00:35<16:54,  1.94it/s]\u001b[A\n",
      "Average Metric: 13 / 31  (41.9):   2%|         | 31/2000 [00:35<35:37,  1.09s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 32  (40.6):   2%|         | 31/2000 [00:35<35:37,  1.09s/it]\u001b[A\n",
      "Average Metric: 13 / 32  (40.6):   2%|         | 32/2000 [00:35<30:26,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 33  (42.4):   2%|         | 32/2000 [00:35<30:26,  1.08it/s]\u001b[A\n",
      "Average Metric: 14 / 33  (42.4):   2%|         | 33/2000 [00:35<26:03,  1.26it/s]\u001b[A\n",
      "Average Metric: 14 / 34  (41.2):   2%|         | 33/2000 [00:35<26:03,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 14 / 35  (40.0):   2%|         | 34/2000 [00:35<26:02,  1.26it/s]\u001b[A\n",
      "Average Metric: 14 / 35  (40.0):   2%|         | 35/2000 [00:35<17:48,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 36  (38.9):   2%|         | 35/2000 [00:36<17:48,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 36  (38.9):   2%|         | 36/2000 [00:36<15:08,  2.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 37  (37.8):   2%|         | 36/2000 [00:36<15:08,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 38  (36.8):   2%|         | 37/2000 [00:36<15:07,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 39  (35.9):   2%|         | 38/2000 [00:36<15:07,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 40  (35.0):   2%|         | 39/2000 [00:36<15:06,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 40  (35.0):   2%|         | 40/2000 [00:36<07:24,  4.41it/s]\u001b[A\n",
      "Average Metric: 14 / 41  (34.1):   2%|         | 40/2000 [00:36<07:24,  4.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 42  (35.7):   2%|         | 41/2000 [00:36<07:24,  4.41it/s]\u001b[A\n",
      "Average Metric: 15 / 42  (35.7):   2%|         | 42/2000 [00:36<06:52,  4.75it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sloid'? A: adapter B: solid C: cake D: truck\n",
      "Answer: B: solid\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bapckcak'? A: corners B: satisfaction C: backpack D: certificate\n",
      "Answer: B: satisfaction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'uuinqe'. A: unique B: amounts C: offered D: observers\n",
      "Answer: A: unique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'moriblmiaea'. A: memorabilia B: proof C: eyes D: spouse\n",
      "Answer: A: memorabilia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gitnas' represent when unscrambled? A: faculty B: changes C: giants D: hardware\n",
      "Answer: D: hardware\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'book'. A: commonly B: pharmacies C: explicit D: book\n",
      "Answer: D: book\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gsals' to form the correct word. A: capacity B: ecology C: somebody D: glass\n",
      "Answer: C: somebody\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hservat'. A: harvest B: necessity C: resource D: visit\n",
      "Answer: D: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 43  (34.9):   2%|         | 42/2000 [00:41<06:52,  4.75it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 16 / 44  (36.4):   2%|         | 43/2000 [00:41<06:51,  4.75it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 16 / 44  (36.4):   2%|         | 44/2000 [00:41<27:08,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 16 / 45  (35.6):   2%|         | 44/2000 [00:41<27:08,  1.20it/s]\u001b[A\n",
      "Average Metric: 16 / 45  (35.6):   2%|         | 45/2000 [00:41<25:14,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 16 / 46  (34.8):   2%|         | 45/2000 [00:41<25:14,  1.29it/s]\u001b[A\n",
      "Average Metric: 16 / 47  (34.0):   2%|         | 46/2000 [00:41<25:14,  1.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ptasa'. A: distributors B: purposes C: vitamin D: pasta\n",
      "Answer: A: distributors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'setpirs'. A: electron B: stripes C: patrol D: economies\n",
      "Answer: A\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'relox' to form the correct word. A: reduce B: rolex C: graphics D: selection\n",
      "Answer: B: rolex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mnitue'. A: minute B: shepherd C: gaming D: balance\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'itrrnctuodoy' represent when unscrambled? A: duff B: readers C: introductory D: twain\n",
      "Answer: D: twain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'drietot'. A: detroit B: glad C: teenage D: webster\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bkroe'. A: yemen B: introductory C: robust D: broke\n",
      "Answer: D: broke\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aanl' represent when unscrambled? A: hope B: waterfront C: calvin D: anal\n",
      "Answer: A: hope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 17 / 48  (35.4):   2%|         | 47/2000 [00:47<25:13,  1.29it/s]\u001b[A\n",
      "Average Metric: 17 / 48  (35.4):   2%|         | 48/2000 [00:47<38:37,  1.19s/it]\u001b[A\n",
      "Average Metric: 18 / 49  (36.7):   2%|         | 48/2000 [00:47<38:37,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 18 / 49  (36.7):   2%|         | 49/2000 [00:47<33:30,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 18 / 50  (36.0):   2%|         | 49/2000 [00:47<33:30,  1.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'maartil'. A: disable B: martial C: pentium D: diary\n",
      "Answer: D: diary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 51  (37.3):   2%|         | 50/2000 [00:47<33:29,  1.03s/it]\u001b[A\n",
      "Average Metric: 19 / 51  (37.3):   3%|         | 51/2000 [00:47<23:59,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 52  (36.5):   3%|         | 51/2000 [00:47<23:59,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 19 / 52  (36.5):   3%|         | 52/2000 [00:47<20:32,  1.58it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 19 / 53  (35.8):   3%|         | 52/2000 [00:47<20:32,  1.58it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 20 / 54  (37.0):   3%|         | 53/2000 [00:47<20:31,  1.58it/s]\u001b[A\n",
      "Average Metric: 20 / 54  (37.0):   3%|         | 54/2000 [00:47<13:58,  2.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 55  (36.4):   3%|         | 54/2000 [00:47<13:58,  2.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 20 / 56  (35.7):   3%|         | 55/2000 [00:47<13:58,  2.32it/s]\u001b[A\n",
      "Average Metric: 20 / 56  (35.7):   3%|         | 56/2000 [00:47<09:52,  3.28it/s]\u001b[A\n",
      "Average Metric: 21 / 57  (36.8):   3%|         | 56/2000 [00:48<09:52,  3.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'beoecms' represent when unscrambled? A: telescope B: hourly C: becomes D: anaheim\n",
      "Answer: D: anaheim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sbatilatlsuny' to form the correct word. A: lamp B: substantially C: genetics D: sewer\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mseseags'? A: messages B: kinase C: life D: arrive\n",
      "Answer: messages\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cohir'. A: aware B: cordless C: choir D: idiot\n",
      "Answer: D: idiot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 22 / 58  (37.9):   3%|         | 57/2000 [00:52<09:51,  3.28it/s]\u001b[A\n",
      "Average Metric: 22 / 58  (37.9):   3%|         | 58/2000 [00:52<32:18,  1.00it/s]\u001b[A\n",
      "Average Metric: 23 / 59  (39.0):   3%|         | 58/2000 [00:52<32:18,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 24 / 60  (40.0):   3%|         | 59/2000 [00:52<32:17,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'decifenfre' represent when unscrambled? A: difference B: portuguese C: immediately D: greens\n",
      "Answer: D: greens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 61  (39.3):   3%|         | 60/2000 [00:53<32:16,  1.00it/s]\u001b[A\n",
      "Average Metric: 24 / 61  (39.3):   3%|         | 61/2000 [00:53<20:05,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 62  (38.7):   3%|         | 61/2000 [00:53<20:05,  1.61it/s]\u001b[A\n",
      "Average Metric: 24 / 63  (38.1):   3%|         | 62/2000 [00:53<20:05,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 24 / 63  (38.1):   3%|         | 63/2000 [00:53<16:07,  2.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 64  (37.5):   3%|         | 63/2000 [00:53<16:07,  2.00it/s]\u001b[A\n",
      "Average Metric: 24 / 64  (37.5):   3%|         | 64/2000 [00:53<14:36,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 25 / 65  (38.5):   3%|         | 64/2000 [00:53<14:36,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 25 / 65  (38.5):   3%|         | 65/2000 [00:53<13:12,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fukny' represent when unscrambled? A: richmond B: funky C: phillip D: cunt\n",
      "Answer: B: funky\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'suols' to form the correct word. A: souls B: shield C: type D: partnerships\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cotnercs' represent when unscrambled? A: concerts B: coding C: supervision D: mill\n",
      "Answer: A: concerts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 66  (39.4):   3%|         | 65/2000 [00:58<13:12,  2.44it/s]\u001b[A\n",
      "Average Metric: 26 / 66  (39.4):   3%|         | 66/2000 [00:58<39:11,  1.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iaintil'. A: fraction B: initial C: bonuses D: thomas\n",
      "Answer: A: fraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ganit'? A: retrieved B: malawi C: charming D: giant\n",
      "Answer: D: giant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 27 / 67  (40.3):   3%|         | 66/2000 [00:58<39:11,  1.22s/it]\u001b[A\n",
      "Average Metric: 27 / 67  (40.3):   3%|         | 67/2000 [00:58<34:03,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 68  (39.7):   3%|         | 67/2000 [00:59<34:03,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 27 / 68  (39.7):   3%|         | 68/2000 [00:59<29:31,  1.09it/s]\u001b[A\n",
      "Average Metric: 27 / 69  (39.1):   3%|         | 68/2000 [00:59<29:31,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bfualfo' to form the correct word. A: implied B: holland C: buffalo D: disability\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mnra'. A: guilty B: gardens C: talked D: mrna\n",
      "Answer: D: mrna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 28 / 70  (40.0):   3%|         | 69/2000 [00:59<29:30,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 71  (39.4):   4%|         | 70/2000 [00:59<29:29,  1.09it/s]\u001b[A\n",
      "Average Metric: 28 / 71  (39.4):   4%|         | 71/2000 [00:59<15:27,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 72  (38.9):   4%|         | 71/2000 [00:59<15:27,  2.08it/s]\u001b[A\n",
      "Average Metric: 28 / 72  (38.9):   4%|         | 72/2000 [00:59<14:01,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 73  (38.4):   4%|         | 72/2000 [00:59<14:01,  2.29it/s]\u001b[A\n",
      "Average Metric: 28 / 73  (38.4):   4%|         | 73/2000 [00:59<12:15,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hmoe'? A: home B: menus C: xerox D: mysterious\n",
      "Answer: A: home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iejknt'. A: inkjet B: montana C: patience D: highlands\n",
      "Answer: A: inkjet\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wehietgd' represent when unscrambled? A: combines B: bestsellers C: weighted D: thermal\n",
      "Answer: B: bestsellers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sisfieatd'. A: satisfied B: offers C: costume D: polyester\n",
      "Answer: A: satisfied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dsheis' to form the correct word. A: deaf B: camcorders C: dishes D: miller\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'airuqce'? A: challenge B: corruption C: heroes D: acquire\n",
      "Answer: D: acquire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 74  (37.8):   4%|         | 73/2000 [01:04<12:15,  2.62it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 74  (37.8):   4%|         | 74/2000 [01:04<42:52,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'drwaer'? A: scholarships B: cleaning C: wrap D: drawer\n",
      "Answer: D: drawer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 28 / 75  (37.3):   4%|         | 74/2000 [01:04<42:52,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 76  (38.2):   4%|         | 75/2000 [01:04<42:51,  1.34s/it]\u001b[A\n",
      "Average Metric: 29 / 76  (38.2):   4%|         | 76/2000 [01:04<26:18,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 29 / 77  (37.7):   4%|         | 76/2000 [01:04<26:18,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 78  (38.5):   4%|         | 77/2000 [01:04<26:17,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 78  (38.5):   4%|         | 78/2000 [01:04<19:29,  1.64it/s]\u001b[A\n",
      "Average Metric: 30 / 79  (38.0):   4%|         | 78/2000 [01:04<19:29,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fsluh'. A: unto B: intuitive C: chairman D: flush\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aorrw'? A: sampling B: arrow C: courage D: send\n",
      "Answer: D: send\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'firseiehs'. A: wholly B: fabric C: weblog D: fisheries\n",
      "Answer: D: fisheries\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ctaehprs' to form the correct word. A: athens B: constitutes C: victim D: chapters\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dmtoticonuaen' represent when unscrambled? A: documentation B: ruby C: generally D: marvel\n",
      "Answer: D: marvel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'deer' represent when unscrambled? A: deer B: additional C: manages D: sweden\n",
      "Answer: A: deer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gdciuane'? A: magnet B: guidance C: conversation D: kazakhstan\n",
      "Answer: B: guidance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'iepnxnvesie' represent when unscrambled? A: halo B: logical C: punk D: inexpensive\n",
      "Answer: A: halo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'studcnaork' to form the correct word. A: restrictions B: solutions C: diana D: soundtrack\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'piferx' to form the correct word. A: prefix B: capacity C: symbolic D: leaving\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 80  (37.5):   4%|         | 79/2000 [01:10<19:29,  1.64it/s]\u001b[A\n",
      "Average Metric: 30 / 80  (37.5):   4%|         | 80/2000 [01:10<43:08,  1.35s/it]\u001b[A\n",
      "Average Metric: 30 / 81  (37.0):   4%|         | 80/2000 [01:10<43:08,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 31 / 82  (37.8):   4%|         | 81/2000 [01:10<43:06,  1.35s/it]\u001b[A\n",
      "Average Metric: 31 / 83  (37.3):   4%|         | 82/2000 [01:10<43:05,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 31 / 83  (37.3):   4%|         | 83/2000 [01:10<25:27,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 84  (36.9):   4%|         | 83/2000 [01:10<25:27,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 85  (36.5):   4%|         | 84/2000 [01:10<25:26,  1.26it/s]\u001b[A\n",
      "Average Metric: 31 / 85  (36.5):   4%|         | 85/2000 [01:10<18:47,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 31 / 86  (36.0):   4%|         | 85/2000 [01:10<18:47,  1.70it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 87  (35.6):   4%|         | 86/2000 [01:10<18:47,  1.70it/s]\u001b[A\n",
      "Average Metric: 31 / 87  (35.6):   4%|         | 87/2000 [01:10<14:10,  2.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 32 / 88  (36.4):   4%|         | 87/2000 [01:10<14:10,  2.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 33 / 89  (37.1):   4%|         | 88/2000 [01:10<14:09,  2.25it/s]\u001b[A\n",
      "Average Metric: 33 / 89  (37.1):   4%|         | 89/2000 [01:10<10:56,  2.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 34 / 90  (37.8):   4%|         | 89/2000 [01:11<10:56,  2.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 35 / 91  (38.5):   4%|         | 90/2000 [01:11<10:56,  2.91it/s]\u001b[A\n",
      "Average Metric: 35 / 91  (38.5):   5%|         | 91/2000 [01:11<08:19,  3.82it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 36 / 92  (39.1):   5%|         | 91/2000 [01:11<08:19,  3.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 36 / 93  (38.7):   5%|         | 92/2000 [01:11<08:18,  3.82it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 36 / 94  (38.3):   5%|         | 93/2000 [01:11<08:18,  3.82it/s]\u001b[A\n",
      "Average Metric: 36 / 94  (38.3):   5%|         | 94/2000 [01:11<05:49,  5.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bkacing' to form the correct word. A: receipts B: studied C: chords D: backing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'esnure'. A: seals B: ensure C: indexes D: undefined\n",
      "Answer: B: ensure\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'puapa' represent when unscrambled? A: overhead B: instruction C: diaries D: papua\n",
      "Answer: D: papua\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'paatwyhs' to form the correct word. A: boot B: brutal C: verified D: pathways\n",
      "Answer: D: pathways\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hriybd' to form the correct word. A: hybrid B: pioneer C: same D: updating\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 95  (38.9):   5%|         | 94/2000 [01:15<05:49,  5.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hrrhiacey'. A: therefore B: hierarchy C: deep D: construction\n",
      "Answer: D: construction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 37 / 96  (38.5):   5%|         | 95/2000 [01:15<05:48,  5.46it/s]\u001b[A\n",
      "Average Metric: 37 / 96  (38.5):   5%|         | 96/2000 [01:15<24:09,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 97  (38.1):   5%|         | 96/2000 [01:16<24:09,  1.31it/s]\u001b[A\n",
      "Average Metric: 37 / 97  (38.1):   5%|         | 97/2000 [01:16<22:03,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 37 / 98  (37.8):   5%|         | 97/2000 [01:16<22:03,  1.44it/s]\u001b[A\n",
      "Average Metric: 38 / 99  (38.4):   5%|         | 98/2000 [01:16<22:02,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 38 / 99  (38.4):   5%|         | 99/2000 [01:16<15:56,  1.99it/s]\u001b[A\n",
      "Average Metric: 38 / 100  (38.0):   5%|         | 99/2000 [01:16<15:56,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'atnitmsdiriave'. A: equipped B: washer C: administrative D: subcommittee\n",
      "Answer: D: subcommittee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hroowdad'. A: calibration B: nano C: redhat D: hardwood\n",
      "Answer: D: hardwood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ungdaa' represent when unscrambled? A: begun B: uganda C: allergy D: demographics\n",
      "Answer: A: begun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 101  (38.6):   5%|         | 100/2000 [01:21<15:56,  1.99it/s]\u001b[A\n",
      "Average Metric: 39 / 101  (38.6):   5%|         | 101/2000 [01:21<35:23,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnmpeectoe'? A: expanded B: clicking C: quotations D: competence\n",
      "Answer: D: competence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 102  (38.2):   5%|         | 101/2000 [01:21<35:23,  1.12s/it]\u001b[A\n",
      "Average Metric: 39 / 102  (38.2):   5%|         | 102/2000 [01:21<31:13,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 103  (37.9):   5%|         | 102/2000 [01:21<31:13,  1.01it/s]\u001b[A\n",
      "Average Metric: 39 / 103  (37.9):   5%|         | 103/2000 [01:22<25:51,  1.22it/s]\u001b[A\n",
      "Average Metric: 40 / 104  (38.5):   5%|         | 103/2000 [01:22<25:51,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 105  (39.0):   5%|         | 104/2000 [01:22<25:50,  1.22it/s]\u001b[A\n",
      "Average Metric: 41 / 105  (39.0):   5%|         | 105/2000 [01:22<17:08,  1.84it/s]\u001b[A\n",
      "Average Metric: 41 / 106  (38.7):   5%|         | 105/2000 [01:22<17:08,  1.84it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 107  (38.3):   5%|         | 106/2000 [01:22<17:08,  1.84it/s]\u001b[A\n",
      "Average Metric: 41 / 107  (38.3):   5%|         | 107/2000 [01:22<11:48,  2.67it/s]\u001b[A\n",
      "Average Metric: 42 / 108  (38.9):   5%|         | 107/2000 [01:22<11:48,  2.67it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 109  (38.5):   5%|         | 108/2000 [01:22<11:47,  2.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 110  (38.2):   5%|         | 109/2000 [01:22<11:47,  2.67it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 110  (38.2):   6%|         | 110/2000 [01:22<08:00,  3.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 43 / 111  (38.7):   6%|         | 110/2000 [01:22<08:00,  3.93it/s]\u001b[A\n",
      "Average Metric: 43 / 112  (38.4):   6%|         | 111/2000 [01:22<08:00,  3.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'almnias' represent when unscrambled? A: devoted B: animals C: trades D: audio\n",
      "Answer: A: devoted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 112  (38.4):   6%|         | 112/2000 [01:22<06:12,  5.07it/s]\u001b[A\n",
      "Average Metric: 43 / 113  (38.1):   6%|         | 112/2000 [01:22<06:12,  5.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ecxittaopens' to form the correct word. A: expectations B: funny C: terminal D: flag\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pnntoiig' represent when unscrambled? A: pointing B: chromosome C: gaps D: publication\n",
      "Answer: D: publication\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bpasys'. A: further B: moore C: bypass D: citations\n",
      "Answer: D: citations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lgoo' represent when unscrambled? A: dayton B: logo C: rolled D: mainstream\n",
      "Answer: B: logo\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sviecres'. A: services B: custody C: fails D: offence\n",
      "Answer: A: services\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 114  (38.6):   6%|         | 113/2000 [01:27<06:12,  5.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'siaroencs'. A: moral B: imperial C: scenarios D: organ\n",
      "Answer: D: organ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 114  (38.6):   6%|         | 114/2000 [01:27<24:44,  1.27it/s]\u001b[A\n",
      "Average Metric: 44 / 115  (38.3):   6%|         | 114/2000 [01:27<24:44,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 44 / 115  (38.3):   6%|         | 115/2000 [01:27<22:40,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 116  (37.9):   6%|         | 115/2000 [01:27<22:40,  1.39it/s]\u001b[A\n",
      "Average Metric: 44 / 116  (37.9):   6%|         | 116/2000 [01:27<19:49,  1.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 117  (37.6):   6%|         | 116/2000 [01:27<19:49,  1.58it/s]\u001b[A\n",
      "Average Metric: 44 / 117  (37.6):   6%|         | 117/2000 [01:27<16:35,  1.89it/s]\u001b[A\n",
      "Average Metric: 44 / 118  (37.3):   6%|         | 117/2000 [01:28<16:35,  1.89it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 44 / 118  (37.3):   6%|         | 118/2000 [01:28<13:40,  2.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 45 / 119  (37.8):   6%|         | 118/2000 [01:28<13:40,  2.29it/s]\u001b[A\n",
      "Average Metric: 45 / 119  (37.8):   6%|         | 119/2000 [01:28<12:05,  2.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'akile'? A: campus B: alike C: pushed D: advertiser\n",
      "Answer: B: alikeAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sldade'. A: generic B: headed C: consequences D: saddle\n",
      "Answer: D: saddle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scomtah'? A: stomach B: lace C: reflecting D: related\n",
      "Answer: A: stomach\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'qautiiles'. A: auditorium B: qualities C: witnesses D: need\n",
      "Answer: D: need\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aearldy'. A: already B: injury C: communications D: rebuild\n",
      "Answer: A: already\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 46 / 120  (38.3):   6%|         | 119/2000 [01:32<12:05,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'paer'. A: viable B: queens C: allows D: pear\n",
      "Answer: D: pear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46 / 120  (38.3):   6%|         | 120/2000 [01:32<45:57,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ygoa' represent when unscrambled? A: reserved B: yoga C: popular D: oecd\n",
      "Answer: B: yoga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'reeslaed' to form the correct word. A: drop B: savannah C: released D: hours\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47 / 121  (38.8):   6%|         | 120/2000 [01:33<45:57,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 47 / 121  (38.8):   6%|         | 121/2000 [01:33<40:31,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 122  (38.5):   6%|         | 121/2000 [01:34<40:31,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 122  (38.5):   6%|         | 122/2000 [01:34<32:52,  1.05s/it]\u001b[A\n",
      "Average Metric: 47 / 123  (38.2):   6%|         | 122/2000 [01:34<32:52,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 47 / 124  (37.9):   6%|         | 123/2000 [01:34<32:51,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 47 / 124  (37.9):   6%|         | 124/2000 [01:34<18:59,  1.65it/s]\u001b[A\n",
      "Average Metric: 48 / 125  (38.4):   6%|         | 124/2000 [01:34<18:59,  1.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 48 / 126  (38.1):   6%|         | 125/2000 [01:34<18:59,  1.65it/s]\u001b[A\n",
      "Average Metric: 48 / 126  (38.1):   6%|         | 126/2000 [01:34<12:29,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'taitoaxn'. A: gazette B: subcommittee C: taxation D: tickets\n",
      "Answer: A: gazette\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'qutaunm'. A: powered B: headers C: quantum D: prescription\n",
      "Answer: D: prescription\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'drmaa' represent when unscrambled? A: gates B: beth C: drama D: overview\n",
      "Answer: D: overview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'piars' represent when unscrambled? A: receivers B: meditation C: pairs D: friday\n",
      "Answer: A: receivers\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ceahpl' to form the correct word. A: arnold B: feedback C: chapel D: strategies\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'snuod' to form the correct word. A: jewel B: sound C: receiving D: impacts\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'oebtsiy' to form the correct word. A: members B: smart C: scared D: obesity\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aianlba'. A: albania B: recognizes C: viable D: reimbursement\n",
      "Answer: A: albania\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ternds' to form the correct word. A: circulation B: baker C: virtual D: trends\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 49 / 127  (38.6):   6%|         | 126/2000 [01:38<12:29,  2.50it/s]\u001b[A\n",
      "Average Metric: 49 / 127  (38.6):   6%|         | 127/2000 [01:38<39:53,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 128  (38.3):   6%|         | 127/2000 [01:38<39:53,  1.28s/it]\u001b[A\n",
      "Average Metric: 49 / 128  (38.3):   6%|         | 128/2000 [01:38<31:41,  1.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hahciti' represent when unscrambled? A: hitachi B: analysis C: permits D: satisfactory\n",
      "Answer: A: hitachi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 129  (38.0):   6%|         | 128/2000 [01:39<31:41,  1.02s/it]\u001b[A\n",
      "Average Metric: 49 / 129  (38.0):   6%|         | 129/2000 [01:39<25:14,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 130  (38.5):   6%|         | 129/2000 [01:39<25:14,  1.24it/s]\u001b[A\n",
      "Average Metric: 50 / 130  (38.5):   6%|         | 130/2000 [01:39<21:26,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 131  (38.2):   6%|         | 130/2000 [01:39<21:26,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'saprk'. A: sewer B: soviet C: grant D: spark\n",
      "Answer: D: spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 132  (38.6):   7%|         | 131/2000 [01:39<21:25,  1.45it/s]\u001b[A\n",
      "Average Metric: 51 / 132  (38.6):   7%|         | 132/2000 [01:39<13:52,  2.24it/s]\u001b[A\n",
      "Average Metric: 51 / 133  (38.3):   7%|         | 132/2000 [01:39<13:52,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 51 / 133  (38.3):   7%|         | 133/2000 [01:39<11:21,  2.74it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 52 / 134  (38.8):   7%|         | 133/2000 [01:39<11:21,  2.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cpocnet' to form the correct word. A: lexmark B: work C: concept D: weekly\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cmap'. A: camp B: belgium C: shades D: improve\n",
      "Answer: D"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'coaclenhlr'? A: sectors B: opponent C: chancellor D: images\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 53 / 135  (39.3):   7%|         | 134/2000 [01:44<11:20,  2.74it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 53 / 135  (39.3):   7%|         | 135/2000 [01:44<37:10,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'nnrusig'. A: nursing B: involved C: gems D: intuitive\n",
      "Answer: D: intuitive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 136  (39.7):   7%|         | 135/2000 [01:45<37:10,  1.20s/it]\u001b[A\n",
      "Average Metric: 54 / 136  (39.7):   7%|         | 136/2000 [01:45<33:42,  1.08s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 137  (39.4):   7%|         | 136/2000 [01:45<33:42,  1.08s/it]\u001b[A\n",
      "Average Metric: 54 / 137  (39.4):   7%|         | 137/2000 [01:45<27:25,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 138  (39.9):   7%|         | 137/2000 [01:45<27:25,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eiuaelvqnt' represent when unscrambled? A: weapon B: equivalent C: acting D: ready\n",
      "Answer: D: ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'muarry' represent when unscrambled? A: reported B: murray C: written D: noaa\n",
      "Answer: B: murray\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'utnetonlfruay'. A: lyrics B: matters C: tires D: unfortunately\n",
      "Answer: D: unfortunately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gtmleuaaa' to form the correct word. A: guatemala B: roster C: tracks D: iran\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pploee'. A: sympathy B: people C: pearl D: paul\n",
      "Answer: A: sympathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rurseatnats' to form the correct word. A: restaurants B: commodity C: left D: accessible\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'btroan'. A: roots B: often C: chords D: barton\n",
      "Answer: D: barton\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fbire' to form the correct word. A: academy B: liberals C: britney D: fibre\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 139  (39.6):   7%|         | 138/2000 [01:50<27:24,  1.13it/s]\u001b[A\n",
      "Average Metric: 55 / 139  (39.6):   7%|         | 139/2000 [01:50<45:00,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 140  (39.3):   7%|         | 139/2000 [01:50<45:00,  1.45s/it]\u001b[A\n",
      "Average Metric: 55 / 140  (39.3):   7%|         | 140/2000 [01:50<35:48,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tduhner'. A: scholar B: thunder C: respiratory D: davidson\n",
      "Answer: D: davidson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 141  (39.7):   7%|         | 140/2000 [01:50<35:48,  1.16s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 141  (39.7):   7%|         | 141/2000 [01:50<31:37,  1.02s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 142  (39.4):   7%|         | 141/2000 [01:50<31:37,  1.02s/it]\u001b[A\n",
      "Average Metric: 57 / 143  (39.9):   7%|         | 142/2000 [01:50<31:36,  1.02s/it]\u001b[A\n",
      "Average Metric: 57 / 144  (39.6):   7%|         | 143/2000 [01:51<31:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 57 / 144  (39.6):   7%|         | 144/2000 [01:51<16:11,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 145  (39.3):   7%|         | 144/2000 [01:51<16:11,  1.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 146  (39.0):   7%|         | 145/2000 [01:51<16:10,  1.91it/s]\u001b[A\n",
      "Average Metric: 57 / 146  (39.0):   7%|         | 146/2000 [01:51<12:01,  2.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 147  (38.8):   7%|         | 146/2000 [01:51<12:01,  2.57it/s]\u001b[A\n",
      "Average Metric: 57 / 147  (38.8):   7%|         | 147/2000 [01:51<10:44,  2.87it/s]\u001b[A\n",
      "Average Metric: 57 / 148  (38.5):   7%|         | 147/2000 [01:51<10:44,  2.87it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 58 / 149  (38.9):   7%|         | 148/2000 [01:51<10:44,  2.87it/s]\u001b[A\n",
      "Average Metric: 59 / 150  (39.3):   7%|         | 149/2000 [01:51<10:43,  2.87it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 59 / 150  (39.3):   8%|         | 150/2000 [01:51<06:30,  4.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sitsttcias'. A: scat B: statistics C: loads D: franc\n",
      "Answer: D"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'polit' represent when unscrambled? A: imperial B: brush C: pilot D: verification\n",
      "Answer: A: imperial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 151  (39.1):   8%|         | 150/2000 [01:55<06:30,  4.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'twarod'? A: toward B: consumers C: past D: lexington\n",
      "Answer: D: lexington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 59 / 152  (38.8):   8%|         | 151/2000 [01:57<06:29,  4.74it/s]\u001b[A\n",
      "Average Metric: 59 / 152  (38.8):   8%|         | 152/2000 [01:57<29:44,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 153  (38.6):   8%|         | 152/2000 [01:57<29:44,  1.04it/s]\u001b[A\n",
      "Average Metric: 59 / 153  (38.6):   8%|         | 153/2000 [01:57<25:59,  1.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'voectily' represent when unscrambled? A: appearances B: experiences C: nominations D: velocity\n",
      "Answer: D: velocity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 154  (39.0):   8%|         | 153/2000 [01:57<25:59,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 60 / 154  (39.0):   8%|         | 154/2000 [01:57<22:40,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 60 / 155  (38.7):   8%|         | 154/2000 [01:57<22:40,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 156  (38.5):   8%|         | 155/2000 [01:57<22:39,  1.36it/s]\u001b[A\n",
      "Average Metric: 60 / 156  (38.5):   8%|         | 156/2000 [01:57<15:32,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dlaysips' to form the correct word. A: imprint B: sensing C: displays D: contributor\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'actusoiiqin' represent when unscrambled? A: operative B: ignored C: insider D: acquisition\n",
      "Answer: A: operative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'riruiqeng'. A: requiring B: ecological C: switches D: cash\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rlciecyng'? A: recycling B: elderly C: mentor D: directv\n",
      "Answer: D: directv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bokcls' represent when unscrambled? A: valued B: blocks C: quantum D: removing\n",
      "Answer: B: blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dbiet'. A: identify B: debit C: reduce D: spirit\n",
      "Answer: D: spirit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'klley'. A: length B: kelly C: incest D: finish\n",
      "Answer: A: length\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tereurass' to form the correct word. A: shoppers B: unauthorized C: treasures D: recognised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'seanncr' to form the correct word. A: advertising B: scanner C: reconstruction D: chef\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'baen'. A: come B: converted C: bean D: patents\n",
      "Answer: A: come\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 157  (38.2):   8%|         | 156/2000 [02:01<15:32,  1.98it/s]\u001b[A\n",
      "Average Metric: 60 / 157  (38.2):   8%|         | 157/2000 [02:01<38:04,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'feorsts'? A: forests B: problem C: vast D: contests\n",
      "Answer: forests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 158  (38.6):   8%|         | 157/2000 [02:02<38:04,  1.24s/it]\u001b[A\n",
      "Average Metric: 61 / 158  (38.6):   8%|         | 158/2000 [02:02<31:42,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 159  (38.4):   8%|         | 158/2000 [02:02<31:42,  1.03s/it]\u001b[A\n",
      "Average Metric: 61 / 159  (38.4):   8%|         | 159/2000 [02:02<26:02,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dtrcomieac' represent when unscrambled? A: democratic B: biographies C: participants D: wonderful\n",
      "Answer: D: wonderful\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oeatpvire'. A: suzuki B: sided C: addresses D: operative\n",
      "Answer: D: operative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 160  (38.1):   8%|         | 159/2000 [02:02<26:02,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 61 / 160  (38.1):   8%|         | 160/2000 [02:02<21:27,  1.43it/s]\u001b[A\n",
      "Average Metric: 62 / 161  (38.5):   8%|         | 160/2000 [02:02<21:27,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 162  (38.9):   8%|         | 161/2000 [02:03<21:26,  1.43it/s]\u001b[A\n",
      "Average Metric: 63 / 162  (38.9):   8%|         | 162/2000 [02:03<15:14,  2.01it/s]\u001b[A\n",
      "Average Metric: 63 / 163  (38.7):   8%|         | 162/2000 [02:03<15:14,  2.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 164  (38.4):   8%|         | 163/2000 [02:03<15:13,  2.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 164  (38.4):   8%|         | 164/2000 [02:03<10:21,  2.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 165  (38.2):   8%|         | 164/2000 [02:03<10:21,  2.96it/s]\u001b[A\n",
      "Average Metric: 63 / 165  (38.2):   8%|         | 165/2000 [02:03<08:56,  3.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'giaturs'? A: guitars B: turn C: tiles D: band\n",
      "Answer: B: turn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 63 / 166  (38.0):   8%|         | 165/2000 [02:07<08:56,  3.42it/s]\u001b[A\n",
      "Average Metric: 63 / 166  (38.0):   8%|         | 166/2000 [02:07<35:32,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'laon'. A: taste B: loan C: carbon D: eleven\n",
      "Answer: D: eleven\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'saevd'. A: tank B: interviews C: saved D: benin\n",
      "Answer: D: benin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 64 / 167  (38.3):   8%|         | 166/2000 [02:08<35:32,  1.16s/it]\u001b[A\n",
      "Average Metric: 64 / 167  (38.3):   8%|         | 167/2000 [02:08<36:29,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 65 / 168  (38.7):   8%|         | 167/2000 [02:08<36:29,  1.19s/it]\u001b[A\n",
      "Average Metric: 65 / 168  (38.7):   8%|         | 168/2000 [02:08<28:10,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 169  (38.5):   8%|         | 168/2000 [02:09<28:10,  1.08it/s]\u001b[A\n",
      "Average Metric: 65 / 170  (38.2):   8%|         | 169/2000 [02:09<28:09,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 170  (38.2):   8%|         | 170/2000 [02:09<17:18,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tchquneie'? A: insure B: inches C: technique D: dogs\n",
      "Answer: technique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 66 / 171  (38.6):   8%|         | 170/2000 [02:13<17:18,  1.76it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 66 / 171  (38.6):   9%|         | 171/2000 [02:13<42:28,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iarneld'. A: ireland B: frank C: rotten D: indonesia\n",
      "Answer: ireland\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'liad'. A: injured B: fibre C: laid D: distributions\n",
      "Answer: A: injured\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'vleuad' to form the correct word. A: valued B: speaker C: subscribe D: cycling\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 67 / 172  (39.0):   9%|         | 171/2000 [02:13<42:28,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 67 / 172  (39.0):   9%|         | 172/2000 [02:13<34:03,  1.12s/it]\u001b[A\n",
      "Average Metric: 67 / 173  (38.7):   9%|         | 172/2000 [02:13<34:03,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 67 / 173  (38.7):   9%|         | 173/2000 [02:13<27:36,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 174  (38.5):   9%|         | 173/2000 [02:13<27:36,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 175  (38.3):   9%|         | 174/2000 [02:14<27:36,  1.10it/s]\u001b[A\n",
      "Average Metric: 67 / 175  (38.3):   9%|         | 175/2000 [02:14<17:41,  1.72it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 176  (38.1):   9%|         | 175/2000 [02:14<17:41,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 67 / 177  (37.9):   9%|         | 176/2000 [02:14<17:40,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'adbitnoy' to form the correct word. A: antibody B: plasma C: sections D: barber\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 68 / 178  (38.2):   9%|         | 177/2000 [02:14<17:40,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 68 / 178  (38.2):   9%|         | 178/2000 [02:14<10:46,  2.82it/s]\u001b[A\n",
      "Average Metric: 69 / 179  (38.5):   9%|         | 178/2000 [02:14<10:46,  2.82it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 70 / 180  (38.9):   9%|         | 179/2000 [02:14<10:46,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sctopiafciien'. A: fewer B: trees C: specification D: deborah\n",
      "Answer: D: deborah\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'marrkes'? A: could B: bailey C: markers D: weddings\n",
      "Answer: B: bailey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 70 / 180  (38.9):   9%|         | 180/2000 [02:14<08:14,  3.68it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 70 / 181  (38.7):   9%|         | 180/2000 [02:14<08:14,  3.68it/s]\u001b[A\n",
      "Average Metric: 70 / 181  (38.7):   9%|         | 181/2000 [02:14<07:50,  3.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 71 / 182  (39.0):   9%|         | 181/2000 [02:15<07:50,  3.86it/s]\u001b[A\n",
      "Average Metric: 71 / 182  (39.0):   9%|         | 182/2000 [02:15<07:45,  3.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'weebr'? A: enjoyable B: weber C: natalie D: radar\n",
      "Answer: B: weber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'itranent'. A: cayman B: intranet C: talk D: privacy\n",
      "Answer: B: intranet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 71 / 183  (38.8):   9%|         | 182/2000 [02:19<07:45,  3.91it/s]\u001b[A\n",
      "Average Metric: 71 / 183  (38.8):   9%|         | 183/2000 [02:19<34:26,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 72 / 184  (39.1):   9%|         | 183/2000 [02:19<34:26,  1.14s/it]\u001b[A\n",
      "Average Metric: 72 / 184  (39.1):   9%|         | 184/2000 [02:19<26:42,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 73 / 185  (39.5):   9%|         | 184/2000 [02:20<26:42,  1.13it/s]\u001b[A\n",
      "Average Metric: 73 / 185  (39.5):   9%|         | 185/2000 [02:20<25:11,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 73 / 186  (39.2):   9%|         | 185/2000 [02:20<25:11,  1.20it/s]\u001b[A\n",
      "Average Metric: 73 / 186  (39.2):   9%|         | 186/2000 [02:20<21:56,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 74 / 187  (39.6):   9%|         | 186/2000 [02:20<21:56,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 188  (39.9):   9%|         | 187/2000 [02:20<21:55,  1.38it/s]\u001b[A\n",
      "Average Metric: 75 / 188  (39.9):   9%|         | 188/2000 [02:20<13:27,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 75 / 189  (39.7):   9%|         | 188/2000 [02:20<13:27,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snyc'. A: sync B: mexican C: lack D: tours\n",
      "Answer: A: sync\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 190  (39.5):   9%|         | 189/2000 [02:20<13:27,  2.24it/s]\u001b[A\n",
      "Average Metric: 75 / 190  (39.5):  10%|         | 190/2000 [02:20<09:37,  3.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 191  (39.3):  10%|         | 190/2000 [02:20<09:37,  3.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'asmoertih'. A: participant B: aerosmith C: hopefully D: infant\n",
      "Answer: D: infant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'adaeptd'. A: spots B: beverage C: adapted D: aircraft\n",
      "Answer: C: adapted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'fienst'? A: finest B: travel C: gibson D: phillips\n",
      "Answer: A: finest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ecficfay'. A: beliefs B: sometimes C: efficacy D: optimization\n",
      "Answer: D: optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'criictsim' represent when unscrambled? A: felt B: polynesia C: bdsm D: criticism\n",
      "Answer: D: criticism\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hrat'. A: fitting B: hart C: except D: efficiency\n",
      "Answer: D: efficiency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ciicartl'? A: final B: watson C: cargo D: critical\n",
      "Answer: D: critical\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ctcertaeiifs'. A: certificates B: revenues C: british D: identical\n",
      "Answer: C: british\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 192  (39.1):  10%|         | 191/2000 [02:24<09:37,  3.13it/s]\u001b[A\n",
      "Average Metric: 75 / 192  (39.1):  10%|         | 192/2000 [02:24<27:25,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sdneeocd' to form the correct word. A: makers B: enable C: seconded D: security\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cssiimoomn' to form the correct word. A: deutsch B: commission C: denim D: languages\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ggae'. A: blogger B: basketball C: enlargement D: gage\n",
      "Answer: D: gage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 76 / 193  (39.4):  10%|         | 192/2000 [02:25<27:25,  1.10it/s]\u001b[A\n",
      "Average Metric: 76 / 193  (39.4):  10%|         | 193/2000 [02:25<28:01,  1.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 194  (39.7):  10%|         | 193/2000 [02:26<28:01,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 77 / 194  (39.7):  10%|         | 194/2000 [02:26<23:35,  1.28it/s]\u001b[A\n",
      "Average Metric: 77 / 195  (39.5):  10%|         | 194/2000 [02:26<23:35,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 196  (39.3):  10%|         | 195/2000 [02:26<23:34,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 77 / 196  (39.3):  10%|         | 196/2000 [02:26<18:33,  1.62it/s]\u001b[A\n",
      "Average Metric: 77 / 197  (39.1):  10%|         | 196/2000 [02:26<18:33,  1.62it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 78 / 198  (39.4):  10%|         | 197/2000 [02:26<18:32,  1.62it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'noriitutn'. A: grove B: nutrition C: collapse D: warriors\n",
      "Answer: D: warriors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dealys'. A: january B: uses C: aviation D: delays\n",
      "Answer: D: delays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 79 / 199  (39.7):  10%|         | 198/2000 [02:30<18:31,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 79 / 199  (39.7):  10%|         | 199/2000 [02:30<27:16,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ctue'? A: oregon B: cute C: boat D: lacrosse\n",
      "Answer: B: cute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'linvig'. A: living B: routers C: sheriff D: triumph\n",
      "Answer: A: living\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 80 / 200  (40.0):  10%|         | 199/2000 [02:32<27:16,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sraes'? A: calendars B: sears C: swim D: manages\n",
      "Answer: B: sears\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 80 / 200  (40.0):  10%|         | 200/2000 [02:32<30:04,  1.00s/it]\u001b[A\n",
      "Average Metric: 81 / 201  (40.3):  10%|         | 200/2000 [02:32<30:04,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 81 / 201  (40.3):  10%|         | 201/2000 [02:32<24:38,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 81 / 202  (40.1):  10%|         | 201/2000 [02:32<24:38,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 81 / 202  (40.1):  10%|         | 202/2000 [02:32<19:54,  1.50it/s]\u001b[A\n",
      "Average Metric: 81 / 203  (39.9):  10%|         | 202/2000 [02:32<19:54,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aemgeenrts' to form the correct word. A: manages B: agreements C: seem D: upcoming\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 82 / 204  (40.2):  10%|         | 203/2000 [02:33<19:54,  1.50it/s]\u001b[A\n",
      "Average Metric: 82 / 204  (40.2):  10%|         | 204/2000 [02:33<16:24,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'olny' to form the correct word. A: aperture B: only C: downloading D: despite\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'daoiteiicrns' represent when unscrambled? A: craig B: sewing C: dictionaries D: furthermore\n",
      "Answer: A: craig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 82 / 205  (40.0):  10%|         | 204/2000 [02:36<16:24,  1.83it/s]\u001b[A\n",
      "Average Metric: 82 / 205  (40.0):  10%|         | 205/2000 [02:36<38:11,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lfet' to form the correct word. A: birds B: left C: odyssey D: placing\n",
      "Answer: D: placing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 83 / 206  (40.3):  10%|         | 205/2000 [02:37<38:11,  1.28s/it]\u001b[A\n",
      "Average Metric: 83 / 206  (40.3):  10%|         | 206/2000 [02:37<31:42,  1.06s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 207  (40.6):  10%|         | 206/2000 [02:37<31:42,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 84 / 207  (40.6):  10%|         | 207/2000 [02:37<27:32,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 85 / 208  (40.9):  10%|         | 207/2000 [02:37<27:32,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 85 / 209  (40.7):  10%|         | 208/2000 [02:37<27:31,  1.09it/s]\u001b[A\n",
      "Average Metric: 85 / 209  (40.7):  10%|         | 209/2000 [02:37<16:51,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'inutps' represent when unscrambled? A: tear B: inputs C: clouds D: legitimate\n",
      "Answer: A: tear\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oiignrs'? A: ninja B: origins C: plumbing D: latvia\n",
      "Answer: B: origins\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'clotran'. A: carlton B: hammer C: whole D: sluts\n",
      "Answer: C: whole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 210  (41.0):  10%|         | 209/2000 [02:38<16:51,  1.77it/s]\u001b[A\n",
      "Average Metric: 86 / 210  (41.0):  10%|         | 210/2000 [02:38<15:18,  1.95it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hguh' represent when unscrambled? A: graduated B: hugh C: baldwin D: techno\n",
      "Answer: B: hugh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'doess' to form the correct word. A: resist B: instructors C: cancel D: doses\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sewhcits' represent when unscrambled? A: detected B: atmospheric C: switches D: girlfriend\n",
      "Answer: D: girlfriend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'euongh'? A: played B: minister C: huge D: enough\n",
      "Answer: played\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 211  (40.8):  10%|         | 210/2000 [02:43<15:18,  1.95it/s]\u001b[A\n",
      "Average Metric: 86 / 211  (40.8):  11%|         | 211/2000 [02:43<46:49,  1.57s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 212  (40.6):  11%|         | 211/2000 [02:43<46:49,  1.57s/it]\u001b[A\n",
      "Average Metric: 86 / 212  (40.6):  11%|         | 212/2000 [02:43<35:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 86 / 213  (40.4):  11%|         | 212/2000 [02:43<35:35,  1.19s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 214  (40.2):  11%|         | 213/2000 [02:43<35:34,  1.19s/it]\u001b[A\n",
      "Average Metric: 86 / 214  (40.2):  11%|         | 214/2000 [02:43<21:06,  1.41it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 215  (40.0):  11%|         | 214/2000 [02:43<21:06,  1.41it/s]\u001b[A\n",
      "Average Metric: 86 / 215  (40.0):  11%|         | 215/2000 [02:43<19:05,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 86 / 216  (39.8):  11%|         | 215/2000 [02:43<19:05,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 86 / 216  (39.8):  11%|         | 216/2000 [02:43<15:06,  1.97it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 217  (40.1):  11%|         | 216/2000 [02:44<15:06,  1.97it/s]\u001b[A\n",
      "Average Metric: 87 / 217  (40.1):  11%|         | 217/2000 [02:44<13:23,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 87 / 218  (39.9):  11%|         | 217/2000 [02:44<13:23,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 219  (40.2):  11%|         | 218/2000 [02:44<13:23,  2.22it/s]\u001b[A\n",
      "Average Metric: 88 / 219  (40.2):  11%|         | 219/2000 [02:44<09:08,  3.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tirsapeht'? A: sports B: simpson C: roberts D: therapist\n",
      "Answer: therapist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'thosomn'. A: supplier B: copying C: thomson D: seriously\n",
      "Answer: D: seriously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'biarenkg'? A: outlook B: breaking C: failed D: cycle\n",
      "Answer: D: cycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'puecroerds' represent when unscrambled? A: recommend B: procedures C: given D: catholic\n",
      "Answer: A: recommend\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lbael' represent when unscrambled? A: register B: impaired C: beans D: label\n",
      "Answer: D: label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'statrs' represent when unscrambled? A: gardening B: starts C: blogthis D: psychological\n",
      "Answer: A: gardening\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ftals'. A: cutting B: flats C: bennett D: initiatives\n",
      "Answer: A: cutting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 220  (40.0):  11%|         | 219/2000 [02:48<09:08,  3.25it/s]\u001b[A\n",
      "Average Metric: 88 / 220  (40.0):  11%|         | 220/2000 [02:48<34:13,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dnayota'? A: msgstr B: pulling C: welding D: daytona\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lvoer' represent when unscrambled? A: lover B: listened C: employee D: reel\n",
      "Answer: A: lover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 221  (39.8):  11%|         | 220/2000 [02:49<34:13,  1.15s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 221  (39.8):  11%|         | 221/2000 [02:49<34:56,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 88 / 222  (39.6):  11%|         | 221/2000 [02:49<34:56,  1.18s/it]\u001b[A\n",
      "Average Metric: 89 / 223  (39.9):  11%|         | 222/2000 [02:49<34:55,  1.18s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 224  (39.7):  11%|         | 223/2000 [02:49<34:53,  1.18s/it]\u001b[A\n",
      "Average Metric: 89 / 224  (39.7):  11%|         | 224/2000 [02:49<17:41,  1.67it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 89 / 225  (39.6):  11%|         | 224/2000 [02:49<17:41,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 89 / 226  (39.4):  11%|        | 225/2000 [02:49<17:41,  1.67it/s]\u001b[A\n",
      "Average Metric: 89 / 226  (39.4):  11%|        | 226/2000 [02:49<12:55,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 227  (39.6):  11%|        | 226/2000 [02:50<12:55,  2.29it/s]\u001b[A\n",
      "Average Metric: 90 / 227  (39.6):  11%|        | 227/2000 [02:50<12:07,  2.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tpioacrl'? A: tropical B: detectors C: outlined D: facilitate\n",
      "Answer: B: detectors\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mlid'? A: cabinets B: mild C: excluded D: dragons\n",
      "Answer: D: dragons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'flreows' to form the correct word. A: answer B: flowers C: maintains D: lawsuit\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'revan'. A: raven B: simulation C: patches D: pantyhose\n",
      "Answer: A: raven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tset' represent when unscrambled? A: venues B: test C: chinese D: blowjobs\n",
      "Answer: A: venues\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nkead'? A: steering B: answered C: naked D: organizing\n",
      "Answer: B: answered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 228  (39.9):  11%|        | 227/2000 [02:55<12:07,  2.44it/s]\u001b[A\n",
      "Average Metric: 91 / 228  (39.9):  11%|        | 228/2000 [02:55<42:04,  1.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'faom' represent when unscrambled? A: jungle B: foam C: viii D: glue\n",
      "Answer: B: foam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 92 / 229  (40.2):  11%|        | 228/2000 [02:55<42:04,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 229  (40.2):  11%|        | 229/2000 [02:55<35:48,  1.21s/it]\u001b[A\n",
      "Average Metric: 92 / 230  (40.0):  11%|        | 229/2000 [02:56<35:48,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 92 / 230  (40.0):  12%|        | 230/2000 [02:56<28:14,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 231  (40.3):  12%|        | 230/2000 [02:56<28:14,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 232  (40.1):  12%|        | 231/2000 [02:56<28:13,  1.04it/s]\u001b[A\n",
      "Average Metric: 93 / 232  (40.1):  12%|        | 232/2000 [02:56<17:12,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aouts' represent when unscrambled? A: genome B: autos C: influence D: atlantic\n",
      "Answer: A: genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'grhaam'? A: bodies B: graham C: welfare D: draw\n",
      "Answer: D: draw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cebeiirtles' to form the correct word. A: evening B: celebrities C: dominated D: clicks\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 233  (40.3):  12%|        | 232/2000 [03:00<17:12,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 233  (40.3):  12%|        | 233/2000 [03:00<40:50,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'plbaayck' to form the correct word. A: playback B: equipment C: motherboard D: deaf\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 234  (40.2):  12%|        | 233/2000 [03:00<40:50,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 234  (40.2):  12%|        | 234/2000 [03:00<33:50,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fteifen' to form the correct word. A: casa B: fifteen C: lawrence D: occupational\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ecdlxue'. A: dean B: permission C: exclude D: exercise\n",
      "Answer: D: exercise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 94 / 235  (40.0):  12%|        | 234/2000 [03:01<33:50,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 235  (40.0):  12%|        | 235/2000 [03:01<27:19,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'agleeld' represent when unscrambled? A: nickname B: relates C: byron D: alleged\n",
      "Answer: D: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 94 / 236  (39.8):  12%|        | 235/2000 [03:01<27:19,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 94 / 236  (39.8):  12%|        | 236/2000 [03:01<22:18,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 237  (39.7):  12%|        | 236/2000 [03:01<22:18,  1.32it/s]\u001b[A\n",
      "Average Metric: 94 / 237  (39.7):  12%|        | 237/2000 [03:01<17:54,  1.64it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 95 / 238  (39.9):  12%|        | 237/2000 [03:01<17:54,  1.64it/s]\u001b[A\n",
      "Average Metric: 95 / 238  (39.9):  12%|        | 238/2000 [03:01<14:12,  2.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 95 / 239  (39.7):  12%|        | 238/2000 [03:01<14:12,  2.07it/s]\u001b[A\n",
      "Average Metric: 95 / 239  (39.7):  12%|        | 239/2000 [03:01<10:59,  2.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 96 / 240  (40.0):  12%|        | 239/2000 [03:01<10:59,  2.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lsaahricne'. A: incorporation B: encyclopedia C: lancashire D: independence\n",
      "Answer: D: independence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rtealy'? A: realty B: adding C: quizzes D: added\n",
      "Answer: A: realty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 96 / 241  (39.8):  12%|        | 240/2000 [03:05<10:58,  2.67it/s]\u001b[A\n",
      "Average Metric: 96 / 241  (39.8):  12%|        | 241/2000 [03:05<28:37,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ckeas'? A: cakes B: generating C: surgeons D: accessed\n",
      "Answer: cakes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sprac' to form the correct word. A: deleted B: verification C: sparc D: frost\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cstoa'. A: receiver B: hydrogen C: costa D: impressions\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 242  (39.7):  12%|        | 241/2000 [03:05<28:37,  1.02it/s]\u001b[A\n",
      "Average Metric: 96 / 242  (39.7):  12%|        | 242/2000 [03:05<26:08,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 243  (39.9):  12%|        | 242/2000 [03:06<26:08,  1.12it/s]\u001b[A\n",
      "Average Metric: 97 / 243  (39.9):  12%|        | 243/2000 [03:06<21:24,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 244  (39.8):  12%|        | 243/2000 [03:06<21:24,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 97 / 245  (39.6):  12%|        | 244/2000 [03:06<21:23,  1.37it/s]\u001b[A\n",
      "Average Metric: 97 / 245  (39.6):  12%|        | 245/2000 [03:06<13:00,  2.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 98 / 246  (39.8):  12%|        | 245/2000 [03:06<13:00,  2.25it/s]\u001b[A\n",
      "Average Metric: 98 / 246  (39.8):  12%|        | 246/2000 [03:06<11:40,  2.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 247  (40.1):  12%|        | 246/2000 [03:06<11:40,  2.50it/s]\u001b[A\n",
      "Average Metric: 99 / 247  (40.1):  12%|        | 247/2000 [03:06<10:04,  2.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 100 / 248  (40.3):  12%|        | 247/2000 [03:06<10:04,  2.90it/s]\u001b[A\n",
      "Average Metric: 100 / 248  (40.3):  12%|        | 248/2000 [03:06<08:22,  3.49it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 249  (40.6):  12%|        | 248/2000 [03:06<08:22,  3.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'barin'. A: sampling B: turks C: brian D: dietary\n",
      "Answer: D: dietary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 250  (40.4):  12%|        | 249/2000 [03:07<08:21,  3.49it/s]\u001b[A\n",
      "Average Metric: 101 / 250  (40.4):  12%|        | 250/2000 [03:07<07:47,  3.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 101 / 251  (40.2):  12%|        | 250/2000 [03:07<07:47,  3.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 101 / 251  (40.2):  13%|        | 251/2000 [03:07<07:11,  4.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'exratct'. A: irvine B: extract C: stakeholders D: button\n",
      "Answer: B: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 252  (40.1):  13%|        | 251/2000 [03:07<07:11,  4.05it/s]\u001b[A\n",
      "Average Metric: 101 / 252  (40.1):  13%|        | 252/2000 [03:07<07:18,  3.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cireatnly'. A: bears B: certainly C: maintained D: info\n",
      "Answer: D: info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t Socket operation on non-socket"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'petojecrd' to form the correct word. A: bahamas B: nokia C: projected D: copenhagen\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ctoetacnd'? A: leicester B: encourages C: wins D: contacted\n",
      "Answer: B: encourages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ierssempd' to form the correct word. A: goes B: kate C: impressed D: guards\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aactecpble'. A: poison B: acceptable C: injury D: gains\n",
      "Answer: D: gains\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'yhaama'. A: glasses B: yamaha C: companion D: week\n",
      "Answer: A: glasses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 253  (39.9):  13%|        | 252/2000 [03:11<07:18,  3.99it/s]\u001b[A\n",
      "Average Metric: 101 / 253  (39.9):  13%|        | 253/2000 [03:11<37:08,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 254  (39.8):  13%|        | 253/2000 [03:12<37:08,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 101 / 254  (39.8):  13%|        | 254/2000 [03:12<30:57,  1.06s/it]\u001b[A\n",
      "Average Metric: 101 / 255  (39.6):  13%|        | 254/2000 [03:12<30:57,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oiffecs'. A: bids B: newsletters C: sauce D: offices\n",
      "Answer: b\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vicnee' represent when unscrambled? A: disabilities B: venice C: realty D: july\n",
      "Answer: A: disabilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 102 / 256  (39.8):  13%|        | 255/2000 [03:12<30:56,  1.06s/it]\u001b[A\n",
      "Average Metric: 102 / 256  (39.8):  13%|        | 256/2000 [03:12<18:30,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 103 / 257  (40.1):  13%|        | 256/2000 [03:12<18:30,  1.57it/s]\u001b[A\n",
      "Average Metric: 103 / 257  (40.1):  13%|        | 257/2000 [03:12<16:56,  1.71it/s]\u001b[A\n",
      "Average Metric: 104 / 258  (40.3):  13%|        | 257/2000 [03:13<16:56,  1.71it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 104 / 258  (40.3):  13%|        | 258/2000 [03:13<14:32,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 259  (40.5):  13%|        | 258/2000 [03:13<14:32,  2.00it/s]\u001b[A\n",
      "Average Metric: 105 / 259  (40.5):  13%|        | 259/2000 [03:13<12:20,  2.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 260  (40.4):  13%|        | 259/2000 [03:13<12:20,  2.35it/s]\u001b[A\n",
      "Average Metric: 105 / 260  (40.4):  13%|        | 260/2000 [03:13<09:48,  2.96it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hsore'? A: turnover B: horse C: player D: sixth\n",
      "Answer: B: horse\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bsuh' to form the correct word. A: buddy B: cents C: bush D: cube\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mnoo' to form the correct word. A: exclusive B: mono C: roberts D: regulatory\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 105 / 261  (40.2):  13%|        | 260/2000 [03:16<09:48,  2.96it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 105 / 261  (40.2):  13%|        | 261/2000 [03:16<34:59,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mutnniog'? A: possession B: multi C: squad D: mounting\n",
      "Answer: D: mounting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cerbnraa'. A: canberra B: pipe C: suburban D: young\n",
      "Answer: D: young\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 106 / 262  (40.5):  13%|        | 261/2000 [03:18<34:59,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 106 / 262  (40.5):  13%|        | 262/2000 [03:18<37:23,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'atbsesos'. A: unbiased B: adolescent C: asbestos D: relax\n",
      "Answer: D: relax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 263  (40.3):  13%|        | 262/2000 [03:18<37:23,  1.29s/it]\u001b[A\n",
      "Average Metric: 106 / 263  (40.3):  13%|        | 263/2000 [03:18<28:22,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 264  (40.5):  13%|        | 263/2000 [03:18<28:22,  1.02it/s]\u001b[A\n",
      "Average Metric: 107 / 264  (40.5):  13%|        | 264/2000 [03:18<21:25,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 265  (40.4):  13%|        | 264/2000 [03:18<21:25,  1.35it/s]\u001b[A\n",
      "Average Metric: 107 / 265  (40.4):  13%|        | 265/2000 [03:18<16:02,  1.80it/s]\u001b[A\n",
      "Average Metric: 108 / 266  (40.6):  13%|        | 265/2000 [03:19<16:02,  1.80it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 108 / 266  (40.6):  13%|        | 266/2000 [03:19<12:16,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 267  (40.4):  13%|        | 266/2000 [03:19<12:16,  2.35it/s]\u001b[A\n",
      "Average Metric: 108 / 267  (40.4):  13%|        | 267/2000 [03:19<10:02,  2.88it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bnliseae' to form the correct word. A: lesbian B: asses C: baseline D: trees\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 268  (40.3):  13%|        | 267/2000 [03:19<10:02,  2.88it/s]\u001b[A\n",
      "Average Metric: 108 / 268  (40.3):  13%|        | 268/2000 [03:19<10:36,  2.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 108 / 269  (40.1):  13%|        | 268/2000 [03:19<10:36,  2.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'eoffrt' to form the correct word. A: bang B: demon C: plastic D: effort\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dteteonin'. A: bryan B: detention C: maiden D: maintains\n",
      "Answer: b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 270  (40.0):  13%|        | 269/2000 [03:23<10:36,  2.72it/s]\u001b[A\n",
      "Average Metric: 108 / 270  (40.0):  14%|        | 270/2000 [03:23<33:48,  1.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pcactire'. A: practice B: boats C: buses D: faculty\n",
      "Answer: A: practice\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ftagnrmes' represent when unscrambled? A: issuance B: fragments C: daniel D: viral\n",
      "Answer: D: viral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 271  (40.2):  14%|        | 270/2000 [03:24<33:48,  1.17s/it]\u001b[A\n",
      "Average Metric: 109 / 271  (40.2):  14%|        | 271/2000 [03:24<28:45,  1.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 272  (40.4):  14%|        | 271/2000 [03:24<28:45,  1.00it/s]\u001b[A\n",
      "Average Metric: 110 / 272  (40.4):  14%|        | 272/2000 [03:24<25:04,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 273  (40.3):  14%|        | 272/2000 [03:24<25:04,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 274  (40.1):  14%|        | 273/2000 [03:25<25:03,  1.15it/s]\u001b[A\n",
      "Average Metric: 110 / 274  (40.1):  14%|        | 274/2000 [03:25<16:10,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'nrusery' represent when unscrambled? A: reasonable B: beaches C: inventory D: nursery\n",
      "Answer: D: nursery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'prbtaline' represent when unscrambled? A: interfaces B: possibly C: printable D: humanitarian\n",
      "Answer: A: interfaces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cifosounn' to form the correct word. A: gratis B: confusion C: submitting D: bunny\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 111 / 275  (40.4):  14%|        | 274/2000 [03:28<16:10,  1.78it/s]\u001b[A\n",
      "Average Metric: 111 / 275  (40.4):  14%|        | 275/2000 [03:28<36:44,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 112 / 276  (40.6):  14%|        | 275/2000 [03:29<36:44,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 276  (40.6):  14%|        | 276/2000 [03:29<29:30,  1.03s/it]\u001b[A\n",
      "Average Metric: 112 / 277  (40.4):  14%|        | 276/2000 [03:29<29:30,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 277  (40.4):  14%|        | 277/2000 [03:29<22:31,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'adrnew'? A: eden B: companion C: sentences D: andrew\n",
      "Answer: D: andrew\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'stgnehrts'. A: strengths B: cities C: suddenly D: bound\n",
      "Answer: D: bound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 278  (40.3):  14%|        | 277/2000 [03:29<22:31,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 112 / 278  (40.3):  14%|        | 278/2000 [03:29<18:59,  1.51it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 113 / 279  (40.5):  14%|        | 278/2000 [03:29<18:59,  1.51it/s]\u001b[A\n",
      "Average Metric: 113 / 279  (40.5):  14%|        | 279/2000 [03:29<15:38,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 113 / 280  (40.4):  14%|        | 279/2000 [03:29<15:38,  1.83it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 281  (40.6):  14%|        | 280/2000 [03:29<15:38,  1.83it/s]\u001b[A\n",
      "Average Metric: 114 / 281  (40.6):  14%|        | 281/2000 [03:29<09:55,  2.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cosingsroeanl'. A: adware B: bluetooth C: childcare D: congressional\n",
      "Answer: D: congressional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 282  (40.4):  14%|        | 281/2000 [03:30<09:55,  2.89it/s]\u001b[A\n",
      "Average Metric: 114 / 282  (40.4):  14%|        | 282/2000 [03:30<08:45,  3.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 114 / 283  (40.3):  14%|        | 282/2000 [03:30<08:45,  3.27it/s]\u001b[A\n",
      "Average Metric: 114 / 283  (40.3):  14%|        | 283/2000 [03:30<08:37,  3.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 284  (40.1):  14%|        | 283/2000 [03:30<08:37,  3.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tuhs' represent when unscrambled? A: convenient B: surfaces C: thus D: fruit\n",
      "Answer: C: thus\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'yarely' represent when unscrambled? A: wise B: yearly C: classical D: palmer\n",
      "Answer: A: wise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anetttimpg'. A: attempting B: disabled C: microphone D: planner\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bolinggg'? A: formulation B: dude C: blogging D: blade\n",
      "Answer: D: blade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 285  (40.0):  14%|        | 284/2000 [03:31<08:36,  3.32it/s]\u001b[A\n",
      "Average Metric: 114 / 285  (40.0):  14%|        | 285/2000 [03:31<12:47,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'blodoy' to form the correct word. A: bloody B: curves C: racial D: warcraft\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mtah'. A: eyes B: math C: intense D: victoria\n",
      "Answer: D: victoria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'desrs'? A: freeware B: basement C: ranch D: dress\n",
      "Answer: D: dress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'magenas'. A: flooring B: computing C: malcolm D: manages\n",
      "Answer: D: manages\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'queit'. A: compare B: quiet C: topless D: confusion\n",
      "Answer: B: quiet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 286  (39.9):  14%|        | 285/2000 [03:35<12:47,  2.24it/s]\u001b[A\n",
      "Average Metric: 114 / 286  (39.9):  14%|        | 286/2000 [03:35<35:12,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 115 / 287  (40.1):  14%|        | 286/2000 [03:35<35:12,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 115 / 287  (40.1):  14%|        | 287/2000 [03:35<28:50,  1.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'puolrdy'. A: stanley B: louisiana C: proudly D: contracts\n",
      "Answer: D: contracts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 116 / 288  (40.3):  14%|        | 287/2000 [03:36<28:50,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 116 / 288  (40.3):  14%|        | 288/2000 [03:36<22:46,  1.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 116 / 289  (40.1):  14%|        | 288/2000 [03:36<22:46,  1.25it/s]\u001b[A\n",
      "Average Metric: 116 / 289  (40.1):  14%|        | 289/2000 [03:36<17:45,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 290  (40.3):  14%|        | 289/2000 [03:36<17:45,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 291  (40.2):  14%|        | 290/2000 [03:36<17:44,  1.61it/s]\u001b[A\n",
      "Average Metric: 117 / 291  (40.2):  15%|        | 291/2000 [03:36<11:39,  2.44it/s]\u001b[A\n",
      "Average Metric: 117 / 292  (40.1):  15%|        | 291/2000 [03:36<11:39,  2.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 117 / 292  (40.1):  15%|        | 292/2000 [03:36<09:42,  2.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 293  (39.9):  15%|        | 292/2000 [03:36<09:42,  2.93it/s]\u001b[A\n",
      "Average Metric: 117 / 293  (39.9):  15%|        | 293/2000 [03:36<08:53,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'qauilty' represent when unscrambled? A: wind B: quality C: efficacy D: conducting\n",
      "Answer: B: quality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ccahne'. A: chance B: banking C: besides D: pgsql\n",
      "Answer: B: banking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rdnenireg' represent when unscrambled? A: traditionally B: nottingham C: conditional D: rendering\n",
      "Answer: D: rendering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 294  (39.8):  15%|        | 293/2000 [03:40<08:53,  3.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oucnrircg'. A: occurring B: easter C: software D: renewed\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'etxdnenig'? A: amino B: enquiries C: extending D: artistic\n",
      "Answer: D: artistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 117 / 294  (39.8):  15%|        | 294/2000 [03:40<37:06,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 295  (40.0):  15%|        | 294/2000 [03:41<37:06,  1.31s/it]\u001b[A\n",
      "Average Metric: 118 / 295  (40.0):  15%|        | 295/2000 [03:41<30:47,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 118 / 296  (39.9):  15%|        | 295/2000 [03:41<30:47,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 118 / 296  (39.9):  15%|        | 296/2000 [03:41<23:57,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ldeas'. A: camel B: relations C: heard D: leads\n",
      "Answer: D: leads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 297  (39.7):  15%|        | 296/2000 [03:41<23:57,  1.19it/s]\u001b[A\n",
      "Average Metric: 118 / 297  (39.7):  15%|        | 297/2000 [03:41<18:54,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 298  (39.6):  15%|        | 297/2000 [03:42<18:54,  1.50it/s]\u001b[A\n",
      "Average Metric: 118 / 298  (39.6):  15%|        | 298/2000 [03:42<15:36,  1.82it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 119 / 299  (39.8):  15%|        | 298/2000 [03:42<15:36,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 119 / 299  (39.8):  15%|        | 299/2000 [03:42<13:13,  2.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 300  (39.7):  15%|        | 299/2000 [03:42<13:13,  2.14it/s]\u001b[A\n",
      "Average Metric: 119 / 300  (39.7):  15%|        | 300/2000 [03:42<11:58,  2.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'piatrck' represent when unscrambled? A: celtic B: body C: clothing D: patrick\n",
      "Answer: A: celtic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 301  (39.9):  15%|        | 300/2000 [03:46<11:58,  2.37it/s]\u001b[A\n",
      "Average Metric: 120 / 301  (39.9):  15%|        | 301/2000 [03:46<39:55,  1.41s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 121 / 302  (40.1):  15%|        | 301/2000 [03:46<39:55,  1.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tnruk' represent when unscrambled? A: trunk B: phase C: programmers D: beings\n",
      "Answer: B: phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'deinefs'. A: attendance B: defines C: financial D: force\n",
      "Answer: D: force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 122 / 303  (40.3):  15%|        | 302/2000 [03:47<39:53,  1.41s/it]\u001b[A\n",
      "Average Metric: 122 / 303  (40.3):  15%|        | 303/2000 [03:47<29:21,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sohp' to form the correct word. A: reporting B: welfare C: shop D: wonders\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 123 / 304  (40.5):  15%|        | 303/2000 [03:47<29:21,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 124 / 305  (40.7):  15%|        | 304/2000 [03:47<29:20,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 124 / 305  (40.7):  15%|        | 305/2000 [03:47<18:59,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'srue'? A: belgium B: wonders C: mysql D: sure\n",
      "Answer: D: sure\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'smlal'. A: small B: claimed C: paraguay D: stated\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pvratie'. A: klein B: owner C: private D: terminal\n",
      "Answer: D: terminal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'oetsvobiran' represent when unscrambled? A: literally B: sectors C: observation D: incorrect\n",
      "Answer: B: sectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 306  (40.8):  15%|        | 305/2000 [03:52<18:59,  1.49it/s]\u001b[A\n",
      "Average Metric: 125 / 306  (40.8):  15%|        | 306/2000 [03:52<43:14,  1.53s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 307  (41.0):  15%|        | 306/2000 [03:52<43:14,  1.53s/it]\u001b[A\n",
      "Average Metric: 126 / 307  (41.0):  15%|        | 307/2000 [03:52<36:01,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 308  (40.9):  15%|        | 307/2000 [03:52<36:01,  1.28s/it]\u001b[A\n",
      "Average Metric: 127 / 309  (41.1):  15%|        | 308/2000 [03:52<36:00,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aera' represent when unscrambled? A: conservation B: orgasm C: area D: smoke\n",
      "Answer: C: area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 310  (41.3):  15%|        | 309/2000 [03:53<35:58,  1.28s/it]\u001b[A\n",
      "Average Metric: 128 / 310  (41.3):  16%|        | 310/2000 [03:53<19:48,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 311  (41.2):  16%|        | 310/2000 [03:53<19:48,  1.42it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 311  (41.2):  16%|        | 311/2000 [03:53<18:20,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'crop' represent when unscrambled? A: funeral B: corp C: ideal D: maiden\n",
      "Answer: C: ideal\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'intvmeetsns' represent when unscrambled? A: discussed B: investments C: consortium D: tall\n",
      "Answer: A: discussed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 312  (41.0):  16%|        | 311/2000 [03:54<18:20,  1.54it/s]\u001b[A\n",
      "Average Metric: 128 / 312  (41.0):  16%|        | 312/2000 [03:54<17:41,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dliraeicmss' represent when unscrambled? A: span B: disclaimers C: monitors D: request\n",
      "Answer: D: request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 313  (40.9):  16%|        | 312/2000 [03:55<17:41,  1.59it/s]\u001b[A\n",
      "Average Metric: 128 / 313  (40.9):  16%|        | 313/2000 [03:55<18:12,  1.54it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'slae' represent when unscrambled? A: drops B: plains C: sale D: christ\n",
      "Answer: C: sale\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iensertd'. A: inserted B: idea C: yards D: lacrosse\n",
      "Answer: A: inserted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'seeuccd'. A: sussex B: ongoing C: webster D: succeed\n",
      "Answer: D: succeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'codroirr'. A: corridor B: acknowledged C: headquarters D: adventures\n",
      "Answer: D: adventures\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wrad'. A: chairs B: ward C: purchasing D: death\n",
      "Answer: C: purchasing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 128 / 314  (40.8):  16%|        | 313/2000 [03:58<18:12,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 128 / 314  (40.8):  16%|        | 314/2000 [03:58<37:22,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 315  (40.6):  16%|        | 314/2000 [03:58<37:22,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 316  (40.5):  16%|        | 315/2000 [03:58<37:21,  1.33s/it]\u001b[A\n",
      "Average Metric: 128 / 316  (40.5):  16%|        | 316/2000 [03:58<23:57,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 128 / 317  (40.4):  16%|        | 316/2000 [03:58<23:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 128 / 318  (40.3):  16%|        | 317/2000 [03:58<23:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 319  (40.1):  16%|        | 318/2000 [03:59<23:56,  1.17it/s]\u001b[A\n",
      "Average Metric: 128 / 319  (40.1):  16%|        | 319/2000 [03:59<14:38,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 128 / 320  (40.0):  16%|        | 319/2000 [03:59<14:38,  1.91it/s]\u001b[A\n",
      "Average Metric: 128 / 320  (40.0):  16%|        | 320/2000 [03:59<13:15,  2.11it/s]\u001b[A\n",
      "Average Metric: 129 / 321  (40.2):  16%|        | 320/2000 [03:59<13:15,  2.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 129 / 321  (40.2):  16%|        | 321/2000 [03:59<12:44,  2.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 129 / 322  (40.1):  16%|        | 321/2000 [04:00<12:44,  2.20it/s]\u001b[A\n",
      "Average Metric: 129 / 322  (40.1):  16%|        | 322/2000 [04:00<10:50,  2.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 129 / 323  (39.9):  16%|        | 322/2000 [04:00<10:50,  2.58it/s]\u001b[A\n",
      "Average Metric: 129 / 323  (39.9):  16%|        | 323/2000 [04:00<09:38,  2.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wwilodrde'? A: worldwide B: powers C: controllers D: even\n",
      "Answer: D: even\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tmep'. A: spoken B: temp C: combined D: salem\n",
      "Answer: A: spoken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mgiac'. A: channels B: magic C: guided D: bhutan\n",
      "Answer: D: bhutan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 324  (40.1):  16%|        | 323/2000 [04:04<09:38,  2.90it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'jsut'? A: earrings B: hang C: attacks D: just\n",
      "Answer: D: just\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 130 / 324  (40.1):  16%|        | 324/2000 [04:04<40:12,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 325  (40.0):  16%|        | 324/2000 [04:04<40:12,  1.44s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 326  (39.9):  16%|        | 325/2000 [04:04<40:11,  1.44s/it]\u001b[A\n",
      "Average Metric: 130 / 326  (39.9):  16%|        | 326/2000 [04:04<23:41,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 327  (39.8):  16%|        | 326/2000 [04:05<23:41,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 130 / 327  (39.8):  16%|        | 327/2000 [04:05<21:24,  1.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'piuovers'. A: cast B: importantly C: previous D: harrison\n",
      "Answer: D: harrison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 131 / 328  (39.9):  16%|        | 327/2000 [04:05<21:24,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 131 / 329  (39.8):  16%|        | 328/2000 [04:06<21:23,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 131 / 329  (39.8):  16%|        | 329/2000 [04:06<18:44,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'uilztie' to form the correct word. A: briefly B: everybody C: utilize D: urgent\n",
      "Answer: Briefly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'grlnealey'. A: capri B: generally C: saves D: renewed\n",
      "Answer: D: renewed\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'crtous'. A: courts B: monica C: jeff D: registration\n",
      "Answer: D: registration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 330  (39.7):  16%|        | 329/2000 [04:10<18:44,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 131 / 330  (39.7):  16%|        | 330/2000 [04:10<36:54,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 331  (39.9):  16%|        | 330/2000 [04:10<36:54,  1.33s/it]\u001b[A\n",
      "Average Metric: 132 / 332  (39.8):  17%|        | 331/2000 [04:10<36:53,  1.33s/it]\u001b[A\n",
      "Average Metric: 132 / 333  (39.6):  17%|        | 332/2000 [04:10<36:51,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 132 / 333  (39.6):  17%|        | 333/2000 [04:10<19:40,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mainehcs'. A: finished B: machines C: fashion D: supplements\n",
      "Answer: D: supplements\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iaktne'? A: bath B: which C: intake D: requirements\n",
      "Answer: D: requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 132 / 334  (39.5):  17%|        | 333/2000 [04:10<19:40,  1.41it/s]\u001b[A\n",
      "Average Metric: 132 / 334  (39.5):  17%|        | 334/2000 [04:10<19:27,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 133 / 335  (39.7):  17%|        | 334/2000 [04:10<19:27,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 133 / 336  (39.6):  17%|        | 335/2000 [04:11<19:26,  1.43it/s]\u001b[A\n",
      "Average Metric: 134 / 337  (39.8):  17%|        | 336/2000 [04:11<19:25,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 134 / 337  (39.8):  17%|        | 337/2000 [04:11<11:24,  2.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 338  (39.6):  17%|        | 337/2000 [04:11<11:24,  2.43it/s]\u001b[A\n",
      "Average Metric: 134 / 338  (39.6):  17%|        | 338/2000 [04:11<10:49,  2.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 135 / 339  (39.8):  17%|        | 338/2000 [04:11<10:49,  2.56it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 135 / 339  (39.8):  17%|        | 339/2000 [04:11<09:26,  2.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snoerposd'. A: sponsored B: boys C: dawn D: petroleum\n",
      "Answer: A: sponsored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rtsipelsobniiy' represent when unscrambled? A: loans B: skating C: inline D: responsibility\n",
      "Answer: D: responsibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 135 / 340  (39.7):  17%|        | 339/2000 [04:16<09:26,  2.93it/s]\u001b[A\n",
      "Average Metric: 135 / 340  (39.7):  17%|        | 340/2000 [04:16<36:57,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'essncee'. A: hungarian B: essence C: twice D: american\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sult'. A: kenny B: slut C: skate D: files\n",
      "Answer: kenny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hyduialrc'. A: intranet B: integrate C: hydraulic D: into\n",
      "Answer: D: into\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'angles'? A: relaxation B: coordinates C: monte D: angels\n",
      "Answer: D: angels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 135 / 341  (39.6):  17%|        | 340/2000 [04:17<36:57,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 135 / 341  (39.6):  17%|        | 341/2000 [04:17<35:10,  1.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 136 / 342  (39.8):  17%|        | 341/2000 [04:17<35:10,  1.27s/it]\u001b[A\n",
      "Average Metric: 136 / 342  (39.8):  17%|        | 342/2000 [04:17<27:48,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'peiotnd' represent when unscrambled? A: pointed B: sanders C: calendar D: folks\n",
      "Answer: A: pointed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rkciy'. A: muze B: ricky C: radar D: establishments\n",
      "Answer: D: establishments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uoinns'? A: unions B: viewpicture C: goal D: amazon\n",
      "Answer: B: viewpicture\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'vwrupicitee'. A: viewpicture B: attendance C: elastic D: seeking\n",
      "Answer: D: seeking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 136 / 343  (39.7):  17%|        | 342/2000 [04:21<27:48,  1.01s/it]\u001b[A\n",
      "Average Metric: 136 / 343  (39.7):  17%|        | 343/2000 [04:21<47:13,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'jepsanae'. A: elementary B: japanese C: guild D: calendar\n",
      "Answer: A: elementary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'turly' to form the correct word. A: truly B: adopted C: titans D: underground\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 137 / 344  (39.8):  17%|        | 343/2000 [04:22<47:13,  1.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 344  (39.8):  17%|        | 344/2000 [04:22<40:40,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'svered'? A: recognised B: served C: discretion D: terrain\n",
      "Answer: B: served\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 137 / 345  (39.7):  17%|        | 344/2000 [04:22<40:40,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 345  (39.7):  17%|        | 345/2000 [04:22<31:12,  1.13s/it]\u001b[A\n",
      "Average Metric: 137 / 346  (39.6):  17%|        | 345/2000 [04:22<31:12,  1.13s/it]\u001b[A\n",
      "Average Metric: 138 / 347  (39.8):  17%|        | 346/2000 [04:22<31:11,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 138 / 347  (39.8):  17%|        | 347/2000 [04:22<19:23,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aotm'? A: save B: quantity C: atom D: thee\n",
      "Answer: D: thee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 139 / 348  (39.9):  17%|        | 347/2000 [04:24<19:23,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 139 / 348  (39.9):  17%|        | 348/2000 [04:24<26:36,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'looaictn'. A: suits B: democracy C: location D: beth\n",
      "Answer: D: beth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'beidse' represent when unscrambled? A: lasting B: sperm C: midwest D: beside\n",
      "Answer: D: beside\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cliam' represent when unscrambled? A: claim B: commitments C: bacon D: unauthorized\n",
      "Answer: A: claim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'srpueb' represent when unscrambled? A: ridge B: superb C: murder D: hist\n",
      "Answer: B: superb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 139 / 349  (39.8):  17%|        | 348/2000 [04:27<26:36,  1.03it/s]\u001b[A\n",
      "Average Metric: 139 / 349  (39.8):  17%|        | 349/2000 [04:27<42:53,  1.56s/it]\u001b[A\n",
      "Average Metric: 139 / 350  (39.7):  17%|        | 349/2000 [04:28<42:53,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 139 / 350  (39.7):  18%|        | 350/2000 [04:28<33:32,  1.22s/it]\u001b[A\n",
      "Average Metric: 139 / 351  (39.6):  18%|        | 350/2000 [04:28<33:32,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 139 / 351  (39.6):  18%|        | 351/2000 [04:28<25:00,  1.10it/s]\u001b[A\n",
      "Average Metric: 140 / 352  (39.8):  18%|        | 351/2000 [04:28<25:00,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 140 / 352  (39.8):  18%|        | 352/2000 [04:28<18:48,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rpiceiotaln'. A: replication B: begin C: copper D: interviews\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mainnainitg' represent when unscrambled? A: after B: genuine C: prepared D: maintaining\n",
      "Answer: D: maintaining\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'intienolnrlatay'. A: internationally B: population C: awarded D: museums\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 353  (39.9):  18%|        | 352/2000 [04:29<18:48,  1.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aoelwld'. A: whitney B: annotation C: allowed D: provinces\n",
      "Answer: D: provinces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 353  (39.9):  18%|        | 353/2000 [04:29<26:22,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'biesdes' to form the correct word. A: trembl B: participating C: prof D: besides\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 142 / 354  (40.1):  18%|        | 353/2000 [04:33<26:22,  1.04it/s]\u001b[A\n",
      "Average Metric: 142 / 354  (40.1):  18%|        | 354/2000 [04:33<44:41,  1.63s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 355  (40.3):  18%|        | 354/2000 [04:33<44:41,  1.63s/it]\u001b[A\n",
      "Average Metric: 143 / 355  (40.3):  18%|        | 355/2000 [04:33<32:50,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sxtih'? A: viruses B: battlefield C: calm D: sixth\n",
      "Answer: D: sixth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 144 / 356  (40.4):  18%|        | 355/2000 [04:33<32:50,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 144 / 356  (40.4):  18%|        | 356/2000 [04:33<27:50,  1.02s/it]\u001b[A\n",
      "Average Metric: 144 / 357  (40.3):  18%|        | 356/2000 [04:34<27:50,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 144 / 357  (40.3):  18%|        | 357/2000 [04:34<21:12,  1.29it/s]\u001b[A\n",
      "Average Metric: 145 / 358  (40.5):  18%|        | 357/2000 [04:34<21:12,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 145 / 359  (40.4):  18%|        | 358/2000 [04:34<21:11,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 145 / 359  (40.4):  18%|        | 359/2000 [04:34<12:25,  2.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'setnceens' represent when unscrambled? A: manuscript B: sentences C: introduce D: chemicals\n",
      "Answer: B: sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 145 / 360  (40.3):  18%|        | 359/2000 [04:34<12:25,  2.20it/s]\u001b[A\n",
      "Average Metric: 145 / 360  (40.3):  18%|        | 360/2000 [04:34<11:30,  2.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 145 / 361  (40.2):  18%|        | 360/2000 [04:34<11:30,  2.37it/s]\u001b[A\n",
      "Average Metric: 145 / 361  (40.2):  18%|        | 361/2000 [04:34<09:45,  2.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scuaellrinve'? A: auction B: heath C: surveillance D: cases\n",
      "Answer: A: auction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 145 / 362  (40.1):  18%|        | 361/2000 [04:34<09:45,  2.80it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 145 / 362  (40.1):  18%|        | 362/2000 [04:34<08:15,  3.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 146 / 363  (40.2):  18%|        | 362/2000 [04:35<08:15,  3.31it/s]\u001b[A\n",
      "Average Metric: 147 / 364  (40.4):  18%|        | 363/2000 [04:35<08:15,  3.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 147 / 364  (40.4):  18%|        | 364/2000 [04:35<07:35,  3.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vieiwng'? A: interested B: states C: viewing D: legislature\n",
      "Answer: D: legislature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cednlas' to form the correct word. A: reference B: understanding C: candles D: please\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'kllis'. A: kills B: areas C: commented D: owned\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 365  (40.3):  18%|        | 364/2000 [04:39<07:35,  3.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 147 / 365  (40.3):  18%|        | 365/2000 [04:39<32:40,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 147 / 366  (40.2):  18%|        | 365/2000 [04:39<32:40,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 367  (40.3):  18%|        | 366/2000 [04:39<32:39,  1.20s/it]\u001b[A\n",
      "Average Metric: 148 / 367  (40.3):  18%|        | 367/2000 [04:39<20:12,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 149 / 368  (40.5):  18%|        | 367/2000 [04:40<20:12,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wievs'. A: nipples B: prostores C: broader D: wives\n",
      "Answer: D: wives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 149 / 368  (40.5):  18%|        | 368/2000 [04:40<18:54,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 150 / 369  (40.7):  18%|        | 368/2000 [04:40<18:54,  1.44it/s]\u001b[A\n",
      "Average Metric: 150 / 369  (40.7):  18%|        | 369/2000 [04:40<15:07,  1.80it/s]\u001b[A\n",
      "Average Metric: 150 / 370  (40.5):  18%|        | 369/2000 [04:40<15:07,  1.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 150 / 370  (40.5):  18%|        | 370/2000 [04:40<12:57,  2.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 371  (40.7):  18%|        | 370/2000 [04:40<12:57,  2.10it/s]\u001b[A\n",
      "Average Metric: 151 / 371  (40.7):  19%|        | 371/2000 [04:41<11:52,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hmeoamde' represent when unscrambled? A: router B: mark C: fellow D: homemade\n",
      "Answer: D: homemade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'chrias'? A: germany B: chairs C: wave D: royalty\n",
      "Answer: C: wave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'saolr'. A: solar B: genre C: remark D: introduction\n",
      "Answer: D: introduction\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aountccs'. A: accounts B: freebsd C: verizon D: dawn\n",
      "Answer: D: dawn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 151 / 372  (40.6):  19%|        | 371/2000 [04:44<11:52,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 151 / 372  (40.6):  19%|        | 372/2000 [04:44<38:06,  1.40s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 373  (40.8):  19%|        | 372/2000 [04:45<38:06,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 152 / 373  (40.8):  19%|        | 373/2000 [04:45<28:52,  1.06s/it]\u001b[A\n",
      "Average Metric: 152 / 374  (40.6):  19%|        | 373/2000 [04:45<28:52,  1.06s/it]\u001b[A\n",
      "Average Metric: 152 / 375  (40.5):  19%|        | 374/2000 [04:45<28:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 152 / 375  (40.5):  19%|        | 375/2000 [04:45<18:30,  1.46it/s]\u001b[A\n",
      "Average Metric: 153 / 376  (40.7):  19%|        | 375/2000 [04:45<18:30,  1.46it/s]\u001b[A\n",
      "Average Metric: 153 / 377  (40.6):  19%|        | 376/2000 [04:45<18:29,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fnitocun' represent when unscrambled? A: signup B: horny C: aspect D: function\n",
      "Answer: D: function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 378  (40.5):  19%|        | 377/2000 [04:46<18:29,  1.46it/s]\u001b[A\n",
      "Average Metric: 153 / 378  (40.5):  19%|        | 378/2000 [04:46<11:37,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'atecvitiis'. A: activities B: spin C: messaging D: worldsex\n",
      "Answer: D: worldsex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 379  (40.4):  19%|        | 378/2000 [04:46<11:37,  2.33it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 379  (40.4):  19%|        | 379/2000 [04:46<11:38,  2.32it/s]\u001b[A\n",
      "Average Metric: 153 / 380  (40.3):  19%|        | 379/2000 [04:46<11:38,  2.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'itliaan'? A: marathon B: jobs C: zoom D: italian\n",
      "Answer: D: italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 381  (40.2):  19%|        | 380/2000 [04:47<11:37,  2.32it/s]\u001b[A\n",
      "Average Metric: 153 / 381  (40.2):  19%|        | 381/2000 [04:47<13:31,  1.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tbaelts'. A: loading B: delivery C: tablets D: webster\n",
      "Answer: D: webster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'teaxs'. A: trained B: towels C: texas D: surprisingly\n",
      "Answer: D: surprisingly\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'boristl'. A: bristol B: beginning C: marie D: fully\n",
      "Answer: D: fully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 382  (40.1):  19%|        | 381/2000 [04:50<13:31,  1.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 153 / 382  (40.1):  19%|        | 382/2000 [04:50<24:38,  1.09it/s]\u001b[A\n",
      "Average Metric: 153 / 383  (39.9):  19%|        | 382/2000 [04:50<24:38,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lses'? A: less B: local C: catholic D: attempt\n",
      "Answer: less\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 153 / 384  (39.8):  19%|        | 383/2000 [04:51<24:37,  1.09it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 384  (39.8):  19%|        | 384/2000 [04:51<20:46,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 385  (39.7):  19%|        | 384/2000 [04:51<20:46,  1.30it/s]\u001b[A\n",
      "Average Metric: 153 / 385  (39.7):  19%|        | 385/2000 [04:51<17:40,  1.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ulnkie'? A: local B: enforcement C: usgs D: unlike\n",
      "Answer: D: unlike\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'apnetnimopt'. A: donation B: appointment C: language D: brunswick\n",
      "Answer: D: brunswick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 386  (39.6):  19%|        | 385/2000 [04:52<17:40,  1.52it/s]\u001b[A\n",
      "Average Metric: 153 / 386  (39.6):  19%|        | 386/2000 [04:52<16:25,  1.64it/s]\u001b[A\n",
      "Average Metric: 153 / 387  (39.5):  19%|        | 386/2000 [04:52<16:25,  1.64it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 153 / 387  (39.5):  19%|        | 387/2000 [04:52<13:31,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'crsuoe' represent when unscrambled? A: affiliation B: course C: ideas D: congo\n",
      "Answer: C: ideas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 154 / 388  (39.7):  19%|        | 387/2000 [04:53<13:31,  1.99it/s]\u001b[A\n",
      "Average Metric: 154 / 388  (39.7):  19%|        | 388/2000 [04:53<15:42,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 154 / 389  (39.6):  19%|        | 388/2000 [04:53<15:42,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'uifonrm' represent when unscrambled? A: flies B: stimulation C: uniform D: traditionally\n",
      "Answer: D: traditionally\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cmoamnd'. A: extras B: command C: temperature D: sanders\n",
      "Answer: C: temperature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 154 / 390  (39.5):  19%|        | 389/2000 [04:56<15:41,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pgirrmmnaog'. A: whitney B: judith C: sahara D: programming\n",
      "Answer: D: programming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 154 / 390  (39.5):  20%|        | 390/2000 [04:57<31:52,  1.19s/it]\u001b[A\n",
      "Average Metric: 155 / 391  (39.6):  20%|        | 390/2000 [04:57<31:52,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'folw'? A: bargains B: flow C: fear D: limitations\n",
      "Answer: B: flow\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'crboa'. A: promote B: myth C: faqs D: cobra\n",
      "Answer: D: cobra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 392  (39.8):  20%|        | 391/2000 [04:58<31:51,  1.19s/it]\u001b[A\n",
      "Average Metric: 156 / 392  (39.8):  20%|        | 392/2000 [04:58<25:47,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 393  (39.7):  20%|        | 392/2000 [04:58<25:47,  1.04it/s]\u001b[A\n",
      "Average Metric: 156 / 394  (39.6):  20%|        | 393/2000 [04:58<25:46,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 156 / 394  (39.6):  20%|        | 394/2000 [04:58<18:47,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'enidf' to form the correct word. A: withdrawn B: accomplished C: endif D: prot\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'henadd'. A: handed B: shooting C: topics D: rendered\n",
      "Answer: D: rendered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'qenstious'? A: shipping B: postcard C: institutions D: questions\n",
      "Answer: D: questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 157 / 395  (39.7):  20%|        | 394/2000 [05:02<18:47,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 157 / 395  (39.7):  20%|        | 395/2000 [05:02<36:01,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 396  (39.6):  20%|        | 395/2000 [05:02<36:01,  1.35s/it]\u001b[A\n",
      "Average Metric: 157 / 396  (39.6):  20%|        | 396/2000 [05:02<30:00,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 157 / 397  (39.5):  20%|        | 396/2000 [05:02<30:00,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 398  (39.7):  20%|        | 397/2000 [05:03<29:59,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'root' to form the correct word. A: patterns B: scheduled C: quoted D: root\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'fcrtaos'? A: marina B: alzheimer C: lasting D: factors\n",
      "Answer: D: factors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 398  (39.7):  20%|        | 398/2000 [05:03<19:37,  1.36it/s]\u001b[A\n",
      "Average Metric: 158 / 399  (39.6):  20%|        | 398/2000 [05:03<19:37,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 158 / 399  (39.6):  20%|        | 399/2000 [05:03<18:17,  1.46it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 400  (39.8):  20%|        | 399/2000 [05:04<18:17,  1.46it/s]\u001b[A\n",
      "Average Metric: 159 / 400  (39.8):  20%|        | 400/2000 [05:04<16:34,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 159 / 401  (39.7):  20%|        | 400/2000 [05:04<16:34,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 401  (39.7):  20%|        | 401/2000 [05:04<13:20,  2.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'horus' to form the correct word. A: jimmy B: hours C: hockey D: indians\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 402  (39.6):  20%|        | 401/2000 [05:04<13:20,  2.00it/s]\u001b[A\n",
      "Average Metric: 159 / 402  (39.6):  20%|        | 402/2000 [05:04<12:03,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 159 / 403  (39.5):  20%|        | 402/2000 [05:04<12:03,  2.21it/s]\u001b[A\n",
      "Average Metric: 159 / 403  (39.5):  20%|        | 403/2000 [05:04<10:32,  2.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'crciaiioettfn'. A: sections B: certification C: orange D: violence\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ceiomuintms' represent when unscrambled? A: weird B: subsidiaries C: exact D: communities\n",
      "Answer: C: exact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'inplaoinidas'. A: indianapolis B: time C: annie D: handbook\n",
      "Answer: A: indianapolis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'svruvoris' represent when unscrambled? A: learn B: jackson C: survivors D: either\n",
      "Answer: D: either\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rncietirug'. A: symposium B: towels C: recruiting D: leak\n",
      "Answer: D: leak\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 404  (39.6):  20%|        | 403/2000 [05:08<10:32,  2.52it/s]\u001b[A\n",
      "Average Metric: 160 / 404  (39.6):  20%|        | 404/2000 [05:08<33:29,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 405  (39.8):  20%|        | 404/2000 [05:08<33:29,  1.26s/it]\u001b[A\n",
      "Average Metric: 161 / 405  (39.8):  20%|        | 405/2000 [05:08<28:45,  1.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'traes'. A: church B: tears C: acting D: incredible\n",
      "Answer: D: incredible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 406  (39.9):  20%|        | 405/2000 [05:08<28:45,  1.08s/it]\u001b[A\n",
      "Average Metric: 162 / 406  (39.9):  20%|        | 406/2000 [05:09<21:13,  1.25it/s]\u001b[A\n",
      "Average Metric: 162 / 407  (39.8):  20%|        | 406/2000 [05:09<21:13,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 407  (39.8):  20%|        | 407/2000 [05:09<16:14,  1.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gbmh' represent when unscrambled? A: reporters B: gmbh C: somewhere D: surprisingly\n",
      "Answer: B: gmbh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tgboao' to form the correct word. A: tobago B: song C: reel D: mighty\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 163 / 408  (40.0):  20%|        | 407/2000 [05:10<16:14,  1.63it/s]\u001b[A\n",
      "Average Metric: 163 / 408  (40.0):  20%|        | 408/2000 [05:10<23:52,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ilnmemept'. A: bankruptcy B: implement C: elite D: relatives\n",
      "Answer: A: bankruptcy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'verteiais'? A: empty B: vernon C: varieties D: semantics\n",
      "Answer: C: varieties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'itaitnie' represent when unscrambled? A: fails B: advantage C: initiate D: urged\n",
      "Answer: D: urged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 164 / 409  (40.1):  20%|        | 408/2000 [05:13<23:52,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 164 / 409  (40.1):  20%|        | 409/2000 [05:13<39:45,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 164 / 410  (40.0):  20%|        | 409/2000 [05:13<39:45,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 411  (40.1):  20%|        | 410/2000 [05:14<39:43,  1.50s/it]\u001b[A\n",
      "Average Metric: 165 / 411  (40.1):  21%|        | 411/2000 [05:14<24:32,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 412  (40.0):  21%|        | 411/2000 [05:14<24:32,  1.08it/s]\u001b[A\n",
      "Average Metric: 165 / 412  (40.0):  21%|        | 412/2000 [05:14<20:38,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'teils' to form the correct word. A: spell B: agreements C: tiles D: strengths\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aairdn'. A: grams B: analysts C: pour D: adrian\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 413  (40.0):  21%|        | 412/2000 [05:14<20:38,  1.28it/s]\u001b[A\n",
      "Average Metric: 165 / 413  (40.0):  21%|        | 413/2000 [05:14<18:22,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'caihamrn'. A: detroit B: hearts C: specific D: chairman\n",
      "Answer: D: chairman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 165 / 414  (39.9):  21%|        | 413/2000 [05:15<18:22,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 165 / 414  (39.9):  21%|        | 414/2000 [05:15<15:39,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 415  (39.8):  21%|        | 414/2000 [05:15<15:39,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 416  (39.7):  21%|        | 415/2000 [05:15<15:39,  1.69it/s]\u001b[A\n",
      "Average Metric: 165 / 416  (39.7):  21%|        | 416/2000 [05:15<10:32,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'barigans'. A: contained B: bargains C: pizza D: satisfied\n",
      "Answer: B: bargains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 417  (39.6):  21%|        | 416/2000 [05:16<10:32,  2.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 165 / 417  (39.6):  21%|        | 417/2000 [05:16<10:49,  2.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 418  (39.5):  21%|        | 417/2000 [05:16<10:49,  2.44it/s]\u001b[A\n",
      "Average Metric: 165 / 418  (39.5):  21%|        | 418/2000 [05:16<09:57,  2.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bool'. A: plants B: bool C: injury D: particular\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 419  (39.4):  21%|        | 418/2000 [05:19<09:57,  2.65it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hwak'. A: outside B: audience C: hawk D: reed\n",
      "Answer: C: hawk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 165 / 419  (39.4):  21%|        | 419/2000 [05:19<27:51,  1.06s/it]\u001b[A\n",
      "Average Metric: 166 / 420  (39.5):  21%|        | 419/2000 [05:19<27:51,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 166 / 420  (39.5):  21%|        | 420/2000 [05:19<23:56,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 166 / 421  (39.4):  21%|        | 420/2000 [05:20<23:56,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 166 / 421  (39.4):  21%|        | 421/2000 [05:20<21:31,  1.22it/s]\u001b[A\n",
      "Average Metric: 167 / 422  (39.6):  21%|        | 421/2000 [05:20<21:31,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 423  (39.5):  21%|        | 422/2000 [05:20<21:30,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 167 / 423  (39.5):  21%|        | 423/2000 [05:20<15:17,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aetcotiidracn'. A: patent B: accreditation C: house D: roughly\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iorn'. A: textile B: constructed C: veterinary D: iron\n",
      "Answer: C: constructed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'feibr' to form the correct word. A: fiber B: stats C: invision D: hardcover\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eprimiacl'. A: moments B: empirical C: clients D: collections\n",
      "Answer: D: collections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'enltisesas' represent when unscrambled? A: restructuring B: lawrence C: essentials D: executives\n",
      "Answer: B: lawrence\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hnkus'? A: maine B: adelaide C: hunks D: motherboards\n",
      "Answer: B: adelaide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 424  (39.4):  21%|        | 423/2000 [05:25<15:17,  1.72it/s]\u001b[A\n",
      "Average Metric: 167 / 424  (39.4):  21%|        | 424/2000 [05:25<43:34,  1.66s/it]\u001b[A\n",
      "Average Metric: 167 / 425  (39.3):  21%|        | 424/2000 [05:26<43:34,  1.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 167 / 425  (39.3):  21%|       | 425/2000 [05:26<33:13,  1.27s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 426  (39.2):  21%|       | 425/2000 [05:26<33:13,  1.27s/it]\u001b[A\n",
      "Average Metric: 167 / 426  (39.2):  21%|       | 426/2000 [05:26<29:02,  1.11s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 427  (39.1):  21%|       | 426/2000 [05:27<29:02,  1.11s/it]\u001b[A\n",
      "Average Metric: 167 / 427  (39.1):  21%|       | 427/2000 [05:27<25:54,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mitoeennd'. A: diego B: mentioned C: excluding D: noticed\n",
      "Answer: D: noticed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 168 / 428  (39.3):  21%|       | 427/2000 [05:28<25:54,  1.01it/s]\u001b[A\n",
      "Average Metric: 168 / 428  (39.3):  21%|       | 428/2000 [05:28<26:29,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'airttoatcn' to form the correct word. A: transmitted B: attraction C: decisions D: incorrect\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'insdeir'. A: advertising B: ranging C: expo D: insider\n",
      "Answer: D: insider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oibtan'? A: gzip B: pull C: obtain D: generations\n",
      "Answer: C: obtain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 168 / 429  (39.2):  21%|       | 428/2000 [05:31<26:29,  1.01s/it]\u001b[A\n",
      "Average Metric: 168 / 429  (39.2):  21%|       | 429/2000 [05:31<39:20,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ecteeld'. A: travels B: elected C: crossword D: insect\n",
      "Answer: D: insect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 169 / 430  (39.3):  21%|       | 429/2000 [05:31<39:20,  1.50s/it]\u001b[A\n",
      "Average Metric: 169 / 430  (39.3):  22%|       | 430/2000 [05:31<30:08,  1.15s/it]\u001b[A\n",
      "Average Metric: 169 / 431  (39.2):  22%|       | 430/2000 [05:31<30:08,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 169 / 431  (39.2):  22%|       | 431/2000 [05:31<24:33,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eanrcta'. A: italia B: peripherals C: encarta D: compensation\n",
      "Answer: D: compensation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bidedr'. A: bidder B: continental C: distributor D: hampshire\n",
      "Answer: D: hampshire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 169 / 432  (39.1):  22%|       | 431/2000 [05:32<24:33,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 169 / 432  (39.1):  22%|       | 432/2000 [05:32<24:57,  1.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 433  (39.3):  22%|       | 432/2000 [05:33<24:57,  1.05it/s]\u001b[A\n",
      "Average Metric: 170 / 433  (39.3):  22%|       | 433/2000 [05:33<18:30,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 434  (39.2):  22%|       | 433/2000 [05:33<18:30,  1.41it/s]\u001b[A\n",
      "Average Metric: 170 / 434  (39.2):  22%|       | 434/2000 [05:33<14:40,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gernrsobeo' represent when unscrambled? A: ambient B: conviction C: blues D: greensboro\n",
      "Answer: D: greensboro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 435  (39.1):  22%|       | 434/2000 [05:34<14:40,  1.78it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 435  (39.1):  22%|       | 435/2000 [05:34<17:57,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 436  (39.2):  22%|       | 435/2000 [05:36<17:57,  1.45it/s]\u001b[A\n",
      "Average Metric: 171 / 436  (39.2):  22%|       | 436/2000 [05:36<29:46,  1.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jtsarliunos' represent when unscrambled? A: cleaned B: recipient C: journalists D: horror\n",
      "Answer: A: cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'deadctiion'? A: expression B: balancing C: msgid D: dedication\n",
      "Answer: D: dedication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 437  (39.1):  22%|       | 436/2000 [05:37<29:46,  1.14s/it]\u001b[A\n",
      "Average Metric: 171 / 437  (39.1):  22%|       | 437/2000 [05:37<26:40,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'regeufe' to form the correct word. A: cold B: colored C: refugee D: scripture\n",
      "Answer: D: scripture\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'piant' to form the correct word. A: spots B: paint C: professors D: assist\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 171 / 438  (39.0):  22%|       | 437/2000 [05:37<26:40,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 171 / 438  (39.0):  22%|       | 438/2000 [05:37<21:59,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 439  (39.0):  22%|       | 438/2000 [05:37<21:59,  1.18it/s]\u001b[A\n",
      "Average Metric: 171 / 439  (39.0):  22%|       | 439/2000 [05:37<17:10,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nwhrsoett'? A: payable B: layout C: northwest D: invasion\n",
      "Answer: D: invasion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 440  (38.9):  22%|       | 439/2000 [05:37<17:10,  1.51it/s]\u001b[A\n",
      "Average Metric: 171 / 440  (38.9):  22%|       | 440/2000 [05:38<13:01,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 441  (38.8):  22%|       | 440/2000 [05:38<13:01,  2.00it/s]\u001b[A\n",
      "Average Metric: 171 / 441  (38.8):  22%|       | 441/2000 [05:38<10:53,  2.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mntael' represent when unscrambled? A: mental B: inserted C: kazaa D: dutch\n",
      "Answer: A: mental\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'plloiw'. A: pillow B: cave C: attributes D: latvia\n",
      "Answer: A: pillow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 172 / 442  (38.9):  22%|       | 441/2000 [05:38<10:53,  2.39it/s]\u001b[A\n",
      "Average Metric: 172 / 442  (38.9):  22%|       | 442/2000 [05:38<09:46,  2.66it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 173 / 443  (39.1):  22%|       | 442/2000 [05:38<09:46,  2.66it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 444  (39.0):  22%|       | 443/2000 [05:38<09:45,  2.66it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 173 / 444  (39.0):  22%|       | 444/2000 [05:38<07:01,  3.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cutretcnosd'. A: performers B: constructed C: estimation D: assessed\n",
      "Answer: C: estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 174 / 445  (39.1):  22%|       | 444/2000 [05:39<07:01,  3.69it/s]\u001b[A\n",
      "Average Metric: 174 / 445  (39.1):  22%|       | 445/2000 [05:39<10:13,  2.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 175 / 446  (39.2):  22%|       | 445/2000 [05:39<10:13,  2.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 175 / 446  (39.2):  22%|       | 446/2000 [05:39<09:00,  2.88it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pron'. A: wednesday B: transmitted C: porn D: healthy\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tnmseaoitlis' to form the correct word. A: virginia B: drops C: absolutely D: testimonials\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 176 / 447  (39.4):  22%|       | 446/2000 [05:42<09:00,  2.88it/s]\u001b[A\n",
      "Average Metric: 176 / 447  (39.4):  22%|       | 447/2000 [05:42<24:24,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'gallieers'. A: galleries B: sphere C: neglect D: heart\n",
      "Answer: D: heart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 176 / 448  (39.3):  22%|       | 447/2000 [05:42<24:24,  1.06it/s]\u001b[A\n",
      "Average Metric: 176 / 448  (39.3):  22%|       | 448/2000 [05:42<20:55,  1.24it/s]\u001b[A\n",
      "Average Metric: 176 / 449  (39.2):  22%|       | 448/2000 [05:43<20:55,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 176 / 449  (39.2):  22%|       | 449/2000 [05:43<21:13,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 450  (39.3):  22%|       | 449/2000 [05:43<21:13,  1.22it/s]\u001b[A\n",
      "Average Metric: 177 / 450  (39.3):  22%|       | 450/2000 [05:43<16:35,  1.56it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 451  (39.2):  22%|       | 450/2000 [05:43<16:35,  1.56it/s]\u001b[A\n",
      "Average Metric: 177 / 451  (39.2):  23%|       | 451/2000 [05:44<12:57,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 452  (39.2):  23%|       | 451/2000 [05:44<12:57,  1.99it/s]\u001b[A\n",
      "Average Metric: 177 / 452  (39.2):  23%|       | 452/2000 [05:44<11:25,  2.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sonw' represent when unscrambled? A: someone B: snow C: factory D: riley\n",
      "Answer: B: snow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 177 / 453  (39.1):  23%|       | 452/2000 [05:44<11:25,  2.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 454  (39.0):  23%|       | 453/2000 [05:44<11:25,  2.26it/s]\u001b[A\n",
      "Average Metric: 177 / 454  (39.0):  23%|       | 454/2000 [05:44<08:43,  2.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'awrdas'. A: dana B: presenting C: awards D: toddler\n",
      "Answer: D: toddler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ptiols'. A: proposed B: issuance C: pilots D: pens\n",
      "Answer: C: pilots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gruoemt' represent when unscrambled? A: demo B: sofa C: disney D: gourmet\n",
      "Answer: D: gourmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 455  (39.1):  23%|       | 454/2000 [05:46<08:43,  2.95it/s]\u001b[A\n",
      "Average Metric: 178 / 455  (39.1):  23%|       | 455/2000 [05:46<16:26,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 456  (39.0):  23%|       | 455/2000 [05:46<16:26,  1.57it/s]\u001b[A\n",
      "Average Metric: 178 / 456  (39.0):  23%|       | 456/2000 [05:46<15:12,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'isnutnmrtael'? A: attended B: instrumental C: phillips D: investigator\n",
      "Answer: B: instrumental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 179 / 457  (39.2):  23%|       | 456/2000 [05:48<15:12,  1.69it/s]\u001b[A\n",
      "Average Metric: 179 / 457  (39.2):  23%|       | 457/2000 [05:48<25:27,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'byus'. A: informed B: regulations C: buys D: various\n",
      "Answer: D: various\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 179 / 458  (39.1):  23%|       | 457/2000 [05:48<25:27,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 179 / 458  (39.1):  23%|       | 458/2000 [05:48<19:20,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 180 / 459  (39.2):  23%|       | 458/2000 [05:49<19:20,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 180 / 459  (39.2):  23%|       | 459/2000 [05:49<20:18,  1.27it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 181 / 460  (39.3):  23%|       | 459/2000 [05:49<20:18,  1.27it/s]\u001b[A\n",
      "Average Metric: 181 / 460  (39.3):  23%|       | 460/2000 [05:50<15:43,  1.63it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 182 / 461  (39.5):  23%|       | 460/2000 [05:50<15:43,  1.63it/s]\u001b[A\n",
      "Average Metric: 182 / 461  (39.5):  23%|       | 461/2000 [05:50<13:06,  1.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 462  (39.6):  23%|       | 461/2000 [05:50<13:06,  1.96it/s]\u001b[A\n",
      "Average Metric: 183 / 462  (39.6):  23%|       | 462/2000 [05:50<10:36,  2.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tarp'. A: trap B: outlined C: procurement D: electronic\n",
      "Answer: A: trap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'corsrswod' to form the correct word. A: phase B: relate C: crossword D: francisco\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 183 / 463  (39.5):  23%|       | 462/2000 [05:51<10:36,  2.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 183 / 463  (39.5):  23%|       | 463/2000 [05:51<15:41,  1.63it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bucnoe'. A: technology B: milwaukee C: hottest D: bounce\n",
      "Answer: D: bounce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 464  (39.4):  23%|       | 463/2000 [05:53<15:41,  1.63it/s]\u001b[A\n",
      "Average Metric: 183 / 464  (39.4):  23%|       | 464/2000 [05:53<28:09,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bnirg' represent when unscrambled? A: kodak B: clean C: bring D: andy\n",
      "Answer: C: bring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 465  (39.4):  23%|       | 464/2000 [05:54<28:09,  1.10s/it]\u001b[A\n",
      "Average Metric: 183 / 465  (39.4):  23%|       | 465/2000 [05:54<26:30,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 466  (39.3):  23%|       | 465/2000 [05:54<26:30,  1.04s/it]\u001b[A\n",
      "Average Metric: 183 / 466  (39.3):  23%|       | 466/2000 [05:54<20:13,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 467  (39.4):  23%|       | 466/2000 [05:55<20:13,  1.26it/s]\u001b[A\n",
      "Average Metric: 184 / 467  (39.4):  23%|       | 467/2000 [05:55<17:50,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 468  (39.3):  23%|       | 467/2000 [05:55<17:50,  1.43it/s]\u001b[A\n",
      "Average Metric: 184 / 468  (39.3):  23%|       | 468/2000 [05:55<13:51,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 469  (39.2):  23%|       | 468/2000 [05:55<13:51,  1.84it/s]\u001b[A\n",
      "Average Metric: 184 / 469  (39.2):  23%|       | 469/2000 [05:55<11:50,  2.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 185 / 470  (39.4):  23%|       | 469/2000 [05:56<11:50,  2.16it/s]\u001b[A\n",
      "Average Metric: 185 / 470  (39.4):  24%|       | 470/2000 [05:56<13:24,  1.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uionn'? A: stopping B: casio C: humanitarian D: union\n",
      "Answer: D: union\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tucrk' to form the correct word. A: welfare B: together C: truck D: navy\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 185 / 471  (39.3):  24%|       | 470/2000 [05:58<13:24,  1.90it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 185 / 471  (39.3):  24%|       | 471/2000 [05:58<26:52,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 185 / 472  (39.2):  24%|       | 471/2000 [05:59<26:52,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 185 / 472  (39.2):  24%|       | 472/2000 [05:59<23:03,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cibmrdgae'? A: bookmark B: statutes C: cambridge D: sensor\n",
      "Answer: B: statutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 473  (39.3):  24%|       | 472/2000 [06:00<23:03,  1.10it/s]\u001b[A\n",
      "Average Metric: 186 / 473  (39.3):  24%|       | 473/2000 [06:00<22:00,  1.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oaitmpl'. A: chat B: buys C: optimal D: within\n",
      "Answer: D: within\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 474  (39.5):  24%|       | 473/2000 [06:00<22:00,  1.16it/s]\u001b[A\n",
      "Average Metric: 187 / 474  (39.5):  24%|       | 474/2000 [06:00<19:22,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 475  (39.4):  24%|       | 474/2000 [06:00<19:22,  1.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tnhak' represent when unscrambled? A: pregnancy B: golden C: frankfurt D: thank\n",
      "Answer: D: thank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 188 / 476  (39.5):  24%|       | 475/2000 [06:00<19:21,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 188 / 476  (39.5):  24%|       | 476/2000 [06:00<11:25,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dknirs'? A: perhaps B: drinks C: enthusiasm D: telescope\n",
      "Answer: D: telescope\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scile'? A: products B: irvine C: intense D: slice\n",
      "Answer: D: slice\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'faounitncl' represent when unscrambled? A: conventional B: ministry C: functional D: dildos\n",
      "Answer: A: conventional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aiudo' to form the correct word. A: baths B: slice C: buck D: audio\n",
      "Answer: D: audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 188 / 477  (39.4):  24%|       | 476/2000 [06:01<11:25,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 188 / 477  (39.4):  24%|       | 477/2000 [06:01<13:27,  1.89it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 478  (39.5):  24%|       | 477/2000 [06:01<13:27,  1.89it/s]\u001b[A\n",
      "Average Metric: 189 / 478  (39.5):  24%|       | 478/2000 [06:01<10:58,  2.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 479  (39.5):  24%|       | 478/2000 [06:02<10:58,  2.31it/s]\u001b[A\n",
      "Average Metric: 189 / 479  (39.5):  24%|       | 479/2000 [06:02<09:55,  2.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'kron'. A: google B: hearings C: korn D: enough\n",
      "Answer: A: google\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 189 / 480  (39.4):  24%|       | 479/2000 [06:02<09:55,  2.55it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 480  (39.4):  24%|       | 480/2000 [06:02<11:33,  2.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 481  (39.3):  24%|       | 480/2000 [06:05<11:33,  2.19it/s]\u001b[A\n",
      "Average Metric: 189 / 481  (39.3):  24%|       | 481/2000 [06:05<27:33,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 482  (39.4):  24%|       | 481/2000 [06:06<27:33,  1.09s/it]\u001b[A\n",
      "Average Metric: 190 / 482  (39.4):  24%|       | 482/2000 [06:06<26:57,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'etinibxihos'? A: begins B: cheney C: tion D: exhibitions\n",
      "Answer: B: cheney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 190 / 483  (39.3):  24%|       | 482/2000 [06:06<26:57,  1.07s/it]\u001b[A\n",
      "Average Metric: 190 / 483  (39.3):  24%|       | 483/2000 [06:06<21:07,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dnimoatoin'? A: auditorium B: governor C: verse D: domination\n",
      "Answer: A: auditorium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 190 / 484  (39.3):  24%|       | 483/2000 [06:07<21:07,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 190 / 484  (39.3):  24%|       | 484/2000 [06:07<23:06,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'metrhos'? A: amplifier B: mountains C: plains D: mothers\n",
      "Answer: A: amplifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 485  (39.4):  24%|       | 484/2000 [06:09<23:06,  1.09it/s]\u001b[A\n",
      "Average Metric: 191 / 485  (39.4):  24%|       | 485/2000 [06:09<29:03,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mrroirs'. A: bennett B: releases C: mirrors D: adapted\n",
      "Answer: D: adapted\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'muidem'? A: medium B: dealer C: enlarge D: auburn\n",
      "Answer: medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 486  (39.3):  24%|       | 485/2000 [06:11<29:03,  1.15s/it]\u001b[A\n",
      "Average Metric: 191 / 486  (39.3):  24%|       | 486/2000 [06:11<34:11,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 487  (39.2):  24%|       | 486/2000 [06:11<34:11,  1.36s/it]\u001b[A\n",
      "Average Metric: 191 / 487  (39.2):  24%|       | 487/2000 [06:11<25:59,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 192 / 488  (39.3):  24%|       | 487/2000 [06:11<25:59,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'firnugshnis'. A: consumption B: poetry C: furnishings D: preceding\n",
      "Answer: D: preceding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aeswnerd'? A: answered B: caribbean C: senior D: sunglasses\n",
      "Answer: D: sunglasses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 489  (39.3):  24%|       | 488/2000 [06:12<25:58,  1.03s/it]\u001b[A\n",
      "Average Metric: 192 / 489  (39.3):  24%|       | 489/2000 [06:12<20:34,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 193 / 490  (39.4):  24%|       | 489/2000 [06:12<20:34,  1.22it/s]\u001b[A\n",
      "Average Metric: 193 / 490  (39.4):  24%|       | 490/2000 [06:12<17:01,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 491  (39.3):  24%|       | 490/2000 [06:13<17:01,  1.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'baet'. A: climbing B: opinions C: beat D: relates\n",
      "Answer: D: relates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 193 / 491  (39.3):  25%|       | 491/2000 [06:13<15:49,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 492  (39.2):  25%|       | 491/2000 [06:13<15:49,  1.59it/s]\u001b[A\n",
      "Average Metric: 193 / 492  (39.2):  25%|       | 492/2000 [06:13<13:18,  1.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rahecl'. A: lily B: insured C: paste D: rachel\n",
      "Answer: D: rachel\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'acdrae'. A: inventory B: choose C: arcade D: compliance\n",
      "Answer: C: arcade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 194 / 493  (39.4):  25%|       | 492/2000 [06:13<13:18,  1.89it/s]\u001b[A\n",
      "Average Metric: 194 / 493  (39.4):  25%|       | 493/2000 [06:13<10:53,  2.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dmeos'. A: cologne B: demos C: subset D: correctly\n",
      "Answer: D: correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 195 / 494  (39.5):  25%|       | 493/2000 [06:14<10:53,  2.31it/s]\u001b[A\n",
      "Average Metric: 195 / 494  (39.5):  25%|       | 494/2000 [06:14<13:29,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'drkiinng'? A: shaw B: understand C: items D: drinking\n",
      "Answer: D: drinking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 495  (39.4):  25%|       | 494/2000 [06:16<13:29,  1.86it/s]\u001b[A\n",
      "Average Metric: 195 / 495  (39.4):  25%|       | 495/2000 [06:16<20:27,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rrpieas' represent when unscrambled? A: topical B: blast C: finances D: repairs\n",
      "Answer: A: topical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 496  (39.5):  25%|       | 495/2000 [06:17<20:27,  1.23it/s]\u001b[A\n",
      "Average Metric: 196 / 496  (39.5):  25%|       | 496/2000 [06:17<26:31,  1.06s/it]\u001b[A\n",
      "Average Metric: 197 / 497  (39.6):  25%|       | 496/2000 [06:18<26:31,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 197 / 497  (39.6):  25%|       | 497/2000 [06:18<22:14,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 198 / 498  (39.8):  25%|       | 497/2000 [06:19<22:14,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 198 / 498  (39.8):  25%|       | 498/2000 [06:19<21:15,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 499  (39.9):  25%|       | 498/2000 [06:19<21:15,  1.18it/s]\u001b[A\n",
      "Average Metric: 199 / 499  (39.9):  25%|       | 499/2000 [06:19<16:31,  1.51it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 200 / 500  (40.0):  25%|       | 499/2000 [06:19<16:31,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 200 / 500  (40.0):  25%|       | 500/2000 [06:19<12:58,  1.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anaitctotrs'. A: methods B: specialist C: hotels D: attractions\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'coorls' represent when unscrambled? A: distinct B: bigger C: colors D: paid\n",
      "Answer: D: paid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ltmioitian' to form the correct word. A: marking B: amps C: alicia D: limitation\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gredas' represent when unscrambled? A: grades B: exclusion C: fell D: cutter\n",
      "Answer: D: cutter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 201 / 501  (40.1):  25%|       | 500/2000 [06:22<12:58,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 201 / 501  (40.1):  25%|       | 501/2000 [06:22<33:19,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'etchail'. A: ethical B: dentists C: strong D: accordingly\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rlol'. A: roll B: newsletter C: heavily D: parameter\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'shiglt'. A: geneva B: slight C: scheduled D: fleet\n",
      "Answer: D: fleet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iechns'. A: knowledgestorm B: inches C: writings D: jill\n",
      "Answer: D: jill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 201 / 502  (40.0):  25%|       | 501/2000 [06:24<33:19,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 502  (40.0):  25%|       | 502/2000 [06:24<35:49,  1.43s/it]\u001b[A\n",
      "Average Metric: 201 / 503  (40.0):  25%|       | 502/2000 [06:24<35:49,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'colepud'? A: promote B: doors C: mission D: coupled\n",
      "Answer: B: doors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 201 / 504  (39.9):  25%|       | 503/2000 [06:24<35:47,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 201 / 504  (39.9):  25%|       | 504/2000 [06:24<19:55,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peslyoina'? A: exports B: cited C: polynesia D: defining\n",
      "Answer: D: defining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 202 / 505  (40.0):  25%|       | 504/2000 [06:25<19:55,  1.25it/s]\u001b[A\n",
      "Average Metric: 202 / 505  (40.0):  25%|       | 505/2000 [06:25<18:28,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 202 / 506  (39.9):  25%|       | 505/2000 [06:25<18:28,  1.35it/s]\u001b[A\n",
      "Average Metric: 202 / 506  (39.9):  25%|       | 506/2000 [06:25<15:02,  1.66it/s]\u001b[A\n",
      "Average Metric: 203 / 507  (40.0):  25%|       | 506/2000 [06:25<15:02,  1.66it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 203 / 508  (40.0):  25%|       | 507/2000 [06:25<15:01,  1.66it/s]\u001b[A\n",
      "Average Metric: 203 / 508  (40.0):  25%|       | 508/2000 [06:25<10:25,  2.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 509  (40.1):  25%|       | 508/2000 [06:25<10:25,  2.38it/s]\u001b[A\n",
      "Average Metric: 204 / 510  (40.0):  25%|       | 509/2000 [06:25<10:25,  2.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 204 / 510  (40.0):  26%|       | 510/2000 [06:25<06:57,  3.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 511  (40.1):  26%|       | 510/2000 [06:26<06:57,  3.57it/s]\u001b[A\n",
      "Average Metric: 205 / 511  (40.1):  26%|       | 511/2000 [06:26<07:18,  3.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'btuetr' to form the correct word. A: bodies B: violin C: smith D: butter\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ilusinn'? A: accommodations B: propaganda C: insulin D: keeps\n",
      "Answer: D: keeps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'stmoopauthn' represent when unscrambled? A: southampton B: specialists C: preference D: harvard\n",
      "Answer: A: southampton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 512  (40.0):  26%|       | 511/2000 [06:28<07:18,  3.40it/s]\u001b[A\n",
      "Average Metric: 205 / 512  (40.0):  26%|       | 512/2000 [06:28<22:12,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mtruae' to form the correct word. A: mature B: live C: nevertheless D: tariff\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pcik'. A: future B: pick C: expressly D: cumshot\n",
      "Answer: A: future\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 513  (40.0):  26%|       | 512/2000 [06:29<22:12,  1.12it/s]\u001b[A\n",
      "Average Metric: 205 / 513  (40.0):  26%|       | 513/2000 [06:29<22:52,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 514  (39.9):  26%|       | 513/2000 [06:30<22:52,  1.08it/s]\u001b[A\n",
      "Average Metric: 205 / 514  (39.9):  26%|       | 514/2000 [06:30<17:59,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 515  (39.8):  26%|       | 514/2000 [06:30<17:59,  1.38it/s]\u001b[A\n",
      "Average Metric: 205 / 515  (39.8):  26%|       | 515/2000 [06:30<16:32,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'iastnnllig' represent when unscrambled? A: installing B: availability C: audience D: biotechnology\n",
      "Answer: A: installing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 516  (39.7):  26%|       | 515/2000 [06:31<16:32,  1.50it/s]\u001b[A\n",
      "Average Metric: 205 / 516  (39.7):  26%|       | 516/2000 [06:31<17:50,  1.39it/s]\u001b[A\n",
      "Average Metric: 205 / 517  (39.7):  26%|       | 516/2000 [06:31<17:50,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 205 / 517  (39.7):  26%|       | 517/2000 [06:31<14:20,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dicss'? A: venue B: renowned C: discs D: moderators\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bogrhut'. A: farmer B: brought C: racism D: acts\n",
      "Answer: D: acts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 206 / 518  (39.8):  26%|       | 517/2000 [06:35<14:20,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 206 / 518  (39.8):  26%|       | 518/2000 [06:35<34:13,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dtboiutiisrn'. A: exceed B: mono C: capture D: distribution\n",
      "Answer: D: distribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 519  (39.7):  26%|       | 518/2000 [06:35<34:13,  1.39s/it]\u001b[A\n",
      "Average Metric: 206 / 519  (39.7):  26%|       | 519/2000 [06:35<30:51,  1.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cfrieited'. A: urls B: watershed C: certified D: pharmacology\n",
      "Answer: D: pharmacology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tankhs' represent when unscrambled? A: stainless B: finger C: thanks D: prayer\n",
      "Answer: C: thanks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 520  (39.6):  26%|       | 519/2000 [06:37<30:51,  1.25s/it]\u001b[A\n",
      "Average Metric: 206 / 520  (39.6):  26%|       | 520/2000 [06:37<30:55,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 207 / 521  (39.7):  26%|       | 520/2000 [06:37<30:55,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 522  (39.8):  26%|       | 521/2000 [06:37<30:54,  1.25s/it]\u001b[A\n",
      "Average Metric: 208 / 522  (39.8):  26%|       | 522/2000 [06:37<17:44,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'exprssely'. A: changed B: detected C: expressly D: startup\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 208 / 523  (39.8):  26%|       | 522/2000 [06:38<17:44,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 208 / 523  (39.8):  26%|       | 523/2000 [06:38<19:13,  1.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 524  (39.7):  26%|       | 523/2000 [06:38<19:13,  1.28it/s]\u001b[A\n",
      "Average Metric: 208 / 524  (39.7):  26%|       | 524/2000 [06:38<15:49,  1.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iitamtne'. A: hannah B: wayne C: intimate D: organization\n",
      "Answer: D: organization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 525  (39.6):  26%|       | 524/2000 [06:39<15:49,  1.55it/s]\u001b[A\n",
      "Average Metric: 208 / 525  (39.6):  26%|       | 525/2000 [06:39<20:07,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 526  (39.7):  26%|       | 525/2000 [06:40<20:07,  1.22it/s]\u001b[A\n",
      "Average Metric: 209 / 526  (39.7):  26%|       | 526/2000 [06:40<16:26,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 209 / 527  (39.7):  26%|       | 526/2000 [06:41<16:26,  1.49it/s]\u001b[A\n",
      "Average Metric: 209 / 527  (39.7):  26%|       | 527/2000 [06:41<21:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 210 / 528  (39.8):  26%|       | 527/2000 [06:41<21:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 210 / 528  (39.8):  26%|       | 528/2000 [06:41<18:04,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ciolears' to form the correct word. A: rapidly B: kurt C: correctly D: calories\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 529  (39.9):  26%|       | 528/2000 [06:42<18:04,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 529  (39.9):  26%|       | 529/2000 [06:42<18:03,  1.36it/s]\u001b[A\n",
      "Average Metric: 211 / 530  (39.8):  26%|       | 529/2000 [06:42<18:03,  1.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tkcurs'. A: condo B: trucks C: establishments D: advertisers\n",
      "Answer: C: establishments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aoinnto'. A: physician B: interval C: antonio D: unable\n",
      "Answer: D: unable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stonloius'. A: italicized B: problem C: solutions D: dairy\n",
      "Answer: C: solutions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'yuong' to form the correct word. A: peters B: different C: human D: young\n",
      "Answer: yuong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bstaowna' to form the correct word. A: botswana B: files C: fifth D: oncology\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tnraxasesul'? A: judy B: accent C: shipments D: transsexual\n",
      "Answer: B: accent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 531  (39.7):  26%|       | 530/2000 [06:46<18:02,  1.36it/s]\u001b[A\n",
      "Average Metric: 211 / 531  (39.7):  27%|       | 531/2000 [06:46<31:16,  1.28s/it]\u001b[A\n",
      "Average Metric: 211 / 532  (39.7):  27%|       | 531/2000 [06:47<31:16,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 211 / 532  (39.7):  27%|       | 532/2000 [06:47<27:54,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 533  (39.8):  27%|       | 532/2000 [06:47<27:54,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 533  (39.8):  27%|       | 533/2000 [06:47<22:16,  1.10it/s]\u001b[A\n",
      "Average Metric: 212 / 534  (39.7):  27%|       | 533/2000 [06:47<22:16,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'irtno' to form the correct word. A: comfort B: oxide C: manufacturing D: intro\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pgae'. A: ignored B: page C: attach D: conservative\n",
      "Answer: C: attach\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'celtuurs' represent when unscrambled? A: ringtones B: cultures C: pics D: lender\n",
      "Answer: C: pics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 213 / 535  (39.8):  27%|       | 534/2000 [06:48<22:15,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 213 / 535  (39.8):  27%|       | 535/2000 [06:48<17:27,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 214 / 536  (39.9):  27%|       | 535/2000 [06:48<17:27,  1.40it/s]\u001b[A\n",
      "Average Metric: 214 / 536  (39.9):  27%|       | 536/2000 [06:48<14:25,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dsisopal' to form the correct word. A: tucker B: suspension C: disposal D: ebooks\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ieirethnd'. A: predictions B: inherited C: decreased D: acdbentity\n",
      "Answer: D: acdbentity\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'paaleinrmt'? A: competence B: parliament C: analyze D: signature\n",
      "Answer: C: analyze\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rageloutr'. A: regulator B: console C: nursing D: croatia\n",
      "Answer: A: regulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bciabill'. A: piece B: real C: biblical D: switch\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 214 / 537  (39.9):  27%|       | 536/2000 [06:51<14:25,  1.69it/s]\u001b[A\n",
      "Average Metric: 214 / 537  (39.9):  27%|       | 537/2000 [06:51<27:04,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 538  (40.0):  27%|       | 537/2000 [06:51<27:04,  1.11s/it]\u001b[A\n",
      "Average Metric: 215 / 538  (40.0):  27%|       | 538/2000 [06:51<24:20,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stituaions'. A: situations B: xerox C: fossil D: harm\n",
      "Answer: A: situations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hgih'? A: atomic B: high C: screen D: scottish\n",
      "Answer: A: atomic\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'invetneics' represent when unscrambled? A: fans B: incentives C: wyoming D: haiti\n",
      "Answer: B: incentives\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'frarems' represent when unscrambled? A: diaries B: seeds C: farmers D: exempt\n",
      "Answer: D: exempt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 216 / 539  (40.1):  27%|       | 538/2000 [06:52<24:20,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 216 / 539  (40.1):  27%|       | 539/2000 [06:52<24:22,  1.00s/it]\u001b[A\n",
      "Average Metric: 217 / 540  (40.2):  27%|       | 539/2000 [06:53<24:22,  1.00s/it]\u001b[A\n",
      "Average Metric: 218 / 541  (40.3):  27%|       | 540/2000 [06:53<24:21,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 218 / 541  (40.3):  27%|       | 541/2000 [06:53<16:35,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'upicnmog' to form the correct word. A: looks B: existing C: wool D: upcoming\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'psotage'? A: tactics B: postage C: smoking D: concrete\n",
      "Answer: B: postage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eelticitrcy' represent when unscrambled? A: electricity B: posted C: trivia D: article\n",
      "Answer: A: electricity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 218 / 542  (40.2):  27%|       | 541/2000 [06:58<16:35,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 218 / 542  (40.2):  27%|       | 542/2000 [06:58<39:00,  1.60s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 218 / 543  (40.1):  27%|       | 542/2000 [06:58<39:00,  1.60s/it]\u001b[A\n",
      "Average Metric: 218 / 543  (40.1):  27%|       | 543/2000 [06:58<30:55,  1.27s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 219 / 544  (40.3):  27%|       | 543/2000 [06:58<30:55,  1.27s/it]\u001b[A\n",
      "Average Metric: 219 / 544  (40.3):  27%|       | 544/2000 [06:58<24:33,  1.01s/it]\u001b[A\n",
      "Average Metric: 219 / 545  (40.2):  27%|       | 544/2000 [06:58<24:33,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pyelad' to form the correct word. A: played B: warrant C: perfume D: worldwide\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 546  (40.3):  27%|       | 545/2000 [07:00<24:32,  1.01s/it]\u001b[A\n",
      "Average Metric: 220 / 546  (40.3):  27%|       | 546/2000 [07:00<21:11,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 547  (40.2):  27%|       | 546/2000 [07:00<21:11,  1.14it/s]\u001b[A\n",
      "Average Metric: 220 / 547  (40.2):  27%|       | 547/2000 [07:00<17:20,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 221 / 548  (40.3):  27%|       | 547/2000 [07:00<17:20,  1.40it/s]\u001b[A\n",
      "Average Metric: 221 / 548  (40.3):  27%|       | 548/2000 [07:00<14:32,  1.66it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 221 / 549  (40.3):  27%|       | 548/2000 [07:00<14:32,  1.66it/s]\u001b[A\n",
      "Average Metric: 221 / 549  (40.3):  27%|       | 549/2000 [07:00<13:34,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ltitle'. A: little B: tobacco C: martha D: investigate\n",
      "Answer: A: little\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 550  (40.4):  27%|       | 549/2000 [07:02<13:34,  1.78it/s]\u001b[A\n",
      "Average Metric: 222 / 550  (40.4):  28%|       | 550/2000 [07:02<19:35,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pcaks' represent when unscrambled? A: ordinance B: packs C: come D: sleep\n",
      "Answer: A: ordinance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 551  (40.3):  28%|       | 550/2000 [07:04<19:35,  1.23it/s]\u001b[A\n",
      "Average Metric: 222 / 551  (40.3):  28%|       | 551/2000 [07:04<27:33,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 223 / 552  (40.4):  28%|       | 551/2000 [07:04<27:33,  1.14s/it]\u001b[A\n",
      "Average Metric: 223 / 552  (40.4):  28%|       | 552/2000 [07:04<21:14,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 553  (40.5):  28%|       | 552/2000 [07:05<21:14,  1.14it/s]\u001b[A\n",
      "Average Metric: 224 / 553  (40.5):  28%|       | 553/2000 [07:05<20:19,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ktnneeh' represent when unscrambled? A: downs B: connection C: kenneth D: pages\n",
      "Answer: D: pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 224 / 554  (40.4):  28%|       | 553/2000 [07:05<20:19,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 224 / 554  (40.4):  28%|       | 554/2000 [07:05<17:36,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 225 / 555  (40.5):  28%|       | 554/2000 [07:06<17:36,  1.37it/s]\u001b[A\n",
      "Average Metric: 225 / 555  (40.5):  28%|       | 555/2000 [07:06<18:59,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gorw'? A: grow B: press C: understanding D: renaissance\n",
      "Answer: A: grow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 226 / 556  (40.6):  28%|       | 555/2000 [07:08<18:59,  1.27it/s]\u001b[A\n",
      "Average Metric: 226 / 556  (40.6):  28%|       | 556/2000 [07:08<25:21,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wlak' represent when unscrambled? A: camera B: walk C: hart D: scanning\n",
      "Answer: A: camera\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'idneed' to form the correct word. A: consumption B: indeed C: admission D: hard\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 227 / 557  (40.8):  28%|       | 556/2000 [07:09<25:21,  1.05s/it]\u001b[A\n",
      "Average Metric: 227 / 557  (40.8):  28%|       | 557/2000 [07:09<22:20,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 558  (40.9):  28%|       | 557/2000 [07:10<22:20,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 558  (40.9):  28%|       | 558/2000 [07:10<25:22,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'renoindpsg' represent when unscrambled? A: gang B: torque C: responding D: clark\n",
      "Answer: D: clark\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seem'. A: plates B: suse C: viagra D: seem\n",
      "Answer: D: seem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'baem' to form the correct word. A: beam B: seeds C: webmasters D: easily\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 559  (41.0):  28%|       | 558/2000 [07:11<25:22,  1.06s/it]\u001b[A\n",
      "Average Metric: 229 / 559  (41.0):  28%|       | 559/2000 [07:11<26:19,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'jfef'? A: jeff B: mystery C: houses D: member\n",
      "Answer: B: mystery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 229 / 560  (40.9):  28%|       | 559/2000 [07:11<26:19,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 560  (40.9):  28%|       | 560/2000 [07:11<19:25,  1.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cionuyrsdte'. A: countryside B: derek C: weapons D: choice\n",
      "Answer: D: choice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 561  (41.0):  28%|       | 560/2000 [07:13<19:25,  1.24it/s]\u001b[A\n",
      "Average Metric: 230 / 561  (41.0):  28%|       | 561/2000 [07:13<28:40,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 231 / 562  (41.1):  28%|       | 561/2000 [07:14<28:40,  1.20s/it]\u001b[A\n",
      "Average Metric: 231 / 562  (41.1):  28%|       | 562/2000 [07:14<25:27,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rnfirreeg' represent when unscrambled? A: talked B: elections C: referring D: consolidation\n",
      "Answer: D: consolidation\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'igtirmmioan' to form the correct word. A: immigration B: translator C: parts D: searching\n",
      "Answer: D: searching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vurses'? A: chances B: versus C: writing D: sonic\n",
      "Answer: B: versus\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'recejt'? A: extremely B: smile C: reject D: know\n",
      "Answer: D: know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 232 / 563  (41.2):  28%|       | 562/2000 [07:15<25:27,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 232 / 563  (41.2):  28%|       | 563/2000 [07:15<25:09,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 233 / 564  (41.3):  28%|       | 563/2000 [07:15<25:09,  1.05s/it]\u001b[A\n",
      "Average Metric: 233 / 564  (41.3):  28%|       | 564/2000 [07:15<19:15,  1.24it/s]\u001b[A\n",
      "Average Metric: 233 / 565  (41.2):  28%|       | 564/2000 [07:15<19:15,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 566  (41.3):  28%|       | 565/2000 [07:16<19:14,  1.24it/s]\u001b[A\n",
      "Average Metric: 234 / 566  (41.3):  28%|       | 566/2000 [07:16<12:24,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 234 / 567  (41.3):  28%|       | 566/2000 [07:16<12:24,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 234 / 567  (41.3):  28%|       | 567/2000 [07:16<12:15,  1.95it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 235 / 568  (41.4):  28%|       | 567/2000 [07:17<12:15,  1.95it/s]\u001b[A\n",
      "Average Metric: 235 / 568  (41.4):  28%|       | 568/2000 [07:17<11:35,  2.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 569  (41.5):  28%|       | 568/2000 [07:17<11:35,  2.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 236 / 569  (41.5):  28%|       | 569/2000 [07:17<10:05,  2.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'utileizd'. A: utilized B: poetry C: preserved D: timber\n",
      "Answer: D: timber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'thuhen' represent when unscrambled? A: barton B: thehun C: teddy D: trend\n",
      "Answer: B: thehun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'poirfts'? A: existing B: portal C: samoa D: profits\n",
      "Answer: D: profits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'clirhae'. A: applying B: earliest C: natural D: charlie\n",
      "Answer: D: charlie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ataeoumtd'. A: automated B: improves C: major D: gregory\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 236 / 570  (41.4):  28%|       | 569/2000 [07:20<10:05,  2.36it/s]\u001b[A\n",
      "Average Metric: 236 / 570  (41.4):  28%|       | 570/2000 [07:20<25:03,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fdees'. A: will B: clouds C: organic D: feeds\n",
      "Answer: D: feeds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 237 / 571  (41.5):  28%|       | 570/2000 [07:21<25:03,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 237 / 571  (41.5):  29%|       | 571/2000 [07:21<26:47,  1.13s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 572  (41.4):  29%|       | 571/2000 [07:21<26:47,  1.13s/it]\u001b[A\n",
      "Average Metric: 237 / 572  (41.4):  29%|       | 572/2000 [07:21<21:02,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 573  (41.5):  29%|       | 572/2000 [07:21<21:02,  1.13it/s]\u001b[A\n",
      "Average Metric: 238 / 573  (41.5):  29%|       | 573/2000 [07:21<16:45,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 574  (41.5):  29%|       | 573/2000 [07:23<16:45,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mredchisnae' to form the correct word. A: warehouse B: baseball C: treating D: merchandise\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 238 / 574  (41.5):  29%|       | 574/2000 [07:23<20:12,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 239 / 575  (41.6):  29%|       | 574/2000 [07:23<20:12,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 239 / 575  (41.6):  29%|       | 575/2000 [07:23<15:33,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uiiotliztan'? A: utilization B: engineer C: bundle D: investigating\n",
      "Answer: D: investigating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t Socket operation on non-socket"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 239 / 576  (41.5):  29%|       | 575/2000 [07:25<15:33,  1.53it/s]\u001b[A\n",
      "Average Metric: 239 / 576  (41.5):  29%|       | 576/2000 [07:25<25:47,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 577  (41.6):  29%|       | 576/2000 [07:26<25:47,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mcoadanld' to form the correct word. A: administrator B: macdonald C: chan D: arising\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 240 / 577  (41.6):  29%|       | 577/2000 [07:26<24:52,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 578  (41.5):  29%|       | 577/2000 [07:27<24:52,  1.05s/it]\u001b[A\n",
      "Average Metric: 240 / 578  (41.5):  29%|       | 578/2000 [07:27<22:32,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 579  (41.5):  29%|       | 578/2000 [07:27<22:32,  1.05it/s]\u001b[A\n",
      "Average Metric: 240 / 579  (41.5):  29%|       | 579/2000 [07:27<17:52,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'whrieen'. A: worldwide B: joined C: wherein D: honeymoon\n",
      "Answer: D: honeymoon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 241 / 580  (41.6):  29%|       | 579/2000 [07:28<17:52,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 241 / 580  (41.6):  29%|       | 580/2000 [07:28<19:38,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'stnkaig'? A: skating B: treating C: trauma D: lambda\n",
      "Answer: skating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 242 / 581  (41.7):  29%|       | 580/2000 [07:28<19:38,  1.20it/s]\u001b[A\n",
      "Average Metric: 242 / 581  (41.7):  29%|       | 581/2000 [07:28<17:17,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 242 / 582  (41.6):  29%|       | 581/2000 [07:30<17:17,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 242 / 582  (41.6):  29%|       | 582/2000 [07:30<19:42,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cazry'. A: oncology B: crazy C: identity D: bounce\n",
      "Answer: D: bounce\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'uoeypnmlnmet' to form the correct word. A: response B: grounds C: pounds D: unemployment\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'orrpetaos'. A: authentication B: operators C: monaco D: seychelles\n",
      "Answer: D: seychelles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 242 / 583  (41.5):  29%|       | 582/2000 [07:31<19:42,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 242 / 583  (41.5):  29%|       | 583/2000 [07:31<25:13,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cchuk' represent when unscrambled? A: consequences B: chuck C: bnet D: leeds\n",
      "Answer: B: chuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 242 / 584  (41.4):  29%|       | 583/2000 [07:32<25:13,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 242 / 584  (41.4):  29%|       | 584/2000 [07:32<20:28,  1.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'naitoton'? A: embrace B: appeared C: notation D: minority\n",
      "Answer: D: minority\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'beaclrets'? A: auction B: bracelets C: bailey D: macedonia\n",
      "Answer: B: bracelets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'iidnan' represent when unscrambled? A: sale B: indian C: darkness D: stakeholders\n",
      "Answer: A: sale\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cemina'. A: cinema B: proceedings C: jewellery D: seattle\n",
      "Answer: A: cinema\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cemabhr'. A: medicaid B: cylinder C: chamber D: massage\n",
      "Answer: C: chamber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cehm'? A: chem B: steven C: checkout D: player\n",
      "Answer: B: steven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 243 / 585  (41.5):  29%|       | 584/2000 [07:35<20:28,  1.15it/s]\u001b[A\n",
      "Average Metric: 243 / 585  (41.5):  29%|       | 585/2000 [07:35<37:33,  1.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pllos'? A: distributed B: minds C: sealed D: polls\n",
      "Answer: D: polls\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Earth B: Mars C: Jupiter D: Venus\n",
      "Answer: C: Jupiter\n",
      "\n",
      "Question: What is the smallest country in the world? A: China B: Japan C: Monaco D: Vatican City\n",
      "Answer: D: Vatican City\n",
      "\n",
      "Question: What is the highest mountain in the world? A: Mount Everest B: Kangchenjunga C: K2 D: Lhotse\n",
      "Answer: A:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 244 / 586  (41.6):  29%|       | 585/2000 [07:35<37:33,  1.59s/it]\u001b[A\n",
      "Average Metric: 244 / 586  (41.6):  29%|       | 586/2000 [07:35<30:36,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 587  (41.7):  29%|       | 586/2000 [07:36<30:36,  1.30s/it]\u001b[A\n",
      "Average Metric: 245 / 587  (41.7):  29%|       | 587/2000 [07:36<27:11,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mzada'. A: aids B: literally C: mazda D: planets\n",
      "Answer: aids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'siwm' represent when unscrambled? A: ports B: swim C: traveller D: bargains\n",
      "Answer: B: swim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 588  (41.8):  29%|       | 587/2000 [07:38<27:11,  1.15s/it]\u001b[A\n",
      "Average Metric: 246 / 588  (41.8):  29%|       | 588/2000 [07:38<31:09,  1.32s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 589  (41.8):  29%|       | 588/2000 [07:38<31:09,  1.32s/it]\u001b[A\n",
      "Average Metric: 246 / 589  (41.8):  29%|       | 589/2000 [07:38<24:09,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cllosey' represent when unscrambled? A: closely B: prospective C: requiring D: coastal\n",
      "Answer: A: closely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 247 / 590  (41.9):  29%|       | 589/2000 [07:39<24:09,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 247 / 590  (41.9):  30%|       | 590/2000 [07:39<22:46,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'riceiootgnn' to form the correct word. A: creek B: recognition C: employers D: systems\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 591  (42.0):  30%|       | 590/2000 [07:39<22:46,  1.03it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 591  (42.0):  30%|       | 591/2000 [07:39<16:45,  1.40it/s]\u001b[A\n",
      "Average Metric: 248 / 592  (41.9):  30%|       | 591/2000 [07:39<16:45,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cmonuopd'. A: pregnancy B: pointed C: compound D: punch\n",
      "Answer: D: punch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 249 / 593  (42.0):  30%|       | 592/2000 [07:40<16:44,  1.40it/s]\u001b[A\n",
      "Average Metric: 249 / 593  (42.0):  30%|       | 593/2000 [07:40<11:05,  2.11it/s]\u001b[A\n",
      "Average Metric: 250 / 594  (42.1):  30%|       | 593/2000 [07:40<11:05,  2.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 595  (42.2):  30%|       | 594/2000 [07:40<11:05,  2.11it/s]\u001b[A\n",
      "Average Metric: 251 / 595  (42.2):  30%|       | 595/2000 [07:40<07:25,  3.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 251 / 596  (42.1):  30%|       | 595/2000 [07:41<07:25,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 251 / 596  (42.1):  30%|       | 596/2000 [07:41<12:14,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'riillateiby'. A: jean B: foto C: reliability D: people\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 597  (42.0):  30%|       | 596/2000 [07:42<12:14,  1.91it/s]\u001b[A\n",
      "Average Metric: 251 / 597  (42.0):  30%|       | 597/2000 [07:42<15:40,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gilud'? A: guild B: utilizing C: behaviour D: frame\n",
      "Answer: D: frame\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iuecnldd'? A: included B: failed C: tribe D: attempted\n",
      "Answer: D: attempted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 252 / 598  (42.1):  30%|       | 597/2000 [07:43<15:40,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 252 / 598  (42.1):  30%|       | 598/2000 [07:43<19:16,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sinprtog'. A: family B: queue C: operator D: sporting\n",
      "Answer: D: sporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 252 / 599  (42.1):  30%|       | 598/2000 [07:44<19:16,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 252 / 599  (42.1):  30%|       | 599/2000 [07:44<16:29,  1.42it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 252 / 600  (42.0):  30%|       | 599/2000 [07:44<16:29,  1.42it/s]\u001b[A\n",
      "Average Metric: 252 / 600  (42.0):  30%|       | 600/2000 [07:44<15:28,  1.51it/s]\u001b[A\n",
      "Average Metric: 252 / 601  (41.9):  30%|       | 600/2000 [07:44<15:28,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 252 / 602  (41.9):  30%|       | 601/2000 [07:45<15:27,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 252 / 602  (41.9):  30%|       | 602/2000 [07:45<09:57,  2.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cltobliooaarn'. A: collaboration B: hits C: photography D: idol\n",
      "Answer: C: photography\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 252 / 603  (41.8):  30%|       | 602/2000 [07:46<09:57,  2.34it/s]\u001b[A\n",
      "Average Metric: 252 / 603  (41.8):  30%|       | 603/2000 [07:46<14:40,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 253 / 604  (41.9):  30%|       | 603/2000 [07:46<14:40,  1.59it/s]\u001b[A\n",
      "Average Metric: 253 / 604  (41.9):  30%|       | 604/2000 [07:46<11:48,  1.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ltgiehr'. A: lighter B: fighters C: plus D: monkey\n",
      "Answer: C: plus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'caelrncae'. A: scattered B: trout C: clearance D: switched\n",
      "Answer: C: clearance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 253 / 605  (41.8):  30%|       | 604/2000 [07:48<11:48,  1.97it/s]\u001b[A\n",
      "Average Metric: 253 / 605  (41.8):  30%|       | 605/2000 [07:48<20:53,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'variga' to form the correct word. A: washer B: viagra C: anywhere D: wearing\n",
      "Answer: D: wearing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 253 / 606  (41.7):  30%|       | 605/2000 [07:49<20:53,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 253 / 606  (41.7):  30%|       | 606/2000 [07:49<23:27,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sopke'. A: spoke B: addressed C: sans D: monitored\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 254 / 607  (41.8):  30%|       | 606/2000 [07:50<23:27,  1.01s/it]\u001b[A\n",
      "Average Metric: 254 / 607  (41.8):  30%|       | 607/2000 [07:50<22:33,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dseaiclmir' to form the correct word. A: crazy B: disclaimer C: helping D: sharp\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 608  (41.9):  30%|       | 607/2000 [07:51<22:33,  1.03it/s]\u001b[A\n",
      "Average Metric: 255 / 608  (41.9):  30%|       | 608/2000 [07:51<21:27,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 609  (41.9):  30%|       | 608/2000 [07:51<21:27,  1.08it/s]\u001b[A\n",
      "Average Metric: 255 / 609  (41.9):  30%|       | 609/2000 [07:51<16:46,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 610  (42.0):  30%|       | 609/2000 [07:51<16:46,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 611  (42.1):  30%|       | 610/2000 [07:52<16:45,  1.38it/s]\u001b[A\n",
      "Average Metric: 257 / 611  (42.1):  31%|       | 611/2000 [07:52<13:52,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mnes'. A: functional B: subject C: mens D: dioxide\n",
      "Answer: A: functional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'vsita' to form the correct word. A: americans B: supervisor C: theorem D: vista\n",
      "Answer: D: vista\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 612  (42.0):  31%|       | 611/2000 [07:55<13:52,  1.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aeeatnrmnrgs'. A: electricity B: gravity C: wonderful D: arrangements\n",
      "Answer: D: arrangements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 257 / 612  (42.0):  31%|       | 612/2000 [07:55<27:35,  1.19s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 613  (41.9):  31%|       | 612/2000 [07:55<27:35,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eiqbuliurim' represent when unscrambled? A: passed B: finances C: month D: equilibrium\n",
      "Answer: D: equilibrium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 614  (41.9):  31%|       | 613/2000 [07:56<27:34,  1.19s/it]\u001b[A\n",
      "Average Metric: 257 / 614  (41.9):  31%|       | 614/2000 [07:56<18:20,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oanrngozaatiil'. A: deposit B: meyer C: organizational D: intervention\n",
      "Answer: D: intervention\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'nrom'. A: podcasts B: fears C: holder D: norm\n",
      "Answer: D: norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'reenottin' represent when unscrambled? A: frontpage B: incentive C: memorandum D: retention\n",
      "Answer: A: frontpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ance'. A: jacob B: acne C: units D: encourage\n",
      "Answer: D: encourage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lokoing'. A: determines B: looking C: concepts D: guided\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'saald' represent when unscrambled? A: salad B: myanmar C: helicopter D: charming\n",
      "Answer: A: salad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'raaoitidn'? A: albuquerque B: road C: actual D: radiation\n",
      "Answer: D: radiation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 615  (41.8):  31%|       | 614/2000 [08:01<18:20,  1.26it/s]\u001b[A\n",
      "Average Metric: 257 / 615  (41.8):  31%|       | 615/2000 [08:01<39:59,  1.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 616  (41.7):  31%|       | 615/2000 [08:02<39:59,  1.73s/it]\u001b[A\n",
      "Average Metric: 257 / 616  (41.7):  31%|       | 616/2000 [08:02<35:56,  1.56s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 617  (41.8):  31%|       | 616/2000 [08:02<35:56,  1.56s/it]\u001b[A\n",
      "Average Metric: 258 / 617  (41.8):  31%|       | 617/2000 [08:02<27:33,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 618  (41.7):  31%|       | 617/2000 [08:02<27:33,  1.20s/it]\u001b[A\n",
      "Average Metric: 258 / 618  (41.7):  31%|       | 618/2000 [08:02<21:17,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lruael'. A: laurel B: wonderful C: theorem D: promotion\n",
      "Answer: D: promotion\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'notgaetie'. A: graphs B: introduces C: negotiate D: lost\n",
      "Answer: D: lost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 619  (41.7):  31%|       | 618/2000 [08:03<21:17,  1.08it/s]\u001b[A\n",
      "Average Metric: 258 / 619  (41.7):  31%|       | 619/2000 [08:03<19:42,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 620  (41.6):  31%|       | 619/2000 [08:03<19:42,  1.17it/s]\u001b[A\n",
      "Average Metric: 258 / 620  (41.6):  31%|       | 620/2000 [08:03<15:27,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 621  (41.5):  31%|       | 620/2000 [08:03<15:27,  1.49it/s]\u001b[A\n",
      "Average Metric: 258 / 621  (41.5):  31%|       | 621/2000 [08:03<13:23,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 622  (41.5):  31%|       | 621/2000 [08:04<13:23,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 622  (41.5):  31%|       | 622/2000 [08:04<13:12,  1.74it/s]\u001b[A\n",
      "Average Metric: 259 / 623  (41.6):  31%|       | 622/2000 [08:04<13:12,  1.74it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 624  (41.7):  31%|       | 623/2000 [08:04<13:11,  1.74it/s]\u001b[A\n",
      "Average Metric: 260 / 624  (41.7):  31%|       | 624/2000 [08:04<10:26,  2.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 625  (41.6):  31%|       | 624/2000 [08:05<10:26,  2.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 260 / 625  (41.6):  31%|      | 625/2000 [08:05<11:29,  1.99it/s]\u001b[A\n",
      "Average Metric: 260 / 626  (41.5):  31%|      | 625/2000 [08:05<11:29,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 260 / 626  (41.5):  31%|      | 626/2000 [08:05<09:13,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lvnoig' to form the correct word. A: loving B: clients C: tape D: backyard\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'smhopnyy'? A: symphony B: mistake C: helped D: periods\n",
      "Answer: B: mistake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'turhogh'? A: applying B: becomes C: concentrate D: through\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fvie' represent when unscrambled? A: robertson B: springer C: individually D: five\n",
      "Answer: D: five\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 260 / 627  (41.5):  31%|      | 626/2000 [08:07<09:13,  2.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 260 / 627  (41.5):  31%|      | 627/2000 [08:07<17:20,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 628  (41.6):  31%|      | 627/2000 [08:07<17:20,  1.32it/s]\u001b[A\n",
      "Average Metric: 261 / 628  (41.6):  31%|      | 628/2000 [08:07<13:55,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 261 / 629  (41.5):  31%|      | 628/2000 [08:08<13:55,  1.64it/s]\u001b[A\n",
      "Average Metric: 261 / 629  (41.5):  31%|      | 629/2000 [08:08<14:47,  1.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 630  (41.4):  31%|      | 629/2000 [08:08<14:47,  1.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'jonhs'. A: tone B: johns C: observer D: rent\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 261 / 630  (41.4):  32%|      | 630/2000 [08:08<12:57,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 631  (41.4):  32%|      | 630/2000 [08:09<12:57,  1.76it/s]\u001b[A\n",
      "Average Metric: 261 / 631  (41.4):  32%|      | 631/2000 [08:09<16:25,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 632  (41.5):  32%|      | 631/2000 [08:11<16:25,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 262 / 632  (41.5):  32%|      | 632/2000 [08:11<24:20,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'somesert'. A: foster B: hung C: somerset D: blonde\n",
      "Answer: C: somerset\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ltian'. A: hardy B: cheaper C: latin D: asylum\n",
      "Answer: A: hardy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'psuae'. A: pause B: files C: justin D: this\n",
      "Answer: A: pause\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fitlncaoituny'. A: wrestling B: gourmet C: bother D: functionality\n",
      "Answer: D: functionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 633  (41.5):  32%|      | 632/2000 [08:13<24:20,  1.07s/it]\u001b[A\n",
      "Average Metric: 263 / 633  (41.5):  32%|      | 633/2000 [08:13<28:41,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 634  (41.5):  32%|      | 633/2000 [08:13<28:41,  1.26s/it]\u001b[A\n",
      "Average Metric: 263 / 634  (41.5):  32%|      | 634/2000 [08:13<21:04,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 635  (41.4):  32%|      | 634/2000 [08:13<21:04,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 636  (41.4):  32%|      | 635/2000 [08:13<21:03,  1.08it/s]\u001b[A\n",
      "Average Metric: 263 / 636  (41.4):  32%|      | 636/2000 [08:13<12:48,  1.78it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 637  (41.4):  32%|      | 636/2000 [08:13<12:48,  1.78it/s]\u001b[A\n",
      "Average Metric: 264 / 637  (41.4):  32%|      | 637/2000 [08:13<10:26,  2.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 265 / 638  (41.5):  32%|      | 637/2000 [08:14<10:26,  2.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 265 / 638  (41.5):  32%|      | 638/2000 [08:14<12:25,  1.83it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 265 / 639  (41.5):  32%|      | 638/2000 [08:14<12:25,  1.83it/s]\u001b[A\n",
      "Average Metric: 265 / 639  (41.5):  32%|      | 639/2000 [08:15<10:36,  2.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'essricon'. A: governing B: ericsson C: pokemon D: wonders\n",
      "Answer: D: wonders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 266 / 640  (41.6):  32%|      | 639/2000 [08:15<10:36,  2.14it/s]\u001b[A\n",
      "Average Metric: 266 / 640  (41.6):  32%|      | 640/2000 [08:15<10:49,  2.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anocmpianycg'. A: grades B: cost C: absolutely D: accompanying\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 641  (41.5):  32%|      | 640/2000 [08:18<10:49,  2.09it/s]\u001b[A\n",
      "Average Metric: 266 / 641  (41.5):  32%|      | 641/2000 [08:18<26:24,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 642  (41.6):  32%|      | 641/2000 [08:19<26:24,  1.17s/it]\u001b[A\n",
      "Average Metric: 267 / 642  (41.6):  32%|      | 642/2000 [08:19<24:15,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'daefet'. A: frances B: barriers C: defeat D: stereo\n",
      "Answer: D: stereo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'msikate'. A: partly B: mistake C: king D: fundamental\n",
      "Answer: B: mistake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 643  (41.5):  32%|      | 642/2000 [08:20<24:15,  1.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wfie'. A: develops B: wife C: nevis D: addresses\n",
      "Answer: D: addresses\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pdcinruog' to form the correct word. A: private B: producing C: christmas D: postcard\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 267 / 643  (41.5):  32%|      | 643/2000 [08:20<24:22,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'drceibse' represent when unscrambled? A: describe B: beauty C: travel D: expressions\n",
      "Answer: D: expressions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 267 / 644  (41.5):  32%|      | 643/2000 [08:21<24:22,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 267 / 644  (41.5):  32%|      | 644/2000 [08:21<23:34,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'isnriatgotves'. A: expertise B: investigators C: bacteria D: suzuki\n",
      "Answer: D: suzuki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lokos'? A: looks B: ongoing C: suggesting D: nearest\n",
      "Answer: D: nearest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'gleeilrnve'. A: greenville B: investigating C: staying D: magazines\n",
      "Answer: D: magazines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 645  (41.4):  32%|      | 644/2000 [08:23<23:34,  1.04s/it]\u001b[A\n",
      "Average Metric: 267 / 645  (41.4):  32%|      | 645/2000 [08:23<29:40,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 268 / 646  (41.5):  32%|      | 645/2000 [08:24<29:40,  1.31s/it]\u001b[A\n",
      "Average Metric: 268 / 646  (41.5):  32%|      | 646/2000 [08:24<26:09,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eslxcivue' represent when unscrambled? A: thin B: exclusive C: examples D: baseball\n",
      "Answer: B: exclusive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'haytt'. A: hyatt B: sides C: narrow D: tobago\n",
      "Answer: D: tobago\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sitnegts'. A: continent B: shawn C: settings D: cracks\n",
      "Answer: D: cracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 269 / 647  (41.6):  32%|      | 646/2000 [08:24<26:09,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 269 / 647  (41.6):  32%|      | 647/2000 [08:24<23:34,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 270 / 648  (41.7):  32%|      | 647/2000 [08:25<23:34,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 270 / 648  (41.7):  32%|      | 648/2000 [08:25<20:09,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 649  (41.6):  32%|      | 648/2000 [08:25<20:09,  1.12it/s]\u001b[A\n",
      "Average Metric: 270 / 649  (41.6):  32%|      | 649/2000 [08:25<16:20,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fornute'. A: every B: email C: intake D: fortune\n",
      "Answer: D: fortune\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 650  (41.7):  32%|      | 649/2000 [08:26<16:20,  1.38it/s]\u001b[A\n",
      "Average Metric: 271 / 650  (41.7):  32%|      | 650/2000 [08:26<19:53,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 651  (41.6):  32%|      | 650/2000 [08:28<19:53,  1.13it/s]\u001b[A\n",
      "Average Metric: 271 / 651  (41.6):  33%|      | 651/2000 [08:28<22:20,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 272 / 652  (41.7):  33%|      | 651/2000 [08:28<22:20,  1.01it/s]\u001b[A\n",
      "Average Metric: 272 / 652  (41.7):  33%|      | 652/2000 [08:28<17:52,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'osioppte'. A: controlled B: retro C: costumes D: opposite\n",
      "Answer: D: opposite\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'adreawd'. A: progress B: florist C: awarded D: branch\n",
      "Answer: D: branch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 653  (41.8):  33%|      | 652/2000 [08:30<17:52,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 653  (41.8):  33%|      | 653/2000 [08:30<24:37,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 654  (41.7):  33%|      | 653/2000 [08:30<24:37,  1.10s/it]\u001b[A\n",
      "Average Metric: 273 / 654  (41.7):  33%|      | 654/2000 [08:30<18:20,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 655  (41.7):  33%|      | 654/2000 [08:30<18:20,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 273 / 655  (41.7):  33%|      | 655/2000 [08:30<15:26,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'noon'. A: prisoners B: noon C: existed D: organizer\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 274 / 656  (41.8):  33%|      | 655/2000 [08:31<15:26,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 656  (41.8):  33%|      | 656/2000 [08:31<13:57,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 657  (41.7):  33%|      | 656/2000 [08:31<13:57,  1.61it/s]\u001b[A\n",
      "Average Metric: 274 / 657  (41.7):  33%|      | 657/2000 [08:31<11:40,  1.92it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'curz'. A: reseller B: nominations C: cruz D: goals\n",
      "Answer: C: cruz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 658  (41.6):  33%|      | 657/2000 [08:32<11:40,  1.92it/s]\u001b[A\n",
      "Average Metric: 274 / 658  (41.6):  33%|      | 658/2000 [08:32<12:45,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 659  (41.6):  33%|      | 658/2000 [08:32<12:45,  1.75it/s]\u001b[A\n",
      "Average Metric: 274 / 659  (41.6):  33%|      | 659/2000 [08:33<13:35,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stcritly'. A: divorce B: page C: strictly D: proceedings\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'faocl' to form the correct word. A: zero B: focal C: chelsea D: overcome\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 660  (41.7):  33%|      | 659/2000 [08:33<13:35,  1.64it/s]\u001b[A\n",
      "Average Metric: 275 / 660  (41.7):  33%|      | 660/2000 [08:33<13:30,  1.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fuard'. A: fraud B: regime C: burst D: formatting\n",
      "Answer: D: formatting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 661  (41.6):  33%|      | 660/2000 [08:35<13:30,  1.65it/s]\u001b[A\n",
      "Average Metric: 275 / 661  (41.6):  33%|      | 661/2000 [08:35<21:39,  1.03it/s]\u001b[A\n",
      "Average Metric: 275 / 662  (41.5):  33%|      | 661/2000 [08:35<21:39,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 275 / 662  (41.5):  33%|      | 662/2000 [08:35<15:55,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'seotrd' represent when unscrambled? A: representation B: duties C: barbados D: stored\n",
      "Answer: B: duties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ctesisnont' to form the correct word. A: headache B: catholic C: consistent D: memo\n",
      "Answer: D: memo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 275 / 663  (41.5):  33%|      | 662/2000 [08:36<15:55,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 275 / 663  (41.5):  33%|      | 663/2000 [08:36<19:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 276 / 664  (41.6):  33%|      | 663/2000 [08:36<19:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 276 / 665  (41.5):  33%|      | 664/2000 [08:36<19:18,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 665  (41.5):  33%|      | 665/2000 [08:36<11:10,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 666  (41.4):  33%|      | 665/2000 [08:38<11:10,  1.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 276 / 666  (41.4):  33%|      | 666/2000 [08:38<15:59,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wras'? A: wars B: loading C: yorkshire D: cards\n",
      "Answer: B: loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 667  (41.4):  33%|      | 666/2000 [08:39<15:59,  1.39it/s]\u001b[A\n",
      "Average Metric: 276 / 667  (41.4):  33%|      | 667/2000 [08:39<16:36,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 277 / 668  (41.5):  33%|      | 667/2000 [08:40<16:36,  1.34it/s]\u001b[A\n",
      "Average Metric: 277 / 668  (41.5):  33%|      | 668/2000 [08:40<19:30,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'clkcis'? A: clicks B: praise C: excess D: your\n",
      "Answer: D: your\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the capital of Spain? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'riavl' represent when unscrambled? A: painful B: deadline C: rival D: developmental\n",
      "Answer: D: developmental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'knog'. A: solve B: abraham C: kong D: representing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 669  (41.4):  33%|      | 668/2000 [08:42<19:30,  1.14it/s]\u001b[A\n",
      "Average Metric: 277 / 669  (41.4):  33%|      | 669/2000 [08:42<29:38,  1.34s/it]\u001b[A\n",
      "Average Metric: 277 / 670  (41.3):  33%|      | 669/2000 [08:43<29:38,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 277 / 670  (41.3):  34%|      | 670/2000 [08:43<23:11,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wcihh'? A: workout B: gamers C: fertility D: which\n",
      "Answer: D: which\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peoprr'. A: strengthen B: considering C: investing D: proper\n",
      "Answer: D: proper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 277 / 671  (41.3):  34%|      | 670/2000 [08:43<23:11,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 671  (41.3):  34%|      | 671/2000 [08:43<19:37,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ptale'. A: plate B: visions C: bounce D: cuts\n",
      "Answer: A: plate\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aomrr' to form the correct word. A: better B: armor C: written D: tragedy\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 672  (41.4):  34%|      | 671/2000 [08:44<19:37,  1.13it/s]\u001b[A\n",
      "Average Metric: 278 / 672  (41.4):  34%|      | 672/2000 [08:44<19:12,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 673  (41.3):  34%|      | 672/2000 [08:44<19:12,  1.15it/s]\u001b[A\n",
      "Average Metric: 278 / 673  (41.3):  34%|      | 673/2000 [08:44<15:55,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'smaimrues' represent when unscrambled? A: packs B: wired C: organizer D: summaries\n",
      "Answer: A: packs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'otpuoiptrny' to form the correct word. A: duration B: opportunity C: forced D: physics\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vitacan' represent when unscrambled? A: copying B: golden C: sender D: vatican\n",
      "Answer: D: vatican\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hstos'. A: complete B: hosts C: extends D: travelling\n",
      "Answer: D: travelling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 279 / 674  (41.4):  34%|      | 673/2000 [08:48<15:55,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 279 / 674  (41.4):  34%|      | 674/2000 [08:48<34:45,  1.57s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 675  (41.5):  34%|      | 674/2000 [08:48<34:45,  1.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 280 / 675  (41.5):  34%|      | 675/2000 [08:48<26:48,  1.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sewedn'. A: accidents B: victim C: mobiles D: sweden\n",
      "Answer: D: sweden\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iearnsce'. A: blogger B: allegations C: disclaimers D: increase\n",
      "Answer: D: increase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 676  (41.4):  34%|      | 675/2000 [08:49<26:48,  1.21s/it]\u001b[A\n",
      "Average Metric: 280 / 676  (41.4):  34%|      | 676/2000 [08:49<22:25,  1.02s/it]\u001b[A\n",
      "Average Metric: 280 / 677  (41.4):  34%|      | 676/2000 [08:49<22:25,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 280 / 677  (41.4):  34%|      | 677/2000 [08:49<16:26,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lokcs'? A: clock B: forth C: paid D: locks\n",
      "Answer: D: locks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 281 / 678  (41.4):  34%|      | 677/2000 [08:49<16:26,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 281 / 678  (41.4):  34%|      | 678/2000 [08:49<13:50,  1.59it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 282 / 679  (41.5):  34%|      | 678/2000 [08:50<13:50,  1.59it/s]\u001b[A\n",
      "Average Metric: 282 / 679  (41.5):  34%|      | 679/2000 [08:50<13:44,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 283 / 680  (41.6):  34%|      | 679/2000 [08:53<13:44,  1.60it/s]\u001b[A\n",
      "Average Metric: 283 / 680  (41.6):  34%|      | 680/2000 [08:53<28:07,  1.28s/it]\u001b[A\n",
      "Average Metric: 284 / 681  (41.7):  34%|      | 680/2000 [08:53<28:07,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 284 / 681  (41.7):  34%|      | 681/2000 [08:53<20:50,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 682  (41.6):  34%|      | 681/2000 [08:53<20:50,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'daen' to form the correct word. A: accommodate B: target C: movie D: dean\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'fniundg'? A: annual B: conducting C: funding D: core\n",
      "Answer: D: core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'meairrd'. A: safely B: carrier C: married D: something\n",
      "Answer: D: something\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'asess'. A: bookstore B: apparatus C: tech D: asses\n",
      "Answer: A: bookstore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 683  (41.6):  34%|      | 682/2000 [08:54<20:49,  1.06it/s]\u001b[A\n",
      "Average Metric: 284 / 683  (41.6):  34%|      | 683/2000 [08:54<15:54,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 684  (41.7):  34%|      | 683/2000 [08:54<15:54,  1.38it/s]\u001b[A\n",
      "Average Metric: 285 / 684  (41.7):  34%|      | 684/2000 [08:54<13:47,  1.59it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 286 / 685  (41.8):  34%|      | 684/2000 [08:54<13:47,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 287 / 686  (41.8):  34%|      | 685/2000 [08:56<13:46,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 287 / 686  (41.8):  34%|      | 686/2000 [08:56<14:30,  1.51it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 687  (41.8):  34%|      | 686/2000 [08:56<14:30,  1.51it/s]\u001b[A\n",
      "Average Metric: 287 / 687  (41.8):  34%|      | 687/2000 [08:56<13:00,  1.68it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pylhslciay'. A: plaintiff B: physically C: symbolic D: scattered\n",
      "Answer: D: scattered\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'anonencud' represent when unscrambled? A: simulated B: meaning C: civil D: announced\n",
      "Answer: D: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 688  (41.7):  34%|      | 687/2000 [08:57<13:00,  1.68it/s]\u001b[A\n",
      "Average Metric: 287 / 688  (41.7):  34%|      | 688/2000 [08:57<15:22,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 288 / 689  (41.8):  34%|      | 688/2000 [08:57<15:22,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 288 / 689  (41.8):  34%|      | 689/2000 [08:57<12:01,  1.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wtineesss'? A: witnesses B: scotland C: voted D: patients\n",
      "Answer: B: scotland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 288 / 690  (41.7):  34%|      | 689/2000 [08:58<12:01,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 288 / 690  (41.7):  34%|      | 690/2000 [08:58<11:13,  1.95it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ganrtaeue'? A: filled B: promoted C: guarantee D: push\n",
      "Answer: D: push\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aatcth' represent when unscrambled? A: tire B: mercury C: owns D: attach\n",
      "Answer: D: attach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 288 / 691  (41.7):  34%|      | 690/2000 [09:00<11:13,  1.95it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 288 / 691  (41.7):  35%|      | 691/2000 [09:00<19:50,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 289 / 692  (41.8):  35%|      | 691/2000 [09:00<19:50,  1.10it/s]\u001b[A\n",
      "Average Metric: 289 / 692  (41.8):  35%|      | 692/2000 [09:00<16:05,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 290 / 693  (41.8):  35%|      | 692/2000 [09:00<16:05,  1.35it/s]\u001b[A\n",
      "Average Metric: 290 / 693  (41.8):  35%|      | 693/2000 [09:00<12:30,  1.74it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 694  (41.9):  35%|      | 693/2000 [09:00<12:30,  1.74it/s]\u001b[A\n",
      "Average Metric: 291 / 694  (41.9):  35%|      | 694/2000 [09:00<10:50,  2.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 695  (41.9):  35%|      | 694/2000 [09:01<10:50,  2.01it/s]\u001b[A\n",
      "Average Metric: 291 / 695  (41.9):  35%|      | 695/2000 [09:01<14:29,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 292 / 696  (42.0):  35%|      | 695/2000 [09:02<14:29,  1.50it/s]\u001b[A\n",
      "Average Metric: 292 / 696  (42.0):  35%|      | 696/2000 [09:02<11:14,  1.93it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 293 / 697  (42.0):  35%|      | 696/2000 [09:03<11:14,  1.93it/s]\u001b[A\n",
      "Average Metric: 293 / 697  (42.0):  35%|      | 697/2000 [09:03<14:15,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 294 / 698  (42.1):  35%|      | 697/2000 [09:04<14:15,  1.52it/s]\u001b[A\n",
      "Average Metric: 294 / 698  (42.1):  35%|      | 698/2000 [09:04<17:58,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rereatt'. A: entertainment B: mcgraw C: centuries D: retreat\n",
      "Answer: D: retreat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'daef'. A: typing B: deaf C: chicken D: besides\n",
      "Answer: D: besides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'silinag' to form the correct word. A: sailing B: banking C: rice D: improving\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 295 / 699  (42.2):  35%|      | 698/2000 [09:05<17:58,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 295 / 699  (42.2):  35%|      | 699/2000 [09:06<23:56,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wdie' to form the correct word. A: giant B: ford C: system D: wide\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 700  (42.1):  35%|      | 699/2000 [09:06<23:56,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mroevs'. A: lease B: movers C: finnish D: router\n",
      "Answer: D: router\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 701  (42.1):  35%|      | 700/2000 [09:07<23:55,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 701  (42.1):  35%|      | 701/2000 [09:07<18:30,  1.17it/s]\u001b[A\n",
      "Average Metric: 295 / 702  (42.0):  35%|      | 701/2000 [09:07<18:30,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'vitnisig'. A: gordon B: eagles C: interests D: visiting\n",
      "Answer: D: visiting\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eixalpns' represent when unscrambled? A: privileges B: distributor C: explains D: preferences\n",
      "Answer: A: privileges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 703  (42.1):  35%|      | 702/2000 [09:08<18:30,  1.17it/s]\u001b[A\n",
      "Average Metric: 296 / 703  (42.1):  35%|      | 703/2000 [09:08<15:01,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mslcue' to form the correct word. A: finds B: forecasts C: muscle D: spacious\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'adtteuits'. A: attitudes B: anthony C: generate D: examine\n",
      "Answer: D: examine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'deicrt'? A: vanity B: satellite C: honor D: direct\n",
      "Answer: D: direct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sapek'? A: amsterdam B: speak C: amanda D: harvey\n",
      "Answer: B: speak\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'veorinss' represent when unscrambled? A: gardens B: expense C: fleet D: versions\n",
      "Answer: D: versions\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sneoor'? A: ranks B: sooner C: burns D: chances\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 704  (42.0):  35%|      | 703/2000 [09:11<15:01,  1.44it/s]\u001b[A\n",
      "Average Metric: 296 / 704  (42.0):  35%|      | 704/2000 [09:11<29:05,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 705  (42.0):  35%|      | 704/2000 [09:12<29:05,  1.35s/it]\u001b[A\n",
      "Average Metric: 296 / 705  (42.0):  35%|      | 705/2000 [09:12<26:15,  1.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 297 / 706  (42.1):  35%|      | 705/2000 [09:12<26:15,  1.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pierton' represent when unscrambled? A: lisa B: protein C: fuels D: torture\n",
      "Answer: A: lisa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aenswr'. A: electrical B: keno C: answer D: violin\n",
      "Answer: C: answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 297 / 707  (42.0):  35%|      | 706/2000 [09:13<26:14,  1.22s/it]\u001b[A\n",
      "Average Metric: 297 / 707  (42.0):  35%|      | 707/2000 [09:13<20:48,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 298 / 708  (42.1):  35%|      | 707/2000 [09:16<20:48,  1.04it/s]\u001b[A\n",
      "Average Metric: 298 / 708  (42.1):  35%|      | 708/2000 [09:16<29:04,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 298 / 709  (42.0):  35%|      | 708/2000 [09:16<29:04,  1.35s/it]\u001b[A\n",
      "Average Metric: 298 / 709  (42.0):  35%|      | 709/2000 [09:16<24:23,  1.13s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 710  (42.1):  35%|      | 709/2000 [09:16<24:23,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 711  (42.1):  36%|      | 710/2000 [09:17<24:21,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 711  (42.1):  36%|      | 711/2000 [09:17<18:54,  1.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'itcesns'. A: tutor B: panic C: insects D: ladyboy\n",
      "Answer: C: insects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 712  (42.0):  36%|      | 711/2000 [09:18<18:54,  1.14it/s]\u001b[A\n",
      "Average Metric: 299 / 712  (42.0):  36%|      | 712/2000 [09:18<16:09,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnsirooutm'? A: jumping B: creation C: common D: consortium\n",
      "Answer: D: consortium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 300 / 713  (42.1):  36%|      | 712/2000 [09:19<16:09,  1.33it/s]\u001b[A\n",
      "Average Metric: 300 / 713  (42.1):  36%|      | 713/2000 [09:19<19:53,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 301 / 714  (42.2):  36%|      | 713/2000 [09:20<19:53,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 301 / 714  (42.2):  36%|      | 714/2000 [09:20<17:28,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oeboctr'. A: october B: walsh C: gang D: discovered\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'stesyms'? A: convention B: feature C: systems D: relax\n",
      "Answer: D: relax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 301 / 715  (42.1):  36%|      | 714/2000 [09:20<17:28,  1.23it/s]\u001b[A\n",
      "Average Metric: 301 / 715  (42.1):  36%|      | 715/2000 [09:20<16:33,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 302 / 716  (42.2):  36%|      | 715/2000 [09:21<16:33,  1.29it/s]\u001b[A\n",
      "Average Metric: 302 / 716  (42.2):  36%|      | 716/2000 [09:21<17:58,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pceturis' to form the correct word. A: webmasters B: pictures C: replication D: race\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 303 / 717  (42.3):  36%|      | 716/2000 [09:23<17:58,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 303 / 717  (42.3):  36%|      | 717/2000 [09:23<24:09,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 304 / 718  (42.3):  36%|      | 717/2000 [09:23<24:09,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ltvirea' represent when unscrambled? A: levitra B: buzz C: trap D: submitted\n",
      "Answer: A: levitra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 719  (42.4):  36%|      | 718/2000 [09:24<24:08,  1.13s/it]\u001b[A\n",
      "Average Metric: 305 / 719  (42.4):  36%|      | 719/2000 [09:24<15:15,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 720  (42.4):  36%|      | 719/2000 [09:24<15:15,  1.40it/s]\u001b[A\n",
      "Average Metric: 305 / 720  (42.4):  36%|      | 720/2000 [09:24<12:16,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'jneesn' to form the correct word. A: hero B: jensen C: waist D: socket\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 721  (42.3):  36%|      | 720/2000 [09:24<12:16,  1.74it/s]\u001b[A\n",
      "Average Metric: 305 / 721  (42.3):  36%|      | 721/2000 [09:24<12:23,  1.72it/s]\u001b[A\n",
      "Average Metric: 305 / 722  (42.2):  36%|      | 721/2000 [09:25<12:23,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 305 / 722  (42.2):  36%|      | 722/2000 [09:25<14:22,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dsrictit' represent when unscrambled? A: sentences B: envelope C: district D: fuels\n",
      "Answer: D: fuels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 305 / 723  (42.2):  36%|      | 722/2000 [09:27<14:22,  1.48it/s]\u001b[A\n",
      "Average Metric: 305 / 723  (42.2):  36%|      | 723/2000 [09:27<20:26,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 306 / 724  (42.3):  36%|      | 723/2000 [09:27<20:26,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 306 / 724  (42.3):  36%|      | 724/2000 [09:27<17:03,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cnebrutary'. A: postscript B: corp C: kitchen D: canterbury\n",
      "Answer: D: canterbury\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'moroe'. A: warnings B: moore C: cares D: tigers\n",
      "Answer: A: warnings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 725  (42.3):  36%|      | 724/2000 [09:28<17:03,  1.25it/s]\u001b[A\n",
      "Average Metric: 307 / 725  (42.3):  36%|      | 725/2000 [09:28<15:31,  1.37it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 726  (42.3):  36%|      | 725/2000 [09:28<15:31,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'qtuiimkce'. A: involves B: fails C: quicktime D: gamecube\n",
      "Answer: D: gamecube\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'afpilmeir'. A: amplifier B: mississippi C: yamaha D: train\n",
      "Answer: A: amplifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 727  (42.2):  36%|      | 726/2000 [09:29<15:30,  1.37it/s]\u001b[A\n",
      "Average Metric: 307 / 727  (42.2):  36%|      | 727/2000 [09:29<12:15,  1.73it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dutecshe'. A: speaking B: deutsche C: helped D: leap\n",
      "Answer: D: leap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 308 / 728  (42.3):  36%|      | 727/2000 [09:29<12:15,  1.73it/s]\u001b[A\n",
      "Average Metric: 308 / 728  (42.3):  36%|      | 728/2000 [09:29<10:58,  1.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 729  (42.4):  36%|      | 728/2000 [09:29<10:58,  1.93it/s]\u001b[A\n",
      "Average Metric: 309 / 729  (42.4):  36%|      | 729/2000 [09:29<09:52,  2.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'htsenoly'. A: britain B: exercises C: honestly D: passes\n",
      "Answer: D: passes\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cnoe'. A: cone B: guatemala C: colorful D: cock\n",
      "Answer: D: cock\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peacagks'? A: simplicity B: forum C: packages D: garnet\n",
      "Answer: B: forum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 730  (42.5):  36%|      | 729/2000 [09:30<09:52,  2.14it/s]\u001b[A\n",
      "Average Metric: 310 / 730  (42.5):  36%|      | 730/2000 [09:30<11:32,  1.83it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 731  (42.5):  36%|      | 730/2000 [09:30<11:32,  1.83it/s]\u001b[A\n",
      "Average Metric: 311 / 731  (42.5):  37%|      | 731/2000 [09:30<10:09,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 732  (42.5):  37%|      | 731/2000 [09:31<10:09,  2.08it/s]\u001b[A\n",
      "Average Metric: 311 / 732  (42.5):  37%|      | 732/2000 [09:31<08:16,  2.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 733  (42.6):  37%|      | 732/2000 [09:31<08:16,  2.56it/s]\u001b[A\n",
      "Average Metric: 312 / 733  (42.6):  37%|      | 733/2000 [09:31<08:52,  2.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hrloeds'. A: geographical B: emily C: orthodox D: holders\n",
      "Answer: D: holders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ulits' represent when unscrambled? A: eclipse B: utils C: copy D: lotion\n",
      "Answer: A: eclipse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 734  (42.5):  37%|      | 733/2000 [09:35<08:52,  2.38it/s]\u001b[A\n",
      "Average Metric: 312 / 734  (42.5):  37%|      | 734/2000 [09:35<28:17,  1.34s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 735  (42.6):  37%|      | 734/2000 [09:35<28:17,  1.34s/it]\u001b[A\n",
      "Average Metric: 313 / 735  (42.6):  37%|      | 735/2000 [09:35<21:12,  1.01s/it]\u001b[A\n",
      "Average Metric: 313 / 736  (42.5):  37%|      | 735/2000 [09:35<21:12,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 313 / 736  (42.5):  37%|      | 736/2000 [09:35<15:56,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 737  (42.6):  37%|      | 736/2000 [09:36<15:56,  1.32it/s]\u001b[A\n",
      "Average Metric: 314 / 737  (42.6):  37%|      | 737/2000 [09:36<17:20,  1.21it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 738  (42.7):  37%|      | 737/2000 [09:36<17:20,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bcrhmenak' represent when unscrambled? A: hurricane B: simultaneously C: benchmark D: political\n",
      "Answer: A: hurricane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 739  (42.6):  37%|      | 738/2000 [09:39<17:20,  1.21it/s]\u001b[A\n",
      "Average Metric: 315 / 739  (42.6):  37%|      | 739/2000 [09:39<22:52,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vualim' represent when unscrambled? A: petite B: diving C: valium D: directive\n",
      "Answer: C: valium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'liqiud'. A: sudan B: claiming C: liquid D: cash\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 740  (42.6):  37%|      | 739/2000 [09:40<22:52,  1.09s/it]\u001b[A\n",
      "Average Metric: 315 / 740  (42.6):  37%|      | 740/2000 [09:40<23:35,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 315 / 741  (42.5):  37%|      | 740/2000 [09:40<23:35,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 742  (42.6):  37%|      | 741/2000 [09:40<23:34,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 743  (42.5):  37%|      | 742/2000 [09:40<23:33,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 744  (42.5):  37%|      | 743/2000 [09:41<23:32,  1.12s/it]\u001b[A\n",
      "Average Metric: 316 / 744  (42.5):  37%|      | 744/2000 [09:41<11:18,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cdnlcoue' represent when unscrambled? A: conclude B: nose C: carrying D: moses\n",
      "Answer: B: nose\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'geirf'? A: grief B: examine C: exceptions D: excluded\n",
      "Answer: grief\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 745  (42.4):  37%|      | 744/2000 [09:42<11:18,  1.85it/s]\u001b[A\n",
      "Average Metric: 316 / 745  (42.4):  37%|      | 745/2000 [09:42<16:08,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bwol'? A: bowl B: channels C: graham D: amplifier\n",
      "Answer: B: channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pruivleosy'? A: movements B: kyoto C: unlike D: previously\n",
      "Answer: B: kyoto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'prloicean'? A: believe B: omissions C: porcelain D: tripadvisor\n",
      "Answer: D: tripadvisor\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sbyomls'. A: scene B: belize C: symbols D: chemicals\n",
      "Answer: D: chemicals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 746  (42.4):  37%|      | 745/2000 [09:46<16:08,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 316 / 746  (42.4):  37%|      | 746/2000 [09:46<27:04,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 747  (42.3):  37%|      | 746/2000 [09:46<27:04,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 747  (42.3):  37%|      | 747/2000 [09:46<21:45,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sacveneserr'. A: nightmare B: lived C: bull D: screensaver\n",
      "Answer: D: screensaver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wesmenttsir'. A: milk B: westminster C: kurt D: positions\n",
      "Answer: D: positions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 748  (42.4):  37%|      | 747/2000 [09:47<21:45,  1.04s/it]\u001b[A\n",
      "Average Metric: 317 / 748  (42.4):  37%|      | 748/2000 [09:47<23:32,  1.13s/it]\u001b[A\n",
      "Average Metric: 317 / 749  (42.3):  37%|      | 748/2000 [09:48<23:32,  1.13s/it]\u001b[A\n",
      "Average Metric: 317 / 749  (42.3):  37%|      | 749/2000 [09:48<18:30,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 317 / 750  (42.3):  37%|      | 749/2000 [09:48<18:30,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 751  (42.2):  38%|      | 750/2000 [09:48<18:29,  1.13it/s]\u001b[A\n",
      "Average Metric: 317 / 751  (42.2):  38%|      | 751/2000 [09:48<13:06,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 752  (42.2):  38%|      | 751/2000 [09:49<13:06,  1.59it/s]\u001b[A\n",
      "Average Metric: 317 / 752  (42.2):  38%|      | 752/2000 [09:49<13:26,  1.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mniwhleae'. A: meanwhile B: pills C: curtain D: myspace\n",
      "Answer: D: myspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mtpliule'? A: arrive B: whereas C: allowance D: multiple\n",
      "Answer: D: multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 753  (42.1):  38%|      | 752/2000 [09:50<13:26,  1.55it/s]\u001b[A\n",
      "Average Metric: 317 / 753  (42.1):  38%|      | 753/2000 [09:50<16:31,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 754  (42.2):  38%|      | 753/2000 [09:50<16:31,  1.26it/s]\u001b[A\n",
      "Average Metric: 318 / 754  (42.2):  38%|      | 754/2000 [09:50<13:38,  1.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 755  (42.1):  38%|      | 754/2000 [09:51<13:38,  1.52it/s]\u001b[A\n",
      "Average Metric: 318 / 755  (42.1):  38%|      | 755/2000 [09:51<14:23,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 756  (42.1):  38%|      | 755/2000 [09:51<14:23,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'psrnitaleoy' to form the correct word. A: lavender B: upgrade C: personality D: tide\n",
      "Answer: D: tide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 318 / 757  (42.0):  38%|      | 756/2000 [09:52<14:22,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 318 / 757  (42.0):  38%|      | 757/2000 [09:52<10:42,  1.93it/s]\u001b[A\n",
      "Average Metric: 318 / 758  (42.0):  38%|      | 757/2000 [09:52<10:42,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 759  (42.0):  38%|      | 758/2000 [09:52<10:42,  1.93it/s]\u001b[A\n",
      "Average Metric: 319 / 759  (42.0):  38%|      | 759/2000 [09:52<08:03,  2.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 760  (42.0):  38%|      | 759/2000 [09:52<08:03,  2.57it/s]\u001b[A\n",
      "Average Metric: 319 / 760  (42.0):  38%|      | 760/2000 [09:52<06:53,  3.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'msetar' to form the correct word. A: useless B: meal C: polar D: master\n",
      "Answer: D: master\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'crraees'. A: retailer B: largest C: careers D: namibia\n",
      "Answer: A: retailer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'levid' to form the correct word. A: cube B: lived C: staying D: tracker\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest prime number?  A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 761  (41.9):  38%|      | 760/2000 [09:53<06:53,  3.00it/s]\u001b[A\n",
      "Average Metric: 319 / 761  (41.9):  38%|      | 761/2000 [09:53<10:33,  1.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 762  (41.9):  38%|      | 761/2000 [09:54<10:33,  1.96it/s]\u001b[A\n",
      "Average Metric: 319 / 762  (41.9):  38%|      | 762/2000 [09:54<10:03,  2.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'jeep'. A: jeep B: words C: clubs D: dressed\n",
      "Answer: A: jeep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ianrian' to form the correct word. A: behaviour B: requirements C: instructor D: iranian\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'clopemid' represent when unscrambled? A: compiled B: canon C: hyundai D: jobs\n",
      "Answer: A: compiled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ksis' to form the correct word. A: occurred B: seychelles C: kiss D: sympathy\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fsahrles'. A: flashers B: textbook C: ultram D: tuesday\n",
      "Answer: A: flashers\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wlhie' to form the correct word. A: while B: concurrent C: smooth D: intranet\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 763  (41.8):  38%|      | 762/2000 [09:58<10:03,  2.05it/s]\u001b[A\n",
      "Average Metric: 319 / 763  (41.8):  38%|      | 763/2000 [09:58<31:01,  1.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 319 / 764  (41.8):  38%|      | 763/2000 [09:58<31:01,  1.51s/it]\u001b[A\n",
      "Average Metric: 319 / 764  (41.8):  38%|      | 764/2000 [09:58<24:35,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peetrflcy'. A: strengthen B: perfectly C: catherine D: specialized\n",
      "Answer: C: catherine\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'flshewoilp'. A: married B: fellowship C: wildlife D: ford\n",
      "Answer: D: ford\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 319 / 765  (41.7):  38%|      | 764/2000 [09:59<24:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 319 / 765  (41.7):  38%|      | 765/2000 [09:59<21:37,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rbebur' to form the correct word. A: priced B: remarkable C: recruiting D: rubber\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pzlaa' to form the correct word. A: hall B: error C: category D: plaza\n",
      "Answer: D: plaza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seccneis'. A: algorithms B: fair C: starring D: sciences\n",
      "Answer: D: sciences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'leis'? A: lies B: earlier C: chairs D: plaza\n",
      "Answer: B: earlier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 766  (41.6):  38%|      | 765/2000 [10:03<21:37,  1.05s/it]\u001b[A\n",
      "Average Metric: 319 / 766  (41.6):  38%|      | 766/2000 [10:03<35:58,  1.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 319 / 767  (41.6):  38%|      | 766/2000 [10:03<35:58,  1.75s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 767  (41.6):  38%|      | 767/2000 [10:03<28:50,  1.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 319 / 768  (41.5):  38%|      | 767/2000 [10:03<28:50,  1.40s/it]\u001b[A\n",
      "Average Metric: 319 / 768  (41.5):  38%|      | 768/2000 [10:03<21:58,  1.07s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 769  (41.5):  38%|      | 768/2000 [10:04<21:58,  1.07s/it]\u001b[A\n",
      "Average Metric: 319 / 769  (41.5):  38%|      | 769/2000 [10:04<18:31,  1.11it/s]\u001b[A\n",
      "Average Metric: 319 / 770  (41.4):  38%|      | 769/2000 [10:04<18:31,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'repnteeavisetrs'. A: virtue B: representatives C: uniform D: luxury\n",
      "Answer: A: virtue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 771  (41.4):  38%|      | 770/2000 [10:05<18:30,  1.11it/s]\u001b[A\n",
      "Average Metric: 319 / 771  (41.4):  39%|      | 771/2000 [10:05<13:01,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gtes'. A: affected B: gets C: variables D: bookmarks\n",
      "Answer: C: variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'frae'? A: fare B: plays C: brazilian D: pages\n",
      "Answer: A: fare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 320 / 772  (41.5):  39%|      | 771/2000 [10:07<13:01,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 772  (41.5):  39%|      | 772/2000 [10:07<22:08,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eeyd' represent when unscrambled? A: beads B: reform C: eyed D: darwin\n",
      "Answer: D: darwin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'anegls' to form the correct word. A: enom B: angles C: keys D: distributor\n",
      "Answer: Distributor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 321 / 773  (41.5):  39%|      | 772/2000 [10:08<22:08,  1.08s/it]\u001b[A\n",
      "Average Metric: 321 / 773  (41.5):  39%|      | 773/2000 [10:09<24:25,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'indsie'. A: attributes B: linear C: inside D: vector\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'daasaetbs' represent when unscrambled? A: walking B: exactly C: charming D: databases\n",
      "Answer: D: databases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 322 / 774  (41.6):  39%|      | 773/2000 [10:10<24:25,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 322 / 774  (41.6):  39%|      | 774/2000 [10:10<25:09,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'drleopvees' to form the correct word. A: cool B: sophisticated C: toolkit D: developers\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 775  (41.7):  39%|      | 774/2000 [10:10<25:09,  1.23s/it]\u001b[A\n",
      "Average Metric: 323 / 775  (41.7):  39%|      | 775/2000 [10:10<20:32,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 776  (41.6):  39%|      | 775/2000 [10:11<20:32,  1.01s/it]\u001b[A\n",
      "Average Metric: 323 / 776  (41.6):  39%|      | 776/2000 [10:11<19:47,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 777  (41.7):  39%|      | 776/2000 [10:11<19:47,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 324 / 777  (41.7):  39%|      | 777/2000 [10:11<14:44,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'prmie'. A: restore B: prime C: ashley D: plenty\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cnurotnligoatas'. A: investigating B: irvine C: chords D: congratulations\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 324 / 778  (41.6):  39%|      | 777/2000 [10:13<14:44,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 324 / 778  (41.6):  39%|      | 778/2000 [10:13<22:21,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 779  (41.6):  39%|      | 778/2000 [10:14<22:21,  1.10s/it]\u001b[A\n",
      "Average Metric: 324 / 779  (41.6):  39%|      | 779/2000 [10:14<20:57,  1.03s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 780  (41.5):  39%|      | 779/2000 [10:14<20:57,  1.03s/it]\u001b[A\n",
      "Average Metric: 324 / 780  (41.5):  39%|      | 780/2000 [10:14<15:29,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 781  (41.6):  39%|      | 780/2000 [10:14<15:29,  1.31it/s]\u001b[A\n",
      "Average Metric: 325 / 781  (41.6):  39%|      | 781/2000 [10:14<11:46,  1.73it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 782  (41.6):  39%|      | 781/2000 [10:15<11:46,  1.73it/s]\u001b[A\n",
      "Average Metric: 325 / 782  (41.6):  39%|      | 782/2000 [10:15<09:56,  2.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 783  (41.5):  39%|      | 782/2000 [10:15<09:56,  2.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 783  (41.5):  39%|      | 783/2000 [10:15<07:49,  2.59it/s]\u001b[A\n",
      "Average Metric: 326 / 784  (41.6):  39%|      | 783/2000 [10:15<07:49,  2.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 327 / 785  (41.7):  39%|      | 784/2000 [10:15<07:49,  2.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'etnioids'. A: overcome B: editions C: accordingly D: fighting\n",
      "Answer: D: fighting\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'resslibpnoe'. A: thrown B: legends C: responsible D: opera\n",
      "Answer: D: opera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rcak'. A: select B: going C: enemies D: rack\n",
      "Answer: D: rack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 327 / 786  (41.6):  39%|      | 785/2000 [10:17<07:48,  2.59it/s]\u001b[A\n",
      "Average Metric: 327 / 786  (41.6):  39%|      | 786/2000 [10:17<11:38,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'chraegrs' represent when unscrambled? A: potter B: turnover C: chargers D: desk\n",
      "Answer: A: potter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hndoa' to form the correct word. A: distinct B: draws C: honda D: hash\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 328 / 787  (41.7):  39%|      | 786/2000 [10:19<11:38,  1.74it/s]\u001b[A\n",
      "Average Metric: 328 / 787  (41.7):  39%|      | 787/2000 [10:19<17:46,  1.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rmeoevd'. A: reload B: geological C: removed D: emotion\n",
      "Answer: D: emotion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fieliams'. A: bonus B: crow C: copyright D: families\n",
      "Answer: D: families\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crok'? A: folders B: weapon C: swing D: cork\n",
      "Answer: D: cork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sryia'? A: songs B: library C: syria D: bool\n",
      "Answer: B: library\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dmeo' to form the correct word. A: penalties B: another C: remaining D: demo\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ritaen'. A: location B: infrared C: minneapolis D: retain\n",
      "Answer: D: retain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 329 / 788  (41.8):  39%|      | 787/2000 [10:21<17:46,  1.14it/s]\u001b[A\n",
      "Average Metric: 329 / 788  (41.8):  39%|      | 788/2000 [10:21<22:58,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 789  (41.8):  39%|      | 788/2000 [10:21<22:58,  1.14s/it]\u001b[A\n",
      "Average Metric: 330 / 789  (41.8):  39%|      | 789/2000 [10:21<18:13,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'arednas'. A: orleans B: andreas C: cotton D: examples\n",
      "Answer: D: examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 330 / 790  (41.8):  39%|      | 789/2000 [10:22<18:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 330 / 790  (41.8):  40%|      | 790/2000 [10:22<15:09,  1.33it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 791  (41.8):  40%|      | 790/2000 [10:22<15:09,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pkemoon' to form the correct word. A: pokemon B: blood C: recorders D: disclosed\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 792  (41.8):  40%|      | 791/2000 [10:25<15:09,  1.33it/s]\u001b[A\n",
      "Average Metric: 331 / 792  (41.8):  40%|      | 792/2000 [10:25<22:58,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 793  (41.7):  40%|      | 792/2000 [10:25<22:58,  1.14s/it]\u001b[A\n",
      "Average Metric: 331 / 793  (41.7):  40%|      | 793/2000 [10:25<20:03,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ctus'. A: israeli B: initiatives C: banks D: cuts\n",
      "Answer: D: cuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 331 / 794  (41.7):  40%|      | 793/2000 [10:26<20:03,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 331 / 794  (41.7):  40%|      | 794/2000 [10:26<19:53,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 331 / 795  (41.6):  40%|      | 794/2000 [10:27<19:53,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 331 / 795  (41.6):  40%|      | 795/2000 [10:27<19:01,  1.06it/s]\u001b[A\n",
      "Average Metric: 331 / 796  (41.6):  40%|      | 795/2000 [10:27<19:01,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 332 / 797  (41.7):  40%|      | 796/2000 [10:28<19:00,  1.06it/s]\u001b[A\n",
      "Average Metric: 332 / 797  (41.7):  40%|      | 797/2000 [10:28<13:03,  1.54it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'qnsueaenld'? A: readers B: clara C: queensland D: packs\n",
      "Answer: B: clara\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 798  (41.7):  40%|      | 797/2000 [10:28<13:03,  1.54it/s]\u001b[A\n",
      "Average Metric: 333 / 798  (41.7):  40%|      | 798/2000 [10:28<13:07,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'trvias'. A: travis B: signs C: fits D: outputs\n",
      "Answer: D: outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 334 / 799  (41.8):  40%|      | 798/2000 [10:31<13:07,  1.53it/s]\u001b[A\n",
      "Average Metric: 334 / 799  (41.8):  40%|      | 799/2000 [10:31<20:47,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sfcraue' represent when unscrambled? A: iceland B: precious C: surface D: outreach\n",
      "Answer: C: surface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cntneots' represent when unscrambled? A: suggestion B: refresh C: contents D: weather\n",
      "Answer: C: contents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 800  (41.8):  40%|      | 799/2000 [10:32<20:47,  1.04s/it]\u001b[A\n",
      "Average Metric: 334 / 800  (41.8):  40%|      | 800/2000 [10:32<22:07,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ctseher' to form the correct word. A: lexington B: blame C: chester D: folders\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 334 / 801  (41.7):  40%|      | 800/2000 [10:33<22:07,  1.11s/it]\u001b[A\n",
      "Average Metric: 334 / 801  (41.7):  40%|      | 801/2000 [10:33<21:59,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sepll' to form the correct word. A: username B: spell C: fabric D: barcelona\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 802  (41.6):  40%|      | 801/2000 [10:33<21:59,  1.10s/it]\u001b[A\n",
      "Average Metric: 334 / 802  (41.6):  40%|      | 802/2000 [10:34<19:06,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 803  (41.6):  40%|      | 802/2000 [10:35<19:06,  1.04it/s]\u001b[A\n",
      "Average Metric: 334 / 803  (41.6):  40%|      | 803/2000 [10:35<20:10,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 804  (41.5):  40%|      | 803/2000 [10:36<20:10,  1.01s/it]\u001b[A\n",
      "Average Metric: 334 / 804  (41.5):  40%|      | 804/2000 [10:36<21:57,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'viod' represent when unscrambled? A: outsourcing B: void C: bloglines D: phoenix\n",
      "Answer: A: outsourcing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 805  (41.5):  40%|      | 804/2000 [10:37<21:57,  1.10s/it]\u001b[A\n",
      "Average Metric: 334 / 805  (41.5):  40%|      | 805/2000 [10:37<23:15,  1.17s/it]\u001b[A\n",
      "Average Metric: 335 / 806  (41.6):  40%|      | 805/2000 [10:38<23:15,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 806  (41.6):  40%|      | 806/2000 [10:38<18:52,  1.05it/s]\u001b[A\n",
      "Average Metric: 335 / 807  (41.5):  40%|      | 806/2000 [10:38<18:52,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 808  (41.5):  40%|      | 807/2000 [10:38<18:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 335 / 808  (41.5):  40%|      | 808/2000 [10:38<10:41,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 336 / 809  (41.5):  40%|      | 808/2000 [10:38<10:41,  1.86it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 336 / 809  (41.5):  40%|      | 809/2000 [10:38<09:07,  2.18it/s]\u001b[A\n",
      "Average Metric: 337 / 810  (41.6):  40%|      | 809/2000 [10:38<09:07,  2.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'setm'. A: stem B: pathway C: pants D: interval\n",
      "Answer: D: interval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'htpts'? A: sbjct B: shop C: https D: targeting\n",
      "Answer: C: https\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'kcntueky'. A: kentucky B: sunrise C: thereafter D: paragraphs\n",
      "Answer: A: kentucky\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ctneoempt' represent when unscrambled? A: arise B: competent C: corrected D: brunswick\n",
      "Answer: B: competent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 337 / 811  (41.6):  40%|      | 810/2000 [10:39<09:06,  2.18it/s]\u001b[A\n",
      "Average Metric: 337 / 811  (41.6):  41%|      | 811/2000 [10:39<10:00,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'qetous' to form the correct word. A: meeting B: quotes C: spoken D: while\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 337 / 812  (41.5):  41%|      | 811/2000 [10:40<10:00,  1.98it/s]\u001b[A\n",
      "Average Metric: 337 / 812  (41.5):  41%|      | 812/2000 [10:40<13:16,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stetres'. A: this B: create C: nightmare D: streets\n",
      "Answer: D: streets\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'feird'. A: finishes B: expensive C: wills D: fired\n",
      "Answer: D: fired\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'anietxy' to form the correct word. A: anxiety B: breathing C: cumulative D: calls\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ajecandt'? A: hebrew B: adjacent C: mississippi D: sucking\n",
      "Answer: D: sucking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'catoed'. A: coated B: amounts C: wastewater D: logged\n",
      "Answer: C: wastewater\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'piootisn'? A: position B: protection C: benz D: customs\n",
      "Answer: B: protection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 338 / 813  (41.6):  41%|      | 812/2000 [10:43<13:16,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 338 / 813  (41.6):  41%|      | 813/2000 [10:43<24:43,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 339 / 814  (41.6):  41%|      | 813/2000 [10:44<24:43,  1.25s/it]\u001b[A\n",
      "Average Metric: 339 / 814  (41.6):  41%|      | 814/2000 [10:44<19:46,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 339 / 815  (41.6):  41%|      | 814/2000 [10:44<19:46,  1.00s/it]\u001b[A\n",
      "Average Metric: 339 / 815  (41.6):  41%|      | 815/2000 [10:44<16:33,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 339 / 816  (41.5):  41%|      | 815/2000 [10:44<16:33,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'niel'? A: bargaining B: dominican C: accessible D: neil\n",
      "Answer: D: neil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 339 / 816  (41.5):  41%|      | 816/2000 [10:44<13:43,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 817  (41.6):  41%|      | 816/2000 [10:45<13:43,  1.44it/s]\u001b[A\n",
      "Average Metric: 340 / 817  (41.6):  41%|      | 817/2000 [10:45<12:47,  1.54it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 818  (41.6):  41%|      | 817/2000 [10:47<12:47,  1.54it/s]\u001b[A\n",
      "Average Metric: 340 / 818  (41.6):  41%|      | 818/2000 [10:47<18:38,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 819  (41.5):  41%|      | 818/2000 [10:49<18:38,  1.06it/s]\u001b[A\n",
      "Average Metric: 340 / 819  (41.5):  41%|      | 819/2000 [10:49<24:35,  1.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ctntcraoor'. A: optic B: unit C: contractor D: humidity\n",
      "Answer: D: humidity\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lgare'? A: deficiency B: desk C: large D: moses\n",
      "Answer: D: moses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 340 / 820  (41.5):  41%|      | 819/2000 [10:49<24:35,  1.25s/it]\u001b[A\n",
      "Average Metric: 340 / 820  (41.5):  41%|      | 820/2000 [10:49<19:36,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'boderr'. A: anybody B: petite C: oceania D: border\n",
      "Answer: B: petite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 821  (41.4):  41%|      | 820/2000 [10:50<19:36,  1.00it/s]\u001b[A\n",
      "Average Metric: 340 / 821  (41.4):  41%|      | 821/2000 [10:50<18:35,  1.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mnylarad' represent when unscrambled? A: maryland B: achieve C: structured D: semester\n",
      "Answer: D: semester\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 340 / 822  (41.4):  41%|      | 821/2000 [10:50<18:35,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 340 / 822  (41.4):  41%|      | 822/2000 [10:50<15:04,  1.30it/s]\u001b[A\n",
      "Average Metric: 341 / 823  (41.4):  41%|      | 822/2000 [10:51<15:04,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 341 / 823  (41.4):  41%|      | 823/2000 [10:51<12:47,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 824  (41.4):  41%|      | 823/2000 [10:51<12:47,  1.53it/s]\u001b[A\n",
      "Average Metric: 341 / 824  (41.4):  41%|      | 824/2000 [10:51<09:39,  2.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tntiseg' to form the correct word. A: generates B: reservoir C: testing D: advised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 825  (41.3):  41%|      | 824/2000 [10:52<09:39,  2.03it/s]\u001b[A\n",
      "Average Metric: 341 / 825  (41.3):  41%|     | 825/2000 [10:52<13:04,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 826  (41.4):  41%|     | 825/2000 [10:54<13:04,  1.50it/s]\u001b[A\n",
      "Average Metric: 342 / 826  (41.4):  41%|     | 826/2000 [10:54<21:38,  1.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aacletlod' to form the correct word. A: allocated B: display C: lace D: subscribe\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aoevidd'. A: risk B: respect C: deployed D: avoided\n",
      "Answer: D: avoided\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'thiaanld'. A: glasses B: thailand C: kiss D: patriot\n",
      "Answer: D: patriot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cllnaeevd'. A: grown B: experiments C: cleveland D: offshore\n",
      "Answer: C: cleveland\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'noevl' represent when unscrambled? A: erik B: novel C: float D: terminology\n",
      "Answer: B: novel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 342 / 827  (41.4):  41%|     | 826/2000 [10:55<21:38,  1.11s/it]\u001b[A\n",
      "Average Metric: 342 / 827  (41.4):  41%|     | 827/2000 [10:55<22:51,  1.17s/it]\u001b[A\n",
      "Average Metric: 342 / 828  (41.3):  41%|     | 827/2000 [10:55<22:51,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 343 / 829  (41.4):  41%|     | 828/2000 [10:56<22:50,  1.17s/it]\u001b[A\n",
      "Average Metric: 343 / 829  (41.4):  41%|     | 829/2000 [10:56<14:46,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 343 / 830  (41.3):  41%|     | 829/2000 [10:56<14:46,  1.32it/s]\u001b[A\n",
      "Average Metric: 343 / 830  (41.3):  42%|     | 830/2000 [10:56<13:40,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'smnkiog'. A: hilary B: cincinnati C: drive D: smoking\n",
      "Answer: D: smoking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 344 / 831  (41.4):  42%|     | 830/2000 [10:57<13:40,  1.43it/s]\u001b[A\n",
      "Average Metric: 344 / 831  (41.4):  42%|     | 831/2000 [10:57<11:32,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 832  (41.3):  42%|     | 831/2000 [10:58<11:32,  1.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 344 / 832  (41.3):  42%|     | 832/2000 [10:58<16:11,  1.20it/s]\u001b[A\n",
      "Average Metric: 344 / 833  (41.3):  42%|     | 832/2000 [10:58<16:11,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 834  (41.2):  42%|     | 833/2000 [10:59<16:10,  1.20it/s]\u001b[A\n",
      "Average Metric: 344 / 834  (41.2):  42%|     | 834/2000 [10:59<12:51,  1.51it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 835  (41.2):  42%|     | 834/2000 [10:59<12:51,  1.51it/s]\u001b[A\n",
      "Average Metric: 344 / 835  (41.2):  42%|     | 835/2000 [10:59<10:57,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hsbunad'? A: uganda B: cuba C: inspired D: husband\n",
      "Answer: D: husband\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 836  (41.1):  42%|     | 835/2000 [11:00<10:57,  1.77it/s]\u001b[A\n",
      "Average Metric: 344 / 836  (41.1):  42%|     | 836/2000 [11:00<14:16,  1.36it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'suiydtng'? A: arizona B: files C: integer D: studying\n",
      "Answer: D: studying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 837  (41.1):  42%|     | 836/2000 [11:01<14:16,  1.36it/s]\u001b[A\n",
      "Average Metric: 344 / 837  (41.1):  42%|     | 837/2000 [11:01<14:29,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 344 / 838  (41.1):  42%|     | 837/2000 [11:02<14:29,  1.34it/s]\u001b[A\n",
      "Average Metric: 344 / 838  (41.1):  42%|     | 838/2000 [11:02<12:41,  1.53it/s]\u001b[A\n",
      "Average Metric: 344 / 839  (41.0):  42%|     | 838/2000 [11:02<12:41,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 344 / 839  (41.0):  42%|     | 839/2000 [11:02<09:48,  1.97it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnoiojuntcn'? A: differential B: conjunction C: kenya D: corpus\n",
      "Answer: B: conjunction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lisence' to form the correct word. A: race B: wage C: python D: license\n",
      "Answer: D: license\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'motbiana'. A: section B: carter C: defines D: manitoba\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'acepct'. A: thrown B: accept C: hiring D: humanities\n",
      "Answer: C: hiring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 840  (41.0):  42%|     | 839/2000 [11:03<09:48,  1.97it/s]\u001b[A\n",
      "Average Metric: 344 / 840  (41.0):  42%|     | 840/2000 [11:03<13:35,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'stwhcied' represent when unscrambled? A: lansing B: fitted C: skype D: switched\n",
      "Answer: D: switched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 345 / 841  (41.0):  42%|     | 840/2000 [11:04<13:35,  1.42it/s]\u001b[A\n",
      "Average Metric: 345 / 841  (41.0):  42%|     | 841/2000 [11:04<13:14,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tomsrehee'. A: adult B: threesome C: shelves D: pass\n",
      "Answer: D: pass\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'seeht' represent when unscrambled? A: waist B: jeff C: reliability D: sheet\n",
      "Answer: A: waist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 346 / 842  (41.1):  42%|     | 841/2000 [11:05<13:14,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 346 / 842  (41.1):  42%|     | 842/2000 [11:05<19:10,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'doonr' to form the correct word. A: humanity B: envelope C: founding D: donor\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 346 / 843  (41.0):  42%|     | 842/2000 [11:06<19:10,  1.01it/s]\u001b[A\n",
      "Average Metric: 346 / 843  (41.0):  42%|     | 843/2000 [11:06<19:45,  1.02s/it]\u001b[A\n",
      "Average Metric: 347 / 844  (41.1):  42%|     | 843/2000 [11:07<19:45,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 347 / 844  (41.1):  42%|     | 844/2000 [11:07<15:43,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pcorieisn'. A: direction B: things C: precision D: indeed\n",
      "Answer: D: indeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'edide'? A: matches B: sussex C: procedure D: eddie\n",
      "Answer: D: eddie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 845  (41.1):  42%|     | 844/2000 [11:08<15:43,  1.22it/s]\u001b[A\n",
      "Average Metric: 347 / 845  (41.1):  42%|     | 845/2000 [11:08<19:35,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 846  (41.0):  42%|     | 845/2000 [11:09<19:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 347 / 846  (41.0):  42%|     | 846/2000 [11:09<19:45,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ceftrad'. A: image B: pear C: porn D: crafted\n",
      "Answer: D: crafted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'webtesr'? A: scam B: webster C: blowjobs D: savage\n",
      "Answer: B: webster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 348 / 847  (41.1):  42%|     | 846/2000 [11:11<19:45,  1.03s/it]\u001b[A\n",
      "Average Metric: 348 / 847  (41.1):  42%|     | 847/2000 [11:11<21:18,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'vuarios'. A: roll B: situations C: various D: routing\n",
      "Answer: C: various\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 349 / 848  (41.2):  42%|     | 847/2000 [11:12<21:18,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 349 / 848  (41.2):  42%|     | 848/2000 [11:12<23:22,  1.22s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 849  (41.1):  42%|     | 848/2000 [11:13<23:22,  1.22s/it]\u001b[A\n",
      "Average Metric: 349 / 849  (41.1):  42%|     | 849/2000 [11:13<20:02,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 350 / 850  (41.2):  42%|     | 849/2000 [11:14<20:02,  1.05s/it]\u001b[A\n",
      "Average Metric: 350 / 850  (41.2):  42%|     | 850/2000 [11:14<18:45,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'beard' to form the correct word. A: bread B: sorry C: sand D: reagan\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 351 / 851  (41.2):  42%|     | 850/2000 [11:14<18:45,  1.02it/s]\u001b[A\n",
      "Average Metric: 351 / 851  (41.2):  43%|     | 851/2000 [11:14<15:17,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 852  (41.2):  43%|     | 851/2000 [11:17<15:17,  1.25it/s]\u001b[A\n",
      "Average Metric: 351 / 852  (41.2):  43%|     | 852/2000 [11:17<28:59,  1.52s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 853  (41.1):  43%|     | 852/2000 [11:17<28:59,  1.52s/it]\u001b[A\n",
      "Average Metric: 351 / 853  (41.1):  43%|     | 853/2000 [11:17<21:10,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'figetrhs'. A: fighters B: mercy C: preston D: portions\n",
      "Answer: A: fighters\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cupoe' to form the correct word. A: duties B: strongly C: opportunities D: coupe\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'clhid'. A: revolution B: quarter C: child D: gzip\n",
      "Answer: D: gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wicth'? A: timely B: known C: uganda D: witch\n",
      "Answer: D: witch\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bicneomg'? A: guard B: becoming C: infantry D: camden\n",
      "Answer: D: camden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 351 / 854  (41.1):  43%|     | 853/2000 [11:18<21:10,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 351 / 854  (41.1):  43%|     | 854/2000 [11:18<20:20,  1.06s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 352 / 855  (41.2):  43%|     | 854/2000 [11:18<20:20,  1.06s/it]\u001b[A\n",
      "Average Metric: 352 / 855  (41.2):  43%|     | 855/2000 [11:18<15:14,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 353 / 856  (41.2):  43%|     | 855/2000 [11:19<15:14,  1.25it/s]\u001b[A\n",
      "Average Metric: 353 / 856  (41.2):  43%|     | 856/2000 [11:19<14:54,  1.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 857  (41.3):  43%|     | 856/2000 [11:19<14:54,  1.28it/s]\u001b[A\n",
      "Average Metric: 354 / 857  (41.3):  43%|     | 857/2000 [11:19<11:13,  1.70it/s]\u001b[A\n",
      "Average Metric: 354 / 858  (41.3):  43%|     | 857/2000 [11:20<11:13,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 858  (41.3):  43%|     | 858/2000 [11:20<09:13,  2.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'danelig'. A: tones B: championships C: labor D: dealing\n",
      "Answer: D: dealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 354 / 859  (41.2):  43%|     | 858/2000 [11:21<09:13,  2.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 859  (41.2):  43%|     | 859/2000 [11:21<14:40,  1.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 860  (41.2):  43%|     | 859/2000 [11:21<14:40,  1.30it/s]\u001b[A\n",
      "Average Metric: 354 / 860  (41.2):  43%|     | 860/2000 [11:21<12:14,  1.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 861  (41.1):  43%|     | 860/2000 [11:22<12:14,  1.55it/s]\u001b[A\n",
      "Average Metric: 354 / 861  (41.1):  43%|     | 861/2000 [11:22<12:39,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rntuioe' represent when unscrambled? A: future B: routine C: traveler D: harassment\n",
      "Answer: A: future\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'twon' to form the correct word. A: obligations B: changelog C: gulf D: town\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'risacm'. A: specialized B: reduced C: racism D: automation\n",
      "Answer: D: automation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rggeae' to form the correct word. A: heating B: queens C: cadillac D: reggae\n",
      "Answer: D: reggae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 354 / 862  (41.1):  43%|     | 861/2000 [11:24<12:39,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 354 / 862  (41.1):  43%|     | 862/2000 [11:24<18:33,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dbuet'. A: berlin B: legend C: reserved D: debut\n",
      "Answer: D: debut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 863  (41.1):  43%|     | 862/2000 [11:24<18:33,  1.02it/s]\u001b[A\n",
      "Average Metric: 355 / 863  (41.1):  43%|     | 863/2000 [11:24<14:58,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 356 / 864  (41.2):  43%|     | 863/2000 [11:25<14:58,  1.27it/s]\u001b[A\n",
      "Average Metric: 356 / 864  (41.2):  43%|     | 864/2000 [11:25<13:30,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 865  (41.2):  43%|     | 864/2000 [11:25<13:30,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 865  (41.2):  43%|     | 865/2000 [11:25<10:32,  1.79it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 866  (41.2):  43%|     | 865/2000 [11:25<10:32,  1.79it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'prcoituodn'? A: spring B: production C: compiled D: areas\n",
      "Answer: B: production\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 358 / 867  (41.3):  43%|     | 866/2000 [11:26<10:32,  1.79it/s]\u001b[A\n",
      "Average Metric: 358 / 867  (41.3):  43%|     | 867/2000 [11:26<09:53,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'diostisoipn'. A: eligible B: michel C: disposition D: weeks\n",
      "Answer: D: weeks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 358 / 868  (41.2):  43%|     | 867/2000 [11:26<09:53,  1.91it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 358 / 868  (41.2):  43%|     | 868/2000 [11:26<09:37,  1.96it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cieraommcl'. A: fixtures B: radius C: affecting D: commercial\n",
      "Answer: D: commercial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'flarmuos' represent when unscrambled? A: voting B: elsewhere C: software D: formulas\n",
      "Answer: A: voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 359 / 869  (41.3):  43%|     | 868/2000 [11:29<09:37,  1.96it/s]\u001b[A\n",
      "Average Metric: 359 / 869  (41.3):  43%|     | 869/2000 [11:29<20:51,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'asdl' to form the correct word. A: toll B: sensitive C: adsl D: deviation\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cmom'? A: comm B: handbags C: leap D: preserve\n",
      "Answer: B: handbags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 870  (41.3):  43%|     | 869/2000 [11:30<20:51,  1.11s/it]\u001b[A\n",
      "Average Metric: 359 / 870  (41.3):  44%|     | 870/2000 [11:30<18:44,  1.00it/s]\u001b[A\n",
      "Average Metric: 359 / 871  (41.2):  44%|     | 870/2000 [11:30<18:44,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'otuput'. A: anywhere B: fans C: output D: reviewed\n",
      "Answer: C: output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 872  (41.3):  44%|     | 871/2000 [11:31<18:43,  1.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 872  (41.3):  44%|     | 872/2000 [11:31<15:58,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aceiamrn' to form the correct word. A: struggling B: american C: critics D: beth\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'coledsrs'? A: cordless B: pupils C: lawyer D: emacs\n",
      "Answer: D: emacs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tdnes' represent when unscrambled? A: delivered B: wichita C: tends D: hardwood\n",
      "Answer: D: hardwood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dcunan'. A: terminated B: duncan C: rock D: dildo\n",
      "Answer: C: rock\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eimtanile'. A: certificates B: athens C: zoloft D: eliminate\n",
      "Answer: D: eliminate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 873  (41.2):  44%|     | 872/2000 [11:34<15:58,  1.18it/s]\u001b[A\n",
      "Average Metric: 360 / 873  (41.2):  44%|     | 873/2000 [11:34<23:23,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 874  (41.2):  44%|     | 873/2000 [11:36<23:23,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 360 / 874  (41.2):  44%|     | 874/2000 [11:36<27:41,  1.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 875  (41.1):  44%|     | 874/2000 [11:36<27:41,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bdes'. A: ipod B: infringement C: intention D: beds\n",
      "Answer: D: beds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 360 / 875  (41.1):  44%|     | 875/2000 [11:36<23:11,  1.24s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 876  (41.1):  44%|     | 875/2000 [11:37<23:11,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 876  (41.1):  44%|     | 876/2000 [11:37<17:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 361 / 877  (41.2):  44%|     | 876/2000 [11:37<17:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 362 / 878  (41.2):  44%|     | 877/2000 [11:37<17:50,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 362 / 878  (41.2):  44%|     | 878/2000 [11:37<12:39,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'suivrvor' to form the correct word. A: backyard B: trails C: survivor D: friendly\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 879  (41.2):  44%|     | 878/2000 [11:40<12:39,  1.48it/s]\u001b[A\n",
      "Average Metric: 362 / 879  (41.2):  44%|     | 879/2000 [11:40<21:45,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tnalet'. A: pull B: talent C: polyphonic D: communication\n",
      "Answer: D: communication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 880  (41.1):  44%|     | 879/2000 [11:41<21:45,  1.16s/it]\u001b[A\n",
      "Average Metric: 362 / 880  (41.1):  44%|     | 880/2000 [11:41<19:22,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pessoss' to form the correct word. A: java B: hugh C: possess D: save\n",
      "Answer: D: save\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'caasul' to form the correct word. A: fisting B: umbrella C: sender D: casual\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'smhrip'. A: chairs B: jessica C: computed D: shrimp\n",
      "Answer: D: shrimp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 362 / 881  (41.1):  44%|     | 880/2000 [11:42<19:22,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 362 / 881  (41.1):  44%|     | 881/2000 [11:42<22:12,  1.19s/it]\u001b[A\n",
      "Average Metric: 363 / 882  (41.2):  44%|     | 881/2000 [11:42<22:12,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cuenrrt'? A: current B: partnership C: mike D: contacted\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 363 / 883  (41.1):  44%|     | 882/2000 [11:44<22:11,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'briazl' to form the correct word. A: packing B: brazil C: deferred D: individuals\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 363 / 883  (41.1):  44%|     | 883/2000 [11:44<20:08,  1.08s/it]\u001b[A\n",
      "Average Metric: 363 / 884  (41.1):  44%|     | 883/2000 [11:44<20:08,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 364 / 885  (41.1):  44%|     | 884/2000 [11:45<20:07,  1.08s/it]\u001b[A\n",
      "Average Metric: 364 / 885  (41.1):  44%|     | 885/2000 [11:45<15:25,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'smidhct'. A: informal B: schmidt C: knives D: ourselves\n",
      "Answer: D: ourselves\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lttaiude'. A: radio B: latitude C: absorption D: listen\n",
      "Answer: D: listen\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'scotk'. A: limiting B: detected C: stock D: lives\n",
      "Answer: D: lives\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'riblatotehiian'. A: outer B: bottle C: rehabilitation D: voyuer\n",
      "Answer: D: voyuer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jtes' represent when unscrambled? A: rewards B: mighty C: honeymoon D: jets\n",
      "Answer: B: mighty\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sekes'. A: seeks B: marco C: chromosome D: valve\n",
      "Answer: A: seeks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 365 / 886  (41.2):  44%|     | 885/2000 [11:47<15:25,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 365 / 886  (41.2):  44%|     | 886/2000 [11:47<19:47,  1.07s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 887  (41.1):  44%|     | 886/2000 [11:47<19:47,  1.07s/it]\u001b[A\n",
      "Average Metric: 365 / 887  (41.1):  44%|     | 887/2000 [11:47<16:27,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 888  (41.2):  44%|     | 887/2000 [11:47<16:27,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 889  (41.2):  44%|     | 888/2000 [11:47<16:26,  1.13it/s]\u001b[A\n",
      "Average Metric: 366 / 889  (41.2):  44%|     | 889/2000 [11:47<10:39,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'selhl' represent when unscrambled? A: forthcoming B: bullet C: parental D: shell\n",
      "Answer: D: shell\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pseverre'. A: wikimedia B: preserve C: marry D: cabin\n",
      "Answer: D: cabin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'veuens'? A: venues B: tiffany C: himself D: totals\n",
      "Answer: venues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 890  (41.1):  44%|     | 889/2000 [11:49<10:39,  1.74it/s]\u001b[A\n",
      "Average Metric: 366 / 890  (41.1):  44%|     | 890/2000 [11:49<15:45,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 891  (41.1):  44%|     | 890/2000 [11:51<15:45,  1.17it/s]\u001b[A\n",
      "Average Metric: 366 / 891  (41.1):  45%|     | 891/2000 [11:51<22:15,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 366 / 892  (41.0):  45%|     | 891/2000 [11:52<22:15,  1.20s/it]\u001b[A\n",
      "Average Metric: 366 / 892  (41.0):  45%|     | 892/2000 [11:52<18:30,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scpeeh'? A: transexuales B: speech C: numbers D: bitter\n",
      "Answer: B: speech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ihsigtns'. A: reached B: hamilton C: holdings D: insights\n",
      "Answer: D: insights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 367 / 893  (41.1):  45%|     | 892/2000 [11:53<18:30,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 367 / 893  (41.1):  45%|     | 893/2000 [11:53<17:52,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snnpideg'. A: brent B: spending C: wicked D: took\n",
      "Answer: b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 894  (41.1):  45%|     | 893/2000 [11:54<17:52,  1.03it/s]\u001b[A\n",
      "Average Metric: 367 / 894  (41.1):  45%|     | 894/2000 [11:54<18:20,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mlratoity' represent when unscrambled? A: girl B: aberdeen C: mortality D: meaning\n",
      "Answer: D: meaning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 367 / 895  (41.0):  45%|     | 894/2000 [11:56<18:20,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 367 / 895  (41.0):  45%|     | 895/2000 [11:56<25:08,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'blnoaols'. A: balloons B: processors C: yeast D: clients\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'coprrotae' to form the correct word. A: corporate B: decent C: fuzzy D: exciting\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'suepr' represent when unscrambled? A: hamilton B: users C: super D: boating\n",
      "Answer: A: hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 896  (41.0):  45%|     | 895/2000 [11:58<25:08,  1.36s/it]\u001b[A\n",
      "Average Metric: 367 / 896  (41.0):  45%|     | 896/2000 [11:58<29:58,  1.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wacsbet' to form the correct word. A: blades B: webcast C: fridge D: analyses\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 367 / 897  (40.9):  45%|     | 896/2000 [11:58<29:58,  1.63s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 898  (40.9):  45%|     | 897/2000 [11:59<29:56,  1.63s/it]\u001b[A\n",
      "Average Metric: 367 / 898  (40.9):  45%|     | 898/2000 [11:59<16:54,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lsaer'? A: laser B: fabrics C: figure D: setup\n",
      "Answer: A: laser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 368 / 899  (40.9):  45%|     | 898/2000 [12:00<16:54,  1.09it/s]\u001b[A\n",
      "Average Metric: 368 / 899  (40.9):  45%|     | 899/2000 [12:00<18:17,  1.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 900  (40.9):  45%|     | 899/2000 [12:00<18:17,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 901  (41.0):  45%|     | 900/2000 [12:00<18:16,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 369 / 901  (41.0):  45%|     | 901/2000 [12:00<11:29,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'haobnodk'. A: hitting B: handbook C: mailbox D: suites\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'orgsaiend' represent when unscrambled? A: organised B: viewers C: tobacco D: hockey\n",
      "Answer: A: organised\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eisgnlh'. A: grid B: english C: cialis D: wilson\n",
      "Answer: D: wilson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'veertan' represent when unscrambled? A: adequately B: veteran C: reasonably D: combining\n",
      "Answer: D: combining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'silnet'. A: silent B: insulation C: attempt D: happened\n",
      "Answer: D: happened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 902  (41.0):  45%|     | 901/2000 [12:04<11:29,  1.59it/s]\u001b[A\n",
      "Average Metric: 370 / 902  (41.0):  45%|     | 902/2000 [12:04<25:58,  1.42s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 903  (41.0):  45%|     | 902/2000 [12:05<25:58,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 370 / 903  (41.0):  45%|     | 903/2000 [12:05<24:19,  1.33s/it]\u001b[A\n",
      "Average Metric: 370 / 904  (40.9):  45%|     | 903/2000 [12:05<24:19,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 371 / 905  (41.0):  45%|     | 904/2000 [12:06<24:18,  1.33s/it]\u001b[A\n",
      "Average Metric: 371 / 905  (41.0):  45%|     | 905/2000 [12:06<15:47,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 906  (41.1):  45%|     | 905/2000 [12:07<15:47,  1.16it/s]\u001b[A\n",
      "Average Metric: 372 / 906  (41.1):  45%|     | 906/2000 [12:07<17:22,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'erous'. A: baseline B: back C: southeast D: euros\n",
      "Answer: C: southeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 372 / 907  (41.0):  45%|     | 906/2000 [12:08<17:22,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 372 / 907  (41.0):  45%|     | 907/2000 [12:08<18:01,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'soon' represent when unscrambled? A: birmingham B: soon C: favors D: achieve\n",
      "Answer: B: soon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 908  (41.0):  45%|     | 907/2000 [12:09<18:01,  1.01it/s]\u001b[A\n",
      "Average Metric: 372 / 908  (41.0):  45%|     | 908/2000 [12:09<16:30,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bleow' to form the correct word. A: price B: below C: determined D: temporal\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bellut'. A: stocks B: attachments C: bullet D: supportive\n",
      "Answer: D: supportive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cinnatos' represent when unscrambled? A: roster B: breasts C: relay D: contains\n",
      "Answer: D: contains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'seurm'. A: diploma B: breasts C: fitting D: serum\n",
      "Answer: D: serum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 909  (40.9):  45%|     | 908/2000 [12:10<16:30,  1.10it/s]\u001b[A\n",
      "Average Metric: 372 / 909  (40.9):  45%|     | 909/2000 [12:10<18:57,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 372 / 910  (40.9):  45%|     | 909/2000 [12:10<18:57,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 372 / 911  (40.8):  46%|     | 910/2000 [12:10<18:56,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 912  (40.9):  46%|     | 911/2000 [12:10<18:55,  1.04s/it]\u001b[A\n",
      "Average Metric: 373 / 912  (40.9):  46%|     | 912/2000 [12:10<09:45,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wreroks'. A: happiness B: workers C: publication D: beastality\n",
      "Answer: D: beastality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pliulng' to form the correct word. A: pulling B: buyers C: news D: episodes\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tanurneomt'? A: tournament B: assisting C: sims D: yale\n",
      "Answer: B: assisting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 913  (40.9):  46%|     | 912/2000 [12:13<09:45,  1.86it/s]\u001b[A\n",
      "Average Metric: 373 / 913  (40.9):  46%|     | 913/2000 [12:13<19:07,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 914  (40.8):  46%|     | 913/2000 [12:14<19:07,  1.06s/it]\u001b[A\n",
      "Average Metric: 373 / 914  (40.8):  46%|     | 914/2000 [12:14<17:54,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 915  (40.9):  46%|     | 914/2000 [12:15<17:54,  1.01it/s]\u001b[A\n",
      "Average Metric: 374 / 915  (40.9):  46%|     | 915/2000 [12:15<15:32,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'shopsnat'? A: miles B: snapshot C: elder D: focal\n",
      "Answer: miles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 375 / 916  (40.9):  46%|     | 915/2000 [12:15<15:32,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 375 / 916  (40.9):  46%|     | 916/2000 [12:15<15:08,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bvoeeld'? A: sheriff B: beloved C: completing D: stack\n",
      "Answer: D: stack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 917  (41.0):  46%|     | 916/2000 [12:16<15:08,  1.19it/s]\u001b[A\n",
      "Average Metric: 376 / 917  (41.0):  46%|     | 917/2000 [12:16<12:37,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 918  (41.0):  46%|     | 917/2000 [12:17<12:37,  1.43it/s]\u001b[A\n",
      "Average Metric: 376 / 918  (41.0):  46%|     | 918/2000 [12:17<13:24,  1.34it/s]\u001b[A\n",
      "Average Metric: 377 / 919  (41.0):  46%|     | 918/2000 [12:17<13:24,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 377 / 919  (41.0):  46%|     | 919/2000 [12:17<10:11,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'door' represent when unscrambled? A: titanium B: door C: gone D: ball\n",
      "Answer: B: door\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 920  (41.0):  46%|     | 919/2000 [12:17<10:11,  1.77it/s]\u001b[A\n",
      "Average Metric: 377 / 920  (41.0):  46%|     | 920/2000 [12:17<09:59,  1.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 921  (40.9):  46%|     | 920/2000 [12:18<09:59,  1.80it/s]\u001b[A\n",
      "Average Metric: 377 / 921  (40.9):  46%|     | 921/2000 [12:18<12:34,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cviic' to form the correct word. A: ride B: clear C: civic D: represents\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fumlroa' represent when unscrambled? A: aware B: examined C: slideshow D: formula\n",
      "Answer: D: formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ternaid'? A: properly B: trained C: nipple D: toolbar\n",
      "Answer: A: properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 922  (40.9):  46%|     | 921/2000 [12:20<12:34,  1.43it/s]\u001b[A\n",
      "Average Metric: 377 / 922  (40.9):  46%|     | 922/2000 [12:20<18:47,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'inenetdd'. A: generators B: riley C: intended D: negative\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ctitnoiounbrs' represent when unscrambled? A: handmade B: freeman C: contributions D: completed\n",
      "Answer: D: completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 378 / 923  (41.0):  46%|     | 922/2000 [12:22<18:47,  1.05s/it]\u001b[A\n",
      "Average Metric: 378 / 923  (41.0):  46%|     | 923/2000 [12:22<20:42,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'vovlo'. A: volvo B: contents C: published D: wagner\n",
      "Answer: D: wagner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dndmaes'? A: meditation B: tanzania C: tennessee D: demands\n",
      "Answer: B: tanzania\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mtreats'? A: essays B: books C: matters D: copenhagen\n",
      "Answer: B: books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 924  (41.0):  46%|     | 923/2000 [12:23<20:42,  1.15s/it]\u001b[A\n",
      "Average Metric: 379 / 924  (41.0):  46%|     | 924/2000 [12:23<21:09,  1.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rsepcet'? A: corresponds B: pogo C: respect D: guardian\n",
      "Answer: D: guardian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 925  (41.0):  46%|     | 924/2000 [12:23<21:09,  1.18s/it]\u001b[A\n",
      "Average Metric: 379 / 925  (41.0):  46%|     | 925/2000 [12:23<16:21,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dualpicte' to form the correct word. A: erotik B: exclusively C: duplicate D: refill\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pkbraapecs'. A: paperbacks B: tamil C: actress D: prague\n",
      "Answer: C: actress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 926  (40.9):  46%|     | 925/2000 [12:25<16:21,  1.10it/s]\u001b[A\n",
      "Average Metric: 379 / 926  (40.9):  46%|     | 926/2000 [12:25<24:14,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sripct' represent when unscrambled? A: ebony B: browsers C: threats D: script\n",
      "Answer: D: script\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 927  (40.9):  46%|     | 926/2000 [12:27<24:14,  1.35s/it]\u001b[A\n",
      "Average Metric: 379 / 927  (40.9):  46%|     | 927/2000 [12:27<25:52,  1.45s/it]\u001b[A\n",
      "Average Metric: 379 / 928  (40.8):  46%|     | 927/2000 [12:27<25:52,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 929  (40.9):  46%|     | 928/2000 [12:28<25:50,  1.45s/it]\u001b[A\n",
      "Average Metric: 380 / 929  (40.9):  46%|     | 929/2000 [12:28<18:44,  1.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tkwins'. A: theory B: mailed C: import D: twinks\n",
      "Answer: D: twinks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'brainbse'. A: entertainment B: provision C: button D: brisbane\n",
      "Answer: D: brisbane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 381 / 930  (41.0):  46%|     | 929/2000 [12:29<18:44,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 381 / 930  (41.0):  46%|     | 930/2000 [12:29<17:39,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cnoan'. A: lauderdale B: canon C: hybrid D: graduated\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gule' represent when unscrambled? A: villa B: cheats C: glue D: broad\n",
      "Answer: D: broad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'szeid' represent when unscrambled? A: sized B: stating C: initiative D: compact\n",
      "Answer: D: compact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iotcuniefs'? A: hierarchy B: tsunami C: infectious D: carl\n",
      "Answer: hierarchy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nwohere'. A: nets B: rest C: nowhere D: bomb\n",
      "Answer: D: bomb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 381 / 931  (40.9):  46%|     | 930/2000 [12:33<17:39,  1.01it/s]\u001b[A\n",
      "Average Metric: 381 / 931  (40.9):  47%|     | 931/2000 [12:33<30:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nniforpot'. A: nonprofit B: atoms C: scream D: slideshow\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 381 / 932  (40.9):  47%|     | 931/2000 [12:33<30:18,  1.70s/it]\u001b[A\n",
      "Average Metric: 381 / 932  (40.9):  47%|     | 932/2000 [12:33<23:48,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 381 / 933  (40.8):  47%|     | 932/2000 [12:33<23:48,  1.34s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 382 / 934  (40.9):  47%|     | 933/2000 [12:33<23:47,  1.34s/it]\u001b[A\n",
      "Average Metric: 382 / 934  (40.9):  47%|     | 934/2000 [12:33<13:48,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 382 / 935  (40.9):  47%|     | 934/2000 [12:34<13:48,  1.29it/s]\u001b[A\n",
      "Average Metric: 382 / 935  (40.9):  47%|     | 935/2000 [12:34<12:10,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'chciamel'. A: relay B: jump C: chemical D: personal\n",
      "Answer: A: relay\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'gard'. A: grad B: films C: different D: appearing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iatoonaimfnrl'? A: smilies B: informational C: away D: determines\n",
      "Answer: D: determines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 936  (40.9):  47%|     | 935/2000 [12:36<12:10,  1.46it/s]\u001b[A\n",
      "Average Metric: 383 / 936  (40.9):  47%|     | 936/2000 [12:36<19:30,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 937  (40.9):  47%|     | 936/2000 [12:37<19:30,  1.10s/it]\u001b[A\n",
      "Average Metric: 383 / 937  (40.9):  47%|     | 937/2000 [12:37<17:46,  1.00s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 938  (40.8):  47%|     | 937/2000 [12:37<17:46,  1.00s/it]\u001b[A\n",
      "Average Metric: 383 / 938  (40.8):  47%|     | 938/2000 [12:37<13:38,  1.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 939  (40.8):  47%|     | 938/2000 [12:37<13:38,  1.30it/s]\u001b[A\n",
      "Average Metric: 383 / 939  (40.8):  47%|     | 939/2000 [12:37<11:52,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'droos'. A: doors B: senegal C: hate D: developments\n",
      "Answer: D: developments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 383 / 940  (40.7):  47%|     | 939/2000 [12:38<11:52,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 383 / 940  (40.7):  47%|     | 940/2000 [12:38<11:50,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ridpas'? A: rapids B: israel C: flavor D: united\n",
      "Answer: D: united\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'uinv'. A: univ B: scales C: productions D: podcasts\n",
      "Answer: A: univ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bteotls' to form the correct word. A: lone B: bottles C: what D: ocean\n",
      "Answer: B\n",
      "\n",
      "Question: Which of the following is the smallest value?  (a) 0.1  (b) 1/3  (c) 1/2  (d) 0.01\n",
      "Answer: d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 383 / 941  (40.7):  47%|     | 940/2000 [12:39<11:50,  1.49it/s]\u001b[A\n",
      "Average Metric: 383 / 941  (40.7):  47%|     | 941/2000 [12:39<13:16,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 942  (40.8):  47%|     | 941/2000 [12:39<13:16,  1.33it/s]\u001b[A\n",
      "Average Metric: 384 / 942  (40.8):  47%|     | 942/2000 [12:39<11:19,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'msuoe' represent when unscrambled? A: analyst B: that C: mouse D: interracial\n",
      "Answer: A: analyst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 384 / 943  (40.7):  47%|     | 942/2000 [12:40<11:19,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 384 / 943  (40.7):  47%|     | 943/2000 [12:40<13:50,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'csehs'. A: manufacturer B: chess C: apply D: nuke\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 944  (40.7):  47%|     | 943/2000 [12:42<13:50,  1.27it/s]\u001b[A\n",
      "Average Metric: 384 / 944  (40.7):  47%|     | 944/2000 [12:42<17:49,  1.01s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 945  (40.6):  47%|     | 944/2000 [12:42<17:49,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ieetrnitvnon' represent when unscrambled? A: thick B: intervention C: overall D: picked\n",
      "Answer: D: picked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mgnaaer' to form the correct word. A: roland B: larger C: cordless D: manager\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 946  (40.7):  47%|     | 945/2000 [12:44<17:48,  1.01s/it]\u001b[A\n",
      "Average Metric: 385 / 946  (40.7):  47%|     | 946/2000 [12:44<19:10,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peessrd'? A: classics B: pressed C: manitoba D: wait\n",
      "Answer: B: pressed\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ftaerhs'. A: finishing B: uniforms C: fathers D: bonds\n",
      "Answer: D: bonds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lgnodtiue' to form the correct word. A: longitude B: journals C: quote D: competition\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cceanl' to form the correct word. A: sold B: newsletter C: segment D: cancel\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 947  (40.8):  47%|     | 946/2000 [12:46<19:10,  1.09s/it]\u001b[A\n",
      "Average Metric: 386 / 947  (40.8):  47%|     | 947/2000 [12:46<20:32,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 387 / 948  (40.8):  47%|     | 947/2000 [12:46<20:32,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 387 / 948  (40.8):  47%|     | 948/2000 [12:46<16:07,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'frobes' represent when unscrambled? A: trains B: suggestions C: forbes D: vocals\n",
      "Answer: A: trains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 387 / 949  (40.8):  47%|     | 948/2000 [12:47<16:07,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 387 / 949  (40.8):  47%|     | 949/2000 [12:47<18:28,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tisohba' represent when unscrambled? A: lunch B: lamp C: toshiba D: toronto\n",
      "Answer: A: lunch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 387 / 950  (40.7):  47%|     | 949/2000 [12:48<18:28,  1.05s/it]\u001b[A\n",
      "Average Metric: 387 / 950  (40.7):  48%|     | 950/2000 [12:48<17:28,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'qenirnoituase'? A: manner B: tries C: sage D: questionnaire\n",
      "Answer: D: questionnaire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'svriuve'. A: slovak B: arabia C: versus D: survive\n",
      "Answer: D: survive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 388 / 951  (40.8):  48%|     | 950/2000 [12:50<17:28,  1.00it/s]\u001b[A\n",
      "Average Metric: 388 / 951  (40.8):  48%|     | 951/2000 [12:50<22:31,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cnmmacuiote' to form the correct word. A: interface B: communicate C: human D: crossing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 389 / 952  (40.9):  48%|     | 951/2000 [12:51<22:31,  1.29s/it]\u001b[A\n",
      "Average Metric: 389 / 952  (40.9):  48%|     | 952/2000 [12:51<19:02,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 390 / 953  (40.9):  48%|     | 952/2000 [12:51<19:02,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 390 / 953  (40.9):  48%|     | 953/2000 [12:51<14:20,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'poduns'. A: looksmart B: introduction C: pounds D: dies\n",
      "Answer: D: dies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 391 / 954  (41.0):  48%|     | 953/2000 [12:54<14:20,  1.22it/s]\u001b[A\n",
      "Average Metric: 391 / 954  (41.0):  48%|     | 954/2000 [12:54<23:27,  1.35s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 391 / 955  (40.9):  48%|     | 954/2000 [12:54<23:27,  1.35s/it]\u001b[A\n",
      "Average Metric: 391 / 955  (40.9):  48%|     | 955/2000 [12:54<17:36,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 956  (41.0):  48%|     | 955/2000 [12:55<17:36,  1.01s/it]\u001b[A\n",
      "Average Metric: 392 / 956  (41.0):  48%|     | 956/2000 [12:55<17:09,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'giong'. A: transcripts B: accordance C: lodges D: going\n",
      "Answer: D: going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hgneyie'? A: swing B: references C: hygiene D: obtaining\n",
      "Answer: D: obtaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 392 / 957  (41.0):  48%|     | 956/2000 [12:56<17:09,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 392 / 957  (41.0):  48%|     | 957/2000 [12:56<20:27,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 392 / 958  (40.9):  48%|     | 957/2000 [12:56<20:27,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 959  (40.9):  48%|     | 958/2000 [12:57<20:25,  1.18s/it]\u001b[A\n",
      "Average Metric: 392 / 959  (40.9):  48%|     | 959/2000 [12:57<12:01,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'trrnoastiptoan'? A: transportation B: assumptions C: inquiry D: expanding\n",
      "Answer: transportation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 392 / 960  (40.8):  48%|     | 959/2000 [12:57<12:01,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 392 / 960  (40.8):  48%|     | 960/2000 [12:57<09:38,  1.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'psnneeorl'. A: personnel B: referring C: gallon D: hyatt\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 392 / 961  (40.8):  48%|     | 960/2000 [12:58<09:38,  1.80it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 392 / 961  (40.8):  48%|     | 961/2000 [12:58<11:30,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 962  (40.9):  48%|     | 961/2000 [12:58<11:30,  1.50it/s]\u001b[A\n",
      "Average Metric: 393 / 962  (40.9):  48%|     | 962/2000 [12:58<09:27,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fmarol' to form the correct word. A: vice B: formal C: obtained D: photography\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 393 / 963  (40.8):  48%|     | 962/2000 [12:59<09:27,  1.83it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 393 / 963  (40.8):  48%|     | 963/2000 [12:59<12:24,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ttrhneeead' represent when unscrambled? A: museum B: oceania C: threatened D: slut\n",
      "Answer: D: slut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 964  (40.9):  48%|     | 963/2000 [13:00<12:24,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 394 / 964  (40.9):  48%|     | 964/2000 [13:00<14:33,  1.19it/s]\u001b[A\n",
      "Average Metric: 394 / 965  (40.8):  48%|     | 964/2000 [13:00<14:33,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tcacital' to form the correct word. A: securely B: tactical C: schemes D: customized\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ceemnt'. A: vacation B: diseases C: cement D: merry\n",
      "Answer: C: cement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lniux'? A: vegetation B: allowance C: linux D: incentive\n",
      "Answer: C: linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'atrs' to form the correct word. A: months B: supplier C: mayor D: arts\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest prime number?  A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hmour' represent when unscrambled? A: viral B: bizarre C: eighth D: humor\n",
      "Answer: D: humor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 394 / 966  (40.8):  48%|     | 965/2000 [13:02<14:33,  1.19it/s]\u001b[A\n",
      "Average Metric: 394 / 966  (40.8):  48%|     | 966/2000 [13:02<16:16,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 395 / 967  (40.8):  48%|     | 966/2000 [13:02<16:16,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 968  (40.9):  48%|     | 967/2000 [13:03<16:15,  1.06it/s]\u001b[A\n",
      "Average Metric: 396 / 968  (40.9):  48%|     | 968/2000 [13:03<10:34,  1.63it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 397 / 969  (41.0):  48%|     | 968/2000 [13:03<10:34,  1.63it/s]\u001b[A\n",
      "Average Metric: 397 / 969  (41.0):  48%|     | 969/2000 [13:03<09:05,  1.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vkolgwesan' represent when unscrambled? A: volkswagen B: cdna C: preview D: glenn\n",
      "Answer: A: volkswagen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gnmoe'. A: gnome B: mirrors C: compact D: tribunal\n",
      "Answer: A: gnome\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'arvired' represent when unscrambled? A: cabin B: counters C: arrived D: proceed\n",
      "Answer: D: proceed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'criale' represent when unscrambled? A: claire B: illustrate C: furthermore D: damages\n",
      "Answer: A: claire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 398 / 970  (41.0):  48%|     | 969/2000 [13:05<09:05,  1.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 970  (41.0):  48%|     | 970/2000 [13:05<17:02,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'maeanitrsm'. A: mainstream B: belts C: binding D: proportion\n",
      "Answer: D: proportion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 399 / 971  (41.1):  48%|     | 970/2000 [13:06<17:02,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 399 / 971  (41.1):  49%|     | 971/2000 [13:06<16:27,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bsuty'? A: install B: busty C: diving D: salvador\n",
      "Answer: D: salvador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fuotrh'. A: cleveland B: searches C: theories D: fourth\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rownened' to form the correct word. A: compute B: gothic C: renowned D: introduces\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 399 / 972  (41.0):  49%|     | 971/2000 [13:09<16:27,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 972  (41.0):  49%|     | 972/2000 [13:09<24:49,  1.45s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 973  (41.0):  49%|     | 972/2000 [13:09<24:49,  1.45s/it]\u001b[A\n",
      "Average Metric: 399 / 973  (41.0):  49%|     | 973/2000 [13:09<19:17,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mmreoy' to form the correct word. A: memory B: norway C: milk D: pressure\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 974  (41.0):  49%|     | 973/2000 [13:12<19:17,  1.13s/it]\u001b[A\n",
      "Average Metric: 399 / 974  (41.0):  49%|     | 974/2000 [13:12<25:14,  1.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 975  (40.9):  49%|     | 974/2000 [13:12<25:14,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 399 / 975  (40.9):  49%|     | 975/2000 [13:12<20:33,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'auldt' to form the correct word. A: remedy B: checking C: kernel D: adult\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'derise'. A: barely B: parents C: bits D: desire\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 976  (40.9):  49%|     | 975/2000 [13:13<20:33,  1.20s/it]\u001b[A\n",
      "Average Metric: 399 / 976  (40.9):  49%|     | 976/2000 [13:13<19:06,  1.12s/it]\u001b[A\n",
      "Average Metric: 399 / 977  (40.8):  49%|     | 976/2000 [13:13<19:06,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 977  (40.8):  49%|     | 977/2000 [13:13<14:53,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'moiauntn' represent when unscrambled? A: yard B: isle C: mountain D: navy\n",
      "Answer: C: mountain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'elemrpoys'. A: optics B: employers C: spotlight D: seat\n",
      "Answer: C: spotlight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cooln'. A: meta B: worked C: beatles D: colon\n",
      "Answer: D: colon\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'elnroscue' represent when unscrambled? A: enclosure B: neat C: uniprotkb D: refinance\n",
      "Answer: A: enclosure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mepg' to form the correct word. A: evaluations B: aged C: mpeg D: oakland\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 399 / 978  (40.8):  49%|     | 977/2000 [13:17<14:53,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 978  (40.8):  49%|     | 978/2000 [13:17<27:51,  1.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 979  (40.8):  49%|     | 978/2000 [13:17<27:51,  1.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 400 / 980  (40.8):  49%|     | 979/2000 [13:18<27:49,  1.64s/it]\u001b[A\n",
      "Average Metric: 400 / 980  (40.8):  49%|     | 980/2000 [13:18<18:59,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 981  (40.9):  49%|     | 980/2000 [13:18<18:59,  1.12s/it]\u001b[A\n",
      "Average Metric: 401 / 981  (40.9):  49%|     | 981/2000 [13:18<16:04,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 982  (40.8):  49%|     | 981/2000 [13:20<16:04,  1.06it/s]\u001b[A\n",
      "Average Metric: 401 / 982  (40.8):  49%|     | 982/2000 [13:20<17:33,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bevieeld' to form the correct word. A: gave B: seeks C: placement D: believed\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 401 / 983  (40.8):  49%|     | 982/2000 [13:20<17:33,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 401 / 983  (40.8):  49%|     | 983/2000 [13:20<14:16,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'onngoig' represent when unscrambled? A: thomas B: inclusion C: cartridge D: ongoing\n",
      "Answer: D: ongoing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 984  (40.8):  49%|     | 983/2000 [13:21<14:16,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 984  (40.8):  49%|     | 984/2000 [13:21<14:51,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 402 / 985  (40.8):  49%|     | 984/2000 [13:21<14:51,  1.14it/s]\u001b[A\n",
      "Average Metric: 402 / 985  (40.8):  49%|     | 985/2000 [13:21<11:25,  1.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sapm'. A: prospects B: spam C: usgs D: tracks\n",
      "Answer: D: tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'terhw' to form the correct word. A: brazilian B: threw C: carlo D: ecommerce\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bratzie'. A: hardcore B: bizrate C: couples D: forwarded\n",
      "Answer: B: bizrate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 402 / 986  (40.8):  49%|     | 985/2000 [13:24<11:25,  1.48it/s]\u001b[A\n",
      "Average Metric: 402 / 986  (40.8):  49%|     | 986/2000 [13:24<20:22,  1.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fcitunnos'. A: proxy B: insure C: browsers D: functions\n",
      "Answer: C: browsers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aovn' represent when unscrambled? A: sign B: attitudes C: avon D: judgment\n",
      "Answer: D: judgment\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tteints'? A: milf B: tittens C: headsets D: biological\n",
      "Answer: B: tittens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 402 / 987  (40.7):  49%|     | 986/2000 [13:25<20:22,  1.21s/it]\u001b[A\n",
      "Average Metric: 402 / 987  (40.7):  49%|     | 987/2000 [13:25<22:13,  1.32s/it]\u001b[A\n",
      "Average Metric: 403 / 988  (40.8):  49%|     | 987/2000 [13:25<22:13,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 404 / 989  (40.8):  49%|     | 988/2000 [13:26<22:12,  1.32s/it]\u001b[A\n",
      "Average Metric: 404 / 989  (40.8):  49%|     | 989/2000 [13:26<13:47,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 405 / 990  (40.9):  49%|     | 989/2000 [13:26<13:47,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 991  (40.9):  50%|     | 990/2000 [13:26<13:46,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 992  (40.8):  50%|     | 991/2000 [13:26<13:45,  1.22it/s]\u001b[A\n",
      "Average Metric: 405 / 992  (40.8):  50%|     | 992/2000 [13:26<07:15,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 993  (40.9):  50%|     | 992/2000 [13:26<07:15,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 994  (40.8):  50%|     | 993/2000 [13:28<07:15,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 994  (40.8):  50%|     | 994/2000 [13:28<12:23,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 406 / 995  (40.8):  50%|     | 994/2000 [13:29<12:23,  1.35it/s]\u001b[A\n",
      "Average Metric: 406 / 995  (40.8):  50%|     | 995/2000 [13:29<12:31,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 407 / 996  (40.9):  50%|     | 995/2000 [13:29<12:31,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 407 / 996  (40.9):  50%|     | 996/2000 [13:29<10:30,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sahw'. A: tennis B: efficiency C: shaw D: brake\n",
      "Answer: A: tennis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'brigaan' represent when unscrambled? A: bargain B: employee C: sites D: tragedy\n",
      "Answer: A: bargain\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lnad' represent when unscrambled? A: wallace B: singapore C: honest D: land\n",
      "Answer: D: land\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'perlhirepas' represent when unscrambled? A: peripherals B: specialty C: defendant D: adaptation\n",
      "Answer: A: peripherals\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pnnelras' represent when unscrambled? A: rest B: valium C: respiratory D: planners\n",
      "Answer: A: rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 997  (40.9):  50%|     | 996/2000 [13:32<10:30,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 408 / 997  (40.9):  50%|     | 997/2000 [13:32<19:07,  1.14s/it]\u001b[A\n",
      "Average Metric: 408 / 998  (40.9):  50%|     | 997/2000 [13:32<19:07,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 409 / 999  (40.9):  50%|     | 998/2000 [13:33<19:05,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 409 / 999  (40.9):  50%|     | 999/2000 [13:33<12:44,  1.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ecepntixg'? A: expecting B: cracks C: draws D: finals\n",
      "Answer: D: finals\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vrenods'? A: towards B: vendors C: heavy D: disasters\n",
      "Answer: D: disasters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 410 / 1000  (41.0):  50%|     | 999/2000 [13:34<12:44,  1.31it/s]\u001b[A\n",
      "Average Metric: 410 / 1000  (41.0):  50%|     | 1000/2000 [13:34<14:46,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lragset'. A: phpbb B: assessed C: fleece D: largest\n",
      "Answer: D: largest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1001  (41.1):  50%|     | 1000/2000 [13:36<14:46,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 411 / 1001  (41.1):  50%|     | 1001/2000 [13:36<18:16,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'msaks'. A: flats B: masks C: face D: ministry\n",
      "Answer: C: face\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1002  (41.0):  50%|     | 1001/2000 [13:36<18:16,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 411 / 1002  (41.0):  50%|     | 1002/2000 [13:36<15:13,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ciisrs' to form the correct word. A: drive B: depth C: freeman D: crisis\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eentr' represent when unscrambled? A: moves B: enter C: eventually D: barton\n",
      "Answer: B: enter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnsot'? A: panic B: const C: factory D: trend\n",
      "Answer: B: const\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 411 / 1003  (41.0):  50%|     | 1002/2000 [13:40<15:13,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 411 / 1003  (41.0):  50%|     | 1003/2000 [13:40<27:29,  1.65s/it]\u001b[A\n",
      "Average Metric: 412 / 1004  (41.0):  50%|     | 1003/2000 [13:40<27:29,  1.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 413 / 1005  (41.1):  50%|     | 1004/2000 [13:40<27:27,  1.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 413 / 1005  (41.1):  50%|     | 1005/2000 [13:40<16:53,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pplrue'? A: give B: similar C: purple D: antibody\n",
      "Answer: D: antibody\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 414 / 1006  (41.2):  50%|     | 1005/2000 [13:42<16:53,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 414 / 1006  (41.2):  50%|     | 1006/2000 [13:42<21:42,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 415 / 1007  (41.2):  50%|     | 1006/2000 [13:44<21:42,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 415 / 1007  (41.2):  50%|     | 1007/2000 [13:44<21:57,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'restors' to form the correct word. A: configuring B: ocean C: resorts D: cutting\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pahts'. A: desperate B: paths C: pound D: compatibility\n",
      "Answer: D: compatibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1008  (41.3):  50%|     | 1007/2000 [13:45<21:57,  1.33s/it]\u001b[A\n",
      "Average Metric: 416 / 1008  (41.3):  50%|     | 1008/2000 [13:45<23:01,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'deis' represent when unscrambled? A: traveling B: accredited C: dies D: valuation\n",
      "Answer: A: traveling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1009  (41.2):  50%|     | 1008/2000 [13:47<23:01,  1.39s/it]\u001b[A\n",
      "Average Metric: 416 / 1009  (41.2):  50%|     | 1009/2000 [13:47<21:58,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1010  (41.2):  50%|     | 1009/2000 [13:47<21:58,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 416 / 1010  (41.2):  50%|     | 1010/2000 [13:47<20:01,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ceoimttmes'. A: committees B: nutten C: inspector D: skill\n",
      "Answer: D: skill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 416 / 1011  (41.1):  50%|     | 1010/2000 [13:48<20:01,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 416 / 1011  (41.1):  51%|     | 1011/2000 [13:48<17:30,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cgpaamnhe' represent when unscrambled? A: champagne B: running C: interviewed D: rubber\n",
      "Answer: A: champagne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1012  (41.1):  51%|     | 1011/2000 [13:48<17:30,  1.06s/it]\u001b[A\n",
      "Average Metric: 416 / 1012  (41.1):  51%|     | 1012/2000 [13:48<13:05,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 417 / 1013  (41.2):  51%|     | 1012/2000 [13:48<13:05,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 417 / 1013  (41.2):  51%|     | 1013/2000 [13:49<10:23,  1.58it/s]\u001b[A\n",
      "Average Metric: 418 / 1014  (41.2):  51%|     | 1013/2000 [13:49<10:23,  1.58it/s]\u001b[A\n",
      "Average Metric: 419 / 1015  (41.3):  51%|     | 1014/2000 [13:49<10:22,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1015  (41.3):  51%|     | 1015/2000 [13:49<06:01,  2.73it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 419 / 1016  (41.2):  51%|     | 1015/2000 [13:49<06:01,  2.73it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'eiquienrs'. A: meant B: copper C: enquiries D: berry\n",
      "Answer: C: enquiries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rurnets'. A: returns B: mauritania C: soldiers D: spanish\n",
      "Answer: D: spanish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'slilnpeg' to form the correct word. A: settlement B: spelling C: costume D: graphical\n",
      "Answer: D: graphical\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pimarry'. A: insure B: trials C: conducted D: primary\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gewnaodrutr'? A: critical B: salt C: groundwater D: processor\n",
      "Answer: D: processor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'epxo' represent when unscrambled? A: lady B: expo C: quizzes D: formulas\n",
      "Answer: A: lady\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 1017  (41.2):  51%|     | 1016/2000 [13:54<06:00,  2.73it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1017  (41.2):  51%|     | 1017/2000 [13:54<20:15,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tspeecole' represent when unscrambled? A: sean B: telescope C: retrieval D: qualify\n",
      "Answer: B: telescope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 419 / 1018  (41.2):  51%|     | 1017/2000 [13:55<20:15,  1.24s/it]\u001b[A\n",
      "Average Metric: 419 / 1018  (41.2):  51%|     | 1018/2000 [13:55<20:12,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ppaadnogra' to form the correct word. A: withdrawn B: amino C: cure D: propaganda\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 1019  (41.1):  51%|     | 1018/2000 [13:58<20:12,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1019  (41.1):  51%|     | 1019/2000 [13:58<25:26,  1.56s/it]\u001b[A\n",
      "Average Metric: 419 / 1020  (41.1):  51%|     | 1019/2000 [13:58<25:26,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1020  (41.1):  51%|     | 1020/2000 [13:58<20:04,  1.23s/it]\u001b[A\n",
      "Average Metric: 419 / 1021  (41.0):  51%|     | 1020/2000 [13:58<20:04,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1022  (41.0):  51%|     | 1021/2000 [13:58<20:03,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1022  (41.0):  51%|     | 1022/2000 [13:58<12:45,  1.28it/s]\u001b[A\n",
      "Average Metric: 419 / 1023  (41.0):  51%|     | 1022/2000 [13:58<12:45,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'haomnry'. A: findlaw B: vancouver C: physicians D: harmony\n",
      "Answer: D: harmony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sehlf' to form the correct word. A: minds B: shelf C: arctic D: aquarium\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hlelo' to form the correct word. A: politics B: light C: paraguay D: hello\n",
      "Answer: D: hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dteslahcund'? A: commits B: render C: elementary D: deutschland\n",
      "Answer: D: deutschland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 420 / 1024  (41.0):  51%|     | 1023/2000 [14:00<12:44,  1.28it/s]\u001b[A\n",
      "Average Metric: 420 / 1024  (41.0):  51%|     | 1024/2000 [14:00<14:48,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 420 / 1025  (41.0):  51%|     | 1024/2000 [14:01<14:48,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 420 / 1025  (41.0):  51%|    | 1025/2000 [14:01<12:11,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'souuedrrnd'. A: surrounded B: religions C: highlight D: matt\n",
      "Answer: D: matt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 421 / 1026  (41.0):  51%|    | 1025/2000 [14:02<12:11,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 421 / 1026  (41.0):  51%|    | 1026/2000 [14:02<13:15,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crapet'? A: carpet B: attributed C: builders D: gaming\n",
      "Answer: carpet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 421 / 1027  (41.0):  51%|    | 1026/2000 [14:03<13:15,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 421 / 1027  (41.0):  51%|    | 1027/2000 [14:03<13:59,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 1028  (41.1):  51%|    | 1027/2000 [14:03<13:59,  1.16it/s]\u001b[A\n",
      "Average Metric: 422 / 1028  (41.1):  51%|    | 1028/2000 [14:03<11:24,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pnioautblcis' represent when unscrambled? A: publications B: devices C: loved D: pubs\n",
      "Answer: D: pubs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 422 / 1029  (41.0):  51%|    | 1028/2000 [14:04<11:24,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 422 / 1029  (41.0):  51%|    | 1029/2000 [14:05<15:31,  1.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sitaemnrg'? A: postcards B: blair C: compensation D: streaming\n",
      "Answer: B: blair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wyas'. A: ways B: porn C: painting D: ultra\n",
      "Answer: D: ultra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 1030  (41.0):  51%|    | 1029/2000 [14:06<15:31,  1.04it/s]\u001b[A\n",
      "Average Metric: 422 / 1030  (41.0):  52%|    | 1030/2000 [14:06<19:55,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 423 / 1031  (41.0):  52%|    | 1030/2000 [14:06<19:55,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jmimy' represent when unscrambled? A: colleges B: knows C: jimmy D: maintaining\n",
      "Answer: B: knows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 423 / 1032  (41.0):  52%|    | 1031/2000 [14:08<19:54,  1.23s/it]\u001b[A\n",
      "Average Metric: 423 / 1032  (41.0):  52%|    | 1032/2000 [14:08<17:07,  1.06s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1033  (41.0):  52%|    | 1032/2000 [14:09<17:07,  1.06s/it]\u001b[A\n",
      "Average Metric: 424 / 1033  (41.0):  52%|    | 1033/2000 [14:09<14:57,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1034  (41.0):  52%|    | 1033/2000 [14:09<14:57,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1034  (41.0):  52%|    | 1034/2000 [14:09<12:52,  1.25it/s]\u001b[A\n",
      "Average Metric: 424 / 1035  (41.0):  52%|    | 1034/2000 [14:09<12:52,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mnoore' to form the correct word. A: monroe B: vocal C: anthropology D: commons\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1036  (40.9):  52%|    | 1035/2000 [14:10<12:52,  1.25it/s]\u001b[A\n",
      "Average Metric: 424 / 1036  (40.9):  52%|    | 1036/2000 [14:10<11:00,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bitetr'. A: purely B: casio C: bitter D: profession\n",
      "Answer: D: profession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1037  (40.9):  52%|    | 1036/2000 [14:11<11:00,  1.46it/s]\u001b[A\n",
      "Average Metric: 424 / 1037  (40.9):  52%|    | 1037/2000 [14:11<10:48,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1038  (40.8):  52%|    | 1037/2000 [14:11<10:48,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 424 / 1038  (40.8):  52%|    | 1038/2000 [14:11<09:42,  1.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1039  (40.8):  52%|    | 1038/2000 [14:11<09:42,  1.65it/s]\u001b[A\n",
      "Average Metric: 424 / 1039  (40.8):  52%|    | 1039/2000 [14:11<08:16,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1040  (40.8):  52%|    | 1039/2000 [14:11<08:16,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bunrs'. A: mileage B: burns C: addressing D: paragraph\n",
      "Answer: D: paragraph\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'seodomby' to form the correct word. A: gage B: sail C: somebody D: searching\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'acidve'. A: zoning B: nodes C: levy D: advice\n",
      "Answer: D: advice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1041  (40.7):  52%|    | 1040/2000 [14:13<08:16,  1.94it/s]\u001b[A\n",
      "Average Metric: 424 / 1041  (40.7):  52%|    | 1041/2000 [14:13<10:18,  1.55it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 425 / 1042  (40.8):  52%|    | 1041/2000 [14:14<10:18,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 425 / 1042  (40.8):  52%|    | 1042/2000 [14:14<10:07,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'psusy' to form the correct word. A: sandra B: clothes C: pussy D: band\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oaiinbtng'. A: individually B: motels C: obtaining D: wonder\n",
      "Answer: D: wonder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'isuess'. A: issues B: portions C: fires D: fujitsu\n",
      "Answer: A: issues\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dsik' represent when unscrambled? A: risk B: japanese C: disk D: alito\n",
      "Answer: D: alito\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 425 / 1043  (40.7):  52%|    | 1042/2000 [14:16<10:07,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 425 / 1043  (40.7):  52%|    | 1043/2000 [14:16<16:11,  1.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'enegagd' represent when unscrambled? A: sends B: engaged C: starsmerchant D: spoke\n",
      "Answer: B: engaged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 425 / 1044  (40.7):  52%|    | 1043/2000 [14:17<16:11,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 425 / 1044  (40.7):  52%|    | 1044/2000 [14:17<15:03,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bonld'. A: blond B: businesses C: designer D: streams\n",
      "Answer: D: streams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 426 / 1045  (40.8):  52%|    | 1044/2000 [14:17<15:03,  1.06it/s]\u001b[A\n",
      "Average Metric: 426 / 1045  (40.8):  52%|    | 1045/2000 [14:17<13:26,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lftniig' represent when unscrambled? A: lifting B: talking C: major D: surely\n",
      "Answer: B: talking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 426 / 1046  (40.7):  52%|    | 1045/2000 [14:21<13:26,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "Average Metric: 426 / 1046  (40.7):  52%|    | 1046/2000 [14:21<24:45,  1.56s/it]  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1047  (40.8):  52%|    | 1046/2000 [14:21<24:45,  1.56s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1047  (40.8):  52%|    | 1047/2000 [14:21<20:24,  1.29s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1048  (40.7):  52%|    | 1047/2000 [14:21<20:24,  1.29s/it]\u001b[A\n",
      "Average Metric: 427 / 1048  (40.7):  52%|    | 1048/2000 [14:21<16:00,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 427 / 1049  (40.7):  52%|    | 1048/2000 [14:23<16:00,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 427 / 1049  (40.7):  52%|    | 1049/2000 [14:23<17:07,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1050  (40.8):  52%|    | 1049/2000 [14:24<17:07,  1.08s/it]\u001b[A\n",
      "Average Metric: 428 / 1050  (40.8):  52%|    | 1050/2000 [14:24<17:11,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'byiung'. A: magazines B: raid C: byron D: buying\n",
      "Answer: D: buying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 428 / 1051  (40.7):  52%|    | 1050/2000 [14:25<17:11,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 428 / 1051  (40.7):  53%|    | 1051/2000 [14:25<16:17,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'felemas'? A: corpus B: pour C: math D: females\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'choen' to form the correct word. A: church B: portfolios C: cohen D: networks\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 428 / 1052  (40.7):  53%|    | 1051/2000 [14:26<16:17,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 428 / 1052  (40.7):  53%|    | 1052/2000 [14:26<16:16,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cihps'? A: plymouth B: chips C: nearest D: robot\n",
      "Answer: B: chips\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'miad'. A: maid B: title C: surrounded D: lincoln\n",
      "Answer: D: lincoln\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eruqniy'. A: refinance B: enquiry C: clinical D: sizes\n",
      "Answer: D: sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1053  (40.6):  53%|    | 1052/2000 [14:29<16:16,  1.03s/it]\u001b[A\n",
      "Average Metric: 428 / 1053  (40.6):  53%|    | 1053/2000 [14:29<24:37,  1.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gievs' to form the correct word. A: cigarettes B: ebooks C: tied D: gives\n",
      "Answer: D: gives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1054  (40.6):  53%|    | 1053/2000 [14:29<24:37,  1.56s/it]\u001b[A\n",
      "Average Metric: 428 / 1054  (40.6):  53%|    | 1054/2000 [14:29<21:13,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 428 / 1055  (40.6):  53%|    | 1054/2000 [14:29<21:13,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lctaoe' represent when unscrambled? A: digg B: antenna C: blair D: locate\n",
      "Answer: D: locate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 429 / 1056  (40.6):  53%|    | 1055/2000 [14:32<21:12,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 429 / 1056  (40.6):  53%|    | 1056/2000 [14:32<21:25,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1057  (40.6):  53%|    | 1056/2000 [14:32<21:25,  1.36s/it]\u001b[A\n",
      "Average Metric: 429 / 1057  (40.6):  53%|    | 1057/2000 [14:32<16:44,  1.07s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1058  (40.5):  53%|    | 1057/2000 [14:33<16:44,  1.07s/it]\u001b[A\n",
      "Average Metric: 429 / 1058  (40.5):  53%|    | 1058/2000 [14:33<13:18,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1059  (40.5):  53%|    | 1058/2000 [14:33<13:18,  1.18it/s]\u001b[A\n",
      "Average Metric: 429 / 1059  (40.5):  53%|    | 1059/2000 [14:33<13:06,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tdioiarsvpr'? A: reprint B: break C: feet D: tripadvisor\n",
      "Answer: D: tripadvisor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 429 / 1060  (40.5):  53%|    | 1059/2000 [14:34<13:06,  1.20it/s]\u001b[A\n",
      "Average Metric: 429 / 1060  (40.5):  53%|    | 1060/2000 [14:34<13:21,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 1061  (40.5):  53%|    | 1060/2000 [14:34<13:21,  1.17it/s]\u001b[A\n",
      "Average Metric: 430 / 1061  (40.5):  53%|    | 1061/2000 [14:34<10:13,  1.53it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 1062  (40.5):  53%|    | 1061/2000 [14:35<10:13,  1.53it/s]\u001b[A\n",
      "Average Metric: 430 / 1062  (40.5):  53%|    | 1062/2000 [14:35<08:25,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1063  (40.5):  53%|    | 1062/2000 [14:35<08:25,  1.86it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tkecit'. A: ticket B: axis C: allowing D: devil\n",
      "Answer: A: ticket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 430 / 1063  (40.5):  53%|    | 1063/2000 [14:35<06:56,  2.25it/s]\u001b[A\n",
      "Average Metric: 430 / 1064  (40.4):  53%|    | 1063/2000 [14:35<06:56,  2.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 430 / 1064  (40.4):  53%|    | 1064/2000 [14:35<06:03,  2.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'detoariacln' to form the correct word. A: gently B: declaration C: credit D: york\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'nxet'. A: environment B: jade C: pricing D: next\n",
      "Answer: D: next\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'neods' represent when unscrambled? A: myanmar B: nodes C: adjusted D: gifts\n",
      "Answer: D: gifts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1065  (40.4):  53%|    | 1064/2000 [14:37<06:03,  2.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 1065  (40.4):  53%|    | 1065/2000 [14:37<12:37,  1.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1066  (40.4):  53%|    | 1065/2000 [14:37<12:37,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 431 / 1066  (40.4):  53%|    | 1066/2000 [14:37<10:39,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 431 / 1067  (40.4):  53%|    | 1066/2000 [14:37<10:39,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 431 / 1067  (40.4):  53%|    | 1067/2000 [14:37<08:12,  1.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dmeoinsin'. A: outer B: bound C: found D: dimension\n",
      "Answer: D: dimension\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'carrries'? A: error B: carriers C: east D: yankees\n",
      "Answer: C: east\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 432 / 1068  (40.4):  53%|    | 1067/2000 [14:39<08:12,  1.90it/s]\u001b[A\n",
      "Average Metric: 432 / 1068  (40.4):  53%|    | 1068/2000 [14:39<11:34,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ansbet'. A: ventilation B: apartment C: absent D: obtaining\n",
      "Answer: D: obtaining\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rruteend'. A: housewives B: returned C: scholar D: postal\n",
      "Answer: D: postal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1069  (40.4):  53%|    | 1068/2000 [14:40<11:34,  1.34it/s]\u001b[A\n",
      "Average Metric: 432 / 1069  (40.4):  53%|    | 1069/2000 [14:40<11:41,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dugrs'. A: hearts B: case C: rates D: drugs\n",
      "Answer: D: drugs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 432 / 1070  (40.4):  53%|    | 1069/2000 [14:40<11:41,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 432 / 1070  (40.4):  54%|    | 1070/2000 [14:40<09:37,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 433 / 1071  (40.4):  54%|    | 1070/2000 [14:40<09:37,  1.61it/s]\u001b[A\n",
      "Average Metric: 433 / 1071  (40.4):  54%|    | 1071/2000 [14:40<09:08,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 434 / 1072  (40.5):  54%|    | 1071/2000 [14:41<09:08,  1.69it/s]\u001b[A\n",
      "Average Metric: 434 / 1072  (40.5):  54%|    | 1072/2000 [14:41<08:22,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'plplihis'. A: dramatic B: compliant C: gadgets D: phillips\n",
      "Answer: A: dramatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1073  (40.5):  54%|    | 1072/2000 [14:42<08:22,  1.85it/s]\u001b[A\n",
      "Average Metric: 435 / 1073  (40.5):  54%|    | 1073/2000 [14:42<13:36,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 436 / 1074  (40.6):  54%|    | 1073/2000 [14:44<13:36,  1.14it/s]\u001b[A\n",
      "Average Metric: 436 / 1074  (40.6):  54%|    | 1074/2000 [14:44<14:50,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'whnacitg'. A: watching B: placement C: saddam D: emotion\n",
      "Answer: C: saddam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 436 / 1075  (40.6):  54%|    | 1074/2000 [14:46<14:50,  1.04it/s]\u001b[A\n",
      "Average Metric: 436 / 1075  (40.6):  54%|    | 1075/2000 [14:46<22:03,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'toiraismsnsn' to form the correct word. A: spirituality B: rats C: transmission D: refund\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'signels' to form the correct word. A: margins B: twice C: singles D: allows\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cosonle'? A: console B: broader C: danger D: handed\n",
      "Answer: console\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1076  (40.6):  54%|    | 1075/2000 [14:48<22:03,  1.43s/it]\u001b[A\n",
      "Average Metric: 437 / 1076  (40.6):  54%|    | 1076/2000 [14:48<24:21,  1.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aeegrs'. A: slower B: subtle C: desirable D: agrees\n",
      "Answer: D: agrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cveor'? A: upgraded B: computers C: cover D: holdings\n",
      "Answer: C: cover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seetl'. A: rentals B: fulfill C: sound D: steel\n",
      "Answer: D: steel\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which is the smallest planet in our solar system? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: Which is the most abundant greenhouse gas in the atmosphere? A: Carbon dioxide B: Methane C: Nitrous oxide D: Water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1077  (40.6):  54%|    | 1076/2000 [14:50<24:21,  1.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1077  (40.6):  54%|    | 1077/2000 [14:50<26:05,  1.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aalrm'? A: bali B: scenes C: climate D: alarm\n",
      "Answer: D: alarm\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ettiny'? A: regulator B: hepatitis C: entity D: were\n",
      "Answer: D: were\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dloube'? A: double B: calculation C: accessible D: entity\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1078  (40.5):  54%|    | 1077/2000 [14:52<26:05,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 437 / 1078  (40.5):  54%|    | 1078/2000 [14:52<29:31,  1.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1079  (40.5):  54%|    | 1078/2000 [14:55<29:31,  1.92s/it]\u001b[A\n",
      "Average Metric: 437 / 1079  (40.5):  54%|    | 1079/2000 [14:55<32:32,  2.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1080  (40.5):  54%|    | 1079/2000 [14:55<32:32,  2.12s/it]\u001b[A\n",
      "Average Metric: 437 / 1080  (40.5):  54%|    | 1080/2000 [14:55<23:29,  1.53s/it]\u001b[A\n",
      "Average Metric: 438 / 1081  (40.5):  54%|    | 1080/2000 [14:56<23:29,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 438 / 1081  (40.5):  54%|    | 1081/2000 [14:56<20:08,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'firnmag'. A: framing B: frontier C: traveling D: carriers\n",
      "Answer: D: carriers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1082  (40.6):  54%|    | 1081/2000 [14:57<20:08,  1.31s/it]\u001b[A\n",
      "Average Metric: 439 / 1082  (40.6):  54%|    | 1082/2000 [14:57<19:57,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1083  (40.5):  54%|    | 1082/2000 [14:57<19:57,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1083  (40.5):  54%|    | 1083/2000 [14:57<14:43,  1.04it/s]\u001b[A\n",
      "Average Metric: 439 / 1084  (40.5):  54%|    | 1083/2000 [14:58<14:43,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'srahaa'. A: discontinued B: pointer C: sahara D: salvador\n",
      "Answer: D: salvador\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iitencnds'? A: incidents B: physically C: tolerance D: arena\n",
      "Answer: B: physically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1085  (40.5):  54%|    | 1084/2000 [14:58<14:42,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1085  (40.5):  54%|    | 1085/2000 [14:58<11:02,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cnet' to form the correct word. A: jurisdiction B: cent C: organizing D: humanitarian\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cook'. A: cook B: worldcat C: simulated D: boring\n",
      "Answer: C: simulated\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sitiralimy' to form the correct word. A: imagination B: similarity C: decade D: replacing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1086  (40.4):  54%|    | 1085/2000 [15:00<11:02,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1086  (40.4):  54%|    | 1086/2000 [15:00<14:05,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'snniping' to form the correct word. A: showers B: spinning C: scat D: gary\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hvaen' represent when unscrambled? A: criminal B: haven C: coordinated D: finished\n",
      "Answer: A: criminal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'euneepdtrxis' represent when unscrambled? A: accompanying B: lipitor C: expenditures D: brokers\n",
      "Answer: A: accompanying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fgnmaert' to form the correct word. A: putting B: vocabulary C: except D: fragment\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'invenstie'. A: accordingly B: intensive C: given D: arrivals\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1087  (40.4):  54%|    | 1086/2000 [15:02<14:05,  1.08it/s]\u001b[A\n",
      "Average Metric: 439 / 1087  (40.4):  54%|    | 1087/2000 [15:02<18:15,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rcoevered'. A: investigate B: recovered C: queens D: cleveland\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bigegr'? A: exciting B: away C: bigger D: suggest\n",
      "Answer: D: suggest\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'weavs'. A: arabic B: championship C: waves D: investing\n",
      "Answer: D: investing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1088  (40.4):  54%|    | 1087/2000 [15:03<18:15,  1.20s/it]\u001b[A\n",
      "Average Metric: 440 / 1088  (40.4):  54%|    | 1088/2000 [15:03<16:29,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'laantis'? A: latinas B: fiction C: irish D: univ\n",
      "Answer: D: univ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1089  (40.4):  54%|    | 1088/2000 [15:03<16:29,  1.08s/it]\u001b[A\n",
      "Average Metric: 440 / 1089  (40.4):  54%|    | 1089/2000 [15:03<14:03,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 440 / 1090  (40.4):  54%|    | 1089/2000 [15:03<14:03,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 440 / 1091  (40.3):  55%|    | 1090/2000 [15:04<14:02,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1091  (40.3):  55%|    | 1091/2000 [15:04<09:32,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 441 / 1092  (40.4):  55%|    | 1091/2000 [15:06<09:32,  1.59it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 441 / 1092  (40.4):  55%|    | 1092/2000 [15:06<16:34,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 442 / 1093  (40.4):  55%|    | 1092/2000 [15:07<16:34,  1.10s/it]\u001b[A\n",
      "Average Metric: 442 / 1093  (40.4):  55%|    | 1093/2000 [15:07<13:31,  1.12it/s]\u001b[A\n",
      "Average Metric: 442 / 1094  (40.4):  55%|    | 1093/2000 [15:07<13:31,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 442 / 1094  (40.4):  55%|    | 1094/2000 [15:07<11:20,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 1095  (40.5):  55%|    | 1094/2000 [15:07<11:20,  1.33it/s]\u001b[A\n",
      "Average Metric: 443 / 1095  (40.5):  55%|    | 1095/2000 [15:07<10:03,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1096  (40.5):  55%|    | 1095/2000 [15:08<10:03,  1.50it/s]\u001b[A\n",
      "Average Metric: 444 / 1096  (40.5):  55%|    | 1096/2000 [15:08<08:23,  1.79it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1097  (40.5):  55%|    | 1096/2000 [15:10<08:23,  1.79it/s]\u001b[A\n",
      "Average Metric: 444 / 1097  (40.5):  55%|    | 1097/2000 [15:10<14:35,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iupnt'. A: because B: input C: triangle D: highly\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tnak' represent when unscrambled? A: hired B: tank C: planting D: chick\n",
      "Answer: A: hired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'siltlhgy'. A: slightly B: because C: eventually D: motorcycles\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'itnenlcgeile'. A: enable B: operate C: intelligence D: roger\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ciyclng'. A: cookie B: crying C: cycling D: discount\n",
      "Answer: C: cycling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1098  (40.5):  55%|    | 1097/2000 [15:12<14:35,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 445 / 1098  (40.5):  55%|    | 1098/2000 [15:12<18:42,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'simga' to form the correct word. A: handjob B: retreat C: sigma D: opinions\n",
      "Answer: D: opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'inceefulnd'. A: benz B: integral C: influenced D: brother\n",
      "Answer: D: brother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'potls' to form the correct word. A: plots B: injuries C: nation D: sized\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wllas' to form the correct word. A: cornwall B: accredited C: walls D: insufficient\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1099  (40.5):  55%|    | 1098/2000 [15:14<18:42,  1.24s/it]\u001b[A\n",
      "Average Metric: 445 / 1099  (40.5):  55%|    | 1099/2000 [15:14<22:02,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'inheernt'? A: inherent B: database C: possible D: changed\n",
      "Answer: A: inherent\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'riogen'. A: hear B: region C: severe D: academy\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1100  (40.5):  55%|    | 1099/2000 [15:16<22:02,  1.47s/it]\u001b[A\n",
      "Average Metric: 445 / 1100  (40.5):  55%|    | 1100/2000 [15:16<25:09,  1.68s/it]\u001b[A\n",
      "Average Metric: 445 / 1101  (40.4):  55%|    | 1100/2000 [15:16<25:09,  1.68s/it]\u001b[A\n",
      "Average Metric: 445 / 1101  (40.4):  55%|    | 1101/2000 [15:16<19:46,  1.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'comoomshre'? A: indexed B: hebrew C: chromosome D: offence\n",
      "Answer: indexed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 445 / 1102  (40.4):  55%|    | 1101/2000 [15:18<19:46,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 445 / 1102  (40.4):  55%|    | 1102/2000 [15:18<20:30,  1.37s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1103  (40.3):  55%|    | 1102/2000 [15:18<20:30,  1.37s/it]\u001b[A\n",
      "Average Metric: 445 / 1103  (40.3):  55%|    | 1103/2000 [15:18<14:57,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Average Metric: 446 / 1104  (40.4):  55%|    | 1103/2000 [15:19<14:57,  1.00s/it]Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "\u001b[A\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Average Metric: 446 / 1104  (40.4):  55%|    | 1104/2000 [15:19<14:27,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 447 / 1105  (40.5):  55%|    | 1104/2000 [15:19<14:27,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 447 / 1105  (40.5):  55%|    | 1105/2000 [15:19<11:34,  1.29it/s]\u001b[A\n",
      "Average Metric: 447 / 1106  (40.4):  55%|    | 1105/2000 [15:20<11:34,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 447 / 1106  (40.4):  55%|    | 1106/2000 [15:20<12:08,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 448 / 1107  (40.5):  55%|    | 1106/2000 [15:20<12:08,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 448 / 1108  (40.4):  55%|    | 1107/2000 [15:21<12:07,  1.23it/s]\u001b[A\n",
      "Average Metric: 448 / 1108  (40.4):  55%|    | 1108/2000 [15:21<09:05,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pvscipotree'. A: pond B: allergy C: prospective D: affiliates\n",
      "Answer: pond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 448 / 1109  (40.4):  55%|    | 1108/2000 [15:21<09:05,  1.64it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 448 / 1109  (40.4):  55%|    | 1109/2000 [15:21<08:22,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 449 / 1110  (40.5):  55%|    | 1109/2000 [15:21<08:22,  1.77it/s]\u001b[A\n",
      "Average Metric: 449 / 1110  (40.5):  56%|    | 1110/2000 [15:21<06:41,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1111  (40.5):  56%|    | 1110/2000 [15:22<06:41,  2.22it/s]\u001b[A\n",
      "Average Metric: 450 / 1111  (40.5):  56%|    | 1111/2000 [15:22<06:16,  2.36it/s]\u001b[A\n",
      "Average Metric: 450 / 1112  (40.5):  56%|    | 1111/2000 [15:22<06:16,  2.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 450 / 1112  (40.5):  56%|    | 1112/2000 [15:22<05:46,  2.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'seakpres'? A: juvenile B: speakers C: saturn D: pamela\n",
      "Answer: B: speakers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1113  (40.4):  56%|    | 1112/2000 [15:25<05:46,  2.57it/s]\u001b[A\n",
      "Average Metric: 450 / 1113  (40.4):  56%|    | 1113/2000 [15:25<16:23,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'reeval' represent when unscrambled? A: muze B: reveal C: intensity D: recommends\n",
      "Answer: B: reveal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'srndaes'. A: sanders B: homes C: statutes D: comfortable\n",
      "Answer: D: comfortable\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'caorton' represent when unscrambled? A: donald B: reimbursement C: glance D: cartoon\n",
      "Answer: C: glance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cnonfiecde' to form the correct word. A: rebecca B: parameters C: harmony D: confidence\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'kosntgin'. A: kingston B: kenny C: bryant D: duncan\n",
      "Answer: D: duncan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 1114  (40.5):  56%|    | 1113/2000 [15:27<16:23,  1.11s/it]\u001b[A\n",
      "Average Metric: 451 / 1114  (40.5):  56%|    | 1114/2000 [15:27<22:07,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1115  (40.5):  56%|    | 1114/2000 [15:27<22:07,  1.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 452 / 1116  (40.5):  56%|    | 1115/2000 [15:27<22:06,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1116  (40.5):  56%|    | 1116/2000 [15:27<12:38,  1.16it/s]\u001b[A\n",
      "Average Metric: 452 / 1117  (40.5):  56%|    | 1116/2000 [15:27<12:38,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'denatl'. A: player B: barriers C: montgomery D: dental\n",
      "Answer: C: montgomery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1118  (40.4):  56%|    | 1117/2000 [15:29<12:38,  1.16it/s]\u001b[A\n",
      "Average Metric: 452 / 1118  (40.4):  56%|    | 1118/2000 [15:29<13:35,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1119  (40.4):  56%|    | 1118/2000 [15:31<13:35,  1.08it/s]\u001b[A\n",
      "Average Metric: 452 / 1119  (40.4):  56%|    | 1119/2000 [15:31<15:44,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1120  (40.4):  56%|    | 1119/2000 [15:32<15:44,  1.07s/it]\u001b[A\n",
      "Average Metric: 452 / 1120  (40.4):  56%|    | 1120/2000 [15:32<14:02,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 453 / 1121  (40.4):  56%|    | 1120/2000 [15:33<14:02,  1.04it/s]\u001b[A\n",
      "Average Metric: 453 / 1121  (40.4):  56%|    | 1121/2000 [15:33<16:26,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'prael'. A: pearl B: monitored C: organizing D: hung\n",
      "Answer: D: hung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 453 / 1122  (40.4):  56%|    | 1121/2000 [15:34<16:26,  1.12s/it]\u001b[A\n",
      "Average Metric: 453 / 1122  (40.4):  56%|    | 1122/2000 [15:34<14:33,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lkae'. A: precisely B: fusion C: cancellation D: lake\n",
      "Answer: D: lake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'prdie'. A: anymore B: ought C: pride D: winchester\n",
      "Answer: C: pride\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 453 / 1123  (40.3):  56%|    | 1122/2000 [15:35<14:33,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 453 / 1123  (40.3):  56%|    | 1123/2000 [15:35<16:36,  1.14s/it]\u001b[A\n",
      "Average Metric: 454 / 1124  (40.4):  56%|    | 1123/2000 [15:36<16:36,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 454 / 1124  (40.4):  56%|    | 1124/2000 [15:36<13:03,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rlaond'. A: ronald B: lecturer C: failure D: ensure\n",
      "Answer: A: ronald\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'htdimuiy' to form the correct word. A: appear B: humidity C: vancouver D: debugging\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gsealss'. A: surge B: thorough C: cash D: glasses\n",
      "Answer: D: glasses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bsais'. A: basis B: religious C: ladies D: tries\n",
      "Answer: A: basis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'puond' to form the correct word. A: sarah B: pound C: brett D: stood\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pihl'? A: survival B: phil C: memorandum D: restore\n",
      "Answer: A: survival\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 454 / 1125  (40.4):  56%|    | 1124/2000 [15:38<13:03,  1.12it/s]\u001b[A\n",
      "Average Metric: 454 / 1125  (40.4):  56%|    | 1125/2000 [15:38<17:09,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fuor' represent when unscrambled? A: four B: stayed C: assistant D: derivative\n",
      "Answer: D: derivative\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'trhu' to form the correct word. A: avalon B: thru C: thompson D: institute\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bsas'? A: campaigns B: fits C: matters D: bass\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 454 / 1126  (40.3):  56%|    | 1125/2000 [15:39<17:09,  1.18s/it]\u001b[A\n",
      "Average Metric: 454 / 1126  (40.3):  56%|    | 1126/2000 [15:39<18:45,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 454 / 1127  (40.3):  56%|    | 1126/2000 [15:40<18:45,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 454 / 1127  (40.3):  56%|    | 1127/2000 [15:40<15:29,  1.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cdotoniaiersn'. A: forbidden B: consideration C: katrina D: chess\n",
      "Answer: D: chess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'reicpenit'. A: aaron B: cheaper C: chile D: recipient\n",
      "Answer: D: recipient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'chmhaopisipns'? A: detectors B: championships C: outer D: competitions\n",
      "Answer: D: competitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prok' to form the correct word. A: emotion B: byte C: ranked D: pork\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 454 / 1128  (40.2):  56%|    | 1127/2000 [15:42<15:29,  1.07s/it]\u001b[A\n",
      "Average Metric: 454 / 1128  (40.2):  56%|    | 1128/2000 [15:42<22:12,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1129  (40.3):  56%|    | 1128/2000 [15:43<22:12,  1.53s/it]\u001b[A\n",
      "Average Metric: 455 / 1129  (40.3):  56%|    | 1129/2000 [15:43<17:22,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 456 / 1130  (40.4):  56%|    | 1129/2000 [15:44<17:22,  1.20s/it]\u001b[A\n",
      "Average Metric: 456 / 1130  (40.4):  56%|    | 1130/2000 [15:44<16:09,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 457 / 1131  (40.4):  56%|    | 1130/2000 [15:44<16:09,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 457 / 1131  (40.4):  57%|    | 1131/2000 [15:44<12:51,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1132  (40.5):  57%|    | 1131/2000 [15:45<12:51,  1.13it/s]\u001b[A\n",
      "Average Metric: 458 / 1132  (40.5):  57%|    | 1132/2000 [15:45<13:07,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 458 / 1133  (40.4):  57%|    | 1132/2000 [15:46<13:07,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 458 / 1133  (40.4):  57%|    | 1133/2000 [15:46<12:18,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1134  (40.4):  57%|    | 1133/2000 [15:46<12:18,  1.17it/s]\u001b[A\n",
      "Average Metric: 458 / 1134  (40.4):  57%|    | 1134/2000 [15:46<09:10,  1.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'geilbrt' to form the correct word. A: gilbert B: anatomy C: petersburg D: dollars\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1135  (40.4):  57%|    | 1134/2000 [15:46<09:10,  1.57it/s]\u001b[A\n",
      "Average Metric: 459 / 1136  (40.4):  57%|    | 1135/2000 [15:46<09:10,  1.57it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 459 / 1136  (40.4):  57%|    | 1136/2000 [15:46<05:51,  2.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 459 / 1137  (40.4):  57%|    | 1136/2000 [15:48<05:51,  2.46it/s]\u001b[A\n",
      "Average Metric: 459 / 1137  (40.4):  57%|    | 1137/2000 [15:48<10:07,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'iioertnr' to form the correct word. A: compute B: journalists C: used D: interior\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'iiandns' to form the correct word. A: indians B: dolls C: battery D: presidents\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1138  (40.4):  57%|    | 1137/2000 [15:49<10:07,  1.42it/s]\u001b[A\n",
      "Average Metric: 460 / 1138  (40.4):  57%|    | 1138/2000 [15:49<11:49,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nsdaaq'? A: shakira B: nasdaq C: mechanical D: newsletters\n",
      "Answer: nasdaq\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'datone'? A: hats B: airports C: prepare D: donate\n",
      "Answer: D: donate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'teihr'. A: wagner B: their C: constitute D: sciences\n",
      "Answer: w\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'shtos'? A: biol B: confidence C: shots D: democratic\n",
      "Answer: D: democratic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1139  (40.4):  57%|    | 1138/2000 [15:51<11:49,  1.21it/s]\u001b[A\n",
      "Average Metric: 460 / 1139  (40.4):  57%|    | 1139/2000 [15:51<17:22,  1.21s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1140  (40.4):  57%|    | 1139/2000 [15:51<17:22,  1.21s/it]\u001b[A\n",
      "Average Metric: 460 / 1140  (40.4):  57%|    | 1140/2000 [15:51<13:57,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1141  (40.3):  57%|    | 1140/2000 [15:53<13:57,  1.03it/s]\u001b[A\n",
      "Average Metric: 460 / 1141  (40.3):  57%|    | 1141/2000 [15:53<16:27,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1142  (40.3):  57%|    | 1141/2000 [15:54<16:27,  1.15s/it]\u001b[A\n",
      "Average Metric: 460 / 1142  (40.3):  57%|    | 1142/2000 [15:54<15:06,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 461 / 1143  (40.3):  57%|    | 1142/2000 [15:55<15:06,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 461 / 1143  (40.3):  57%|    | 1143/2000 [15:55<13:29,  1.06it/s]\u001b[A\n",
      "Average Metric: 462 / 1144  (40.4):  57%|    | 1143/2000 [15:57<13:29,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 462 / 1144  (40.4):  57%|    | 1144/2000 [15:57<18:46,  1.32s/it]\u001b[A\n",
      "Average Metric: 462 / 1145  (40.3):  57%|    | 1144/2000 [15:57<18:46,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 462 / 1145  (40.3):  57%|    | 1145/2000 [15:57<15:55,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 462 / 1146  (40.3):  57%|    | 1145/2000 [16:00<15:55,  1.12s/it]\u001b[A\n",
      "Average Metric: 462 / 1146  (40.3):  57%|    | 1146/2000 [16:00<22:55,  1.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 463 / 1147  (40.4):  57%|    | 1146/2000 [16:01<22:55,  1.61s/it]\u001b[A\n",
      "Average Metric: 463 / 1147  (40.4):  57%|    | 1147/2000 [16:01<17:48,  1.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jstiiefud' represent when unscrambled? A: detection B: holmes C: compete D: justified\n",
      "Answer: D: justified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 464 / 1148  (40.4):  57%|    | 1147/2000 [16:01<17:48,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1148  (40.4):  57%|    | 1148/2000 [16:01<15:14,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'inimvoprg'? A: kathy B: algeria C: improving D: html\n",
      "Answer: D: html\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dplaisy' to form the correct word. A: establish B: certificate C: formulation D: display\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'flolew'? A: libya B: featured C: fellow D: automated\n",
      "Answer: D: automated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rpae'. A: bicycle B: fans C: halloween D: rape\n",
      "Answer: D: rape\n",
      "\n",
      "Question: What is the capital of France? A: Berlin B: Paris C: Rome D: Madrid\n",
      "Answer: B: Paris\n",
      "\n",
      "Question: What is the smallest planet in our solar system? A: Jupiter B: Venus C: Mars D: Mercury\n",
      "Answer: D: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: What is the smallest country in the world? A: Vatican City B: Monaco C: San Marino D: Nauru\n",
      "Answer: D:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1149  (40.5):  57%|    | 1148/2000 [16:02<15:14,  1.07s/it]\u001b[A\n",
      "Average Metric: 465 / 1149  (40.5):  57%|    | 1149/2000 [16:02<14:52,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1150  (40.4):  57%|    | 1149/2000 [16:03<14:52,  1.05s/it]\u001b[A\n",
      "Average Metric: 465 / 1150  (40.4):  57%|    | 1150/2000 [16:03<14:06,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'afcira'. A: refugee B: entertainment C: worm D: africa\n",
      "Answer: D: africa\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pduerroce'. A: procedure B: herbert C: blanket D: consultant\n",
      "Answer: D: consultant\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'caopmnhis'. A: discussing B: champions C: neglect D: kills\n",
      "Answer: D: kills\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 466 / 1151  (40.5):  57%|    | 1150/2000 [16:05<14:06,  1.00it/s]\u001b[A\n",
      "Average Metric: 466 / 1151  (40.5):  58%|    | 1151/2000 [16:05<16:04,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cwrnaoll' represent when unscrambled? A: cornwall B: ranging C: involves D: jets\n",
      "Answer: A: cornwall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'edslnes'. A: testing B: endless C: beer D: wires\n",
      "Answer: D: wires\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 467 / 1152  (40.5):  58%|    | 1151/2000 [16:08<16:04,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 467 / 1152  (40.5):  58%|    | 1152/2000 [16:08<27:06,  1.92s/it]\u001b[A\n",
      "Average Metric: 467 / 1153  (40.5):  58%|    | 1152/2000 [16:08<27:06,  1.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pnrmosiesis'. A: guru B: sanders C: permissions D: purchasing\n",
      "Answer: guru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 467 / 1153  (40.5):  58%|    | 1153/2000 [16:08<19:41,  1.39s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 1154  (40.5):  58%|    | 1153/2000 [16:09<19:41,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 467 / 1155  (40.4):  58%|    | 1154/2000 [16:09<19:39,  1.39s/it]\u001b[A\n",
      "Average Metric: 467 / 1155  (40.4):  58%|    | 1155/2000 [16:09<10:58,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 1156  (40.4):  58%|    | 1155/2000 [16:09<10:58,  1.28it/s]\u001b[A\n",
      "Average Metric: 467 / 1156  (40.4):  58%|    | 1156/2000 [16:09<10:29,  1.34it/s]\u001b[A\n",
      "Average Metric: 467 / 1157  (40.4):  58%|    | 1156/2000 [16:09<10:29,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rtia'. A: rita B: plug C: trackbacks D: patience\n",
      "Answer: A: rita\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stealte'. A: madison B: rocket C: claimed D: seattle\n",
      "Answer: A: madison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 1158  (40.3):  58%|    | 1157/2000 [16:10<10:28,  1.34it/s]\u001b[A\n",
      "Average Metric: 467 / 1158  (40.3):  58%|    | 1158/2000 [16:10<09:12,  1.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tirvia'. A: azerbaijan B: outsourcing C: bride D: trivia\n",
      "Answer: D: trivia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 467 / 1159  (40.3):  58%|    | 1158/2000 [16:11<09:12,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 467 / 1159  (40.3):  58%|    | 1159/2000 [16:11<08:59,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 468 / 1160  (40.3):  58%|    | 1159/2000 [16:12<08:59,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 468 / 1160  (40.3):  58%|    | 1160/2000 [16:12<11:53,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1161  (40.3):  58%|    | 1160/2000 [16:13<11:53,  1.18it/s]\u001b[A\n",
      "Average Metric: 468 / 1161  (40.3):  58%|    | 1161/2000 [16:13<10:24,  1.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'renoigal' to form the correct word. A: elvis B: wichita C: look D: regional\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1162  (40.3):  58%|    | 1161/2000 [16:13<10:24,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 468 / 1162  (40.3):  58%|    | 1162/2000 [16:13<08:21,  1.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hreats'. A: frequently B: from C: sources D: hearts\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cpmetuor'. A: george B: prayer C: coin D: computer\n",
      "Answer: D: computer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'muacrs' to form the correct word. A: arrivals B: experimental C: carl D: marcus\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 469 / 1163  (40.3):  58%|    | 1162/2000 [16:14<08:21,  1.67it/s]\u001b[A\n",
      "Average Metric: 469 / 1163  (40.3):  58%|    | 1163/2000 [16:14<10:05,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'reeitlar'? A: average B: retailer C: parks D: instances\n",
      "Answer: B: retailer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 469 / 1164  (40.3):  58%|    | 1163/2000 [16:17<10:05,  1.38it/s]\u001b[A\n",
      "Average Metric: 469 / 1164  (40.3):  58%|    | 1164/2000 [16:17<20:31,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'folor'. A: empire B: poem C: floor D: cruz\n",
      "Answer: D: cruz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'magasacdar' represent when unscrambled? A: displayed B: madagascar C: cultures D: equipped\n",
      "Answer: B: madagascar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1165  (40.3):  58%|    | 1164/2000 [16:20<20:31,  1.47s/it]\u001b[A\n",
      "Average Metric: 470 / 1165  (40.3):  58%|    | 1165/2000 [16:20<23:35,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'varetiy'. A: staffing B: falling C: variety D: india\n",
      "Answer: D: india\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1166  (40.4):  58%|    | 1165/2000 [16:20<23:35,  1.70s/it]\u001b[A\n",
      "Average Metric: 471 / 1166  (40.4):  58%|    | 1166/2000 [16:20<18:02,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 472 / 1167  (40.4):  58%|    | 1166/2000 [16:21<18:02,  1.30s/it]\u001b[A\n",
      "Average Metric: 472 / 1167  (40.4):  58%|    | 1167/2000 [16:21<15:02,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 473 / 1168  (40.5):  58%|    | 1167/2000 [16:21<15:02,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 473 / 1168  (40.5):  58%|    | 1168/2000 [16:21<12:14,  1.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'eivl'. A: nationwide B: lack C: jewel D: evil\n",
      "Answer: D: evil\n",
      "\n",
      "Question: Which is the smallest value?  A: 0.1  B: 0.01  C: 0.001  D: 0.0001\n",
      "Answer: D: 0.0001\n",
      "\n",
      "Question: Which is the third biggest value?  A: 0.1  B: 0.01  C: 0.001  D: 0.0001\n",
      "Answer: C: 0.001\n",
      "\n",
      "Question: Which is the biggest value?  A: 0.1  B: 0.01  C: 0.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1169  (40.5):  58%|    | 1168/2000 [16:22<12:14,  1.13it/s]\u001b[A\n",
      "Average Metric: 473 / 1169  (40.5):  58%|    | 1169/2000 [16:22<12:57,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'arighltom'. A: algorithm B: fight C: refugees D: richardson\n",
      "Answer: D: richardson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 473 / 1170  (40.4):  58%|    | 1169/2000 [16:23<12:57,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 473 / 1170  (40.4):  58%|    | 1170/2000 [16:23<13:19,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'prriodevs'. A: providers B: trains C: markets D: surname\n",
      "Answer: C: markets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1171  (40.4):  58%|    | 1170/2000 [16:25<13:19,  1.04it/s]\u001b[A\n",
      "Average Metric: 473 / 1171  (40.4):  59%|    | 1171/2000 [16:25<17:26,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pmrriliay'. A: ideal B: primarily C: stylish D: lesson\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1172  (40.4):  59%|    | 1171/2000 [16:26<17:26,  1.26s/it]\u001b[A\n",
      "Average Metric: 473 / 1172  (40.4):  59%|    | 1172/2000 [16:26<15:15,  1.11s/it]\u001b[A\n",
      "Average Metric: 473 / 1173  (40.3):  59%|    | 1172/2000 [16:27<15:15,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1173  (40.3):  59%|    | 1173/2000 [16:27<15:30,  1.12s/it]\u001b[A\n",
      "Average Metric: 473 / 1174  (40.3):  59%|    | 1173/2000 [16:27<15:30,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pfromrenig'. A: ipod B: clerk C: performing D: suspected\n",
      "Answer: D: suspected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1175  (40.3):  59%|    | 1174/2000 [16:29<15:29,  1.12s/it]\u001b[A\n",
      "Average Metric: 473 / 1175  (40.3):  59%|    | 1175/2000 [16:29<15:40,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bbaes'. A: scandal B: babes C: store D: police\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sults' represent when unscrambled? A: rays B: sluts C: scandal D: ripe\n",
      "Answer: D: ripe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lnhugiag'. A: proceed B: provider C: cutting D: laughing\n",
      "Answer: D: laughing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'vtores' to form the correct word. A: tracks B: atom C: voters D: idea\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 473 / 1176  (40.2):  59%|    | 1175/2000 [16:31<15:40,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 473 / 1176  (40.2):  59%|    | 1176/2000 [16:31<18:41,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'avreirs'? A: traditional B: considerably C: unofficial D: arrives\n",
      "Answer: D: arrives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 474 / 1177  (40.3):  59%|    | 1176/2000 [16:32<18:41,  1.36s/it]\u001b[A\n",
      "Average Metric: 474 / 1177  (40.3):  59%|    | 1177/2000 [16:32<15:18,  1.12s/it]\u001b[A\n",
      "Average Metric: 475 / 1178  (40.3):  59%|    | 1177/2000 [16:32<15:18,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 475 / 1178  (40.3):  59%|    | 1178/2000 [16:32<11:48,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'snata'. A: genes B: housewares C: bubble D: santa\n",
      "Answer: D: santa\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tebus'? A: tubes B: manga C: condition D: linux\n",
      "Answer: B: manga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 475 / 1179  (40.3):  59%|    | 1178/2000 [16:32<11:48,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 475 / 1179  (40.3):  59%|    | 1179/2000 [16:32<10:10,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 476 / 1180  (40.3):  59%|    | 1179/2000 [16:33<10:10,  1.35it/s]\u001b[A\n",
      "Average Metric: 476 / 1180  (40.3):  59%|    | 1180/2000 [16:33<08:35,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 476 / 1181  (40.3):  59%|    | 1180/2000 [16:33<08:35,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 476 / 1181  (40.3):  59%|    | 1181/2000 [16:33<08:01,  1.70it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'conseufd'. A: josh B: confused C: groundwater D: smart\n",
      "Answer: D: smart\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cicuotrotnsn' represent when unscrambled? A: yukon B: construction C: from D: organic\n",
      "Answer: C: from\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lveles' represent when unscrambled? A: addresses B: stylus C: jewish D: levels\n",
      "Answer: D: levels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 476 / 1182  (40.3):  59%|    | 1181/2000 [16:35<08:01,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 476 / 1182  (40.3):  59%|    | 1182/2000 [16:35<13:56,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1183  (40.3):  59%|    | 1182/2000 [16:36<13:56,  1.02s/it]\u001b[A\n",
      "Average Metric: 477 / 1183  (40.3):  59%|    | 1183/2000 [16:36<12:14,  1.11it/s]\u001b[A\n",
      "Average Metric: 478 / 1184  (40.4):  59%|    | 1183/2000 [16:36<12:14,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 478 / 1185  (40.3):  59%|    | 1184/2000 [16:36<12:13,  1.11it/s]\u001b[A\n",
      "Average Metric: 478 / 1185  (40.3):  59%|    | 1185/2000 [16:36<07:25,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'coallr' to form the correct word. A: occupancy B: holmes C: yemen D: collar\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'spudneesd' represent when unscrambled? A: professional B: readily C: milfhunter D: suspended\n",
      "Answer: A: professional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 479 / 1186  (40.4):  59%|    | 1185/2000 [16:37<07:25,  1.83it/s]\u001b[A\n",
      "Average Metric: 479 / 1186  (40.4):  59%|    | 1186/2000 [16:37<10:00,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1187  (40.4):  59%|    | 1186/2000 [16:38<10:00,  1.36it/s]\u001b[A\n",
      "Average Metric: 480 / 1187  (40.4):  59%|    | 1187/2000 [16:38<07:54,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seed'. A: binding B: seed C: column D: alphabetical\n",
      "Answer: A: binding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gmmaa' represent when unscrambled? A: daytona B: gamma C: mastercard D: exchange\n",
      "Answer: A: daytona\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rsulets' to form the correct word. A: results B: variations C: potential D: tuner\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'maeixcn' to form the correct word. A: mexican B: dock C: scream D: missed\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 480 / 1188  (40.4):  59%|    | 1187/2000 [16:41<07:54,  1.71it/s]\u001b[A\n",
      "Average Metric: 480 / 1188  (40.4):  59%|    | 1188/2000 [16:41<17:31,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1189  (40.4):  59%|    | 1188/2000 [16:42<17:31,  1.30s/it]\u001b[A\n",
      "Average Metric: 480 / 1189  (40.4):  59%|    | 1189/2000 [16:42<17:17,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 1190  (40.4):  59%|    | 1189/2000 [16:43<17:17,  1.28s/it]\u001b[A\n",
      "Average Metric: 481 / 1190  (40.4):  60%|    | 1190/2000 [16:43<15:14,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tbue'. A: arrives B: tube C: expenditures D: italy\n",
      "Answer: A: arrives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 481 / 1191  (40.4):  60%|    | 1190/2000 [16:43<15:14,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 481 / 1191  (40.4):  60%|    | 1191/2000 [16:43<13:01,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 1192  (40.4):  60%|    | 1191/2000 [16:45<13:01,  1.03it/s]\u001b[A\n",
      "Average Metric: 481 / 1192  (40.4):  60%|    | 1192/2000 [16:45<14:05,  1.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tpoic' to form the correct word. A: detection B: topic C: participation D: brazil\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 482 / 1193  (40.4):  60%|    | 1192/2000 [16:45<14:05,  1.05s/it]\u001b[A\n",
      "Average Metric: 482 / 1193  (40.4):  60%|    | 1193/2000 [16:45<11:55,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 482 / 1194  (40.4):  60%|    | 1193/2000 [16:46<11:55,  1.13it/s]\u001b[A\n",
      "Average Metric: 482 / 1194  (40.4):  60%|    | 1194/2000 [16:46<11:01,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'connairtes'? A: inspiration B: joke C: vector D: containers\n",
      "Answer: D: containers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pors' represent when unscrambled? A: victorian B: pros C: monte D: filtering\n",
      "Answer: A: victorian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ogcnoloy' to form the correct word. A: sunglasses B: sands C: quotations D: oncology\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 482 / 1195  (40.3):  60%|    | 1194/2000 [16:48<11:01,  1.22it/s]\u001b[A\n",
      "Average Metric: 482 / 1195  (40.3):  60%|    | 1195/2000 [16:48<16:45,  1.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 483 / 1196  (40.4):  60%|    | 1195/2000 [16:49<16:45,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 483 / 1196  (40.4):  60%|    | 1196/2000 [16:49<14:20,  1.07s/it]\u001b[A\n",
      "Average Metric: 484 / 1197  (40.4):  60%|    | 1196/2000 [16:49<14:20,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 484 / 1197  (40.4):  60%|    | 1197/2000 [16:49<13:03,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bwrose' represent when unscrambled? A: bell B: transcription C: browse D: gene\n",
      "Answer: C: browse"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 484 / 1198  (40.4):  60%|    | 1197/2000 [16:52<13:03,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 484 / 1198  (40.4):  60%|    | 1198/2000 [16:52<19:22,  1.45s/it]\u001b[A\n",
      "Average Metric: 484 / 1199  (40.4):  60%|    | 1198/2000 [16:52<19:22,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bwilong' represent when unscrambled? A: mime B: dead C: bowling D: satisfied\n",
      "Answer: B: dead\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wseieldrns'. A: vietnamese B: wilderness C: salary D: commissioners\n",
      "Answer: A: vietnamese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fmile'. A: continental B: full C: soup D: filme\n",
      "Answer: A: continental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1200  (40.4):  60%|    | 1199/2000 [16:54<19:21,  1.45s/it]\u001b[A\n",
      "Average Metric: 485 / 1200  (40.4):  60%|    | 1200/2000 [16:54<17:56,  1.35s/it]\u001b[A\n",
      "Average Metric: 486 / 1201  (40.5):  60%|    | 1200/2000 [16:55<17:56,  1.35s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 486 / 1201  (40.5):  60%|    | 1201/2000 [16:55<14:44,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 486 / 1202  (40.4):  60%|    | 1201/2000 [16:55<14:44,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 486 / 1202  (40.4):  60%|    | 1202/2000 [16:55<11:38,  1.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hdiing'? A: croatia B: caps C: macdonald D: hiding\n",
      "Answer: D: hiding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pakecd' represent when unscrambled? A: root B: pass C: integer D: packed\n",
      "Answer: D: packed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 486 / 1203  (40.4):  60%|    | 1202/2000 [16:55<11:38,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 486 / 1203  (40.4):  60%|    | 1203/2000 [16:55<10:05,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 486 / 1204  (40.4):  60%|    | 1203/2000 [16:56<10:05,  1.32it/s]\u001b[A\n",
      "Average Metric: 486 / 1204  (40.4):  60%|    | 1204/2000 [16:56<09:07,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 487 / 1205  (40.4):  60%|    | 1204/2000 [16:57<09:07,  1.45it/s]\u001b[A\n",
      "Average Metric: 487 / 1205  (40.4):  60%|    | 1205/2000 [16:57<08:39,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pweorhsot' represent when unscrambled? A: faster B: powershot C: address D: sciences\n",
      "Answer: A: faster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1206  (40.5):  60%|    | 1205/2000 [16:58<08:39,  1.53it/s]\u001b[A\n",
      "Average Metric: 488 / 1206  (40.5):  60%|    | 1206/2000 [16:58<11:57,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 489 / 1207  (40.5):  60%|    | 1206/2000 [16:58<11:57,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 489 / 1207  (40.5):  60%|    | 1207/2000 [16:58<09:05,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bnoirg'. A: needed B: boring C: coat D: procedure\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1208  (40.6):  60%|    | 1207/2000 [16:59<09:05,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 490 / 1208  (40.6):  60%|    | 1208/2000 [16:59<07:46,  1.70it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vkniig' represent when unscrambled? A: consent B: viking C: ownership D: allan\n",
      "Answer: B: viking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sacpeil' represent when unscrambled? A: faqs B: special C: worried D: deviantart\n",
      "Answer: A: faqs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 491 / 1209  (40.6):  60%|    | 1208/2000 [17:00<07:46,  1.70it/s]\u001b[A\n",
      "Average Metric: 491 / 1209  (40.6):  60%|    | 1209/2000 [17:00<09:11,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fnud'. A: experiencing B: girls C: fund D: italian\n",
      "Answer: D: italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 492 / 1210  (40.7):  60%|    | 1209/2000 [17:00<09:11,  1.43it/s]\u001b[A\n",
      "Average Metric: 492 / 1210  (40.7):  60%|    | 1210/2000 [17:00<09:50,  1.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 492 / 1211  (40.6):  60%|    | 1210/2000 [17:01<09:50,  1.34it/s]\u001b[A\n",
      "Average Metric: 492 / 1211  (40.6):  61%|    | 1211/2000 [17:01<08:50,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gnelty' represent when unscrambled? A: gently B: boolean C: cherokee D: scottish\n",
      "Answer: A: gently\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dwionlnadog'. A: dialogue B: downloading C: thehun D: connectivity\n",
      "Answer: D: connectivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'kuergr' represent when unscrambled? A: gaining B: kruger C: consortium D: trek\n",
      "Answer: A: gaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dteabes' to form the correct word. A: gage B: extending C: debates D: highest\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'kaasakhztn'? A: saddam B: kazakhstan C: faqs D: ware\n",
      "Answer: C: faqs\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'eyepelmos'? A: meanwhile B: lesbian C: employees D: sending\n",
      "Answer: D: sending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 493 / 1212  (40.7):  61%|    | 1211/2000 [17:06<08:50,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 493 / 1212  (40.7):  61%|    | 1212/2000 [17:06<26:28,  2.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fimorng' to form the correct word. A: forming B: voted C: lower D: haven\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'oeutr' to form the correct word. A: review B: interactive C: reply D: outer\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 494 / 1213  (40.7):  61%|    | 1212/2000 [17:07<26:28,  2.02s/it]\u001b[A\n",
      "Average Metric: 494 / 1213  (40.7):  61%|    | 1213/2000 [17:07<23:05,  1.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 494 / 1214  (40.7):  61%|    | 1213/2000 [17:08<23:05,  1.76s/it]\u001b[A\n",
      "Average Metric: 494 / 1214  (40.7):  61%|    | 1214/2000 [17:08<17:27,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 494 / 1215  (40.7):  61%|    | 1214/2000 [17:08<17:27,  1.33s/it]\u001b[A\n",
      "Average Metric: 494 / 1215  (40.7):  61%|    | 1215/2000 [17:08<12:55,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ietidenfid' to form the correct word. A: selected B: catering C: dans D: identified\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mdlaevis'? A: nextel B: maldives C: established D: impaired\n",
      "Answer: D: impaired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1216  (40.7):  61%|    | 1215/2000 [17:10<12:55,  1.01it/s]\u001b[A\n",
      "Average Metric: 495 / 1216  (40.7):  61%|    | 1216/2000 [17:10<18:45,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'uesd'. A: waters B: basic C: wishlist D: used\n",
      "Answer: D: used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bduides' to form the correct word. A: wiley B: vegetables C: buddies D: mileage\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'inentd' represent when unscrambled? A: jury B: reply C: intend D: shoe\n",
      "Answer: D: shoe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 495 / 1217  (40.7):  61%|    | 1216/2000 [17:11<18:45,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 495 / 1217  (40.7):  61%|    | 1217/2000 [17:11<16:33,  1.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ubeinsad'. A: formulation B: recorded C: articles D: unbiased\n",
      "Answer: D: unbiased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1218  (40.7):  61%|    | 1217/2000 [17:12<16:33,  1.27s/it]\u001b[A\n",
      "Average Metric: 496 / 1218  (40.7):  61%|    | 1218/2000 [17:12<16:12,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cieocontnn'. A: peripheral B: connection C: efficiently D: priority\n",
      "Answer: C: efficiently"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1219  (40.7):  61%|    | 1218/2000 [17:15<16:12,  1.24s/it]\u001b[A\n",
      "Average Metric: 496 / 1219  (40.7):  61%|    | 1219/2000 [17:15<20:10,  1.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 496 / 1220  (40.7):  61%|    | 1219/2000 [17:15<20:10,  1.55s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1220  (40.7):  61%|    | 1220/2000 [17:15<15:29,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'etaing'. A: recommendations B: performing C: pins D: eating\n",
      "Answer: D: eating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 497 / 1221  (40.7):  61%|    | 1220/2000 [17:17<15:29,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'moiidfed'? A: modified B: disaster C: notices D: useful\n",
      "Answer: D: useful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 497 / 1221  (40.7):  61%|    | 1221/2000 [17:17<17:58,  1.38s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1222  (40.7):  61%|    | 1221/2000 [17:17<17:58,  1.38s/it]\u001b[A\n",
      "Average Metric: 497 / 1223  (40.6):  61%|    | 1222/2000 [17:17<17:57,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 497 / 1223  (40.6):  61%|    | 1223/2000 [17:17<11:26,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 498 / 1224  (40.7):  61%|    | 1223/2000 [17:17<11:26,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 498 / 1225  (40.7):  61%|    | 1224/2000 [17:18<11:25,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 498 / 1225  (40.7):  61%|   | 1225/2000 [17:18<08:41,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'boiecth'. A: anchorage B: arbitrary C: biotech D: widely\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 499 / 1226  (40.7):  61%|   | 1225/2000 [17:18<08:41,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 499 / 1227  (40.7):  61%|   | 1226/2000 [17:18<08:40,  1.49it/s]\u001b[A\n",
      "Average Metric: 499 / 1227  (40.7):  61%|   | 1227/2000 [17:18<06:27,  2.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 499 / 1228  (40.6):  61%|   | 1227/2000 [17:19<06:27,  2.00it/s]\u001b[A\n",
      "Average Metric: 499 / 1228  (40.6):  61%|   | 1228/2000 [17:19<05:29,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ddlio'. A: timber B: suits C: telecom D: dildo\n",
      "Answer: D: dildo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 499 / 1229  (40.6):  61%|   | 1228/2000 [17:20<05:29,  2.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 499 / 1229  (40.6):  61%|   | 1229/2000 [17:20<09:40,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'terorr' represent when unscrambled? A: environmental B: terror C: odds D: senior\n",
      "Answer: B: terror\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'omzietpid'. A: optimized B: communication C: ceramic D: revised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'feflairid'. A: fairfield B: links C: discs D: brush\n",
      "Answer: D: brush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'anbydoy' to form the correct word. A: limitations B: energy C: opportunities D: anybody\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 499 / 1230  (40.6):  61%|   | 1229/2000 [17:26<09:40,  1.33it/s]\u001b[A\n",
      "Average Metric: 499 / 1230  (40.6):  62%|   | 1230/2000 [17:26<25:34,  1.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bblie' represent when unscrambled? A: engine B: bible C: mauritania D: possibly\n",
      "Answer: D: possibly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 500 / 1231  (40.6):  62%|   | 1230/2000 [17:27<25:34,  1.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1231  (40.6):  62%|   | 1231/2000 [17:27<21:53,  1.71s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1232  (40.6):  62%|   | 1231/2000 [17:27<21:53,  1.71s/it]\u001b[A\n",
      "Average Metric: 500 / 1232  (40.6):  62%|   | 1232/2000 [17:27<16:27,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eelln'. A: fourth B: ellen C: porter D: worthy\n",
      "Answer: B: ellen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hrroor'. A: horror B: promotion C: newsgroups D: serum\n",
      "Answer: A: horror\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1233  (40.6):  62%|   | 1232/2000 [17:30<16:27,  1.29s/it]\u001b[A\n",
      "Average Metric: 500 / 1233  (40.6):  62%|   | 1233/2000 [17:30<20:01,  1.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1234  (40.5):  62%|   | 1233/2000 [17:30<20:01,  1.57s/it]\u001b[A\n",
      "Average Metric: 500 / 1234  (40.5):  62%|   | 1234/2000 [17:30<15:33,  1.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1235  (40.5):  62%|   | 1234/2000 [17:30<15:33,  1.22s/it]\u001b[A\n",
      "Average Metric: 500 / 1235  (40.5):  62%|   | 1235/2000 [17:30<11:53,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'amiebn'? A: strings B: oxford C: imports D: ambien\n",
      "Answer: D: ambien\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1236  (40.5):  62%|   | 1235/2000 [17:31<11:53,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 500 / 1236  (40.5):  62%|   | 1236/2000 [17:31<12:07,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'daoeisttnins'. A: destinations B: tray C: excerpt D: equations\n",
      "Answer: D: equations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'figindns'. A: ultimate B: ashley C: timber D: findings\n",
      "Answer: D: findings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 500 / 1237  (40.4):  62%|   | 1236/2000 [17:33<12:07,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 500 / 1237  (40.4):  62%|   | 1237/2000 [17:33<14:44,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1238  (40.4):  62%|   | 1237/2000 [17:33<14:44,  1.16s/it]\u001b[A\n",
      "Average Metric: 500 / 1238  (40.4):  62%|   | 1238/2000 [17:33<12:09,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cucirit' represent when unscrambled? A: attended B: commit C: circuit D: carbon\n",
      "Answer: C: circuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1239  (40.4):  62%|   | 1238/2000 [17:34<12:09,  1.05it/s]\u001b[A\n",
      "Average Metric: 500 / 1239  (40.4):  62%|   | 1239/2000 [17:34<11:03,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cearmn'. A: carmen B: beaten C: hunter D: relation\n",
      "Answer: A: carmen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 501 / 1240  (40.4):  62%|   | 1239/2000 [17:35<11:03,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 501 / 1240  (40.4):  62%|   | 1240/2000 [17:35<10:17,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tlevelarr'. A: volt B: attempts C: northwestern D: traveller\n",
      "Answer: D: traveller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'podnirivg'. A: diseases B: providing C: invasion D: controversial\n",
      "Answer: D: controversial"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 501 / 1241  (40.4):  62%|   | 1240/2000 [17:36<10:17,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 501 / 1241  (40.4):  62%|   | 1241/2000 [17:36<12:39,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pianckg'? A: packing B: additionally C: upgraded D: taylor\n",
      "Answer: D: taylor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 502 / 1242  (40.4):  62%|   | 1241/2000 [17:37<12:39,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 502 / 1242  (40.4):  62%|   | 1242/2000 [17:38<14:15,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'divres' to form the correct word. A: nominations B: attachments C: jackie D: drives\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'athltee'. A: encryption B: athlete C: earned D: orchestra\n",
      "Answer: A: encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 502 / 1243  (40.4):  62%|   | 1242/2000 [17:40<14:15,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 502 / 1243  (40.4):  62%|   | 1243/2000 [17:40<18:26,  1.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sasoen' represent when unscrambled? A: stars B: miscellaneous C: season D: credit\n",
      "Answer: C: season\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rtenlaig'? A: usps B: relating C: phentermine D: pastor\n",
      "Answer: usps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1244  (40.4):  62%|   | 1243/2000 [17:41<18:26,  1.46s/it]\u001b[A\n",
      "Average Metric: 503 / 1244  (40.4):  62%|   | 1244/2000 [17:41<16:21,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1245  (40.4):  62%|   | 1244/2000 [17:41<16:21,  1.30s/it]\u001b[A\n",
      "Average Metric: 503 / 1245  (40.4):  62%|   | 1245/2000 [17:41<13:50,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'amablaa'. A: survey B: alabama C: shakespeare D: articles\n",
      "Answer: D: articles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1246  (40.4):  62%|   | 1245/2000 [17:42<13:50,  1.10s/it]\u001b[A\n",
      "Average Metric: 503 / 1246  (40.4):  62%|   | 1246/2000 [17:42<13:46,  1.10s/it]\u001b[A\n",
      "Average Metric: 504 / 1247  (40.4):  62%|   | 1246/2000 [17:44<13:46,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 504 / 1247  (40.4):  62%|   | 1247/2000 [17:44<14:54,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'slteys' represent when unscrambled? A: throwing B: styles C: penguin D: projected\n",
      "Answer: B: styles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 504 / 1248  (40.4):  62%|   | 1247/2000 [17:45<14:54,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1248  (40.4):  62%|   | 1248/2000 [17:45<14:02,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1249  (40.4):  62%|   | 1248/2000 [17:45<14:02,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 504 / 1249  (40.4):  62%|   | 1249/2000 [17:45<12:18,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 1250  (40.4):  62%|   | 1249/2000 [17:46<12:18,  1.02it/s]\u001b[A\n",
      "Average Metric: 505 / 1250  (40.4):  62%|   | 1250/2000 [17:46<09:35,  1.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mlik'. A: indonesian B: milk C: souls D: sided\n",
      "Answer: A: indonesian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ppoaosrl' to form the correct word. A: proposal B: allow C: taxi D: licking\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 505 / 1251  (40.4):  62%|   | 1250/2000 [17:46<09:35,  1.30it/s]\u001b[A\n",
      "Average Metric: 505 / 1251  (40.4):  63%|   | 1251/2000 [17:46<09:12,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 1252  (40.3):  63%|   | 1251/2000 [17:47<09:12,  1.36it/s]\u001b[A\n",
      "Average Metric: 505 / 1252  (40.3):  63%|   | 1252/2000 [17:47<07:59,  1.56it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1253  (40.4):  63%|   | 1252/2000 [17:47<07:59,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ulcne'? A: hurricane B: uncle C: grew D: pleasant\n",
      "Answer: B: uncle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'detfces'? A: defects B: headers C: riding D: harold\n",
      "Answer: D: harold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1254  (40.4):  63%|   | 1253/2000 [17:47<07:58,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 506 / 1254  (40.4):  63%|   | 1254/2000 [17:47<06:05,  2.04it/s]\u001b[A\n",
      "Average Metric: 507 / 1255  (40.4):  63%|   | 1254/2000 [17:47<06:05,  2.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 508 / 1256  (40.4):  63%|   | 1255/2000 [17:48<06:05,  2.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 508 / 1256  (40.4):  63%|   | 1256/2000 [17:48<04:24,  2.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mrteysy' to form the correct word. A: enforcement B: mystery C: humanities D: bounce\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 509 / 1257  (40.5):  63%|   | 1256/2000 [17:50<04:24,  2.81it/s]\u001b[A\n",
      "Average Metric: 509 / 1257  (40.5):  63%|   | 1257/2000 [17:50<08:36,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 509 / 1258  (40.5):  63%|   | 1257/2000 [17:51<08:36,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 509 / 1258  (40.5):  63%|   | 1258/2000 [17:51<11:06,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'siehld' represent when unscrambled? A: shield B: legs C: respondents D: with\n",
      "Answer: A: shield\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'losnig' to form the correct word. A: arrest B: biotech C: diving D: losing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'srhaochsilp'? A: dell B: jpeg C: scholarship D: snowboard\n",
      "Answer: D: snowboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'atnyhing'. A: pollution B: holocaust C: bookmark D: anything\n",
      "Answer: D: anything\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 509 / 1259  (40.4):  63%|   | 1258/2000 [17:53<11:06,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 509 / 1259  (40.4):  63%|   | 1259/2000 [17:53<15:36,  1.26s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 509 / 1260  (40.4):  63%|   | 1259/2000 [17:54<15:36,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'males'? A: emission B: drops C: meals D: duck\n",
      "Answer: A: emission\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hsottet' represent when unscrambled? A: hygiene B: hottest C: suggested D: warm\n",
      "Answer: D: warm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 510 / 1261  (40.4):  63%|   | 1260/2000 [17:55<15:35,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 510 / 1261  (40.4):  63%|   | 1261/2000 [17:55<12:44,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'smunraie'? A: caption B: accessories C: suriname D: javascript\n",
      "Answer: caption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 510 / 1262  (40.4):  63%|   | 1261/2000 [17:57<12:44,  1.03s/it]\u001b[A\n",
      "Average Metric: 510 / 1262  (40.4):  63%|   | 1262/2000 [17:57<14:35,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 510 / 1263  (40.4):  63%|   | 1262/2000 [17:57<14:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 510 / 1263  (40.4):  63%|   | 1263/2000 [17:57<11:19,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'oenfsfe' to form the correct word. A: indicated B: ottawa C: households D: offense\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Madrid  B: Berlin  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest prime number?  A\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cntuoy'. A: jump B: county C: twinks D: spiritual\n",
      "Answer: A: jump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 510 / 1264  (40.3):  63%|   | 1263/2000 [17:57<11:19,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 510 / 1264  (40.3):  63%|   | 1264/2000 [17:57<10:50,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 511 / 1265  (40.4):  63%|   | 1264/2000 [17:59<10:50,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eetmxre'. A: trackback B: extreme C: advance D: location\n",
      "Answer: D: location\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crwod'? A: margaret B: crowd C: party D: annually\n",
      "Answer: B: crowd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 511 / 1265  (40.4):  63%|   | 1265/2000 [17:59<12:03,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 512 / 1266  (40.4):  63%|   | 1265/2000 [17:59<12:03,  1.02it/s]\u001b[A\n",
      "Average Metric: 512 / 1266  (40.4):  63%|   | 1266/2000 [17:59<10:09,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 512 / 1267  (40.4):  63%|   | 1266/2000 [17:59<10:09,  1.20it/s]\u001b[A\n",
      "Average Metric: 512 / 1267  (40.4):  63%|   | 1267/2000 [17:59<07:38,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'coeecnattnrd'. A: stolen B: exterior C: zealand D: concentrated\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 513 / 1268  (40.5):  63%|   | 1267/2000 [17:59<07:38,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 513 / 1268  (40.5):  63%|   | 1268/2000 [17:59<06:05,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tjtiaasikn'. A: horny B: tajikistan C: drawings D: auditing\n",
      "Answer: D: auditing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ragne' to form the correct word. A: yemen B: range C: snacks D: released\n",
      "Answer: B: range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 513 / 1269  (40.4):  63%|   | 1268/2000 [18:04<06:05,  2.00it/s]\u001b[A\n",
      "Average Metric: 513 / 1269  (40.4):  63%|   | 1269/2000 [18:04<20:59,  1.72s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 513 / 1270  (40.4):  63%|   | 1269/2000 [18:05<20:59,  1.72s/it]\u001b[A\n",
      "Average Metric: 513 / 1270  (40.4):  64%|   | 1270/2000 [18:05<16:16,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lsoictgis'. A: logistics B: verbal C: korean D: selected\n",
      "Answer: D: selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1271  (40.4):  64%|   | 1270/2000 [18:06<16:16,  1.34s/it]\u001b[A\n",
      "Average Metric: 514 / 1271  (40.4):  64%|   | 1271/2000 [18:06<15:33,  1.28s/it]\u001b[A\n",
      "Average Metric: 514 / 1272  (40.4):  64%|   | 1271/2000 [18:06<15:33,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1272  (40.4):  64%|   | 1272/2000 [18:06<13:18,  1.10s/it]\u001b[A\n",
      "Average Metric: 514 / 1273  (40.4):  64%|   | 1272/2000 [18:07<13:18,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1273  (40.4):  64%|   | 1273/2000 [18:07<10:04,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 514 / 1274  (40.3):  64%|   | 1273/2000 [18:07<10:04,  1.20it/s]\u001b[A\n",
      "Average Metric: 514 / 1274  (40.3):  64%|   | 1274/2000 [18:07<08:23,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aplipcant'. A: atomic B: emerging C: applicant D: distinguish\n",
      "Answer: D: distinguish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1275  (40.3):  64%|   | 1274/2000 [18:09<08:23,  1.44it/s]\u001b[A\n",
      "Average Metric: 514 / 1275  (40.3):  64%|   | 1275/2000 [18:09<11:59,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 515 / 1276  (40.4):  64%|   | 1275/2000 [18:09<11:59,  1.01it/s]\u001b[A\n",
      "Average Metric: 515 / 1276  (40.4):  64%|   | 1276/2000 [18:09<08:49,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 516 / 1277  (40.4):  64%|   | 1276/2000 [18:09<08:49,  1.37it/s]\u001b[A\n",
      "Average Metric: 516 / 1277  (40.4):  64%|   | 1277/2000 [18:09<07:00,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 517 / 1278  (40.5):  64%|   | 1277/2000 [18:09<07:00,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fere' to form the correct word. A: appointment B: prevent C: administration D: free\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'maimi'. A: miami B: initiative C: hugh D: occurs\n",
      "Answer: miami\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 517 / 1278  (40.5):  64%|   | 1278/2000 [18:09<05:17,  2.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 518 / 1279  (40.5):  64%|   | 1278/2000 [18:09<05:17,  2.27it/s]\u001b[A\n",
      "Average Metric: 518 / 1279  (40.5):  64%|   | 1279/2000 [18:10<05:08,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nwreak'? A: tire B: question C: newark D: intersection\n",
      "Answer: D: intersection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 518 / 1280  (40.5):  64%|   | 1279/2000 [18:10<05:08,  2.33it/s]\u001b[A\n",
      "Average Metric: 518 / 1280  (40.5):  64%|   | 1280/2000 [18:10<05:19,  2.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'smbiut'. A: blacks B: submit C: financial D: consult\n",
      "Answer: D: consult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'golw' to form the correct word. A: sought B: glow C: commitments D: pubmed\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rlaediy'? A: readily B: tell C: sexuality D: bikes\n",
      "Answer: B: tell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 518 / 1281  (40.4):  64%|   | 1280/2000 [18:10<05:19,  2.25it/s]\u001b[A\n",
      "Average Metric: 518 / 1281  (40.4):  64%|   | 1281/2000 [18:11<05:36,  2.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'beign'? A: begin B: weakness C: coordinator D: montgomery\n",
      "Answer: begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dladey'. A: postgraduate B: plugin C: shoe D: deadly\n",
      "Answer: D: deadly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 519 / 1282  (40.5):  64%|   | 1281/2000 [18:14<05:36,  2.13it/s]\u001b[A\n",
      "Average Metric: 519 / 1282  (40.5):  64%|   | 1282/2000 [18:14<16:54,  1.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mtala'. A: technicians B: forces C: vintage D: malta\n",
      "Answer: D: malta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 519 / 1283  (40.5):  64%|   | 1282/2000 [18:15<16:54,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 519 / 1283  (40.5):  64%|   | 1283/2000 [18:15<16:30,  1.38s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 519 / 1284  (40.4):  64%|   | 1283/2000 [18:17<16:30,  1.38s/it]\u001b[A\n",
      "Average Metric: 519 / 1284  (40.4):  64%|   | 1284/2000 [18:17<16:11,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ltaest'. A: valid B: establishment C: enterprise D: latest\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'digeensrs'. A: happen B: designers C: disorders D: basics\n",
      "Answer: C: disorders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 520 / 1285  (40.5):  64%|   | 1284/2000 [18:20<16:11,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 520 / 1285  (40.5):  64%|   | 1285/2000 [18:20<21:47,  1.83s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 521 / 1286  (40.5):  64%|   | 1285/2000 [18:20<21:47,  1.83s/it]\u001b[A\n",
      "Average Metric: 521 / 1286  (40.5):  64%|   | 1286/2000 [18:20<16:06,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pool' represent when unscrambled? A: surfing B: pool C: dealtime D: currently\n",
      "Answer: A: surfing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wveon'. A: elevation B: woven C: prices D: brian\n",
      "Answer: A: elevation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bairrer' to form the correct word. A: barrier B: start C: humidity D: secondary\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'nmaes' to form the correct word. A: newbie B: manual C: multimedia D: names\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 522 / 1287  (40.6):  64%|   | 1286/2000 [18:22<16:06,  1.35s/it]\u001b[A\n",
      "Average Metric: 522 / 1287  (40.6):  64%|   | 1287/2000 [18:22<17:11,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 523 / 1288  (40.6):  64%|   | 1287/2000 [18:22<17:11,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "\u001b[A\n",
      "Average Metric: 523 / 1288  (40.6):  64%|   | 1288/2000 [18:22<14:06,  1.19s/it]  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'coiunntg' represent when unscrambled? A: reporters B: carnegie C: plain D: counting\n",
      "Answer: D: counting"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sosonpr' represent when unscrambled? A: lesser B: lincoln C: sponsor D: filling\n",
      "Answer: C: sponsor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mnius' represent when unscrambled? A: governmental B: cape C: minus D: broadway\n",
      "Answer: B: cape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 523 / 1289  (40.6):  64%|   | 1288/2000 [18:25<14:06,  1.19s/it]\u001b[A\n",
      "Average Metric: 523 / 1289  (40.6):  64%|   | 1289/2000 [18:25<18:12,  1.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'daiomn' represent when unscrambled? A: become B: domain C: bunch D: experimental\n",
      "Answer: D: experimental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rreecveis' represent when unscrambled? A: analysis B: receivers C: conflicts D: channel\n",
      "Answer: D: channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 523 / 1290  (40.5):  64%|   | 1289/2000 [18:27<18:12,  1.54s/it]\u001b[A\n",
      "Average Metric: 523 / 1290  (40.5):  64%|   | 1290/2000 [18:27<21:14,  1.79s/it]\u001b[A\n",
      "Average Metric: 523 / 1291  (40.5):  64%|   | 1290/2000 [18:27<21:14,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 523 / 1291  (40.5):  65%|   | 1291/2000 [18:28<17:00,  1.44s/it]\u001b[A\n",
      "Average Metric: 524 / 1292  (40.6):  65%|   | 1291/2000 [18:28<17:00,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 524 / 1292  (40.6):  65%|   | 1292/2000 [18:28<13:55,  1.18s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 525 / 1293  (40.6):  65%|   | 1292/2000 [18:28<13:55,  1.18s/it]\u001b[A\n",
      "Average Metric: 525 / 1293  (40.6):  65%|   | 1293/2000 [18:29<11:08,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 525 / 1294  (40.6):  65%|   | 1293/2000 [18:29<11:08,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 525 / 1295  (40.5):  65%|   | 1294/2000 [18:29<11:07,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 525 / 1296  (40.5):  65%|   | 1295/2000 [18:29<11:06,  1.06it/s]\u001b[A\n",
      "Average Metric: 525 / 1296  (40.5):  65%|   | 1296/2000 [18:29<05:10,  2.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bilnk'? A: instructional B: blink C: raise D: champion\n",
      "Answer: B: blink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 526 / 1297  (40.6):  65%|   | 1296/2000 [18:29<05:10,  2.27it/s]\u001b[A\n",
      "Average Metric: 526 / 1297  (40.6):  65%|   | 1297/2000 [18:29<05:16,  2.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 527 / 1298  (40.6):  65%|   | 1297/2000 [18:30<05:16,  2.22it/s]\u001b[A\n",
      "Average Metric: 527 / 1298  (40.6):  65%|   | 1298/2000 [18:30<05:14,  2.23it/s]\u001b[A\n",
      "Average Metric: 528 / 1299  (40.6):  65%|   | 1298/2000 [18:30<05:14,  2.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 528 / 1299  (40.6):  65%|   | 1299/2000 [18:30<05:18,  2.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 528 / 1300  (40.6):  65%|   | 1299/2000 [18:31<05:18,  2.20it/s]\u001b[A\n",
      "Average Metric: 528 / 1300  (40.6):  65%|   | 1300/2000 [18:31<06:52,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ssloaciit' to form the correct word. A: nickname B: cartridge C: socialist D: betting\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sulppy'. A: supply B: acceptance C: philosophy D: rfid\n",
      "Answer: D: rfid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 529 / 1301  (40.7):  65%|   | 1300/2000 [18:33<06:52,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 529 / 1301  (40.7):  65%|   | 1301/2000 [18:33<11:56,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'kocnk'. A: dramatic B: knock C: exhaust D: swan\n",
      "Answer: A: dramatic\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cnueonsss' represent when unscrambled? A: free B: okay C: consensus D: cant\n",
      "Answer: D: cant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'smoe'. A: scripting B: ballot C: grief D: some\n",
      "Answer: D: some\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cepathr' to form the correct word. A: chapter B: oxford C: ranger D: operates\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mmos' represent when unscrambled? A: hunger B: moms C: jane D: resolution\n",
      "Answer: A: hunger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 529 / 1302  (40.6):  65%|   | 1301/2000 [18:38<11:56,  1.03s/it]\u001b[A\n",
      "Average Metric: 529 / 1302  (40.6):  65%|   | 1302/2000 [18:38<22:50,  1.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 529 / 1303  (40.6):  65%|   | 1302/2000 [18:38<22:50,  1.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 529 / 1303  (40.6):  65%|   | 1303/2000 [18:38<17:06,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'raosnlebae' represent when unscrambled? A: observed B: reasonable C: scenario D: hearts\n",
      "Answer: D: hearts\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ejnoy'? A: enjoy B: vessel C: tries D: alberta\n",
      "Answer: enjoy\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pset'. A: pest B: modular C: stars D: liberal\n",
      "Answer: pest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1304  (40.6):  65%|   | 1303/2000 [18:38<17:06,  1.47s/it]\u001b[A\n",
      "Average Metric: 529 / 1304  (40.6):  65%|   | 1304/2000 [18:38<13:56,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1305  (40.5):  65%|   | 1304/2000 [18:38<13:56,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'brun'. A: memorabilia B: burn C: steady D: sears\n",
      "Answer: D: sears\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'baanmese' represent when unscrambled? A: straps B: morrison C: webmasters D: basename\n",
      "Answer: A: straps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1306  (40.5):  65%|   | 1305/2000 [18:40<13:55,  1.20s/it]\u001b[A\n",
      "Average Metric: 529 / 1306  (40.5):  65%|   | 1306/2000 [18:40<12:23,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1307  (40.5):  65%|   | 1306/2000 [18:42<12:23,  1.07s/it]\u001b[A\n",
      "Average Metric: 529 / 1307  (40.5):  65%|   | 1307/2000 [18:42<15:17,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'clut'? A: inclusive B: surfaces C: wall D: cult\n",
      "Answer: D: cult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 530 / 1308  (40.5):  65%|   | 1307/2000 [18:42<15:17,  1.32s/it]\u001b[A\n",
      "Average Metric: 530 / 1308  (40.5):  65%|   | 1308/2000 [18:42<11:51,  1.03s/it]\u001b[A\n",
      "Average Metric: 531 / 1309  (40.6):  65%|   | 1308/2000 [18:43<11:51,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 531 / 1309  (40.6):  65%|   | 1309/2000 [18:43<10:20,  1.11it/s]\u001b[A\n",
      "Average Metric: 531 / 1310  (40.5):  65%|   | 1309/2000 [18:43<10:20,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 532 / 1311  (40.6):  66%|   | 1310/2000 [18:44<10:19,  1.11it/s]\u001b[A\n",
      "Average Metric: 532 / 1311  (40.6):  66%|   | 1311/2000 [18:44<07:45,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'skocs'. A: native B: antigua C: socks D: zoophilia\n",
      "Answer: A: native\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wnehever' to form the correct word. A: shades B: attractive C: whenever D: dakota\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 533 / 1312  (40.6):  66%|   | 1311/2000 [18:45<07:45,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 533 / 1312  (40.6):  66%|   | 1312/2000 [18:45<10:10,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nitoce'. A: notice B: slut C: adrian D: include\n",
      "Answer: D: include\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'plezzus' to form the correct word. A: puzzles B: properties C: describes D: compare\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bdinidg'? A: pregnancy B: ordinary C: bidding D: ministries\n",
      "Answer: B: ordinary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 534 / 1313  (40.7):  66%|   | 1312/2000 [18:47<10:10,  1.13it/s]\u001b[A\n",
      "Average Metric: 534 / 1313  (40.7):  66%|   | 1313/2000 [18:47<12:49,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'manrthecs'? A: ieee B: beam C: separation D: merchants\n",
      "Answer: B: beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wdisnor' represent when unscrambled? A: utilization B: businesses C: retain D: windsor\n",
      "Answer: D: windsor\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rgeuefes'? A: refugees B: cant C: music D: avenue\n",
      "Answer: refugees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'chanoegpen'. A: raise B: copenhagen C: offender D: makers\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'birtsih'. A: british B: collision C: analyses D: threshold\n",
      "Answer: A: british\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 535 / 1314  (40.7):  66%|   | 1313/2000 [18:50<12:49,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 535 / 1314  (40.7):  66%|   | 1314/2000 [18:50<17:33,  1.54s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 536 / 1315  (40.8):  66%|   | 1314/2000 [18:50<17:33,  1.54s/it]\u001b[A\n",
      "Average Metric: 536 / 1315  (40.8):  66%|   | 1315/2000 [18:50<13:20,  1.17s/it]\u001b[A\n",
      "Average Metric: 537 / 1316  (40.8):  66%|   | 1315/2000 [18:50<13:20,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 538 / 1317  (40.9):  66%|   | 1316/2000 [18:51<13:19,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 538 / 1317  (40.9):  66%|   | 1317/2000 [18:51<10:14,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 538 / 1318  (40.8):  66%|   | 1317/2000 [18:51<10:14,  1.11it/s]\u001b[A\n",
      "Average Metric: 538 / 1318  (40.8):  66%|   | 1318/2000 [18:51<08:39,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 538 / 1319  (40.8):  66%|   | 1318/2000 [18:52<08:39,  1.31it/s]\u001b[A\n",
      "Average Metric: 538 / 1319  (40.8):  66%|   | 1319/2000 [18:52<06:44,  1.68it/s]\u001b[A\n",
      "Average Metric: 539 / 1320  (40.8):  66%|   | 1319/2000 [18:52<06:44,  1.68it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 539 / 1320  (40.8):  66%|   | 1320/2000 [18:52<05:15,  2.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 539 / 1321  (40.8):  66%|   | 1320/2000 [18:53<05:15,  2.16it/s]\u001b[A\n",
      "Average Metric: 539 / 1321  (40.8):  66%|   | 1321/2000 [18:53<06:46,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rbuy'. A: translators B: member C: ruby D: installing\n",
      "Answer: B: member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 540 / 1322  (40.8):  66%|   | 1321/2000 [18:54<06:46,  1.67it/s]\u001b[A\n",
      "Average Metric: 540 / 1322  (40.8):  66%|   | 1322/2000 [18:54<09:14,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 540 / 1323  (40.8):  66%|   | 1322/2000 [18:56<09:14,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 540 / 1323  (40.8):  66%|   | 1323/2000 [18:56<13:45,  1.22s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 541 / 1324  (40.9):  66%|   | 1323/2000 [18:57<13:45,  1.22s/it]\u001b[A\n",
      "Average Metric: 541 / 1324  (40.9):  66%|   | 1324/2000 [18:57<10:41,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'benyrfiod'. A: boyfriend B: geographical C: cameroon D: sample\n",
      "Answer: D: sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 542 / 1325  (40.9):  66%|   | 1324/2000 [18:57<10:41,  1.05it/s]\u001b[A\n",
      "Average Metric: 542 / 1325  (40.9):  66%|   | 1325/2000 [18:57<10:01,  1.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mmaethctais'. A: mathematics B: publicly C: structural D: profiles\n",
      "Answer: D: profiles"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cricteasyh'. A: citysearch B: customers C: cisco D: subscriptions\n",
      "Answer: C: cisco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 543 / 1326  (41.0):  66%|   | 1325/2000 [18:58<10:01,  1.12it/s]\u001b[A\n",
      "Average Metric: 543 / 1326  (41.0):  66%|   | 1326/2000 [18:58<09:26,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'celcys' to form the correct word. A: cycles B: bits C: delay D: controller\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mouldes'. A: modules B: happening C: enquiry D: traditionally\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rnitneg'. A: coaching B: renting C: bibliographic D: contrast\n",
      "Answer: D: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 544 / 1327  (41.0):  66%|   | 1326/2000 [19:01<09:26,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 544 / 1327  (41.0):  66%|   | 1327/2000 [19:01<15:24,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'myaor'. A: grid B: mayor C: chill D: hilton\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wlels'. A: burton B: cheque C: moore D: wells\n",
      "Answer: D: wells\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'liimt'. A: steroids B: electro C: limit D: focusing\n",
      "Answer: C: limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 544 / 1328  (41.0):  66%|   | 1327/2000 [19:01<15:24,  1.37s/it]\u001b[A\n",
      "Average Metric: 544 / 1328  (41.0):  66%|   | 1328/2000 [19:01<13:19,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'srapy' to form the correct word. A: spray B: house C: coordination D: appliance\n",
      "Answer: A: spray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 545 / 1329  (41.0):  66%|   | 1328/2000 [19:05<13:19,  1.19s/it]\u001b[A\n",
      "Average Metric: 545 / 1329  (41.0):  66%|   | 1329/2000 [19:05<22:39,  2.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'heplfluoy' represent when unscrambled? A: rica B: ambient C: senate D: hopefully\n",
      "Answer: A: rica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 545 / 1330  (41.0):  66%|   | 1329/2000 [19:05<22:39,  2.03s/it]\u001b[A\n",
      "Average Metric: 546 / 1331  (41.0):  66%|   | 1330/2000 [19:05<22:37,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 546 / 1332  (41.0):  67%|   | 1331/2000 [19:06<22:35,  2.03s/it]\u001b[A\n",
      "Average Metric: 546 / 1332  (41.0):  67%|   | 1332/2000 [19:06<11:20,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 546 / 1333  (41.0):  67%|   | 1332/2000 [19:07<11:20,  1.02s/it]\u001b[A\n",
      "Average Metric: 546 / 1333  (41.0):  67%|   | 1333/2000 [19:07<10:46,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'diestny'? A: only B: hazards C: density D: everything\n",
      "Answer: D: everything\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pigtianns'. A: paintings B: bookmark C: minority D: rico\n",
      "Answer: D: rico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'jisewh'. A: identifying B: bind C: jewish D: fold\n",
      "Answer: D: fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 547 / 1334  (41.0):  67%|   | 1333/2000 [19:08<10:46,  1.03it/s]\u001b[A\n",
      "Average Metric: 547 / 1334  (41.0):  67%|   | 1334/2000 [19:08<10:50,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crlaa'? A: clara B: floppy C: plates D: wrapped\n",
      "Answer: D: wrapped\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aragnre'? A: ruled B: witch C: arrange D: sexual\n",
      "Answer: C: arrange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 547 / 1335  (41.0):  67%|   | 1334/2000 [19:10<10:50,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 547 / 1335  (41.0):  67%|   | 1335/2000 [19:10<12:57,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'roobt' to form the correct word. A: transcription B: clouds C: investigated D: robot\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 547 / 1336  (40.9):  67%|   | 1335/2000 [19:11<12:57,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 547 / 1336  (40.9):  67%|   | 1336/2000 [19:11<12:18,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 548 / 1337  (41.0):  67%|   | 1336/2000 [19:12<12:18,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 548 / 1337  (41.0):  67%|   | 1337/2000 [19:12<12:01,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fngeir' to form the correct word. A: shot B: finger C: transparent D: lighting\n",
      "Answer: D: lighting\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'qiut' to form the correct word. A: events B: greatly C: quit D: formatting\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 549 / 1338  (41.0):  67%|   | 1337/2000 [19:12<12:01,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 549 / 1338  (41.0):  67%|   | 1338/2000 [19:12<09:24,  1.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cepoor'? A: heather B: cooper C: appraisal D: soldiers\n",
      "Answer: B: cooper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 550 / 1339  (41.1):  67%|   | 1338/2000 [19:13<09:24,  1.17it/s]\u001b[A\n",
      "Average Metric: 550 / 1339  (41.1):  67%|   | 1339/2000 [19:13<09:32,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 551 / 1340  (41.1):  67%|   | 1339/2000 [19:13<09:32,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 551 / 1341  (41.1):  67%|   | 1340/2000 [19:14<09:31,  1.15it/s]\u001b[A\n",
      "Average Metric: 551 / 1341  (41.1):  67%|   | 1341/2000 [19:14<07:51,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 551 / 1342  (41.1):  67%|   | 1341/2000 [19:14<07:51,  1.40it/s]\u001b[A\n",
      "Average Metric: 551 / 1342  (41.1):  67%|   | 1342/2000 [19:14<06:59,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 552 / 1343  (41.1):  67%|   | 1342/2000 [19:15<06:59,  1.57it/s]\u001b[A\n",
      "Average Metric: 552 / 1343  (41.1):  67%|   | 1343/2000 [19:15<07:33,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ptocepsrs' represent when unscrambled? A: robot B: catalog C: prospects D: flags\n",
      "Answer: A: robot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 552 / 1344  (41.1):  67%|   | 1343/2000 [19:17<07:33,  1.45it/s]\u001b[A\n",
      "Average Metric: 552 / 1344  (41.1):  67%|   | 1344/2000 [19:17<12:26,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 552 / 1345  (41.0):  67%|   | 1344/2000 [19:17<12:26,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1346  (41.1):  67%|   | 1345/2000 [19:18<12:25,  1.14s/it]\u001b[A\n",
      "Average Metric: 553 / 1346  (41.1):  67%|   | 1346/2000 [19:18<07:34,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'nceliy' to form the correct word. A: nicely B: yamaha C: ellen D: pole\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'avehiced'? A: achieved B: statutory C: depend D: hall\n",
      "Answer: achieved\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'birany'. A: trembl B: binary C: approved D: marino\n",
      "Answer: B: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1347  (41.1):  67%|   | 1346/2000 [19:19<07:34,  1.44it/s]\u001b[A\n",
      "Average Metric: 553 / 1347  (41.1):  67%|   | 1347/2000 [19:19<08:33,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 553 / 1348  (41.0):  67%|   | 1347/2000 [19:19<08:33,  1.27it/s]\u001b[A\n",
      "Average Metric: 553 / 1348  (41.0):  67%|   | 1348/2000 [19:19<06:49,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1349  (41.0):  67%|   | 1348/2000 [19:19<06:49,  1.59it/s]\u001b[A\n",
      "Average Metric: 553 / 1349  (41.0):  67%|   | 1349/2000 [19:19<05:18,  2.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'teinarr' to form the correct word. A: scottish B: potatoes C: outlook D: trainer\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tsak' represent when unscrambled? A: fairfield B: task C: critical D: holland\n",
      "Answer: B: task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1350  (41.0):  67%|   | 1349/2000 [19:19<05:18,  2.05it/s]\u001b[A\n",
      "Average Metric: 553 / 1350  (41.0):  68%|   | 1350/2000 [19:19<04:41,  2.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 554 / 1351  (41.0):  68%|   | 1350/2000 [19:21<04:41,  2.31it/s]\u001b[A\n",
      "Average Metric: 554 / 1351  (41.0):  68%|   | 1351/2000 [19:21<07:18,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tmroroow'? A: accountant B: tomorrow C: optical D: chandler\n",
      "Answer: C: optical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'geek' to form the correct word. A: geek B: oliver C: alternatively D: trailers\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lcak'? A: lack B: approval C: anchorage D: arthritis\n",
      "Answer: A: lack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ryas'. A: suggesting B: rays C: packing D: voyeurweb\n",
      "Answer: D: voyeurweb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 555 / 1352  (41.1):  68%|   | 1351/2000 [19:23<07:18,  1.48it/s]\u001b[A\n",
      "Average Metric: 555 / 1352  (41.1):  68%|   | 1352/2000 [19:23<13:02,  1.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 555 / 1353  (41.0):  68%|   | 1352/2000 [19:26<13:02,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 555 / 1353  (41.0):  68%|   | 1353/2000 [19:26<17:29,  1.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 555 / 1354  (41.0):  68%|   | 1353/2000 [19:27<17:29,  1.62s/it]\u001b[A\n",
      "Average Metric: 555 / 1354  (41.0):  68%|   | 1354/2000 [19:27<16:28,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 555 / 1355  (41.0):  68%|   | 1354/2000 [19:28<16:28,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 555 / 1355  (41.0):  68%|   | 1355/2000 [19:28<15:31,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gdenraa'. A: grenada B: points C: instantly D: novell\n",
      "Answer: D: novell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 556 / 1356  (41.0):  68%|   | 1355/2000 [19:29<15:31,  1.44s/it]\u001b[A\n",
      "Average Metric: 556 / 1356  (41.0):  68%|   | 1356/2000 [19:29<11:49,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 557 / 1357  (41.0):  68%|   | 1356/2000 [19:30<11:49,  1.10s/it]\u001b[A\n",
      "Average Metric: 557 / 1357  (41.0):  68%|   | 1357/2000 [19:30<11:54,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 557 / 1358  (41.0):  68%|   | 1357/2000 [19:30<11:54,  1.11s/it]\u001b[A\n",
      "Average Metric: 557 / 1358  (41.0):  68%|   | 1358/2000 [19:30<09:01,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tgaerpleh' to form the correct word. A: wage B: telegraph C: abilities D: administration\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1359  (41.1):  68%|   | 1358/2000 [19:32<09:01,  1.19it/s]\u001b[A\n",
      "Average Metric: 558 / 1359  (41.1):  68%|   | 1359/2000 [19:32<12:09,  1.14s/it]\u001b[A\n",
      "Average Metric: 558 / 1360  (41.0):  68%|   | 1359/2000 [19:32<12:09,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 558 / 1360  (41.0):  68%|   | 1360/2000 [19:32<09:01,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'deaelyd'. A: delayed B: teachers C: picture D: buck\n",
      "Answer: D: buck\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wliissht'. A: wishlist B: rarely C: oregon D: fatty\n",
      "Answer: D: fatty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1361  (41.0):  68%|   | 1360/2000 [19:33<09:01,  1.18it/s]\u001b[A\n",
      "Average Metric: 558 / 1361  (41.0):  68%|   | 1361/2000 [19:33<08:23,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1362  (41.0):  68%|   | 1361/2000 [19:33<08:23,  1.27it/s]\u001b[A\n",
      "Average Metric: 558 / 1362  (41.0):  68%|   | 1362/2000 [19:33<06:38,  1.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fnieegls' to form the correct word. A: bangbus B: recruiting C: feelings D: prospect\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1363  (40.9):  68%|   | 1362/2000 [19:33<06:38,  1.60it/s]\u001b[A\n",
      "Average Metric: 558 / 1363  (40.9):  68%|   | 1363/2000 [19:33<05:27,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'schaolr' represent when unscrambled? A: scholar B: also C: utilizing D: pole\n",
      "Answer: A: scholar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1364  (40.9):  68%|   | 1363/2000 [19:34<05:27,  1.94it/s]\u001b[A\n",
      "Average Metric: 558 / 1364  (40.9):  68%|   | 1364/2000 [19:34<07:09,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'falvor'. A: flavor B: rival C: checklist D: gadgets\n",
      "Answer: A: flavor\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'baed'. A: bead B: sorry C: phrase D: handheld\n",
      "Answer: D: handheld\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mlysef'? A: coated B: yukon C: myself D: museums\n",
      "Answer: B: yukon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 558 / 1365  (40.9):  68%|   | 1364/2000 [19:35<07:09,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 558 / 1365  (40.9):  68%|   | 1365/2000 [19:35<07:14,  1.46it/s]\u001b[A\n",
      "Average Metric: 559 / 1366  (40.9):  68%|   | 1365/2000 [19:35<07:14,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 559 / 1366  (40.9):  68%|   | 1366/2000 [19:35<05:57,  1.77it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 559 / 1367  (40.9):  68%|   | 1366/2000 [19:36<05:57,  1.77it/s]\u001b[A\n",
      "Average Metric: 559 / 1367  (40.9):  68%|   | 1367/2000 [19:36<05:48,  1.82it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'stutaets'? A: weapon B: statutes C: brook D: tourists\n",
      "Answer: B: statutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 560 / 1368  (40.9):  68%|   | 1367/2000 [19:36<05:48,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 560 / 1368  (40.9):  68%|   | 1368/2000 [19:36<06:15,  1.68it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'liimts' represent when unscrambled? A: admitted B: limits C: dates D: taylor\n",
      "Answer: B: limits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'reioatcn'? A: hints B: austria C: reaction D: makeup\n",
      "Answer: B: austria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 561 / 1369  (41.0):  68%|   | 1368/2000 [19:40<06:15,  1.68it/s]\u001b[A\n",
      "Average Metric: 561 / 1369  (41.0):  68%|   | 1369/2000 [19:40<15:05,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 562 / 1370  (41.0):  68%|   | 1369/2000 [19:40<15:05,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 562 / 1370  (41.0):  68%|   | 1370/2000 [19:40<11:28,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 562 / 1371  (41.0):  68%|   | 1370/2000 [19:41<11:28,  1.09s/it]\u001b[A\n",
      "Average Metric: 562 / 1371  (41.0):  69%|   | 1371/2000 [19:41<11:44,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1372  (41.0):  69%|   | 1371/2000 [19:41<11:44,  1.12s/it]\u001b[A\n",
      "Average Metric: 563 / 1372  (41.0):  69%|   | 1372/2000 [19:41<08:53,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sadonkrcuts'. A: configure B: money C: soundtracks D: midnight\n",
      "Answer: D: midnight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1373  (41.0):  69%|   | 1372/2000 [19:44<08:53,  1.18it/s]\u001b[A\n",
      "Average Metric: 563 / 1373  (41.0):  69%|   | 1373/2000 [19:44<12:58,  1.24s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1374  (41.0):  69%|   | 1373/2000 [19:44<12:58,  1.24s/it]\u001b[A\n",
      "Average Metric: 563 / 1374  (41.0):  69%|   | 1374/2000 [19:44<10:27,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bokors' to form the correct word. A: flow B: brooks C: leading D: roma\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1375  (40.9):  69%|   | 1374/2000 [19:45<10:27,  1.00s/it]\u001b[A\n",
      "Average Metric: 563 / 1375  (40.9):  69%|   | 1375/2000 [19:45<09:14,  1.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rseos'. A: tends B: roses C: suddenly D: stay\n",
      "Answer: D: stay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 563 / 1376  (40.9):  69%|   | 1375/2000 [19:45<09:14,  1.13it/s]\u001b[A\n",
      "Average Metric: 563 / 1376  (40.9):  69%|   | 1376/2000 [19:45<09:04,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 564 / 1377  (41.0):  69%|   | 1376/2000 [19:46<09:04,  1.15it/s]\u001b[A\n",
      "Average Metric: 564 / 1377  (41.0):  69%|   | 1377/2000 [19:46<08:39,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'kngihts'. A: exempt B: religious C: barrel D: knights\n",
      "Answer: D: knights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 565 / 1378  (41.0):  69%|   | 1377/2000 [19:47<08:39,  1.20it/s]\u001b[A\n",
      "Average Metric: 565 / 1378  (41.0):  69%|   | 1378/2000 [19:47<09:24,  1.10it/s]\u001b[A\n",
      "Average Metric: 565 / 1379  (41.0):  69%|   | 1378/2000 [19:47<09:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 565 / 1380  (40.9):  69%|   | 1379/2000 [19:48<09:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\u001b[A\n",
      "Average Metric: 565 / 1380  (40.9):  69%|   | 1380/2000 [19:48<05:56,  1.74it/s]\u001b[ATraceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oangiezrd'. A: sculpture B: appointed C: organized D: hazards\n",
      "Answer: D: hazards"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 565 / 1381  (40.9):  69%|   | 1380/2000 [19:50<05:56,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1381  (40.9):  69%|   | 1381/2000 [19:50<10:34,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cheuqe'. A: hybrid B: graduates C: cheque D: poem\n",
      "Answer: C: cheque\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1382  (40.9):  69%|   | 1381/2000 [19:51<10:34,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'menictnnaae' represent when unscrambled? A: promotes B: decay C: others D: maintenance\n",
      "Answer: D: maintenance\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dmoe'? A: steven B: dome C: escort D: animals\n",
      "Answer: B: dome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 565 / 1382  (40.9):  69%|   | 1382/2000 [19:51<11:15,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'taaiwn'? A: dropped B: chile C: blessed D: taiwan\n",
      "Answer: D: taiwan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1383  (40.9):  69%|   | 1382/2000 [19:54<11:15,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1383  (40.9):  69%|   | 1383/2000 [19:54<15:49,  1.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aacttvie'? A: satellite B: corps C: patio D: activate\n",
      "Answer: D: activate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 566 / 1384  (40.9):  69%|   | 1383/2000 [19:56<15:49,  1.54s/it]\u001b[A\n",
      "Average Metric: 566 / 1384  (40.9):  69%|   | 1384/2000 [19:56<15:34,  1.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 566 / 1385  (40.9):  69%|   | 1384/2000 [19:56<15:34,  1.52s/it]\u001b[A\n",
      "Average Metric: 566 / 1385  (40.9):  69%|   | 1385/2000 [19:56<12:21,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 567 / 1386  (40.9):  69%|   | 1385/2000 [19:56<12:21,  1.20s/it]\u001b[A\n",
      "Average Metric: 567 / 1386  (40.9):  69%|   | 1386/2000 [19:56<09:09,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'saetrm' represent when unscrambled? A: might B: scenic C: desktop D: stream\n",
      "Answer: D: stream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 568 / 1387  (41.0):  69%|   | 1386/2000 [19:58<09:09,  1.12it/s]\u001b[A\n",
      "Average Metric: 568 / 1387  (41.0):  69%|   | 1387/2000 [19:58<11:20,  1.11s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1388  (41.0):  69%|   | 1387/2000 [19:58<11:20,  1.11s/it]\u001b[A\n",
      "Average Metric: 569 / 1388  (41.0):  69%|   | 1388/2000 [19:58<08:18,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 569 / 1389  (41.0):  69%|   | 1388/2000 [19:59<08:18,  1.23it/s]\u001b[A\n",
      "Average Metric: 569 / 1389  (41.0):  69%|   | 1389/2000 [19:59<07:59,  1.27it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1390  (40.9):  69%|   | 1389/2000 [19:59<07:59,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fiisninhg'. A: finishing B: carefully C: cattle D: goat\n",
      "Answer: D: goat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dvirers'. A: strange B: bibliographic C: darwin D: drivers\n",
      "Answer: D: drivers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1391  (40.9):  70%|   | 1390/2000 [20:00<07:58,  1.27it/s]\u001b[A\n",
      "Average Metric: 569 / 1391  (40.9):  70%|   | 1391/2000 [20:00<08:39,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 569 / 1392  (40.9):  70%|   | 1391/2000 [20:01<08:39,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 569 / 1392  (40.9):  70%|   | 1392/2000 [20:02<09:15,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eedn' represent when unscrambled? A: jeep B: eden C: median D: poster\n",
      "Answer: A: jeep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1393  (40.8):  70%|   | 1392/2000 [20:03<09:15,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1393  (40.8):  70%|   | 1393/2000 [20:03<10:36,  1.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pnieunlsa'? A: homeland B: peninsula C: chances D: skirt\n",
      "Answer: B: peninsula\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eirn'. A: erin B: focus C: kelkoo D: jonathan\n",
      "Answer: A: erin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 570 / 1394  (40.9):  70%|   | 1393/2000 [20:04<10:36,  1.05s/it]\u001b[A\n",
      "Average Metric: 570 / 1394  (40.9):  70%|   | 1394/2000 [20:04<11:11,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wilnilg'. A: bath B: away C: willing D: budget\n",
      "Answer: D: budget\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 570 / 1395  (40.9):  70%|   | 1394/2000 [20:06<11:11,  1.11s/it]\u001b[A\n",
      "Average Metric: 570 / 1395  (40.9):  70%|   | 1395/2000 [20:06<13:15,  1.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 571 / 1396  (40.9):  70%|   | 1395/2000 [20:07<13:15,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 571 / 1396  (40.9):  70%|   | 1396/2000 [20:07<12:39,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cmredaocr' to form the correct word. A: camcorder B: dedication C: atari D: gambling\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 571 / 1397  (40.9):  70%|   | 1396/2000 [20:08<12:39,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 571 / 1397  (40.9):  70%|   | 1397/2000 [20:08<11:14,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pctiirancg'. A: ultimate B: practicing C: prototype D: hose\n",
      "Answer: D: hose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bjowlob'. A: duplicate B: newcastle C: harm D: blowjob\n",
      "Answer: D: blowjob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1398  (40.8):  70%|   | 1397/2000 [20:09<11:14,  1.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nteos'. A: midlands B: iron C: notes D: reception\n",
      "Answer: D: reception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 571 / 1398  (40.8):  70%|   | 1398/2000 [20:09<10:20,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1399  (40.8):  70%|   | 1398/2000 [20:09<10:20,  1.03s/it]\u001b[A\n",
      "Average Metric: 571 / 1399  (40.8):  70%|   | 1399/2000 [20:09<08:57,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'yenake' represent when unscrambled? A: yankee B: lawsuit C: publishing D: foundations\n",
      "Answer: A: yankee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 571 / 1400  (40.8):  70%|   | 1399/2000 [20:10<08:57,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 571 / 1400  (40.8):  70%|   | 1400/2000 [20:10<09:03,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1401  (40.8):  70%|   | 1400/2000 [20:10<09:03,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1401  (40.8):  70%|   | 1401/2000 [20:10<06:52,  1.45it/s]\u001b[A\n",
      "Average Metric: 571 / 1402  (40.7):  70%|   | 1401/2000 [20:10<06:52,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1403  (40.7):  70%|   | 1402/2000 [20:11<06:52,  1.45it/s]\u001b[A\n",
      "Average Metric: 571 / 1403  (40.7):  70%|   | 1403/2000 [20:11<05:13,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1404  (40.7):  70%|   | 1403/2000 [20:12<05:13,  1.91it/s]\u001b[A\n",
      "Average Metric: 571 / 1404  (40.7):  70%|   | 1404/2000 [20:12<05:40,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uetarndekn'? A: kyoto B: hospital C: undertaken D: ever\n",
      "Answer: D: ever\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 571 / 1405  (40.6):  70%|   | 1404/2000 [20:12<05:40,  1.75it/s]\u001b[A\n",
      "Average Metric: 571 / 1405  (40.6):  70%|   | 1405/2000 [20:12<04:28,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gian' represent when unscrambled? A: valued B: dietary C: recruitment D: gain\n",
      "Answer: A: valued"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'teunr'. A: tuner B: blast C: obesity D: bangbus\n",
      "Answer: A: tuner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ptnaoesirntes'. A: presentations B: collaboration C: various D: known\n",
      "Answer: D: known\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 572 / 1406  (40.7):  70%|   | 1405/2000 [20:16<04:28,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 572 / 1406  (40.7):  70%|   | 1406/2000 [20:16<13:24,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lwsaiut'. A: lawsuit B: candles C: terminate D: explaining\n",
      "Answer: D: explaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ingndeuios'? A: schedule B: indigenous C: immigration D: traders\n",
      "Answer: D: traders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'nmaewn' to form the correct word. A: excellence B: newman C: securities D: marking\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 573 / 1407  (40.7):  70%|   | 1406/2000 [20:18<13:24,  1.36s/it]\u001b[A\n",
      "Average Metric: 573 / 1407  (40.7):  70%|   | 1407/2000 [20:18<16:40,  1.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rzgoceiend'? A: race B: initial C: solely D: recognized\n",
      "Answer: D: recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 574 / 1408  (40.8):  70%|   | 1407/2000 [20:19<16:40,  1.69s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1408  (40.8):  70%|   | 1408/2000 [20:19<13:29,  1.37s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1409  (40.7):  70%|   | 1408/2000 [20:19<13:29,  1.37s/it]\u001b[A\n",
      "Average Metric: 574 / 1409  (40.7):  70%|   | 1409/2000 [20:19<10:17,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'barnch'. A: worked B: branch C: mistress D: surplus\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 574 / 1410  (40.7):  70%|   | 1409/2000 [20:21<10:17,  1.04s/it]\u001b[A\n",
      "Average Metric: 574 / 1410  (40.7):  70%|   | 1410/2000 [20:21<11:47,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 574 / 1411  (40.7):  70%|   | 1410/2000 [20:21<11:47,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1411  (40.7):  71%|   | 1411/2000 [20:21<09:29,  1.03it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1412  (40.7):  71%|   | 1411/2000 [20:21<09:29,  1.03it/s]\u001b[A\n",
      "Average Metric: 574 / 1412  (40.7):  71%|   | 1412/2000 [20:21<07:30,  1.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1413  (40.6):  71%|   | 1412/2000 [20:22<07:30,  1.30it/s]\u001b[A\n",
      "Average Metric: 574 / 1413  (40.6):  71%|   | 1413/2000 [20:22<06:25,  1.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ktae'? A: died B: hardwood C: kate D: thank\n",
      "Answer: D: thank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1414  (40.6):  71%|   | 1413/2000 [20:22<06:25,  1.52it/s]\u001b[A\n",
      "Average Metric: 574 / 1414  (40.6):  71%|   | 1414/2000 [20:22<05:35,  1.75it/s]\u001b[A\n",
      "Average Metric: 574 / 1415  (40.6):  71%|   | 1414/2000 [20:23<05:35,  1.75it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 574 / 1415  (40.6):  71%|   | 1415/2000 [20:23<07:34,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1416  (40.5):  71%|   | 1415/2000 [20:24<07:34,  1.29it/s]\u001b[A\n",
      "Average Metric: 574 / 1416  (40.5):  71%|   | 1416/2000 [20:24<07:34,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cetelcloblis'? A: korn B: palace C: nascar D: collectibles\n",
      "Answer: B: palace\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tlit'. A: tilt B: lost C: spoke D: critic\n",
      "Answer: D: critic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 574 / 1417  (40.5):  71%|   | 1416/2000 [20:26<07:34,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1417  (40.5):  71%|   | 1417/2000 [20:26<11:03,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'avertiredss' to form the correct word. A: photographer B: modular C: advertisers D: nelson\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 0.5  B: 0.2  C: 0.1  D: 0.01\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the correct spelling of the word 'col\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1418  (40.5):  71%|   | 1417/2000 [20:27<11:03,  1.14s/it]\u001b[A\n",
      "Average Metric: 574 / 1418  (40.5):  71%|   | 1418/2000 [20:27<09:14,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'snpak'. A: spank B: unified C: decorated D: theater\n",
      "Answer: D: theater\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 574 / 1419  (40.5):  71%|   | 1418/2000 [20:29<09:14,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 574 / 1419  (40.5):  71%|   | 1419/2000 [20:29<12:28,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ptorlmpy'? A: bonds B: crowd C: promptly D: surrounded\n",
      "Answer: D: surrounded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1420  (40.4):  71%|   | 1419/2000 [20:29<12:28,  1.29s/it]\u001b[A\n",
      "Average Metric: 574 / 1420  (40.4):  71%|   | 1420/2000 [20:29<10:46,  1.11s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 1421  (40.5):  71%|   | 1420/2000 [20:30<10:46,  1.11s/it]\u001b[A\n",
      "Average Metric: 575 / 1421  (40.5):  71%|   | 1421/2000 [20:30<08:18,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 1422  (40.4):  71%|   | 1421/2000 [20:30<08:18,  1.16it/s]\u001b[A\n",
      "Average Metric: 575 / 1422  (40.4):  71%|   | 1422/2000 [20:30<06:42,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 575 / 1423  (40.4):  71%|   | 1422/2000 [20:33<06:42,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 575 / 1423  (40.4):  71%|   | 1423/2000 [20:33<13:38,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 1424  (40.4):  71%|   | 1423/2000 [20:33<13:38,  1.42s/it]\u001b[A\n",
      "Average Metric: 575 / 1424  (40.4):  71%|   | 1424/2000 [20:33<09:53,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'xxnx'? A: guild B: clarity C: belarus D: xnxx\n",
      "Answer: xnxx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 576 / 1425  (40.4):  71%|   | 1424/2000 [20:34<09:53,  1.03s/it]\u001b[A\n",
      "Average Metric: 576 / 1425  (40.4):  71%|  | 1425/2000 [20:34<08:36,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'houisng'? A: housing B: terrorist C: capabilities D: profiles\n",
      "Answer: A: housing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dirvceite' represent when unscrambled? A: directive B: venus C: contests D: dildo\n",
      "Answer: A: directive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 576 / 1426  (40.4):  71%|  | 1425/2000 [20:36<08:36,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 576 / 1426  (40.4):  71%|  | 1426/2000 [20:36<11:05,  1.16s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 576 / 1427  (40.4):  71%|  | 1426/2000 [20:36<11:05,  1.16s/it]\u001b[A\n",
      "Average Metric: 576 / 1427  (40.4):  71%|  | 1427/2000 [20:36<08:11,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 577 / 1428  (40.4):  71%|  | 1427/2000 [20:36<08:11,  1.17it/s]\u001b[A\n",
      "Average Metric: 577 / 1428  (40.4):  71%|  | 1428/2000 [20:36<06:40,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 577 / 1429  (40.4):  71%|  | 1428/2000 [20:37<06:40,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 577 / 1429  (40.4):  71%|  | 1429/2000 [20:37<06:46,  1.40it/s]\u001b[A\n",
      "Average Metric: 577 / 1430  (40.3):  71%|  | 1429/2000 [20:37<06:46,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 577 / 1430  (40.3):  72%|  | 1430/2000 [20:37<05:08,  1.85it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 577 / 1431  (40.3):  72%|  | 1430/2000 [20:37<05:08,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 578 / 1432  (40.4):  72%|  | 1431/2000 [20:40<05:07,  1.85it/s]\u001b[A\n",
      "Average Metric: 578 / 1432  (40.4):  72%|  | 1432/2000 [20:40<08:22,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sitvreey'. A: severity B: reputation C: restaurants D: credit\n",
      "Answer: A: severity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'balme' to form the correct word. A: blame B: slip C: colorado D: grill\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'meovd'. A: flashing B: defect C: reprints D: moved\n",
      "Answer: D: moved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 579 / 1433  (40.4):  72%|  | 1432/2000 [20:41<08:22,  1.13it/s]\u001b[A\n",
      "Average Metric: 579 / 1433  (40.4):  72%|  | 1433/2000 [20:41<09:56,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hbioebs' to form the correct word. A: nearby B: virtual C: hobbies D: specifically\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 579 / 1434  (40.4):  72%|  | 1433/2000 [20:42<09:56,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 579 / 1434  (40.4):  72%|  | 1434/2000 [20:42<10:03,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wtaosn' represent when unscrambled? A: titten B: watson C: december D: figures\n",
      "Answer: B: watson\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cesalss'. A: classes B: trophy C: rear D: dedication\n",
      "Answer: D: dedication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 579 / 1435  (40.3):  72%|  | 1434/2000 [20:43<10:03,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 579 / 1435  (40.3):  72%|  | 1435/2000 [20:43<10:07,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mieralns'. A: minerals B: opportunity C: hang D: efficiency\n",
      "Answer: A: minerals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1436  (40.4):  72%|  | 1435/2000 [20:47<10:07,  1.08s/it]\u001b[A\n",
      "Average Metric: 580 / 1436  (40.4):  72%|  | 1436/2000 [20:47<15:45,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'atvilecy'. A: round B: china C: clayton D: actively\n",
      "Answer: D: actively\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1437  (40.4):  72%|  | 1436/2000 [20:47<15:45,  1.68s/it]\u001b[A\n",
      "Average Metric: 580 / 1437  (40.4):  72%|  | 1437/2000 [20:47<11:47,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'beelkrey' represent when unscrambled? A: randy B: bridal C: berkeley D: printable\n",
      "Answer: A: randy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wram'? A: wilson B: tied C: warm D: hardy\n",
      "Answer: A: wilson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 580 / 1438  (40.3):  72%|  | 1437/2000 [20:48<11:47,  1.26s/it]\u001b[A\n",
      "Average Metric: 580 / 1438  (40.3):  72%|  | 1438/2000 [20:48<12:53,  1.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dnaa'? A: continental B: restricted C: holy D: dana\n",
      "Answer: D: dana\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'andlae'? A: potentially B: andale C: daily D: developer\n",
      "Answer: D: developer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1439  (40.3):  72%|  | 1438/2000 [20:49<12:53,  1.38s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1439  (40.3):  72%|  | 1439/2000 [20:49<11:11,  1.20s/it]\u001b[A\n",
      "Average Metric: 580 / 1440  (40.3):  72%|  | 1439/2000 [20:49<11:11,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cliceaalnotn'? A: keeps B: duplicate C: cancellation D: indiana\n",
      "Answer: D: indiana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 580 / 1441  (40.2):  72%|  | 1440/2000 [20:50<11:10,  1.20s/it]\u001b[A\n",
      "Average Metric: 580 / 1441  (40.2):  72%|  | 1441/2000 [20:50<08:26,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 581 / 1442  (40.3):  72%|  | 1441/2000 [20:51<08:26,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 581 / 1442  (40.3):  72%|  | 1442/2000 [20:51<08:51,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peetr'. A: halloween B: pierce C: freeman D: peter\n",
      "Answer: D: peter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 581 / 1443  (40.3):  72%|  | 1442/2000 [20:52<08:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 581 / 1443  (40.3):  72%|  | 1443/2000 [20:52<07:38,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 582 / 1444  (40.3):  72%|  | 1443/2000 [20:53<07:38,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 582 / 1444  (40.3):  72%|  | 1444/2000 [20:53<07:29,  1.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seiphpd'. A: size B: celebrate C: shipped D: discrepancies\n",
      "Answer: D: discrepancies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 583 / 1445  (40.3):  72%|  | 1444/2000 [20:53<07:29,  1.24it/s]\u001b[A\n",
      "Average Metric: 583 / 1445  (40.3):  72%|  | 1445/2000 [20:53<07:22,  1.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 583 / 1446  (40.3):  72%|  | 1445/2000 [20:53<07:22,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 584 / 1447  (40.4):  72%|  | 1446/2000 [20:54<07:22,  1.25it/s]\u001b[A\n",
      "Average Metric: 584 / 1447  (40.4):  72%|  | 1447/2000 [20:54<05:34,  1.65it/s]\u001b[A\n",
      "Average Metric: 584 / 1448  (40.3):  72%|  | 1447/2000 [20:55<05:34,  1.65it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 584 / 1448  (40.3):  72%|  | 1448/2000 [20:55<06:15,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anluuimm'. A: spiral B: council C: preserved D: aluminum\n",
      "Answer: D: aluminum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 585 / 1449  (40.4):  72%|  | 1448/2000 [20:56<06:15,  1.47it/s]\u001b[A\n",
      "Average Metric: 585 / 1449  (40.4):  72%|  | 1449/2000 [20:56<08:02,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 586 / 1450  (40.4):  72%|  | 1449/2000 [20:57<08:02,  1.14it/s]\u001b[A\n",
      "Average Metric: 586 / 1450  (40.4):  72%|  | 1450/2000 [20:57<07:32,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'heelwtt' represent when unscrambled? A: palmer B: hewlett C: rebecca D: threat\n",
      "Answer: A: palmer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 586 / 1451  (40.4):  72%|  | 1450/2000 [20:58<07:32,  1.22it/s]\u001b[A\n",
      "Average Metric: 586 / 1451  (40.4):  73%|  | 1451/2000 [20:58<07:12,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'amuesss' represent when unscrambled? A: assumes B: canterbury C: floral D: passwords\n",
      "Answer: A: assumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 587 / 1452  (40.4):  73%|  | 1451/2000 [20:59<07:12,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 587 / 1452  (40.4):  73%|  | 1452/2000 [20:59<08:04,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'qruretlay' to form the correct word. A: subjects B: forbidden C: minimal D: quarterly\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cpoomiteln'. A: completion B: level C: anxiety D: trust\n",
      "Answer: D: trust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 587 / 1453  (40.4):  73%|  | 1452/2000 [21:00<08:04,  1.13it/s]\u001b[A\n",
      "Average Metric: 587 / 1453  (40.4):  73%|  | 1453/2000 [21:00<08:16,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 587 / 1454  (40.4):  73%|  | 1453/2000 [21:01<08:16,  1.10it/s]\u001b[A\n",
      "Average Metric: 587 / 1454  (40.4):  73%|  | 1454/2000 [21:01<08:29,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 587 / 1455  (40.3):  73%|  | 1454/2000 [21:02<08:29,  1.07it/s]\u001b[A\n",
      "Average Metric: 587 / 1455  (40.3):  73%|  | 1455/2000 [21:02<09:14,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 588 / 1456  (40.4):  73%|  | 1455/2000 [21:04<09:14,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 588 / 1456  (40.4):  73%|  | 1456/2000 [21:04<10:36,  1.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fianlly' to form the correct word. A: gays B: operation C: finally D: titled\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gaxaly' to form the correct word. A: galaxy B: christmas C: inherited D: writings\n",
      "Answer: A: galaxy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 589 / 1457  (40.4):  73%|  | 1456/2000 [21:05<10:36,  1.17s/it]\u001b[A\n",
      "Average Metric: 589 / 1457  (40.4):  73%|  | 1457/2000 [21:05<11:14,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'amrs' to form the correct word. A: henry B: arms C: mint D: exchange\n",
      "Answer: D: exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'raenl'. A: renal B: bones C: therapeutic D: reproductive\n",
      "Answer: A: renal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 590 / 1458  (40.5):  73%|  | 1457/2000 [21:06<11:14,  1.24s/it]\u001b[A\n",
      "Average Metric: 590 / 1458  (40.5):  73%|  | 1458/2000 [21:06<09:14,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peiord'? A: nature B: period C: arise D: shemale\n",
      "Answer: B: period\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'paaranmreitly'. A: parliamentary B: pause C: discussed D: treasure\n",
      "Answer: D: treasure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 590 / 1459  (40.4):  73%|  | 1458/2000 [21:07<09:14,  1.02s/it]\u001b[A\n",
      "Average Metric: 590 / 1459  (40.4):  73%|  | 1459/2000 [21:07<09:27,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 591 / 1460  (40.5):  73%|  | 1459/2000 [21:07<09:27,  1.05s/it]\u001b[A\n",
      "Average Metric: 591 / 1460  (40.5):  73%|  | 1460/2000 [21:07<07:53,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 592 / 1461  (40.5):  73%|  | 1460/2000 [21:08<07:53,  1.14it/s]\u001b[A\n",
      "Average Metric: 592 / 1461  (40.5):  73%|  | 1461/2000 [21:08<06:47,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'faer' represent when unscrambled? A: fear B: thousand C: camera D: intersection\n",
      "Answer: A: fear"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 592 / 1462  (40.5):  73%|  | 1461/2000 [21:09<06:47,  1.32it/s]\u001b[A\n",
      "Average Metric: 592 / 1462  (40.5):  73%|  | 1462/2000 [21:10<09:41,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dntermepaatl'. A: departmental B: stronger C: approaching D: lopez\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wnig'. A: authorities B: johnston C: zshops D: wing\n",
      "Answer: D: wing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'msuuem'? A: mann B: museum C: treated D: palm\n",
      "Answer: B: museum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anghsaaitfn'. A: afghanistan B: designer C: owners D: baked\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 593 / 1463  (40.5):  73%|  | 1462/2000 [21:12<09:41,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 593 / 1463  (40.5):  73%|  | 1463/2000 [21:12<13:54,  1.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 594 / 1464  (40.6):  73%|  | 1463/2000 [21:13<13:54,  1.55s/it]\u001b[A\n",
      "Average Metric: 594 / 1464  (40.6):  73%|  | 1464/2000 [21:13<12:42,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 595 / 1465  (40.6):  73%|  | 1464/2000 [21:14<12:42,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 595 / 1465  (40.6):  73%|  | 1465/2000 [21:14<10:22,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'coecrltlos' represent when unscrambled? A: currencies B: truth C: collectors D: beliefs\n",
      "Answer: B: truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 595 / 1466  (40.6):  73%|  | 1465/2000 [21:14<10:22,  1.16s/it]\u001b[A\n",
      "Average Metric: 595 / 1466  (40.6):  73%|  | 1466/2000 [21:14<08:19,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'slehter'. A: forming B: shelter C: isle D: oman\n",
      "Answer: C: isle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 596 / 1467  (40.6):  73%|  | 1466/2000 [21:15<08:19,  1.07it/s]\u001b[A\n",
      "Average Metric: 596 / 1467  (40.6):  73%|  | 1467/2000 [21:15<07:06,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jeoks' represent when unscrambled? A: highly B: subsidiary C: apparent D: jokes\n",
      "Answer: D: jokes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'satr'? A: bathroom B: recognize C: star D: plaintiff\n",
      "Answer: A: bathroom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 596 / 1468  (40.6):  73%|  | 1467/2000 [21:18<07:06,  1.25it/s]\u001b[A\n",
      "Average Metric: 596 / 1468  (40.6):  73%|  | 1468/2000 [21:18<12:44,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 596 / 1469  (40.6):  73%|  | 1468/2000 [21:18<12:44,  1.44s/it]\u001b[A\n",
      "Average Metric: 596 / 1469  (40.6):  73%|  | 1469/2000 [21:18<10:25,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'poettr'? A: accept B: potter C: webcast D: updated\n",
      "Answer: B: potter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 597 / 1470  (40.6):  73%|  | 1469/2000 [21:19<10:25,  1.18s/it]\u001b[A\n",
      "Average Metric: 597 / 1470  (40.6):  74%|  | 1470/2000 [21:19<08:56,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ueurcnsed' represent when unscrambled? A: injured B: hoping C: unsecured D: democrat\n",
      "Answer: D: democrat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'revsere'? A: iraqi B: reverse C: clue D: impossible\n",
      "Answer: B: reverse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 597 / 1471  (40.6):  74%|  | 1470/2000 [21:22<08:56,  1.01s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 597 / 1471  (40.6):  74%|  | 1471/2000 [21:22<14:57,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fotry' to form the correct word. A: forty B: predict C: funny D: explanation\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cosenlos'. A: consoles B: arrange C: wars D: illustrations\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 598 / 1472  (40.6):  74%|  | 1471/2000 [21:23<14:57,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 598 / 1472  (40.6):  74%|  | 1472/2000 [21:23<14:01,  1.59s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 599 / 1473  (40.7):  74%|  | 1472/2000 [21:24<14:01,  1.59s/it]\u001b[A\n",
      "Average Metric: 599 / 1473  (40.7):  74%|  | 1473/2000 [21:24<11:55,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 600 / 1474  (40.7):  74%|  | 1473/2000 [21:25<11:55,  1.36s/it]\u001b[A\n",
      "Average Metric: 600 / 1474  (40.7):  74%|  | 1474/2000 [21:25<10:51,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 600 / 1475  (40.7):  74%|  | 1474/2000 [21:26<10:51,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 600 / 1475  (40.7):  74%|  | 1475/2000 [21:26<08:43,  1.00it/s]\u001b[A\n",
      "Average Metric: 600 / 1476  (40.7):  74%|  | 1475/2000 [21:26<08:43,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 600 / 1476  (40.7):  74%|  | 1476/2000 [21:26<06:27,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gsetus' to form the correct word. A: contribute B: guests C: blowjobs D: roman\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 600 / 1477  (40.6):  74%|  | 1476/2000 [21:28<06:27,  1.35it/s]\u001b[A\n",
      "Average Metric: 600 / 1477  (40.6):  74%|  | 1477/2000 [21:28<10:03,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 601 / 1478  (40.7):  74%|  | 1477/2000 [21:29<10:03,  1.15s/it]\u001b[A\n",
      "Average Metric: 601 / 1478  (40.7):  74%|  | 1478/2000 [21:29<08:47,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'flirdoa'. A: samuel B: decent C: florida D: greenhouse\n",
      "Answer: D: greenhouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 601 / 1479  (40.6):  74%|  | 1478/2000 [21:30<08:47,  1.01s/it]\u001b[A\n",
      "Average Metric: 601 / 1479  (40.6):  74%|  | 1479/2000 [21:30<08:56,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aacfrin' to form the correct word. A: african B: systematic C: mode D: moderate\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 601 / 1480  (40.6):  74%|  | 1479/2000 [21:30<08:56,  1.03s/it]\u001b[A\n",
      "Average Metric: 601 / 1480  (40.6):  74%|  | 1480/2000 [21:30<07:36,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eupraeon' represent when unscrambled? A: european B: plated C: oriental D: school\n",
      "Answer: A: european\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'brduen'. A: criminal B: secretariat C: burden D: cracks\n",
      "Answer: A: criminal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'innndeeepdt' represent when unscrambled? A: aimed B: independent C: mesh D: dimensions\n",
      "Answer: D: dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 602 / 1481  (40.6):  74%|  | 1480/2000 [21:33<07:36,  1.14it/s]\u001b[A\n",
      "Average Metric: 602 / 1481  (40.6):  74%|  | 1481/2000 [21:33<12:17,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 603 / 1482  (40.7):  74%|  | 1481/2000 [21:34<12:17,  1.42s/it]\u001b[A\n",
      "Average Metric: 603 / 1482  (40.7):  74%|  | 1482/2000 [21:34<12:05,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hladne'? A: sediment B: todd C: latter D: handle\n",
      "Answer: B: todd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iiadstrunl'. A: bubble B: industrial C: flood D: pubmed\n",
      "Answer: D: pubmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'amuutn'. A: creative B: vacuum C: autumn D: cuisine\n",
      "Answer: D: cuisine\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'siuotprpve'? A: transsexual B: alarms C: supportive D: visitors\n",
      "Answer: D: visitors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 603 / 1483  (40.7):  74%|  | 1482/2000 [21:36<12:05,  1.40s/it]\u001b[A\n",
      "Average Metric: 603 / 1483  (40.7):  74%|  | 1483/2000 [21:36<13:35,  1.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'seewt' represent when unscrambled? A: slovakia B: panties C: barry D: sweet\n",
      "Answer: D: sweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 1484  (40.7):  74%|  | 1483/2000 [21:38<13:35,  1.58s/it]\u001b[A\n",
      "Average Metric: 604 / 1484  (40.7):  74%|  | 1484/2000 [21:38<13:11,  1.53s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 1485  (40.7):  74%|  | 1484/2000 [21:38<13:11,  1.53s/it]\u001b[A\n",
      "Average Metric: 604 / 1485  (40.7):  74%|  | 1485/2000 [21:38<10:06,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sgitraht' to form the correct word. A: straight B: tuesday C: scheduling D: series\n",
      "Answer: D: series\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 604 / 1486  (40.6):  74%|  | 1485/2000 [21:39<10:06,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 604 / 1486  (40.6):  74%|  | 1486/2000 [21:39<08:52,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'plao'? A: northern B: palo C: genus D: algebra\n",
      "Answer: B: paloAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cmmiot'. A: hitachi B: backing C: commit D: except\n",
      "Answer: D: except\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cliavn' to form the correct word. A: blank B: calvin C: meeting D: eliminated\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'serhpehd' represent when unscrambled? A: back B: reward C: masks D: shepherd\n",
      "Answer: D: shepherd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 1487  (40.7):  74%|  | 1486/2000 [21:42<08:52,  1.04s/it]\u001b[A\n",
      "Average Metric: 605 / 1487  (40.7):  74%|  | 1487/2000 [21:42<15:18,  1.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 1488  (40.7):  74%|  | 1487/2000 [21:43<15:18,  1.79s/it]\u001b[A\n",
      "Average Metric: 605 / 1488  (40.7):  74%|  | 1488/2000 [21:43<11:30,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sfaari' to form the correct word. A: charles B: approx C: safari D: kodak\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 1489  (40.6):  74%|  | 1488/2000 [21:43<11:30,  1.35s/it]\u001b[A\n",
      "Average Metric: 605 / 1489  (40.6):  74%|  | 1489/2000 [21:43<09:00,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cunot'? A: continuous B: clearing C: count D: locally\n",
      "Answer: D: locally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 1490  (40.7):  74%|  | 1489/2000 [21:44<09:00,  1.06s/it]\u001b[A\n",
      "Average Metric: 606 / 1490  (40.7):  74%|  | 1490/2000 [21:44<07:41,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 1491  (40.6):  74%|  | 1490/2000 [21:44<07:41,  1.10it/s]\u001b[A\n",
      "Average Metric: 606 / 1491  (40.6):  75%|  | 1491/2000 [21:44<06:01,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 1492  (40.6):  75%|  | 1491/2000 [21:45<06:01,  1.41it/s]\u001b[A\n",
      "Average Metric: 606 / 1492  (40.6):  75%|  | 1492/2000 [21:45<08:24,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rnad'? A: houston B: aggressive C: rand D: feeling\n",
      "Answer: D: feeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 607 / 1493  (40.7):  75%|  | 1492/2000 [21:46<08:24,  1.01it/s]\u001b[A\n",
      "Average Metric: 607 / 1493  (40.7):  75%|  | 1493/2000 [21:46<06:52,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fweer' to form the correct word. A: fewer B: grain C: infinite D: brook\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mlaotprieton' to form the correct word. A: auditing B: raise C: varying D: metropolitan\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 607 / 1494  (40.6):  75%|  | 1493/2000 [21:47<06:52,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 607 / 1494  (40.6):  75%|  | 1494/2000 [21:47<07:50,  1.08it/s]\u001b[A\n",
      "Average Metric: 608 / 1495  (40.7):  75%|  | 1494/2000 [21:47<07:50,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mree'. A: mere B: jessica C: control D: athlon\n",
      "Answer: D: athlon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'toreapml'? A: deputy B: find C: temporal D: elimination\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 609 / 1496  (40.7):  75%|  | 1495/2000 [21:50<07:49,  1.08it/s]\u001b[A\n",
      "Average Metric: 609 / 1496  (40.7):  75%|  | 1496/2000 [21:50<09:03,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'kegdwlnoe' represent when unscrambled? A: yale B: bingo C: knowledge D: edited\n",
      "Answer: D: edited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'berhancs' to form the correct word. A: notice B: float C: branches D: working\n",
      "Answer: D"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 610 / 1497  (40.7):  75%|  | 1496/2000 [21:52<09:03,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 610 / 1497  (40.7):  75%|  | 1497/2000 [21:52<11:24,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'eatluvaing'? A: battlefield B: wars C: evaluating D: depend\n",
      "Answer: D: depend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 611 / 1498  (40.8):  75%|  | 1497/2000 [21:53<11:24,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fxtuiers' to form the correct word. A: traffic B: assault C: fixtures D: respond\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 611 / 1498  (40.8):  75%|  | 1498/2000 [21:53<11:25,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 612 / 1499  (40.8):  75%|  | 1498/2000 [21:54<11:25,  1.36s/it]\u001b[A\n",
      "Average Metric: 612 / 1499  (40.8):  75%|  | 1499/2000 [21:54<09:12,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cianorla'? A: sandwich B: electron C: carolina D: collected\n",
      "Answer: D: collected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1500  (40.9):  75%|  | 1499/2000 [21:54<09:12,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1500  (40.9):  75%|  | 1500/2000 [21:54<08:02,  1.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peirottncg'. A: protecting B: fold C: surveys D: identify\n",
      "Answer: D: identify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'snas'. A: friends B: sans C: expectations D: relevance\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'spcheees' to form the correct word. A: lights B: proper C: hartford D: speeches\n",
      "Answer: D: speeches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1501  (40.8):  75%|  | 1500/2000 [21:56<08:02,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 613 / 1501  (40.8):  75%|  | 1501/2000 [21:56<09:32,  1.15s/it]\u001b[A\n",
      "Average Metric: 613 / 1502  (40.8):  75%|  | 1501/2000 [21:57<09:32,  1.15s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1502  (40.8):  75%|  | 1502/2000 [21:57<08:52,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1503  (40.8):  75%|  | 1502/2000 [21:58<08:52,  1.07s/it]\u001b[A\n",
      "Average Metric: 613 / 1503  (40.8):  75%|  | 1503/2000 [21:58<09:13,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1504  (40.8):  75%|  | 1503/2000 [21:59<09:13,  1.11s/it]\u001b[A\n",
      "Average Metric: 613 / 1504  (40.8):  75%|  | 1504/2000 [21:59<08:51,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ittisaollurn' represent when unscrambled? A: consumption B: taxes C: prefer D: illustration\n",
      "Answer: A: consumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 613 / 1505  (40.7):  75%|  | 1504/2000 [21:59<08:51,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 613 / 1505  (40.7):  75%|  | 1505/2000 [21:59<06:34,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'puopp' to form the correct word. A: popup B: partly C: architects D: kills\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hunragy' to form the correct word. A: hungary B: optimization C: condos D: stroke\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1506  (40.7):  75%|  | 1505/2000 [22:00<06:34,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 613 / 1506  (40.7):  75%|  | 1506/2000 [22:00<07:54,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rreushiebfd'. A: refurbished B: trim C: write D: move\n",
      "Answer: D: move\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rngares' to form the correct word. A: purpose B: guides C: rangers D: glasgow\n",
      "Answer: DAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'asissts'. A: appliances B: kitchen C: pete D: assists\n",
      "Answer: D: assists\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which planet is closest to the sun? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: Which country invented the light bulb? A: Germany B: United States C: Italy D: France\n",
      "Answer: B: United States\n",
      "\n",
      "Question: What is the\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cnlooy' represent when unscrambled? A: amateur B: accounting C: colony D: heart\n",
      "Answer: D: heart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1507  (40.7):  75%|  | 1506/2000 [22:03<07:54,  1.04it/s]\u001b[A\n",
      "Average Metric: 613 / 1507  (40.7):  75%|  | 1507/2000 [22:03<12:28,  1.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anitlrgon'. A: thinkpad B: arlington C: windows D: wilderness\n",
      "Answer: D: wilderness\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'caameinottnd'. A: contaminated B: supervisors C: portrait D: agencies\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'martnoey' to form the correct word. A: conversation B: monetary C: regression D: circumstances\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1508  (40.6):  75%|  | 1507/2000 [22:05<12:28,  1.52s/it]\u001b[A\n",
      "Average Metric: 613 / 1508  (40.6):  75%|  | 1508/2000 [22:05<13:39,  1.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hloets' represent when unscrambled? A: hotels B: summaries C: frost D: improved\n",
      "Answer: A: hotels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1509  (40.6):  75%|  | 1508/2000 [22:06<13:39,  1.67s/it]\u001b[A\n",
      "Average Metric: 613 / 1509  (40.6):  75%|  | 1509/2000 [22:06<11:27,  1.40s/it]\u001b[A\n",
      "Average Metric: 614 / 1510  (40.7):  75%|  | 1509/2000 [22:06<11:27,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1511  (40.6):  76%|  | 1510/2000 [22:06<11:26,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1511  (40.6):  76%|  | 1511/2000 [22:06<06:45,  1.20it/s]\u001b[A\n",
      "Average Metric: 614 / 1512  (40.6):  76%|  | 1511/2000 [22:07<06:45,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1512  (40.6):  76%|  | 1512/2000 [22:07<07:21,  1.10it/s]\u001b[A\n",
      "Average Metric: 614 / 1513  (40.6):  76%|  | 1512/2000 [22:07<07:21,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 614 / 1514  (40.6):  76%|  | 1513/2000 [22:08<07:21,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1514  (40.6):  76%|  | 1514/2000 [22:08<05:13,  1.55it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 615 / 1515  (40.6):  76%|  | 1514/2000 [22:08<05:13,  1.55it/s]\u001b[A\n",
      "Average Metric: 615 / 1515  (40.6):  76%|  | 1515/2000 [22:08<04:27,  1.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fcaed' represent when unscrambled? A: distribute B: pissing C: faced D: phentermine\n",
      "Answer: A: distribute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lnae'? A: lane B: accomplish C: household D: bath\n",
      "Answer: D: bath\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ofroxd' represent when unscrambled? A: oxford B: jackets C: ncaa D: boxed\n",
      "Answer: A: oxford\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 615 / 1516  (40.6):  76%|  | 1515/2000 [22:10<04:27,  1.81it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 615 / 1516  (40.6):  76%|  | 1516/2000 [22:10<06:20,  1.27it/s]\u001b[A\n",
      "Average Metric: 616 / 1517  (40.6):  76%|  | 1516/2000 [22:10<06:20,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 616 / 1517  (40.6):  76%|  | 1517/2000 [22:10<05:58,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 616 / 1518  (40.6):  76%|  | 1517/2000 [22:12<05:58,  1.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'durg'. A: filters B: reader C: drug D: cent\n",
      "Answer: C: drug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 616 / 1518  (40.6):  76%|  | 1518/2000 [22:12<08:46,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'psoreimd' to form the correct word. A: dolls B: disagree C: security D: promised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 617 / 1519  (40.6):  76%|  | 1518/2000 [22:17<08:46,  1.09s/it]\u001b[A\n",
      "Average Metric: 617 / 1519  (40.6):  76%|  | 1519/2000 [22:17<15:45,  1.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'massttasheucs'. A: dildos B: dies C: massachusetts D: easy\n",
      "Answer: d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'clriecs' represent when unscrambled? A: circles B: website C: sheep D: sight\n",
      "Answer: D: sight\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'analittc'? A: atlantic B: atlanta C: note D: restore\n",
      "Answer: D: restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 617 / 1520  (40.6):  76%|  | 1519/2000 [22:19<15:45,  1.96s/it]\u001b[A\n",
      "Average Metric: 617 / 1520  (40.6):  76%|  | 1520/2000 [22:19<16:05,  2.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 618 / 1521  (40.6):  76%|  | 1520/2000 [22:19<16:05,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 618 / 1521  (40.6):  76%|  | 1521/2000 [22:19<12:27,  1.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 619 / 1522  (40.7):  76%|  | 1521/2000 [22:21<12:27,  1.56s/it]\u001b[A\n",
      "Average Metric: 619 / 1522  (40.7):  76%|  | 1522/2000 [22:21<12:10,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 619 / 1523  (40.6):  76%|  | 1522/2000 [22:21<12:10,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 619 / 1523  (40.6):  76%|  | 1523/2000 [22:21<09:48,  1.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cplioxemty' to form the correct word. A: variant B: journals C: complexity D: glen\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 619 / 1524  (40.6):  76%|  | 1523/2000 [22:21<09:48,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 619 / 1524  (40.6):  76%|  | 1524/2000 [22:21<07:26,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 620 / 1525  (40.7):  76%|  | 1524/2000 [22:22<07:26,  1.07it/s]\u001b[A\n",
      "Average Metric: 620 / 1525  (40.7):  76%|  | 1525/2000 [22:22<06:40,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'weed'? A: weed B: internationally C: amateur D: inventory\n",
      "Answer: D: inventory\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'valibe'. A: viable B: char C: assisted D: movie\n",
      "Answer: A: viable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 621 / 1526  (40.7):  76%|  | 1525/2000 [22:23<06:40,  1.19it/s]\u001b[A\n",
      "Average Metric: 621 / 1526  (40.7):  76%|  | 1526/2000 [22:23<07:07,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cignoinufrg' represent when unscrambled? A: controllers B: configuring C: quit D: though\n",
      "Answer: D: though\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'drak'? A: dark B: numerical C: cocks D: observation\n",
      "Answer: A: darkAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'radny' represent when unscrambled? A: gamecube B: recipes C: randy D: dennis\n",
      "Answer: A: gamecube\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lebrial' represent when unscrambled? A: ideas B: sparc C: interaction D: liberal\n",
      "Answer: D: liberal\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'femrad'. A: affiliated B: configuration C: framed D: endless\n",
      "Answer: D: endless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 622 / 1527  (40.7):  76%|  | 1526/2000 [22:27<07:07,  1.11it/s]\u001b[A\n",
      "Average Metric: 622 / 1527  (40.7):  76%|  | 1527/2000 [22:27<15:08,  1.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cntenaiod' represent when unscrambled? A: extends B: finds C: principal D: contained\n",
      "Answer: D: contained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 622 / 1528  (40.7):  76%|  | 1527/2000 [22:28<15:08,  1.92s/it]\u001b[A\n",
      "Average Metric: 622 / 1528  (40.7):  76%|  | 1528/2000 [22:28<12:20,  1.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 623 / 1529  (40.7):  76%|  | 1528/2000 [22:29<12:20,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 623 / 1529  (40.7):  76%|  | 1529/2000 [22:29<10:09,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 623 / 1530  (40.7):  76%|  | 1529/2000 [22:29<10:09,  1.29s/it]\u001b[A\n",
      "Average Metric: 623 / 1530  (40.7):  76%|  | 1530/2000 [22:29<07:45,  1.01it/s]\u001b[A\n",
      "Average Metric: 624 / 1531  (40.8):  76%|  | 1530/2000 [22:29<07:45,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 624 / 1531  (40.8):  77%|  | 1531/2000 [22:29<05:51,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ceerk'? A: seek B: affairs C: midlands D: creek\n",
      "Answer: creek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fctas' represent when unscrambled? A: forwarded B: facts C: lender D: clocks\n",
      "Answer: A: forwarded\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bnealkt'. A: belkin B: blanket C: connectors D: caribbean\n",
      "Answer: D: caribbean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 1532  (40.8):  77%|  | 1531/2000 [22:31<05:51,  1.34it/s]\u001b[A\n",
      "Average Metric: 625 / 1532  (40.8):  77%|  | 1532/2000 [22:31<08:32,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 625 / 1533  (40.8):  77%|  | 1532/2000 [22:31<08:32,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 1534  (40.7):  77%|  | 1533/2000 [22:31<08:31,  1.09s/it]\u001b[A\n",
      "Average Metric: 625 / 1534  (40.7):  77%|  | 1534/2000 [22:31<05:16,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rduece'? A: client B: reduce C: longer D: kill\n",
      "Answer: B: reduce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 1535  (40.7):  77%|  | 1534/2000 [22:32<05:16,  1.47it/s]\u001b[A\n",
      "Average Metric: 625 / 1535  (40.7):  77%|  | 1535/2000 [22:32<05:53,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1536  (40.8):  77%|  | 1535/2000 [22:33<05:53,  1.32it/s]\u001b[A\n",
      "Average Metric: 626 / 1536  (40.8):  77%|  | 1536/2000 [22:33<05:50,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'atshma' to form the correct word. A: resolution B: asthma C: children D: phpbb\n",
      "Answer: B: asthma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 626 / 1537  (40.7):  77%|  | 1536/2000 [22:35<05:50,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 626 / 1537  (40.7):  77%|  | 1537/2000 [22:35<08:13,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cliitooan' represent when unscrambled? A: coalition B: dirty C: guitars D: charges\n",
      "Answer: A: coalition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aobrr' to form the correct word. A: discounts B: researcher C: arbor D: situated\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'retoprs' to form the correct word. A: according B: allowed C: reports D: combined\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1538  (40.7):  77%|  | 1537/2000 [22:39<08:13,  1.07s/it]\u001b[A\n",
      "Average Metric: 626 / 1538  (40.7):  77%|  | 1538/2000 [22:39<15:05,  1.96s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1539  (40.7):  77%|  | 1538/2000 [22:39<15:05,  1.96s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1540  (40.6):  77%|  | 1539/2000 [22:40<15:03,  1.96s/it]\u001b[A\n",
      "Average Metric: 626 / 1540  (40.6):  77%|  | 1540/2000 [22:40<09:02,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 626 / 1541  (40.6):  77%|  | 1540/2000 [22:40<09:02,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 626 / 1541  (40.6):  77%|  | 1541/2000 [22:40<07:36,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dleay'. A: tools B: screw C: handmade D: delay\n",
      "Answer: D: delay\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stie'. A: covering B: researcher C: khan D: site\n",
      "Answer: A: covering\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rael'? A: real B: scripts C: pretty D: innocent\n",
      "Answer: real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 627 / 1542  (40.7):  77%|  | 1541/2000 [22:41<07:36,  1.01it/s]\u001b[A\n",
      "Average Metric: 627 / 1542  (40.7):  77%|  | 1542/2000 [22:41<07:20,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 627 / 1543  (40.6):  77%|  | 1542/2000 [22:41<07:20,  1.04it/s]\u001b[A\n",
      "Average Metric: 627 / 1543  (40.6):  77%|  | 1543/2000 [22:41<06:06,  1.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'alriutsaa'. A: pediatric B: bent C: australia D: podcast\n",
      "Answer: A: pediatric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 1544  (40.7):  77%|  | 1543/2000 [22:42<06:06,  1.25it/s]\u001b[A\n",
      "Average Metric: 628 / 1544  (40.7):  77%|  | 1544/2000 [22:42<06:14,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 1545  (40.6):  77%|  | 1544/2000 [22:43<06:14,  1.22it/s]\u001b[A\n",
      "Average Metric: 628 / 1545  (40.6):  77%|  | 1545/2000 [22:43<05:29,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 1546  (40.6):  77%|  | 1545/2000 [22:43<05:29,  1.38it/s]\u001b[A\n",
      "Average Metric: 628 / 1546  (40.6):  77%|  | 1546/2000 [22:43<04:29,  1.69it/s]\u001b[A\n",
      "Average Metric: 629 / 1547  (40.7):  77%|  | 1546/2000 [22:44<04:29,  1.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 629 / 1547  (40.7):  77%|  | 1547/2000 [22:44<04:37,  1.63it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cdaseiilfss'. A: coaches B: classifieds C: floating D: villages\n",
      "Answer: C: floating\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'srvee'. A: belize B: ought C: attend D: serve\n",
      "Answer: D: serve\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'waogn' to form the correct word. A: pushed B: seventh C: wagon D: adsl\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lrbotaraoy' represent when unscrambled? A: laboratory B: keep C: adjusted D: debates\n",
      "Answer: A: laboratory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sehpad'. A: serbia B: threshold C: shaped D: boyfriend\n",
      "Answer: A: serbia\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'piaentt'. A: patient B: tubes C: heads D: attachments\n",
      "Answer: A: patient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vgteearain' represent when unscrambled? A: accordingly B: newsletters C: vegetarian D: commented\n",
      "Answer: D: commentedAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'kpbs'? A: kbps B: shuttle C: album D: beatles\n",
      "Answer: kbps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1548  (40.6):  77%|  | 1547/2000 [22:49<04:37,  1.63it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1548  (40.6):  77%|  | 1548/2000 [22:49<14:51,  1.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 629 / 1549  (40.6):  77%|  | 1548/2000 [22:50<14:51,  1.97s/it]\u001b[A\n",
      "Average Metric: 629 / 1549  (40.6):  77%|  | 1549/2000 [22:50<12:17,  1.64s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1550  (40.6):  77%|  | 1549/2000 [22:50<12:17,  1.64s/it]\u001b[A\n",
      "Average Metric: 629 / 1550  (40.6):  78%|  | 1550/2000 [22:50<09:36,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 629 / 1551  (40.6):  78%|  | 1550/2000 [22:50<09:36,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1552  (40.5):  78%|  | 1551/2000 [22:50<09:34,  1.28s/it]\u001b[A\n",
      "Average Metric: 629 / 1552  (40.5):  78%|  | 1552/2000 [22:50<05:33,  1.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1553  (40.5):  78%|  | 1552/2000 [22:51<05:33,  1.34it/s]\u001b[A\n",
      "Average Metric: 629 / 1553  (40.5):  78%|  | 1553/2000 [22:51<04:32,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'setnueqlbusy' to form the correct word. A: step B: subsequently C: start D: furnishings\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1554  (40.5):  78%|  | 1553/2000 [22:52<04:32,  1.64it/s]\u001b[A\n",
      "Average Metric: 629 / 1554  (40.5):  78%|  | 1554/2000 [22:52<06:14,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1555  (40.5):  78%|  | 1554/2000 [22:53<06:14,  1.19it/s]\u001b[A\n",
      "Average Metric: 629 / 1555  (40.5):  78%|  | 1555/2000 [22:53<05:31,  1.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1556  (40.4):  78%|  | 1555/2000 [22:53<05:31,  1.34it/s]\u001b[A\n",
      "Average Metric: 629 / 1556  (40.4):  78%|  | 1556/2000 [22:53<04:18,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1557  (40.4):  78%|  | 1556/2000 [22:53<04:18,  1.72it/s]\u001b[A\n",
      "Average Metric: 629 / 1557  (40.4):  78%|  | 1557/2000 [22:53<03:26,  2.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ltifmiee'. A: lifetime B: segments C: brutal D: arcade\n",
      "Answer: D: arcade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 630 / 1558  (40.4):  78%|  | 1557/2000 [22:53<03:26,  2.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sroce'. A: score B: halo C: fundamental D: vegetarian\n",
      "Answer: A: score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 630 / 1559  (40.4):  78%|  | 1558/2000 [22:54<03:25,  2.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 630 / 1559  (40.4):  78%|  | 1559/2000 [22:54<03:07,  2.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 630 / 1560  (40.4):  78%|  | 1559/2000 [22:54<03:07,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 631 / 1561  (40.4):  78%|  | 1560/2000 [22:54<03:07,  2.35it/s]\u001b[A\n",
      "Average Metric: 631 / 1561  (40.4):  78%|  | 1561/2000 [22:54<02:11,  3.35it/s]\u001b[A\n",
      "Average Metric: 631 / 1562  (40.4):  78%|  | 1561/2000 [22:54<02:11,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 631 / 1562  (40.4):  78%|  | 1562/2000 [22:54<01:55,  3.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'flians'. A: ports B: pathway C: vietnamese D: finals\n",
      "Answer: D: finals\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'derefred'. A: assume B: query C: sure D: deferred\n",
      "Answer: D: deferred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 631 / 1563  (40.4):  78%|  | 1562/2000 [23:00<01:55,  3.80it/s]\u001b[A\n",
      "Average Metric: 631 / 1563  (40.4):  78%|  | 1563/2000 [23:00<11:43,  1.61s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 631 / 1564  (40.3):  78%|  | 1563/2000 [23:00<11:43,  1.61s/it]\u001b[A\n",
      "Average Metric: 631 / 1564  (40.3):  78%|  | 1564/2000 [23:00<09:09,  1.26s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 631 / 1565  (40.3):  78%|  | 1564/2000 [23:00<09:09,  1.26s/it]\u001b[A\n",
      "Average Metric: 631 / 1565  (40.3):  78%|  | 1565/2000 [23:00<07:08,  1.02it/s]\u001b[A\n",
      "Average Metric: 631 / 1566  (40.3):  78%|  | 1565/2000 [23:00<07:08,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ecnveide'? A: parent B: pays C: entering D: evidence\n",
      "Answer: D: evidence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 632 / 1567  (40.3):  78%|  | 1566/2000 [23:01<07:07,  1.02it/s]\u001b[A\n",
      "Average Metric: 632 / 1567  (40.3):  78%|  | 1567/2000 [23:01<05:18,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 632 / 1568  (40.3):  78%|  | 1567/2000 [23:01<05:18,  1.36it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 632 / 1569  (40.3):  78%|  | 1568/2000 [23:01<05:17,  1.36it/s]\u001b[A\n",
      "Average Metric: 632 / 1569  (40.3):  78%|  | 1569/2000 [23:01<03:31,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'renvaecle' represent when unscrambled? A: relevance B: appropriately C: april D: groundwater\n",
      "Answer: A: relevance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 633 / 1570  (40.3):  78%|  | 1569/2000 [23:02<03:31,  2.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 633 / 1570  (40.3):  78%|  | 1570/2000 [23:02<04:13,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 633 / 1571  (40.3):  78%|  | 1570/2000 [23:03<04:13,  1.69it/s]\u001b[A\n",
      "Average Metric: 633 / 1571  (40.3):  79%|  | 1571/2000 [23:03<03:34,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 633 / 1572  (40.3):  79%|  | 1571/2000 [23:04<03:34,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'srbuaubn'. A: vivid B: utah C: queens D: suburban\n",
      "Answer: D: suburban\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 633 / 1572  (40.3):  79%|  | 1572/2000 [23:04<04:21,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aodmbssaar'? A: ambassador B: expired C: webmasters D: bedrooms\n",
      "Answer: B: expired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 634 / 1573  (40.3):  79%|  | 1572/2000 [23:04<04:21,  1.64it/s]\u001b[A\n",
      "Average Metric: 634 / 1573  (40.3):  79%|  | 1573/2000 [23:04<04:48,  1.48it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 634 / 1574  (40.3):  79%|  | 1573/2000 [23:05<04:48,  1.48it/s]\u001b[A\n",
      "Average Metric: 634 / 1574  (40.3):  79%|  | 1574/2000 [23:05<03:50,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 634 / 1575  (40.3):  79%|  | 1574/2000 [23:08<03:50,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 634 / 1575  (40.3):  79%|  | 1575/2000 [23:08<09:28,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 635 / 1576  (40.3):  79%|  | 1575/2000 [23:11<09:28,  1.34s/it]\u001b[A\n",
      "Average Metric: 635 / 1576  (40.3):  79%|  | 1576/2000 [23:11<13:22,  1.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 1577  (40.3):  79%|  | 1576/2000 [23:12<13:22,  1.89s/it]\u001b[A\n",
      "Average Metric: 636 / 1577  (40.3):  79%|  | 1577/2000 [23:12<10:24,  1.48s/it]\u001b[A\n",
      "Average Metric: 636 / 1578  (40.3):  79%|  | 1577/2000 [23:12<10:24,  1.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 636 / 1578  (40.3):  79%|  | 1578/2000 [23:12<08:15,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 1579  (40.3):  79%|  | 1578/2000 [23:12<08:15,  1.17s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 1580  (40.3):  79%|  | 1579/2000 [23:12<08:14,  1.17s/it]\u001b[A\n",
      "Average Metric: 636 / 1580  (40.3):  79%|  | 1580/2000 [23:12<04:41,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 637 / 1581  (40.3):  79%|  | 1580/2000 [23:13<04:41,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 637 / 1581  (40.3):  79%|  | 1581/2000 [23:13<05:30,  1.27it/s]\u001b[A\n",
      "Average Metric: 637 / 1582  (40.3):  79%|  | 1581/2000 [23:14<05:30,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 637 / 1582  (40.3):  79%|  | 1582/2000 [23:14<05:24,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 637 / 1583  (40.2):  79%|  | 1582/2000 [23:18<05:24,  1.29it/s]\u001b[A\n",
      "Average Metric: 637 / 1583  (40.2):  79%|  | 1583/2000 [23:18<11:15,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 638 / 1584  (40.3):  79%|  | 1583/2000 [23:19<11:15,  1.62s/it]\u001b[A\n",
      "Average Metric: 638 / 1584  (40.3):  79%|  | 1584/2000 [23:19<09:01,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 639 / 1585  (40.3):  79%|  | 1584/2000 [23:19<09:01,  1.30s/it]\u001b[A\n",
      "Average Metric: 639 / 1585  (40.3):  79%|  | 1585/2000 [23:19<07:45,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 640 / 1586  (40.4):  79%|  | 1585/2000 [23:19<07:45,  1.12s/it]\u001b[A\n",
      "Average Metric: 640 / 1586  (40.4):  79%|  | 1586/2000 [23:19<05:45,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 640 / 1587  (40.3):  79%|  | 1586/2000 [23:20<05:45,  1.20it/s]\u001b[A\n",
      "Average Metric: 640 / 1587  (40.3):  79%|  | 1587/2000 [23:20<05:27,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 641 / 1588  (40.4):  79%|  | 1587/2000 [23:20<05:27,  1.26it/s]\u001b[A\n",
      "Average Metric: 641 / 1588  (40.4):  79%|  | 1588/2000 [23:20<04:19,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 642 / 1589  (40.4):  79%|  | 1588/2000 [23:21<04:19,  1.59it/s]\u001b[A\n",
      "Average Metric: 642 / 1589  (40.4):  79%|  | 1589/2000 [23:21<03:38,  1.88it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 642 / 1590  (40.4):  79%|  | 1589/2000 [23:21<03:38,  1.88it/s]\u001b[A\n",
      "Average Metric: 643 / 1591  (40.4):  80%|  | 1590/2000 [23:21<03:37,  1.88it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 643 / 1591  (40.4):  80%|  | 1591/2000 [23:21<02:10,  3.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 644 / 1592  (40.5):  80%|  | 1591/2000 [23:21<02:10,  3.13it/s]\u001b[A\n",
      "Average Metric: 644 / 1592  (40.5):  80%|  | 1592/2000 [23:21<02:20,  2.90it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 644 / 1593  (40.4):  80%|  | 1592/2000 [23:21<02:20,  2.90it/s]\u001b[A\n",
      "Average Metric: 644 / 1593  (40.4):  80%|  | 1593/2000 [23:21<02:21,  2.87it/s]\u001b[A\n",
      "Average Metric: 645 / 1594  (40.5):  80%|  | 1593/2000 [23:22<02:21,  2.87it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 645 / 1594  (40.5):  80%|  | 1594/2000 [23:22<03:24,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 645 / 1595  (40.4):  80%|  | 1594/2000 [23:22<03:24,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 645 / 1596  (40.4):  80%|  | 1595/2000 [23:23<03:24,  1.98it/s]\u001b[A\n",
      "Average Metric: 645 / 1596  (40.4):  80%|  | 1596/2000 [23:23<03:02,  2.22it/s]\u001b[A\n",
      "Average Metric: 646 / 1597  (40.5):  80%|  | 1596/2000 [23:23<03:02,  2.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 646 / 1597  (40.5):  80%|  | 1597/2000 [23:23<02:34,  2.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 646 / 1598  (40.4):  80%|  | 1597/2000 [23:23<02:34,  2.61it/s]\u001b[A\n",
      "Average Metric: 646 / 1599  (40.4):  80%|  | 1598/2000 [23:27<02:33,  2.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 646 / 1599  (40.4):  80%|  | 1599/2000 [23:27<06:24,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 646 / 1600  (40.4):  80%|  | 1599/2000 [23:29<06:24,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 646 / 1600  (40.4):  80%|  | 1600/2000 [23:29<08:40,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 647 / 1601  (40.4):  80%|  | 1600/2000 [23:29<08:40,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 647 / 1602  (40.4):  80%|  | 1601/2000 [23:30<08:39,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 647 / 1602  (40.4):  80%|  | 1602/2000 [23:30<06:14,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 647 / 1603  (40.4):  80%|  | 1602/2000 [23:31<06:14,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 647 / 1603  (40.4):  80%|  | 1603/2000 [23:31<05:27,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 648 / 1604  (40.4):  80%|  | 1603/2000 [23:31<05:27,  1.21it/s]\u001b[A\n",
      "Average Metric: 648 / 1604  (40.4):  80%|  | 1604/2000 [23:31<04:26,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gstereat'? A: belle B: shoot C: driver D: greatest\n",
      "Answer: D: greatest\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which planet is closest to the sun? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: elephant B: whale C: bear D: giraffe\n",
      "Answer: B: whale\n",
      "\n",
      "Question: Which country invented the light bulb? A: Germany B: United States C: Italy D: France\n",
      "Answer: A: Germany\n",
      "\n",
      "Question: What is the smallest country in the world? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 648 / 1605  (40.4):  80%|  | 1604/2000 [23:32<04:26,  1.49it/s]\u001b[A\n",
      "Average Metric: 648 / 1605  (40.4):  80%|  | 1605/2000 [23:32<04:48,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 648 / 1606  (40.3):  80%|  | 1605/2000 [23:39<04:48,  1.37it/s]\u001b[A\n",
      "Average Metric: 648 / 1606  (40.3):  80%|  | 1606/2000 [23:39<15:31,  2.37s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 649 / 1607  (40.4):  80%|  | 1606/2000 [23:39<15:31,  2.37s/it]\u001b[A\n",
      "Average Metric: 649 / 1607  (40.4):  80%|  | 1607/2000 [23:39<12:02,  1.84s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 650 / 1608  (40.4):  80%|  | 1607/2000 [23:39<12:02,  1.84s/it]\u001b[A\n",
      "Average Metric: 650 / 1608  (40.4):  80%|  | 1608/2000 [23:39<09:09,  1.40s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 650 / 1609  (40.4):  80%|  | 1608/2000 [23:39<09:09,  1.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 650 / 1610  (40.4):  80%|  | 1609/2000 [23:40<09:07,  1.40s/it]\u001b[A\n",
      "Average Metric: 650 / 1610  (40.4):  80%|  | 1610/2000 [23:40<06:44,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 651 / 1611  (40.4):  80%|  | 1610/2000 [23:41<06:44,  1.04s/it]\u001b[A\n",
      "Average Metric: 651 / 1611  (40.4):  81%|  | 1611/2000 [23:41<06:12,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 651 / 1612  (40.4):  81%|  | 1611/2000 [23:42<06:12,  1.04it/s]\u001b[A\n",
      "Average Metric: 651 / 1612  (40.4):  81%|  | 1612/2000 [23:42<05:10,  1.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 652 / 1613  (40.4):  81%|  | 1612/2000 [23:42<05:10,  1.25it/s]\u001b[A\n",
      "Average Metric: 652 / 1613  (40.4):  81%|  | 1613/2000 [23:42<04:24,  1.47it/s]\u001b[A\n",
      "Average Metric: 653 / 1614  (40.5):  81%|  | 1613/2000 [23:42<04:24,  1.47it/s]\u001b[A\n",
      "Average Metric: 653 / 1615  (40.4):  81%|  | 1614/2000 [23:43<04:23,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 653 / 1615  (40.4):  81%|  | 1615/2000 [23:43<03:58,  1.62it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 653 / 1616  (40.4):  81%|  | 1615/2000 [23:45<03:58,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 653 / 1616  (40.4):  81%|  | 1616/2000 [23:45<06:00,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 654 / 1617  (40.4):  81%|  | 1616/2000 [23:46<06:00,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 654 / 1617  (40.4):  81%|  | 1617/2000 [23:46<05:35,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 654 / 1618  (40.4):  81%|  | 1617/2000 [23:46<05:35,  1.14it/s]\u001b[A\n",
      "Average Metric: 654 / 1618  (40.4):  81%|  | 1618/2000 [23:46<04:34,  1.39it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 655 / 1619  (40.5):  81%|  | 1618/2000 [23:46<04:34,  1.39it/s]\u001b[A\n",
      "Average Metric: 655 / 1619  (40.5):  81%|  | 1619/2000 [23:46<03:41,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 656 / 1620  (40.5):  81%|  | 1619/2000 [23:48<03:41,  1.72it/s]\u001b[A\n",
      "Average Metric: 656 / 1620  (40.5):  81%|  | 1620/2000 [23:48<06:06,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 657 / 1621  (40.5):  81%|  | 1620/2000 [23:48<06:06,  1.04it/s]\u001b[A\n",
      "Average Metric: 658 / 1622  (40.6):  81%|  | 1621/2000 [23:48<06:05,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 658 / 1622  (40.6):  81%|  | 1622/2000 [23:48<03:35,  1.75it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 659 / 1623  (40.6):  81%|  | 1622/2000 [23:49<03:35,  1.75it/s]\u001b[A\n",
      "Average Metric: 659 / 1623  (40.6):  81%|  | 1623/2000 [23:49<03:48,  1.65it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 660 / 1624  (40.6):  81%|  | 1623/2000 [23:49<03:48,  1.65it/s]\u001b[A\n",
      "Average Metric: 660 / 1624  (40.6):  81%|  | 1624/2000 [23:49<03:25,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 660 / 1625  (40.6):  81%|  | 1624/2000 [23:51<03:25,  1.83it/s]\u001b[A\n",
      "Average Metric: 660 / 1625  (40.6):  81%| | 1625/2000 [23:51<06:05,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1626  (40.7):  81%| | 1625/2000 [23:52<06:05,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\u001b[ATraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "Average Metric: 661 / 1626  (40.7):  81%| | 1626/2000 [23:52<05:38,  1.11it/s]  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 661 / 1627  (40.6):  81%| | 1626/2000 [23:53<05:38,  1.11it/s]\u001b[A\n",
      "Average Metric: 661 / 1627  (40.6):  81%| | 1627/2000 [23:53<04:51,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 661 / 1628  (40.6):  81%| | 1627/2000 [23:56<04:51,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 661 / 1628  (40.6):  81%| | 1628/2000 [23:56<09:53,  1.59s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1629  (40.6):  81%| | 1628/2000 [23:56<09:53,  1.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1630  (40.6):  81%| | 1629/2000 [23:57<09:51,  1.59s/it]\u001b[A\n",
      "Average Metric: 661 / 1630  (40.6):  82%| | 1630/2000 [23:57<06:25,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1631  (40.5):  82%| | 1630/2000 [23:58<06:25,  1.04s/it]\u001b[A\n",
      "Average Metric: 661 / 1631  (40.5):  82%| | 1631/2000 [23:58<06:07,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1632  (40.5):  82%| | 1631/2000 [23:59<06:07,  1.00it/s]\u001b[A\n",
      "Average Metric: 661 / 1632  (40.5):  82%| | 1632/2000 [23:59<06:53,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 662 / 1633  (40.5):  82%| | 1632/2000 [24:00<06:53,  1.12s/it]\u001b[A\n",
      "Average Metric: 662 / 1633  (40.5):  82%| | 1633/2000 [24:00<06:37,  1.08s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 663 / 1634  (40.6):  82%| | 1633/2000 [24:01<06:37,  1.08s/it]\u001b[A\n",
      "Average Metric: 663 / 1634  (40.6):  82%| | 1634/2000 [24:01<05:53,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 663 / 1635  (40.6):  82%| | 1634/2000 [24:01<05:53,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 663 / 1635  (40.6):  82%| | 1635/2000 [24:01<04:44,  1.28it/s]\u001b[A\n",
      "Average Metric: 663 / 1636  (40.5):  82%| | 1635/2000 [24:01<04:44,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 664 / 1637  (40.6):  82%| | 1636/2000 [24:03<04:43,  1.28it/s]\u001b[A\n",
      "Average Metric: 664 / 1637  (40.6):  82%| | 1637/2000 [24:03<04:39,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 664 / 1638  (40.5):  82%| | 1637/2000 [24:03<04:39,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 664 / 1638  (40.5):  82%| | 1638/2000 [24:03<04:11,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 665 / 1639  (40.6):  82%| | 1638/2000 [24:04<04:11,  1.44it/s]\u001b[A\n",
      "Average Metric: 665 / 1639  (40.6):  82%| | 1639/2000 [24:04<03:50,  1.56it/s]\u001b[A\n",
      "Average Metric: 665 / 1640  (40.5):  82%| | 1639/2000 [24:04<03:50,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 665 / 1640  (40.5):  82%| | 1640/2000 [24:04<03:22,  1.78it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 665 / 1641  (40.5):  82%| | 1640/2000 [24:04<03:22,  1.78it/s]\u001b[A\n",
      "Average Metric: 665 / 1641  (40.5):  82%| | 1641/2000 [24:04<02:47,  2.15it/s]\u001b[A\n",
      "Average Metric: 666 / 1642  (40.6):  82%| | 1641/2000 [24:05<02:47,  2.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 666 / 1642  (40.6):  82%| | 1642/2000 [24:05<02:26,  2.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1643  (40.5):  82%| | 1642/2000 [24:06<02:26,  2.44it/s]\u001b[A\n",
      "Average Metric: 666 / 1643  (40.5):  82%| | 1643/2000 [24:06<03:43,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 666 / 1644  (40.5):  82%| | 1643/2000 [24:06<03:43,  1.60it/s]\u001b[A\n",
      "Average Metric: 666 / 1644  (40.5):  82%| | 1644/2000 [24:06<02:49,  2.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 666 / 1645  (40.5):  82%| | 1644/2000 [24:07<02:49,  2.10it/s]\u001b[A\n",
      "Average Metric: 666 / 1645  (40.5):  82%| | 1645/2000 [24:07<04:11,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1646  (40.5):  82%| | 1645/2000 [24:08<04:11,  1.41it/s]\u001b[A\n",
      "Average Metric: 666 / 1646  (40.5):  82%| | 1646/2000 [24:08<04:52,  1.21it/s]\u001b[A\n",
      "Average Metric: 666 / 1647  (40.4):  82%| | 1646/2000 [24:09<04:52,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 666 / 1647  (40.4):  82%| | 1647/2000 [24:09<04:21,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 666 / 1648  (40.4):  82%| | 1647/2000 [24:09<04:21,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 666 / 1648  (40.4):  82%| | 1648/2000 [24:09<04:09,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1649  (40.4):  82%| | 1648/2000 [24:10<04:09,  1.41it/s]\u001b[A\n",
      "Average Metric: 666 / 1649  (40.4):  82%| | 1649/2000 [24:10<04:42,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1650  (40.4):  82%| | 1649/2000 [24:13<04:42,  1.24it/s]\u001b[A\n",
      "Average Metric: 666 / 1650  (40.4):  82%| | 1650/2000 [24:13<07:46,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 667 / 1651  (40.4):  82%| | 1650/2000 [24:14<07:46,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 667 / 1651  (40.4):  83%| | 1651/2000 [24:14<07:19,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 667 / 1652  (40.4):  83%| | 1651/2000 [24:15<07:19,  1.26s/it]\u001b[A\n",
      "Average Metric: 667 / 1652  (40.4):  83%| | 1652/2000 [24:15<06:00,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 667 / 1653  (40.4):  83%| | 1652/2000 [24:15<06:00,  1.04s/it]\u001b[A\n",
      "Average Metric: 667 / 1653  (40.4):  83%| | 1653/2000 [24:15<04:55,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 668 / 1654  (40.4):  83%| | 1653/2000 [24:19<04:55,  1.18it/s]\u001b[A\n",
      "Average Metric: 668 / 1654  (40.4):  83%| | 1654/2000 [24:19<10:24,  1.80s/it]\u001b[A\n",
      "Average Metric: 668 / 1655  (40.4):  83%| | 1654/2000 [24:19<10:24,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 668 / 1656  (40.3):  83%| | 1655/2000 [24:19<10:22,  1.80s/it]\u001b[A\n",
      "Average Metric: 668 / 1656  (40.3):  83%| | 1656/2000 [24:19<05:57,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 668 / 1657  (40.3):  83%| | 1656/2000 [24:21<05:57,  1.04s/it]\u001b[A\n",
      "Average Metric: 668 / 1657  (40.3):  83%| | 1657/2000 [24:21<06:14,  1.09s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 669 / 1658  (40.3):  83%| | 1657/2000 [24:21<06:14,  1.09s/it]\u001b[A\n",
      "Average Metric: 669 / 1658  (40.3):  83%| | 1658/2000 [24:21<05:27,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 670 / 1659  (40.4):  83%| | 1658/2000 [24:22<05:27,  1.04it/s]\u001b[A\n",
      "Average Metric: 670 / 1659  (40.4):  83%| | 1659/2000 [24:22<04:57,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 670 / 1660  (40.4):  83%| | 1659/2000 [24:23<04:57,  1.15it/s]\u001b[A\n",
      "Average Metric: 670 / 1660  (40.4):  83%| | 1660/2000 [24:23<04:57,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 670 / 1661  (40.3):  83%| | 1660/2000 [24:23<04:57,  1.14it/s]\u001b[A\n",
      "Average Metric: 670 / 1661  (40.3):  83%| | 1661/2000 [24:23<04:13,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 671 / 1662  (40.4):  83%| | 1661/2000 [24:23<04:13,  1.34it/s]\u001b[A\n",
      "Average Metric: 671 / 1662  (40.4):  83%| | 1662/2000 [24:23<03:35,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 671 / 1663  (40.3):  83%| | 1662/2000 [24:24<03:35,  1.57it/s]\u001b[A\n",
      "Average Metric: 671 / 1663  (40.3):  83%| | 1663/2000 [24:24<03:15,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 671 / 1664  (40.3):  83%| | 1663/2000 [24:25<03:15,  1.72it/s]\u001b[A\n",
      "Average Metric: 671 / 1664  (40.3):  83%| | 1664/2000 [24:25<04:26,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 672 / 1665  (40.4):  83%| | 1664/2000 [24:26<04:26,  1.26it/s]\u001b[A\n",
      "Average Metric: 672 / 1665  (40.4):  83%| | 1665/2000 [24:26<05:01,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 672 / 1666  (40.3):  83%| | 1665/2000 [24:27<05:01,  1.11it/s]\u001b[A\n",
      "Average Metric: 672 / 1666  (40.3):  83%| | 1666/2000 [24:27<03:56,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1667  (40.3):  83%| | 1666/2000 [24:27<03:56,  1.41it/s]\u001b[A\n",
      "Average Metric: 672 / 1667  (40.3):  83%| | 1667/2000 [24:27<03:50,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1668  (40.3):  83%| | 1667/2000 [24:28<03:50,  1.45it/s]\u001b[A\n",
      "Average Metric: 672 / 1668  (40.3):  83%| | 1668/2000 [24:28<04:20,  1.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1669  (40.3):  83%| | 1668/2000 [24:29<04:20,  1.28it/s]\u001b[A\n",
      "Average Metric: 672 / 1669  (40.3):  83%| | 1669/2000 [24:29<03:31,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1670  (40.2):  83%| | 1669/2000 [24:29<03:31,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 673 / 1671  (40.3):  84%| | 1670/2000 [24:30<03:30,  1.57it/s]\u001b[A\n",
      "Average Metric: 673 / 1671  (40.3):  84%| | 1671/2000 [24:30<03:54,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 673 / 1672  (40.3):  84%| | 1671/2000 [24:31<03:54,  1.40it/s]\u001b[A\n",
      "Average Metric: 673 / 1672  (40.3):  84%| | 1672/2000 [24:31<03:44,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 673 / 1673  (40.2):  84%| | 1672/2000 [24:31<03:44,  1.46it/s]\u001b[A\n",
      "Average Metric: 673 / 1673  (40.2):  84%| | 1673/2000 [24:31<03:42,  1.47it/s]\u001b[A\n",
      "Average Metric: 674 / 1674  (40.3):  84%| | 1673/2000 [24:32<03:42,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 674 / 1674  (40.3):  84%| | 1674/2000 [24:32<02:55,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 675 / 1675  (40.3):  84%| | 1674/2000 [24:33<02:55,  1.86it/s]\u001b[A\n",
      "Average Metric: 675 / 1675  (40.3):  84%| | 1675/2000 [24:33<03:36,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 675 / 1676  (40.3):  84%| | 1675/2000 [24:33<03:36,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 675 / 1677  (40.3):  84%| | 1676/2000 [24:33<03:36,  1.50it/s]\u001b[A\n",
      "Average Metric: 675 / 1677  (40.3):  84%| | 1677/2000 [24:33<02:20,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 676 / 1678  (40.3):  84%| | 1677/2000 [24:34<02:20,  2.31it/s]\u001b[A\n",
      "Average Metric: 676 / 1678  (40.3):  84%| | 1678/2000 [24:34<03:12,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 676 / 1679  (40.3):  84%| | 1678/2000 [24:37<03:12,  1.67it/s]\u001b[A\n",
      "Average Metric: 676 / 1679  (40.3):  84%| | 1679/2000 [24:37<06:05,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 677 / 1680  (40.3):  84%| | 1679/2000 [24:37<06:05,  1.14s/it]\u001b[A\n",
      "Average Metric: 677 / 1680  (40.3):  84%| | 1680/2000 [24:37<04:43,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 677 / 1681  (40.3):  84%| | 1680/2000 [24:38<04:43,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 677 / 1681  (40.3):  84%| | 1681/2000 [24:38<05:32,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 677 / 1682  (40.2):  84%| | 1681/2000 [24:39<05:32,  1.04s/it]\u001b[A\n",
      "Average Metric: 677 / 1682  (40.2):  84%| | 1682/2000 [24:39<05:09,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 678 / 1683  (40.3):  84%| | 1682/2000 [24:40<05:09,  1.03it/s]\u001b[A\n",
      "Average Metric: 678 / 1683  (40.3):  84%| | 1683/2000 [24:40<04:56,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 679 / 1684  (40.3):  84%| | 1683/2000 [24:41<04:56,  1.07it/s]\u001b[A\n",
      "Average Metric: 679 / 1684  (40.3):  84%| | 1684/2000 [24:41<04:44,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 679 / 1685  (40.3):  84%| | 1684/2000 [24:42<04:44,  1.11it/s]\u001b[A\n",
      "Average Metric: 679 / 1685  (40.3):  84%| | 1685/2000 [24:42<05:03,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 679 / 1686  (40.3):  84%| | 1685/2000 [24:43<05:03,  1.04it/s]\u001b[A\n",
      "Average Metric: 679 / 1686  (40.3):  84%| | 1686/2000 [24:43<04:40,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 680 / 1687  (40.3):  84%| | 1686/2000 [24:43<04:40,  1.12it/s]\u001b[A\n",
      "Average Metric: 680 / 1687  (40.3):  84%| | 1687/2000 [24:43<03:46,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 680 / 1688  (40.3):  84%| | 1687/2000 [24:46<03:46,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 680 / 1688  (40.3):  84%| | 1688/2000 [24:46<06:39,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 681 / 1689  (40.3):  84%| | 1688/2000 [24:46<06:39,  1.28s/it]\u001b[A\n",
      "Average Metric: 681 / 1689  (40.3):  84%| | 1689/2000 [24:46<04:49,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 682 / 1690  (40.4):  84%| | 1689/2000 [24:46<04:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 682 / 1690  (40.4):  84%| | 1690/2000 [24:46<04:18,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 683 / 1691  (40.4):  84%| | 1690/2000 [24:49<04:18,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 683 / 1691  (40.4):  85%| | 1691/2000 [24:49<07:01,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 683 / 1692  (40.4):  85%| | 1691/2000 [24:49<07:01,  1.36s/it]\u001b[A\n",
      "Average Metric: 683 / 1692  (40.4):  85%| | 1692/2000 [24:49<05:17,  1.03s/it]\u001b[A\n",
      "Average Metric: 684 / 1693  (40.4):  85%| | 1692/2000 [24:49<05:17,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 685 / 1694  (40.4):  85%| | 1693/2000 [24:50<05:16,  1.03s/it]\u001b[A\n",
      "Average Metric: 685 / 1694  (40.4):  85%| | 1694/2000 [24:50<04:07,  1.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 686 / 1695  (40.5):  85%| | 1694/2000 [24:51<04:07,  1.23it/s]\u001b[A\n",
      "Average Metric: 686 / 1695  (40.5):  85%| | 1695/2000 [24:51<03:47,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 687 / 1696  (40.5):  85%| | 1695/2000 [24:53<03:47,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 687 / 1696  (40.5):  85%| | 1696/2000 [24:53<05:18,  1.05s/it]\u001b[A\n",
      "Average Metric: 687 / 1697  (40.5):  85%| | 1696/2000 [24:53<05:18,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 687 / 1697  (40.5):  85%| | 1697/2000 [24:53<04:03,  1.24it/s]\u001b[A\n",
      "Average Metric: 688 / 1698  (40.5):  85%| | 1697/2000 [24:54<04:03,  1.24it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 688 / 1698  (40.5):  85%| | 1698/2000 [24:54<05:00,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 688 / 1699  (40.5):  85%| | 1698/2000 [24:54<05:00,  1.00it/s]\u001b[A\n",
      "Average Metric: 688 / 1700  (40.5):  85%| | 1699/2000 [24:54<04:59,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 688 / 1701  (40.4):  85%| | 1700/2000 [24:56<04:58,  1.00it/s]\u001b[A\n",
      "Average Metric: 688 / 1701  (40.4):  85%| | 1701/2000 [24:56<03:38,  1.37it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 689 / 1702  (40.5):  85%| | 1701/2000 [24:56<03:38,  1.37it/s]\u001b[A\n",
      "Average Metric: 689 / 1702  (40.5):  85%| | 1702/2000 [24:56<03:05,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 689 / 1703  (40.5):  85%| | 1702/2000 [24:57<03:05,  1.61it/s]\u001b[A\n",
      "Average Metric: 689 / 1703  (40.5):  85%| | 1703/2000 [24:57<03:50,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 690 / 1704  (40.5):  85%| | 1703/2000 [24:58<03:50,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 690 / 1704  (40.5):  85%| | 1704/2000 [24:58<04:08,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 690 / 1705  (40.5):  85%| | 1704/2000 [24:59<04:08,  1.19it/s]\u001b[A\n",
      "Average Metric: 690 / 1705  (40.5):  85%| | 1705/2000 [24:59<04:13,  1.16it/s]\u001b[A\n",
      "Average Metric: 690 / 1706  (40.4):  85%| | 1705/2000 [25:00<04:13,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 690 / 1706  (40.4):  85%| | 1706/2000 [25:00<03:49,  1.28it/s]\u001b[A\n",
      "Average Metric: 691 / 1707  (40.5):  85%| | 1706/2000 [25:00<03:49,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 691 / 1707  (40.5):  85%| | 1707/2000 [25:00<03:24,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 691 / 1708  (40.5):  85%| | 1707/2000 [25:01<03:24,  1.43it/s]\u001b[A\n",
      "Average Metric: 691 / 1708  (40.5):  85%| | 1708/2000 [25:01<03:47,  1.28it/s]\u001b[A\n",
      "Average Metric: 692 / 1709  (40.5):  85%| | 1708/2000 [25:03<03:47,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 692 / 1709  (40.5):  85%| | 1709/2000 [25:03<04:47,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 693 / 1710  (40.5):  85%| | 1709/2000 [25:03<04:47,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 694 / 1711  (40.6):  86%| | 1710/2000 [25:03<04:46,  1.01it/s]\u001b[A\n",
      "Average Metric: 694 / 1711  (40.6):  86%| | 1711/2000 [25:03<02:43,  1.76it/s]\u001b[A\n",
      "Average Metric: 695 / 1712  (40.6):  86%| | 1711/2000 [25:04<02:43,  1.76it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 695 / 1712  (40.6):  86%| | 1712/2000 [25:04<02:43,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 695 / 1713  (40.6):  86%| | 1712/2000 [25:04<02:43,  1.76it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 695 / 1714  (40.5):  86%| | 1713/2000 [25:06<02:42,  1.76it/s]\u001b[A\n",
      "Average Metric: 695 / 1714  (40.5):  86%| | 1714/2000 [25:06<04:06,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 695 / 1715  (40.5):  86%| | 1714/2000 [25:06<04:06,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 696 / 1716  (40.6):  86%| | 1715/2000 [25:07<04:05,  1.16it/s]\u001b[A\n",
      "Average Metric: 696 / 1716  (40.6):  86%| | 1716/2000 [25:07<02:59,  1.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 696 / 1717  (40.5):  86%| | 1716/2000 [25:07<02:59,  1.58it/s]\u001b[A\n",
      "Average Metric: 696 / 1717  (40.5):  86%| | 1717/2000 [25:07<02:39,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 696 / 1718  (40.5):  86%| | 1717/2000 [25:08<02:39,  1.78it/s]\u001b[A\n",
      "Average Metric: 696 / 1718  (40.5):  86%| | 1718/2000 [25:08<02:55,  1.60it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 696 / 1719  (40.5):  86%| | 1718/2000 [25:09<02:55,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 696 / 1719  (40.5):  86%| | 1719/2000 [25:09<03:37,  1.29it/s]\u001b[A\n",
      "Average Metric: 697 / 1720  (40.5):  86%| | 1719/2000 [25:09<03:37,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 697 / 1721  (40.5):  86%| | 1720/2000 [25:10<03:36,  1.29it/s]\u001b[A\n",
      "Average Metric: 697 / 1721  (40.5):  86%| | 1721/2000 [25:10<02:45,  1.68it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 698 / 1722  (40.5):  86%| | 1721/2000 [25:10<02:45,  1.68it/s]\u001b[A\n",
      "Average Metric: 698 / 1722  (40.5):  86%| | 1722/2000 [25:10<02:35,  1.79it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1723  (40.6):  86%| | 1722/2000 [25:12<02:35,  1.79it/s]\u001b[A\n",
      "Average Metric: 699 / 1723  (40.6):  86%| | 1723/2000 [25:12<03:45,  1.23it/s]\u001b[A\n",
      "Average Metric: 699 / 1724  (40.5):  86%| | 1723/2000 [25:13<03:45,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 699 / 1724  (40.5):  86%| | 1724/2000 [25:13<03:51,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1725  (40.5):  86%| | 1724/2000 [25:13<03:51,  1.19it/s]\u001b[A\n",
      "Average Metric: 699 / 1725  (40.5):  86%| | 1725/2000 [25:13<03:30,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1726  (40.5):  86%| | 1725/2000 [25:14<03:30,  1.31it/s]\u001b[A\n",
      "Average Metric: 699 / 1726  (40.5):  86%| | 1726/2000 [25:14<04:07,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1727  (40.5):  86%| | 1726/2000 [25:15<04:07,  1.11it/s]\u001b[A\n",
      "Average Metric: 699 / 1727  (40.5):  86%| | 1727/2000 [25:15<03:17,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 700 / 1728  (40.5):  86%| | 1727/2000 [25:15<03:17,  1.38it/s]\u001b[A\n",
      "Average Metric: 700 / 1729  (40.5):  86%| | 1728/2000 [25:15<03:16,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 700 / 1729  (40.5):  86%| | 1729/2000 [25:15<02:05,  2.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 700 / 1730  (40.5):  86%| | 1729/2000 [25:16<02:05,  2.16it/s]\u001b[A\n",
      "Average Metric: 700 / 1730  (40.5):  86%| | 1730/2000 [25:16<02:34,  1.75it/s]\u001b[A\n",
      "Average Metric: 701 / 1731  (40.5):  86%| | 1730/2000 [25:16<02:34,  1.75it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 701 / 1732  (40.5):  87%| | 1731/2000 [25:17<02:34,  1.75it/s]\u001b[A\n",
      "Average Metric: 701 / 1732  (40.5):  87%| | 1732/2000 [25:17<02:11,  2.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 702 / 1733  (40.5):  87%| | 1732/2000 [25:17<02:11,  2.05it/s]\u001b[A\n",
      "Average Metric: 702 / 1733  (40.5):  87%| | 1733/2000 [25:17<02:11,  2.02it/s]\u001b[A\n",
      "Average Metric: 703 / 1734  (40.5):  87%| | 1733/2000 [25:17<02:11,  2.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 703 / 1734  (40.5):  87%| | 1734/2000 [25:17<02:01,  2.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1735  (40.6):  87%| | 1734/2000 [25:20<02:01,  2.20it/s]\u001b[A\n",
      "Average Metric: 704 / 1735  (40.6):  87%| | 1735/2000 [25:20<04:07,  1.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1736  (40.6):  87%| | 1735/2000 [25:20<04:07,  1.07it/s]\u001b[A\n",
      "Average Metric: 704 / 1736  (40.6):  87%| | 1736/2000 [25:20<03:36,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1737  (40.5):  87%| | 1736/2000 [25:21<03:36,  1.22it/s]\u001b[A\n",
      "Average Metric: 704 / 1737  (40.5):  87%| | 1737/2000 [25:21<03:05,  1.41it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1738  (40.5):  87%| | 1737/2000 [25:21<03:05,  1.41it/s]\u001b[A\n",
      "Average Metric: 704 / 1738  (40.5):  87%| | 1738/2000 [25:21<02:43,  1.60it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 705 / 1739  (40.5):  87%| | 1738/2000 [25:21<02:43,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 705 / 1739  (40.5):  87%| | 1739/2000 [25:21<02:14,  1.94it/s]\u001b[A\n",
      "Average Metric: 705 / 1740  (40.5):  87%| | 1739/2000 [25:21<02:14,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 706 / 1741  (40.6):  87%| | 1740/2000 [25:23<02:13,  1.94it/s]\u001b[A\n",
      "Average Metric: 706 / 1741  (40.6):  87%| | 1741/2000 [25:23<02:33,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 707 / 1742  (40.6):  87%| | 1741/2000 [25:23<02:33,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 707 / 1742  (40.6):  87%| | 1742/2000 [25:23<02:13,  1.93it/s]\u001b[A\n",
      "Average Metric: 707 / 1743  (40.6):  87%| | 1742/2000 [25:23<02:13,  1.93it/s]\u001b[A\n",
      "Average Metric: 707 / 1744  (40.5):  87%| | 1743/2000 [25:23<02:13,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 707 / 1744  (40.5):  87%| | 1744/2000 [25:23<01:42,  2.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 707 / 1745  (40.5):  87%| | 1744/2000 [25:25<01:42,  2.50it/s]\u001b[A\n",
      "Average Metric: 707 / 1745  (40.5):  87%| | 1745/2000 [25:25<02:47,  1.52it/s]\u001b[A\n",
      "Average Metric: 708 / 1746  (40.5):  87%| | 1745/2000 [25:26<02:47,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 708 / 1746  (40.5):  87%| | 1746/2000 [25:26<03:00,  1.41it/s]\u001b[A\n",
      "Average Metric: 709 / 1747  (40.6):  87%| | 1746/2000 [25:27<03:00,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 709 / 1747  (40.6):  87%| | 1747/2000 [25:27<03:14,  1.30it/s]\u001b[A\n",
      "Average Metric: 709 / 1748  (40.6):  87%| | 1747/2000 [25:27<03:14,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 709 / 1748  (40.6):  87%| | 1748/2000 [25:27<02:36,  1.61it/s]\u001b[A\n",
      "Average Metric: 709 / 1749  (40.5):  87%| | 1748/2000 [25:29<02:36,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 709 / 1749  (40.5):  87%| | 1749/2000 [25:29<03:59,  1.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 709 / 1750  (40.5):  87%| | 1749/2000 [25:29<03:59,  1.05it/s]\u001b[A\n",
      "Average Metric: 709 / 1750  (40.5):  88%| | 1750/2000 [25:29<03:05,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1751  (40.5):  88%| | 1750/2000 [25:30<03:05,  1.35it/s]\u001b[A\n",
      "Average Metric: 710 / 1751  (40.5):  88%| | 1751/2000 [25:30<02:56,  1.41it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1752  (40.5):  88%| | 1751/2000 [25:30<02:56,  1.41it/s]\u001b[A\n",
      "Average Metric: 710 / 1752  (40.5):  88%| | 1752/2000 [25:30<02:52,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1753  (40.5):  88%| | 1752/2000 [25:31<02:52,  1.44it/s]\u001b[A\n",
      "Average Metric: 710 / 1753  (40.5):  88%| | 1753/2000 [25:31<02:21,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1754  (40.5):  88%| | 1753/2000 [25:31<02:21,  1.75it/s]\u001b[A\n",
      "Average Metric: 710 / 1754  (40.5):  88%| | 1754/2000 [25:31<01:50,  2.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1755  (40.5):  88%| | 1754/2000 [25:31<01:50,  2.22it/s]\u001b[A\n",
      "Average Metric: 710 / 1755  (40.5):  88%| | 1755/2000 [25:31<01:44,  2.35it/s]\u001b[A\n",
      "Average Metric: 710 / 1756  (40.4):  88%| | 1755/2000 [25:31<01:44,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 710 / 1756  (40.4):  88%| | 1756/2000 [25:31<01:29,  2.73it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 710 / 1757  (40.4):  88%| | 1756/2000 [25:32<01:29,  2.73it/s]\u001b[A\n",
      "Average Metric: 710 / 1757  (40.4):  88%| | 1757/2000 [25:32<02:21,  1.72it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 711 / 1758  (40.4):  88%| | 1757/2000 [25:33<02:21,  1.72it/s]\u001b[A\n",
      "Average Metric: 711 / 1758  (40.4):  88%| | 1758/2000 [25:33<02:16,  1.78it/s]\u001b[A\n",
      "Average Metric: 711 / 1759  (40.4):  88%| | 1758/2000 [25:34<02:16,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 711 / 1759  (40.4):  88%| | 1759/2000 [25:34<03:16,  1.23it/s]\u001b[A\n",
      "Average Metric: 711 / 1760  (40.4):  88%| | 1759/2000 [25:36<03:16,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 711 / 1760  (40.4):  88%| | 1760/2000 [25:36<03:45,  1.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 711 / 1761  (40.4):  88%| | 1760/2000 [25:36<03:45,  1.07it/s]\u001b[A\n",
      "Average Metric: 711 / 1761  (40.4):  88%| | 1761/2000 [25:36<03:04,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 712 / 1762  (40.4):  88%| | 1761/2000 [25:36<03:04,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 713 / 1763  (40.4):  88%| | 1762/2000 [25:37<03:03,  1.29it/s]\u001b[A\n",
      "Average Metric: 713 / 1763  (40.4):  88%| | 1763/2000 [25:37<02:27,  1.61it/s]\u001b[A\n",
      "Average Metric: 713 / 1764  (40.4):  88%| | 1763/2000 [25:37<02:27,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 713 / 1764  (40.4):  88%| | 1764/2000 [25:37<02:18,  1.70it/s]\u001b[A\n",
      "Average Metric: 714 / 1765  (40.5):  88%| | 1764/2000 [25:37<02:18,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 714 / 1766  (40.4):  88%| | 1765/2000 [25:38<02:17,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 714 / 1766  (40.4):  88%| | 1766/2000 [25:38<01:52,  2.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1767  (40.5):  88%| | 1766/2000 [25:39<01:52,  2.07it/s]\u001b[A\n",
      "Average Metric: 715 / 1767  (40.5):  88%| | 1767/2000 [25:39<02:15,  1.72it/s]\u001b[A\n",
      "Average Metric: 715 / 1768  (40.4):  88%| | 1767/2000 [25:40<02:15,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 715 / 1768  (40.4):  88%| | 1768/2000 [25:40<02:28,  1.56it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1769  (40.4):  88%| | 1768/2000 [25:40<02:28,  1.56it/s]\u001b[A\n",
      "Average Metric: 715 / 1769  (40.4):  88%| | 1769/2000 [25:40<02:20,  1.64it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1770  (40.4):  88%| | 1769/2000 [25:42<02:20,  1.64it/s]\u001b[A\n",
      "Average Metric: 715 / 1770  (40.4):  88%| | 1770/2000 [25:42<03:12,  1.19it/s]\u001b[A\n",
      "Average Metric: 715 / 1771  (40.4):  88%| | 1770/2000 [25:42<03:12,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 715 / 1771  (40.4):  89%| | 1771/2000 [25:42<02:30,  1.52it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1772  (40.3):  89%| | 1771/2000 [25:42<02:30,  1.52it/s]\u001b[A\n",
      "Average Metric: 715 / 1772  (40.3):  89%| | 1772/2000 [25:42<02:14,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 715 / 1773  (40.3):  89%| | 1772/2000 [25:43<02:14,  1.69it/s]\u001b[A\n",
      "Average Metric: 715 / 1773  (40.3):  89%| | 1773/2000 [25:43<02:08,  1.77it/s]\u001b[A\n",
      "Average Metric: 715 / 1774  (40.3):  89%| | 1773/2000 [25:43<02:08,  1.77it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 715 / 1774  (40.3):  89%| | 1774/2000 [25:43<01:57,  1.92it/s]\u001b[A\n",
      "Average Metric: 715 / 1775  (40.3):  89%| | 1774/2000 [25:44<01:57,  1.92it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1775  (40.3):  89%| | 1775/2000 [25:44<02:12,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 716 / 1776  (40.3):  89%| | 1775/2000 [25:45<02:12,  1.69it/s]\u001b[A\n",
      "Average Metric: 716 / 1776  (40.3):  89%| | 1776/2000 [25:45<02:08,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 716 / 1777  (40.3):  89%| | 1776/2000 [25:45<02:08,  1.74it/s]\u001b[A\n",
      "Average Metric: 716 / 1777  (40.3):  89%| | 1777/2000 [25:45<02:19,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 716 / 1778  (40.3):  89%| | 1777/2000 [25:46<02:19,  1.59it/s]\u001b[A\n",
      "Average Metric: 716 / 1778  (40.3):  89%| | 1778/2000 [25:46<02:08,  1.73it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 716 / 1779  (40.2):  89%| | 1778/2000 [25:47<02:08,  1.73it/s]\u001b[A\n",
      "Average Metric: 716 / 1779  (40.2):  89%| | 1779/2000 [25:47<02:23,  1.54it/s]\u001b[A\n",
      "Average Metric: 717 / 1780  (40.3):  89%| | 1779/2000 [25:47<02:23,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 717 / 1780  (40.3):  89%| | 1780/2000 [25:47<01:56,  1.89it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 717 / 1781  (40.3):  89%| | 1780/2000 [25:47<01:56,  1.89it/s]\u001b[A\n",
      "Average Metric: 717 / 1781  (40.3):  89%| | 1781/2000 [25:47<01:46,  2.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 717 / 1782  (40.2):  89%| | 1781/2000 [25:48<01:46,  2.05it/s]\u001b[A\n",
      "Average Metric: 717 / 1782  (40.2):  89%| | 1782/2000 [25:48<02:08,  1.70it/s]\u001b[A\n",
      "Average Metric: 717 / 1783  (40.2):  89%| | 1782/2000 [25:48<02:08,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 717 / 1783  (40.2):  89%| | 1783/2000 [25:48<01:51,  1.94it/s]\u001b[A\n",
      "Average Metric: 717 / 1784  (40.2):  89%| | 1783/2000 [25:49<01:51,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 717 / 1784  (40.2):  89%| | 1784/2000 [25:49<01:46,  2.02it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 718 / 1785  (40.2):  89%| | 1784/2000 [25:49<01:46,  2.02it/s]\u001b[A\n",
      "Average Metric: 718 / 1785  (40.2):  89%| | 1785/2000 [25:49<01:23,  2.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 719 / 1786  (40.3):  89%| | 1785/2000 [25:50<01:23,  2.58it/s]\u001b[A\n",
      "Average Metric: 719 / 1786  (40.3):  89%| | 1786/2000 [25:50<01:57,  1.83it/s]\u001b[A\n",
      "Average Metric: 719 / 1787  (40.2):  89%| | 1786/2000 [25:50<01:57,  1.83it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 719 / 1787  (40.2):  89%| | 1787/2000 [25:50<01:29,  2.37it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 719 / 1788  (40.2):  89%| | 1787/2000 [25:51<01:29,  2.37it/s]\u001b[A\n",
      "Average Metric: 719 / 1788  (40.2):  89%| | 1788/2000 [25:51<01:46,  1.99it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 720 / 1789  (40.2):  89%| | 1788/2000 [25:52<01:46,  1.99it/s]\u001b[A\n",
      "Average Metric: 720 / 1789  (40.2):  89%| | 1789/2000 [25:52<02:29,  1.41it/s]\u001b[A\n",
      "Average Metric: 720 / 1790  (40.2):  89%| | 1789/2000 [25:53<02:29,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 720 / 1790  (40.2):  90%| | 1790/2000 [25:53<02:28,  1.42it/s]\u001b[A\n",
      "Average Metric: 720 / 1791  (40.2):  90%| | 1790/2000 [25:53<02:28,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 720 / 1791  (40.2):  90%| | 1791/2000 [25:53<02:06,  1.65it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 721 / 1792  (40.2):  90%| | 1791/2000 [25:53<02:06,  1.65it/s]\u001b[A\n",
      "Average Metric: 721 / 1792  (40.2):  90%| | 1792/2000 [25:53<01:40,  2.08it/s]\u001b[A\n",
      "Average Metric: 721 / 1793  (40.2):  90%| | 1792/2000 [25:55<01:40,  2.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 721 / 1793  (40.2):  90%| | 1793/2000 [25:55<02:51,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 721 / 1794  (40.2):  90%| | 1793/2000 [25:55<02:51,  1.20it/s]\u001b[A\n",
      "Average Metric: 721 / 1794  (40.2):  90%| | 1794/2000 [25:55<02:23,  1.44it/s]\u001b[A\n",
      "Average Metric: 722 / 1795  (40.2):  90%| | 1794/2000 [25:56<02:23,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 722 / 1795  (40.2):  90%| | 1795/2000 [25:56<02:09,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'irsih'. A: bother B: governing C: irish D: officers\n",
      "Answer: D: officers\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which is the smallest planet in our solar system? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: Which is the most abundant greenhouse gas in the atmosphere? A: Carbon dioxide B: Methane C: Nitrous oxide D: Water\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cchenas'? A: tiny B: directors C: bugs D: chances\n",
      "Answer: D: chances\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the smallest mammal? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 722 / 1796  (40.2):  90%| | 1795/2000 [25:57<02:09,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 722 / 1796  (40.2):  90%| | 1796/2000 [25:57<02:54,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 722 / 1797  (40.2):  90%| | 1796/2000 [25:57<02:54,  1.17it/s]\u001b[A\n",
      "Average Metric: 722 / 1797  (40.2):  90%| | 1797/2000 [25:57<02:16,  1.48it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 723 / 1798  (40.2):  90%| | 1797/2000 [25:58<02:16,  1.48it/s]\u001b[A\n",
      "Average Metric: 723 / 1798  (40.2):  90%| | 1798/2000 [25:58<01:45,  1.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 724 / 1799  (40.2):  90%| | 1798/2000 [25:58<01:45,  1.91it/s]\u001b[A\n",
      "Average Metric: 724 / 1799  (40.2):  90%| | 1799/2000 [25:58<01:51,  1.81it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 725 / 1800  (40.3):  90%| | 1799/2000 [25:58<01:51,  1.81it/s]\u001b[A\n",
      "Average Metric: 725 / 1800  (40.3):  90%| | 1800/2000 [25:58<01:29,  2.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 725 / 1801  (40.3):  90%| | 1800/2000 [25:59<01:29,  2.23it/s]\u001b[A\n",
      "Average Metric: 725 / 1801  (40.3):  90%| | 1801/2000 [25:59<01:41,  1.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 725 / 1802  (40.2):  90%| | 1801/2000 [26:00<01:41,  1.96it/s]\u001b[A\n",
      "Average Metric: 725 / 1802  (40.2):  90%| | 1802/2000 [26:00<01:57,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1803  (40.3):  90%| | 1802/2000 [26:00<01:57,  1.69it/s]\u001b[A\n",
      "Average Metric: 726 / 1803  (40.3):  90%| | 1803/2000 [26:00<01:51,  1.77it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1804  (40.2):  90%| | 1803/2000 [26:01<01:51,  1.77it/s]\u001b[A\n",
      "Average Metric: 726 / 1804  (40.2):  90%| | 1804/2000 [26:01<02:15,  1.44it/s]\u001b[A\n",
      "Average Metric: 726 / 1805  (40.2):  90%| | 1804/2000 [26:03<02:15,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 726 / 1805  (40.2):  90%| | 1805/2000 [26:03<02:47,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1806  (40.2):  90%| | 1805/2000 [26:04<02:47,  1.17it/s]\u001b[A\n",
      "Average Metric: 726 / 1806  (40.2):  90%| | 1806/2000 [26:04<03:07,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1807  (40.2):  90%| | 1806/2000 [26:04<03:07,  1.04it/s]\u001b[A\n",
      "Average Metric: 726 / 1807  (40.2):  90%| | 1807/2000 [26:04<02:52,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1808  (40.2):  90%| | 1807/2000 [26:05<02:52,  1.12it/s]\u001b[A\n",
      "Average Metric: 726 / 1808  (40.2):  90%| | 1808/2000 [26:05<02:40,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1809  (40.1):  90%| | 1808/2000 [26:06<02:40,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 726 / 1809  (40.1):  90%| | 1809/2000 [26:06<02:29,  1.28it/s]\u001b[A\n",
      "Average Metric: 726 / 1810  (40.1):  90%| | 1809/2000 [26:06<02:29,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'raclles' to form the correct word. A: educate B: economic C: recalls D: streaming\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 0.5  B: 0.2  C: 0.1  D: 0.01\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the correct spelling of the word 'col\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1811  (40.1):  90%| | 1810/2000 [26:06<02:28,  1.28it/s]\u001b[A\n",
      "Average Metric: 726 / 1811  (40.1):  91%| | 1811/2000 [26:06<01:35,  1.99it/s]\u001b[A\n",
      "Average Metric: 727 / 1812  (40.1):  91%| | 1811/2000 [26:08<01:35,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 727 / 1812  (40.1):  91%| | 1812/2000 [26:08<02:27,  1.28it/s]\u001b[A\n",
      "Average Metric: 727 / 1813  (40.1):  91%| | 1812/2000 [26:08<02:27,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 727 / 1813  (40.1):  91%| | 1813/2000 [26:08<02:04,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 728 / 1814  (40.1):  91%| | 1813/2000 [26:08<02:04,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 729 / 1815  (40.2):  91%| | 1814/2000 [26:09<02:04,  1.50it/s]\u001b[A\n",
      "Average Metric: 729 / 1815  (40.2):  91%| | 1815/2000 [26:09<01:33,  1.98it/s]\u001b[A\n",
      "Average Metric: 729 / 1816  (40.1):  91%| | 1815/2000 [26:09<01:33,  1.98it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 729 / 1816  (40.1):  91%| | 1816/2000 [26:09<01:22,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 730 / 1817  (40.2):  91%| | 1816/2000 [26:10<01:22,  2.24it/s]\u001b[A\n",
      "Average Metric: 730 / 1817  (40.2):  91%| | 1817/2000 [26:10<01:28,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 730 / 1818  (40.2):  91%| | 1817/2000 [26:11<01:28,  2.08it/s]\u001b[A\n",
      "Average Metric: 730 / 1818  (40.2):  91%| | 1818/2000 [26:11<01:53,  1.61it/s]\u001b[A\n",
      "Average Metric: 731 / 1819  (40.2):  91%| | 1818/2000 [26:12<01:53,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 731 / 1819  (40.2):  91%| | 1819/2000 [26:12<02:25,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 732 / 1820  (40.2):  91%| | 1819/2000 [26:13<02:25,  1.24it/s]\u001b[A\n",
      "Average Metric: 732 / 1820  (40.2):  91%| | 1820/2000 [26:13<02:36,  1.15it/s]\u001b[A\n",
      "Average Metric: 732 / 1821  (40.2):  91%| | 1820/2000 [26:14<02:36,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 732 / 1821  (40.2):  91%| | 1821/2000 [26:14<02:32,  1.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'orthes'. A: vacant B: donald C: tension D: others\n",
      "Answer: D: others\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Jupiter D: Mars\n",
      "Answer: C: Jupiter\n",
      "\n",
      "Question: What is the smallest mammal? A: elephant B: mouse C: whale D: giraffe\n",
      "Answer: B: mouse\n",
      "\n",
      "Question: What is the smallest country in the world\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 732 / 1822  (40.2):  91%| | 1821/2000 [26:15<02:32,  1.18it/s]\u001b[A\n",
      "Average Metric: 732 / 1822  (40.2):  91%| | 1822/2000 [26:15<02:33,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 733 / 1823  (40.2):  91%| | 1822/2000 [26:16<02:33,  1.16it/s]\u001b[A\n",
      "Average Metric: 733 / 1823  (40.2):  91%| | 1823/2000 [26:16<02:55,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 734 / 1824  (40.2):  91%| | 1823/2000 [26:16<02:55,  1.01it/s]\u001b[A\n",
      "Average Metric: 734 / 1824  (40.2):  91%| | 1824/2000 [26:16<02:24,  1.22it/s]\u001b[A\n",
      "Average Metric: 735 / 1825  (40.3):  91%| | 1824/2000 [26:17<02:24,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 735 / 1825  (40.3):  91%|| 1825/2000 [26:17<02:21,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 736 / 1826  (40.3):  91%|| 1825/2000 [26:18<02:21,  1.24it/s]\u001b[A\n",
      "Average Metric: 736 / 1826  (40.3):  91%|| 1826/2000 [26:18<02:00,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 737 / 1827  (40.3):  91%|| 1826/2000 [26:18<02:00,  1.44it/s]\u001b[A\n",
      "Average Metric: 737 / 1827  (40.3):  91%|| 1827/2000 [26:18<01:40,  1.72it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 738 / 1828  (40.4):  91%|| 1827/2000 [26:19<01:40,  1.72it/s]\u001b[A\n",
      "Average Metric: 738 / 1828  (40.4):  91%|| 1828/2000 [26:19<01:52,  1.53it/s]\u001b[A\n",
      "Average Metric: 738 / 1829  (40.3):  91%|| 1828/2000 [26:20<01:52,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 738 / 1829  (40.3):  91%|| 1829/2000 [26:20<02:25,  1.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fveer' to form the correct word. A: initiative B: barrier C: fever D: israeli\n",
      "Answer: E\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.2\n",
      "Answer: C: 0.01\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Madrid  B: Berlin  C: Paris  D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.2\n",
      "Answer: A: 1/3\n",
      "\n",
      "Question: Which of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 739 / 1830  (40.4):  91%|| 1829/2000 [26:21<02:25,  1.17it/s]\u001b[A\n",
      "Average Metric: 739 / 1830  (40.4):  92%|| 1830/2000 [26:21<02:31,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 739 / 1831  (40.4):  92%|| 1830/2000 [26:21<02:31,  1.12it/s]\u001b[A\n",
      "Average Metric: 739 / 1831  (40.4):  92%|| 1831/2000 [26:21<01:55,  1.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bcaks' represent when unscrambled? A: hood B: tobacco C: moon D: backs\n",
      "Answer: D: backs\n",
      "\n",
      "Question: Which of the following is not a primary color? A: red B: blue C: yellow D: green\n",
      "Answer: D: green\n",
      "\n",
      "Question: What is the capital of France? A: London B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which of the following is not a planet in our solar system? A: Earth B: Mars C: Jupiter D: Venus\n",
      "Answer: B: Mars\n",
      "\n",
      "Question: What is the smallest value in 0.1, 0.5, 0.01, -0.2? A: 0.1 B: 0.5 C:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 739 / 1832  (40.3):  92%|| 1831/2000 [26:23<01:55,  1.47it/s]\u001b[A\n",
      "Average Metric: 739 / 1832  (40.3):  92%|| 1832/2000 [26:23<02:35,  1.08it/s]\u001b[A\n",
      "Average Metric: 740 / 1833  (40.4):  92%|| 1832/2000 [26:23<02:35,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 740 / 1833  (40.4):  92%|| 1833/2000 [26:23<01:54,  1.46it/s]\u001b[A\n",
      "Average Metric: 741 / 1834  (40.4):  92%|| 1833/2000 [26:23<01:54,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 741 / 1834  (40.4):  92%|| 1834/2000 [26:23<01:42,  1.62it/s]\u001b[A\n",
      "Average Metric: 741 / 1835  (40.4):  92%|| 1834/2000 [26:24<01:42,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 741 / 1835  (40.4):  92%|| 1835/2000 [26:24<01:46,  1.55it/s]\u001b[A\n",
      "Average Metric: 742 / 1836  (40.4):  92%|| 1835/2000 [26:25<01:46,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 742 / 1836  (40.4):  92%|| 1836/2000 [26:25<01:49,  1.49it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 742 / 1837  (40.4):  92%|| 1836/2000 [26:25<01:49,  1.49it/s]\u001b[A\n",
      "Average Metric: 742 / 1837  (40.4):  92%|| 1837/2000 [26:25<01:34,  1.73it/s]\u001b[A\n",
      "Average Metric: 742 / 1838  (40.4):  92%|| 1837/2000 [26:25<01:34,  1.73it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 742 / 1838  (40.4):  92%|| 1838/2000 [26:25<01:27,  1.85it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 742 / 1839  (40.3):  92%|| 1838/2000 [26:26<01:27,  1.85it/s]\u001b[A\n",
      "Average Metric: 742 / 1839  (40.3):  92%|| 1839/2000 [26:26<01:16,  2.09it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 743 / 1840  (40.4):  92%|| 1839/2000 [26:27<01:16,  2.09it/s]\u001b[A\n",
      "Average Metric: 743 / 1840  (40.4):  92%|| 1840/2000 [26:27<01:30,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 744 / 1841  (40.4):  92%|| 1840/2000 [26:27<01:30,  1.76it/s]\u001b[A\n",
      "Average Metric: 744 / 1841  (40.4):  92%|| 1841/2000 [26:27<01:11,  2.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1842  (40.4):  92%|| 1841/2000 [26:28<01:11,  2.23it/s]\u001b[A\n",
      "Average Metric: 744 / 1842  (40.4):  92%|| 1842/2000 [26:28<01:31,  1.72it/s]\u001b[A\n",
      "Average Metric: 744 / 1843  (40.4):  92%|| 1842/2000 [26:28<01:31,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 744 / 1843  (40.4):  92%|| 1843/2000 [26:28<01:17,  2.02it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1844  (40.3):  92%|| 1843/2000 [26:29<01:17,  2.02it/s]\u001b[A\n",
      "Average Metric: 744 / 1844  (40.3):  92%|| 1844/2000 [26:29<01:41,  1.54it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1845  (40.3):  92%|| 1844/2000 [26:29<01:41,  1.54it/s]\u001b[A\n",
      "Average Metric: 744 / 1845  (40.3):  92%|| 1845/2000 [26:29<01:23,  1.86it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1846  (40.3):  92%|| 1845/2000 [26:29<01:23,  1.86it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1847  (40.3):  92%|| 1846/2000 [26:29<01:22,  1.86it/s]\u001b[A\n",
      "Average Metric: 744 / 1847  (40.3):  92%|| 1847/2000 [26:29<00:53,  2.87it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 744 / 1848  (40.3):  92%|| 1847/2000 [26:30<00:53,  2.87it/s]\u001b[A\n",
      "Average Metric: 744 / 1848  (40.3):  92%|| 1848/2000 [26:30<00:46,  3.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 745 / 1849  (40.3):  92%|| 1848/2000 [26:30<00:46,  3.26it/s]\u001b[A\n",
      "Average Metric: 745 / 1849  (40.3):  92%|| 1849/2000 [26:30<00:51,  2.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 746 / 1850  (40.3):  92%|| 1849/2000 [26:30<00:51,  2.91it/s]\u001b[A\n",
      "Average Metric: 746 / 1850  (40.3):  92%|| 1850/2000 [26:30<00:50,  2.97it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1851  (40.4):  92%|| 1850/2000 [26:31<00:50,  2.97it/s]\u001b[A\n",
      "Average Metric: 747 / 1851  (40.4):  93%|| 1851/2000 [26:31<00:53,  2.76it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1852  (40.3):  93%|| 1851/2000 [26:33<00:53,  2.76it/s]\u001b[A\n",
      "Average Metric: 747 / 1852  (40.3):  93%|| 1852/2000 [26:33<01:52,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1853  (40.3):  93%|| 1852/2000 [26:33<01:52,  1.32it/s]\u001b[A\n",
      "Average Metric: 747 / 1853  (40.3):  93%|| 1853/2000 [26:33<01:29,  1.64it/s]\u001b[A\n",
      "Average Metric: 747 / 1854  (40.3):  93%|| 1853/2000 [26:34<01:29,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 747 / 1854  (40.3):  93%|| 1854/2000 [26:34<02:07,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1855  (40.3):  93%|| 1854/2000 [26:35<02:07,  1.14it/s]\u001b[A\n",
      "Average Metric: 747 / 1855  (40.3):  93%|| 1855/2000 [26:35<01:55,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 747 / 1856  (40.2):  93%|| 1855/2000 [26:36<01:55,  1.25it/s]\u001b[A\n",
      "Average Metric: 747 / 1856  (40.2):  93%|| 1856/2000 [26:36<01:51,  1.29it/s]\u001b[A\n",
      "Average Metric: 748 / 1857  (40.3):  93%|| 1856/2000 [26:37<01:51,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 748 / 1857  (40.3):  93%|| 1857/2000 [26:37<02:17,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1858  (40.3):  93%|| 1857/2000 [26:37<02:17,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1859  (40.3):  93%|| 1858/2000 [26:38<02:16,  1.04it/s]\u001b[A\n",
      "Average Metric: 749 / 1859  (40.3):  93%|| 1859/2000 [26:38<01:27,  1.60it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1860  (40.3):  93%|| 1859/2000 [26:41<01:27,  1.60it/s]\u001b[A\n",
      "Average Metric: 749 / 1860  (40.3):  93%|| 1860/2000 [26:41<02:55,  1.25s/it]\u001b[A\n",
      "Average Metric: 750 / 1861  (40.3):  93%|| 1860/2000 [26:41<02:55,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 750 / 1861  (40.3):  93%|| 1861/2000 [26:41<02:22,  1.02s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 751 / 1862  (40.3):  93%|| 1861/2000 [26:41<02:22,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 751 / 1862  (40.3):  93%|| 1862/2000 [26:41<01:48,  1.27it/s]\u001b[A\n",
      "Average Metric: 751 / 1863  (40.3):  93%|| 1862/2000 [26:41<01:48,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 752 / 1864  (40.3):  93%|| 1863/2000 [26:42<01:48,  1.27it/s]\u001b[A\n",
      "Average Metric: 752 / 1864  (40.3):  93%|| 1864/2000 [26:42<01:17,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 753 / 1865  (40.4):  93%|| 1864/2000 [26:42<01:17,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 753 / 1865  (40.4):  93%|| 1865/2000 [26:42<01:16,  1.77it/s]\u001b[A\n",
      "Average Metric: 753 / 1866  (40.4):  93%|| 1865/2000 [26:42<01:16,  1.77it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 754 / 1867  (40.4):  93%|| 1866/2000 [26:43<01:15,  1.77it/s]\u001b[A\n",
      "Average Metric: 754 / 1867  (40.4):  93%|| 1867/2000 [26:43<01:09,  1.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 754 / 1868  (40.4):  93%|| 1867/2000 [26:44<01:09,  1.91it/s]\u001b[A\n",
      "Average Metric: 754 / 1868  (40.4):  93%|| 1868/2000 [26:44<01:10,  1.87it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 754 / 1869  (40.3):  93%|| 1868/2000 [26:44<01:10,  1.87it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 754 / 1870  (40.3):  93%|| 1869/2000 [26:44<01:09,  1.87it/s]\u001b[A\n",
      "Average Metric: 754 / 1870  (40.3):  94%|| 1870/2000 [26:44<00:45,  2.86it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 755 / 1871  (40.4):  94%|| 1870/2000 [26:44<00:45,  2.86it/s]\u001b[A\n",
      "Average Metric: 755 / 1871  (40.4):  94%|| 1871/2000 [26:44<00:38,  3.32it/s]\u001b[A\n",
      "Average Metric: 755 / 1872  (40.3):  94%|| 1871/2000 [26:44<00:38,  3.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 755 / 1872  (40.3):  94%|| 1872/2000 [26:44<00:37,  3.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 756 / 1873  (40.4):  94%|| 1872/2000 [26:45<00:37,  3.42it/s]\u001b[A\n",
      "Average Metric: 756 / 1873  (40.4):  94%|| 1873/2000 [26:45<00:47,  2.66it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 756 / 1874  (40.3):  94%|| 1873/2000 [26:47<00:47,  2.66it/s]\u001b[A\n",
      "Average Metric: 756 / 1874  (40.3):  94%|| 1874/2000 [26:47<01:26,  1.45it/s]\u001b[A\n",
      "Average Metric: 757 / 1875  (40.4):  94%|| 1874/2000 [26:47<01:26,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 757 / 1875  (40.4):  94%|| 1875/2000 [26:47<01:26,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 757 / 1876  (40.4):  94%|| 1875/2000 [26:48<01:26,  1.45it/s]\u001b[A\n",
      "Average Metric: 757 / 1876  (40.4):  94%|| 1876/2000 [26:48<01:43,  1.20it/s]\u001b[A\n",
      "Average Metric: 758 / 1877  (40.4):  94%|| 1876/2000 [26:48<01:43,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 758 / 1878  (40.4):  94%|| 1877/2000 [26:49<01:42,  1.20it/s]\u001b[A\n",
      "Average Metric: 758 / 1878  (40.4):  94%|| 1878/2000 [26:49<01:14,  1.64it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 759 / 1879  (40.4):  94%|| 1878/2000 [26:50<01:14,  1.64it/s]\u001b[A\n",
      "Average Metric: 759 / 1879  (40.4):  94%|| 1879/2000 [26:50<01:07,  1.79it/s]\u001b[A\n",
      "Average Metric: 759 / 1880  (40.4):  94%|| 1879/2000 [26:51<01:07,  1.79it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 759 / 1880  (40.4):  94%|| 1880/2000 [26:51<01:26,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 760 / 1881  (40.4):  94%|| 1880/2000 [26:52<01:26,  1.38it/s]\u001b[A\n",
      "Average Metric: 760 / 1881  (40.4):  94%|| 1881/2000 [26:52<01:29,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 760 / 1882  (40.4):  94%|| 1881/2000 [26:52<01:29,  1.32it/s]\u001b[A\n",
      "Average Metric: 760 / 1882  (40.4):  94%|| 1882/2000 [26:52<01:14,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 760 / 1883  (40.4):  94%|| 1882/2000 [26:53<01:14,  1.57it/s]\u001b[A\n",
      "Average Metric: 760 / 1883  (40.4):  94%|| 1883/2000 [26:53<01:14,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 761 / 1884  (40.4):  94%|| 1883/2000 [26:53<01:14,  1.56it/s]\u001b[A\n",
      "Average Metric: 761 / 1884  (40.4):  94%|| 1884/2000 [26:53<00:56,  2.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 762 / 1885  (40.4):  94%|| 1884/2000 [26:53<00:56,  2.05it/s]\u001b[A\n",
      "Average Metric: 763 / 1886  (40.5):  94%|| 1885/2000 [26:53<00:56,  2.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 763 / 1886  (40.5):  94%|| 1886/2000 [26:53<00:49,  2.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 764 / 1887  (40.5):  94%|| 1886/2000 [26:54<00:49,  2.29it/s]\u001b[A\n",
      "Average Metric: 764 / 1887  (40.5):  94%|| 1887/2000 [26:54<00:45,  2.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 764 / 1888  (40.5):  94%|| 1887/2000 [26:54<00:45,  2.50it/s]\u001b[A\n",
      "Average Metric: 764 / 1888  (40.5):  94%|| 1888/2000 [26:54<00:47,  2.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 765 / 1889  (40.5):  94%|| 1888/2000 [26:55<00:47,  2.34it/s]\u001b[A\n",
      "Average Metric: 765 / 1889  (40.5):  94%|| 1889/2000 [26:55<00:48,  2.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 765 / 1890  (40.5):  94%|| 1889/2000 [26:55<00:48,  2.30it/s]\u001b[A\n",
      "Average Metric: 765 / 1890  (40.5):  94%|| 1890/2000 [26:55<00:52,  2.08it/s]\u001b[A\n",
      "Average Metric: 765 / 1891  (40.5):  94%|| 1890/2000 [26:55<00:52,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 765 / 1891  (40.5):  95%|| 1891/2000 [26:55<00:42,  2.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 766 / 1892  (40.5):  95%|| 1891/2000 [26:56<00:42,  2.56it/s]\u001b[A\n",
      "Average Metric: 766 / 1892  (40.5):  95%|| 1892/2000 [26:56<00:42,  2.55it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 766 / 1893  (40.5):  95%|| 1892/2000 [26:56<00:42,  2.55it/s]\u001b[A\n",
      "Average Metric: 766 / 1893  (40.5):  95%|| 1893/2000 [26:56<00:37,  2.82it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 766 / 1894  (40.4):  95%|| 1893/2000 [26:58<00:37,  2.82it/s]\u001b[A\n",
      "Average Metric: 766 / 1894  (40.4):  95%|| 1894/2000 [26:58<01:16,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 767 / 1895  (40.5):  95%|| 1894/2000 [26:58<01:16,  1.38it/s]\u001b[A\n",
      "Average Metric: 767 / 1895  (40.5):  95%|| 1895/2000 [26:58<01:08,  1.54it/s]\u001b[A\n",
      "Average Metric: 767 / 1896  (40.5):  95%|| 1895/2000 [26:58<01:08,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 767 / 1896  (40.5):  95%|| 1896/2000 [26:58<00:51,  2.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 768 / 1897  (40.5):  95%|| 1896/2000 [26:59<00:51,  2.02it/s]\u001b[A\n",
      "Average Metric: 768 / 1897  (40.5):  95%|| 1897/2000 [26:59<00:50,  2.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 768 / 1898  (40.5):  95%|| 1897/2000 [26:59<00:50,  2.06it/s]\u001b[A\n",
      "Average Metric: 768 / 1898  (40.5):  95%|| 1898/2000 [26:59<00:52,  1.95it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 768 / 1899  (40.4):  95%|| 1898/2000 [27:00<00:52,  1.95it/s]\u001b[A\n",
      "Average Metric: 768 / 1899  (40.4):  95%|| 1899/2000 [27:00<00:52,  1.93it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 769 / 1900  (40.5):  95%|| 1899/2000 [27:01<00:52,  1.93it/s]\u001b[A\n",
      "Average Metric: 769 / 1900  (40.5):  95%|| 1900/2000 [27:01<01:09,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 769 / 1901  (40.5):  95%|| 1900/2000 [27:02<01:09,  1.44it/s]\u001b[A\n",
      "Average Metric: 769 / 1901  (40.5):  95%|| 1901/2000 [27:02<01:33,  1.06it/s]\u001b[A\n",
      "Average Metric: 770 / 1902  (40.5):  95%|| 1901/2000 [27:03<01:33,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 770 / 1902  (40.5):  95%|| 1902/2000 [27:03<01:23,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1903  (40.5):  95%|| 1902/2000 [27:03<01:23,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1904  (40.4):  95%|| 1903/2000 [27:04<01:22,  1.18it/s]\u001b[A\n",
      "Average Metric: 770 / 1904  (40.4):  95%|| 1904/2000 [27:04<00:59,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 770 / 1905  (40.4):  95%|| 1904/2000 [27:04<00:59,  1.62it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 770 / 1906  (40.4):  95%|| 1905/2000 [27:05<00:58,  1.62it/s]\u001b[A\n",
      "Average Metric: 770 / 1906  (40.4):  95%|| 1906/2000 [27:05<00:54,  1.73it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1907  (40.4):  95%|| 1906/2000 [27:06<00:54,  1.73it/s]\u001b[A\n",
      "Average Metric: 770 / 1907  (40.4):  95%|| 1907/2000 [27:06<00:56,  1.65it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1908  (40.4):  95%|| 1907/2000 [27:06<00:56,  1.65it/s]\u001b[A\n",
      "Average Metric: 770 / 1908  (40.4):  95%|| 1908/2000 [27:06<00:50,  1.82it/s]\u001b[A\n",
      "Average Metric: 771 / 1909  (40.4):  95%|| 1908/2000 [27:07<00:50,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 771 / 1909  (40.4):  95%|| 1909/2000 [27:07<00:54,  1.68it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 771 / 1910  (40.4):  95%|| 1909/2000 [27:07<00:54,  1.68it/s]\u001b[A\n",
      "Average Metric: 771 / 1910  (40.4):  96%|| 1910/2000 [27:07<00:42,  2.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 771 / 1911  (40.3):  96%|| 1910/2000 [27:07<00:42,  2.13it/s]\u001b[A\n",
      "Average Metric: 771 / 1911  (40.3):  96%|| 1911/2000 [27:07<00:35,  2.50it/s]\u001b[A\n",
      "Average Metric: 771 / 1912  (40.3):  96%|| 1911/2000 [27:07<00:35,  2.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 771 / 1912  (40.3):  96%|| 1912/2000 [27:07<00:31,  2.79it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 772 / 1913  (40.4):  96%|| 1912/2000 [27:08<00:31,  2.79it/s]\u001b[A\n",
      "Average Metric: 772 / 1913  (40.4):  96%|| 1913/2000 [27:08<00:38,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 773 / 1914  (40.4):  96%|| 1913/2000 [27:09<00:38,  2.29it/s]\u001b[A\n",
      "Average Metric: 773 / 1914  (40.4):  96%|| 1914/2000 [27:09<00:50,  1.72it/s]\u001b[A\n",
      "Average Metric: 773 / 1915  (40.4):  96%|| 1914/2000 [27:09<00:50,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 773 / 1915  (40.4):  96%|| 1915/2000 [27:09<00:42,  1.99it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1916  (40.3):  96%|| 1915/2000 [27:10<00:42,  1.99it/s]\u001b[A\n",
      "Average Metric: 773 / 1916  (40.3):  96%|| 1916/2000 [27:10<00:39,  2.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1917  (40.3):  96%|| 1916/2000 [27:10<00:39,  2.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1918  (40.3):  96%|| 1917/2000 [27:11<00:38,  2.14it/s]\u001b[A\n",
      "Average Metric: 773 / 1918  (40.3):  96%|| 1918/2000 [27:11<00:41,  1.97it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1919  (40.3):  96%|| 1918/2000 [27:11<00:41,  1.97it/s]\u001b[A\n",
      "Average Metric: 773 / 1919  (40.3):  96%|| 1919/2000 [27:11<00:35,  2.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 774 / 1920  (40.3):  96%|| 1919/2000 [27:11<00:35,  2.28it/s]\u001b[A\n",
      "Average Metric: 774 / 1920  (40.3):  96%|| 1920/2000 [27:11<00:37,  2.12it/s]\u001b[A\n",
      "Average Metric: 774 / 1921  (40.3):  96%|| 1920/2000 [27:12<00:37,  2.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1921  (40.3):  96%|| 1921/2000 [27:12<00:49,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1922  (40.3):  96%|| 1921/2000 [27:12<00:49,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1923  (40.2):  96%|| 1922/2000 [27:12<00:48,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 774 / 1924  (40.2):  96%|| 1923/2000 [27:13<00:47,  1.61it/s]\u001b[A\n",
      "Average Metric: 774 / 1924  (40.2):  96%|| 1924/2000 [27:13<00:32,  2.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'alein'? A: ranges B: bear C: rights D: alien\n",
      "Answer: D: alien\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the smallest mammal? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 774 / 1925  (40.2):  96%|| 1924/2000 [27:14<00:32,  2.34it/s]\u001b[A\n",
      "Average Metric: 774 / 1925  (40.2):  96%|| 1925/2000 [27:14<00:41,  1.79it/s]\u001b[A\n",
      "Average Metric: 774 / 1926  (40.2):  96%|| 1925/2000 [27:15<00:41,  1.79it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 774 / 1926  (40.2):  96%|| 1926/2000 [27:15<00:43,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1927  (40.2):  96%|| 1926/2000 [27:15<00:43,  1.72it/s]\u001b[A\n",
      "Average Metric: 774 / 1927  (40.2):  96%|| 1927/2000 [27:15<00:35,  2.06it/s]\u001b[A\n",
      "Average Metric: 774 / 1928  (40.1):  96%|| 1927/2000 [27:15<00:35,  2.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 774 / 1928  (40.1):  96%|| 1928/2000 [27:15<00:29,  2.42it/s]\u001b[A\n",
      "Average Metric: 774 / 1929  (40.1):  96%|| 1928/2000 [27:15<00:29,  2.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1930  (40.1):  96%|| 1929/2000 [27:16<00:29,  2.42it/s]\u001b[A\n",
      "Average Metric: 774 / 1930  (40.1):  96%|| 1930/2000 [27:16<00:21,  3.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1931  (40.1):  96%|| 1930/2000 [27:16<00:21,  3.25it/s]\u001b[A\n",
      "Average Metric: 775 / 1931  (40.1):  97%|| 1931/2000 [27:16<00:23,  2.99it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1932  (40.1):  97%|| 1931/2000 [27:18<00:23,  2.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 775 / 1932  (40.1):  97%|| 1932/2000 [27:18<00:55,  1.23it/s]\u001b[A\n",
      "Average Metric: 775 / 1933  (40.1):  97%|| 1932/2000 [27:18<00:55,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 775 / 1934  (40.1):  97%|| 1933/2000 [27:18<00:54,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 775 / 1935  (40.1):  97%|| 1934/2000 [27:19<00:53,  1.23it/s]\u001b[A\n",
      "Average Metric: 775 / 1935  (40.1):  97%|| 1935/2000 [27:19<00:27,  2.33it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1936  (40.0):  97%|| 1935/2000 [27:19<00:27,  2.33it/s]\u001b[A\n",
      "Average Metric: 775 / 1936  (40.0):  97%|| 1936/2000 [27:19<00:24,  2.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1937  (40.0):  97%|| 1936/2000 [27:19<00:24,  2.61it/s]\u001b[A\n",
      "Average Metric: 775 / 1937  (40.0):  97%|| 1937/2000 [27:19<00:27,  2.33it/s]\u001b[A\n",
      "Average Metric: 775 / 1938  (40.0):  97%|| 1937/2000 [27:20<00:27,  2.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 775 / 1938  (40.0):  97%|| 1938/2000 [27:20<00:33,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1939  (40.0):  97%|| 1938/2000 [27:20<00:33,  1.84it/s]\u001b[A\n",
      "Average Metric: 775 / 1939  (40.0):  97%|| 1939/2000 [27:20<00:26,  2.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 776 / 1940  (40.0):  97%|| 1939/2000 [27:21<00:26,  2.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 776 / 1940  (40.0):  97%|| 1940/2000 [27:21<00:25,  2.33it/s]\u001b[A\n",
      "Average Metric: 776 / 1941  (40.0):  97%|| 1940/2000 [27:21<00:25,  2.33it/s]\u001b[A\n",
      "Average Metric: 776 / 1942  (40.0):  97%|| 1941/2000 [27:22<00:25,  2.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 776 / 1942  (40.0):  97%|| 1942/2000 [27:22<00:30,  1.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 776 / 1943  (39.9):  97%|| 1942/2000 [27:23<00:30,  1.90it/s]\u001b[A\n",
      "Average Metric: 776 / 1943  (39.9):  97%|| 1943/2000 [27:23<00:31,  1.81it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 777 / 1944  (40.0):  97%|| 1943/2000 [27:23<00:31,  1.81it/s]\u001b[A\n",
      "Average Metric: 777 / 1944  (40.0):  97%|| 1944/2000 [27:23<00:27,  2.03it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 778 / 1945  (40.0):  97%|| 1944/2000 [27:24<00:27,  2.03it/s]\u001b[A\n",
      "Average Metric: 778 / 1945  (40.0):  97%|| 1945/2000 [27:24<00:28,  1.93it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1946  (40.0):  97%|| 1945/2000 [27:25<00:28,  1.93it/s]\u001b[A\n",
      "Average Metric: 779 / 1946  (40.0):  97%|| 1946/2000 [27:25<00:33,  1.60it/s]\u001b[A\n",
      "Average Metric: 779 / 1947  (40.0):  97%|| 1946/2000 [27:26<00:33,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 779 / 1947  (40.0):  97%|| 1947/2000 [27:26<00:44,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1948  (40.0):  97%|| 1947/2000 [27:26<00:44,  1.18it/s]\u001b[A\n",
      "Average Metric: 779 / 1948  (40.0):  97%|| 1948/2000 [27:26<00:34,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1949  (40.0):  97%|| 1948/2000 [27:26<00:34,  1.50it/s]\u001b[A\n",
      "Average Metric: 779 / 1949  (40.0):  97%|| 1949/2000 [27:26<00:26,  1.90it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1950  (39.9):  97%|| 1949/2000 [27:27<00:26,  1.90it/s]\u001b[A\n",
      "Average Metric: 779 / 1950  (39.9):  98%|| 1950/2000 [27:27<00:29,  1.70it/s]\u001b[A\n",
      "Average Metric: 779 / 1951  (39.9):  98%|| 1950/2000 [27:28<00:29,  1.70it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 779 / 1951  (39.9):  98%|| 1951/2000 [27:28<00:35,  1.36it/s]\u001b[A\n",
      "Average Metric: 779 / 1952  (39.9):  98%|| 1951/2000 [27:29<00:35,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 779 / 1952  (39.9):  98%|| 1952/2000 [27:29<00:32,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 780 / 1953  (39.9):  98%|| 1952/2000 [27:29<00:32,  1.49it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 780 / 1953  (39.9):  98%|| 1953/2000 [27:29<00:27,  1.72it/s]\u001b[A\n",
      "Average Metric: 781 / 1954  (40.0):  98%|| 1953/2000 [27:29<00:27,  1.72it/s]\u001b[A\n",
      "Average Metric: 781 / 1955  (39.9):  98%|| 1954/2000 [27:31<00:26,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 781 / 1955  (39.9):  98%|| 1955/2000 [27:31<00:31,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 781 / 1956  (39.9):  98%|| 1955/2000 [27:31<00:31,  1.43it/s]\u001b[A\n",
      "Average Metric: 781 / 1956  (39.9):  98%|| 1956/2000 [27:31<00:25,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 782 / 1957  (40.0):  98%|| 1956/2000 [27:31<00:25,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 783 / 1958  (40.0):  98%|| 1957/2000 [27:31<00:24,  1.75it/s]\u001b[A\n",
      "Average Metric: 783 / 1958  (40.0):  98%|| 1958/2000 [27:31<00:18,  2.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 783 / 1959  (40.0):  98%|| 1958/2000 [27:32<00:18,  2.31it/s]\u001b[A\n",
      "Average Metric: 783 / 1959  (40.0):  98%|| 1959/2000 [27:32<00:16,  2.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 783 / 1960  (39.9):  98%|| 1959/2000 [27:32<00:16,  2.48it/s]\u001b[A\n",
      "Average Metric: 783 / 1960  (39.9):  98%|| 1960/2000 [27:32<00:14,  2.69it/s]\u001b[A\n",
      "Average Metric: 783 / 1961  (39.9):  98%|| 1960/2000 [27:32<00:14,  2.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 783 / 1961  (39.9):  98%|| 1961/2000 [27:32<00:13,  2.84it/s]\u001b[A\n",
      "Average Metric: 784 / 1962  (40.0):  98%|| 1961/2000 [27:33<00:13,  2.84it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 784 / 1962  (40.0):  98%|| 1962/2000 [27:34<00:22,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 785 / 1963  (40.0):  98%|| 1962/2000 [27:34<00:22,  1.71it/s]\u001b[A\n",
      "Average Metric: 785 / 1963  (40.0):  98%|| 1963/2000 [27:35<00:26,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 786 / 1964  (40.0):  98%|| 1963/2000 [27:35<00:26,  1.42it/s]\u001b[A\n",
      "Average Metric: 786 / 1964  (40.0):  98%|| 1964/2000 [27:35<00:25,  1.39it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 786 / 1965  (40.0):  98%|| 1964/2000 [27:37<00:25,  1.39it/s]\u001b[A\n",
      "Average Metric: 786 / 1965  (40.0):  98%|| 1965/2000 [27:37<00:30,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 786 / 1966  (40.0):  98%|| 1965/2000 [27:37<00:30,  1.15it/s]\u001b[A\n",
      "Average Metric: 786 / 1966  (40.0):  98%|| 1966/2000 [27:37<00:25,  1.34it/s]\u001b[A\n",
      "Average Metric: 787 / 1967  (40.0):  98%|| 1966/2000 [27:37<00:25,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 787 / 1967  (40.0):  98%|| 1967/2000 [27:37<00:19,  1.72it/s]\u001b[A\n",
      "Average Metric: 787 / 1968  (40.0):  98%|| 1967/2000 [27:37<00:19,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 787 / 1968  (40.0):  98%|| 1968/2000 [27:37<00:14,  2.17it/s]\u001b[A\n",
      "Average Metric: 787 / 1969  (40.0):  98%|| 1968/2000 [27:37<00:14,  2.17it/s]\u001b[A\n",
      "Average Metric: 787 / 1970  (39.9):  98%|| 1969/2000 [27:38<00:14,  2.17it/s]\u001b[A\n",
      "Average Metric: 787 / 1970  (39.9):  98%|| 1970/2000 [27:38<00:12,  2.31it/s]\u001b[A\n",
      "Average Metric: 787 / 1971  (39.9):  98%|| 1970/2000 [27:38<00:12,  2.31it/s]\u001b[A\n",
      "Average Metric: 787 / 1971  (39.9):  99%|| 1971/2000 [27:38<00:10,  2.72it/s]\u001b[A\n",
      "Average Metric: 788 / 1972  (40.0):  99%|| 1971/2000 [27:39<00:10,  2.72it/s]\u001b[A\n",
      "Average Metric: 788 / 1972  (40.0):  99%|| 1972/2000 [27:39<00:12,  2.17it/s]\u001b[A\n",
      "Average Metric: 788 / 1973  (39.9):  99%|| 1972/2000 [27:39<00:12,  2.17it/s]\u001b[A\n",
      "Average Metric: 788 / 1973  (39.9):  99%|| 1973/2000 [27:39<00:12,  2.23it/s]\u001b[A\n",
      "Average Metric: 789 / 1974  (40.0):  99%|| 1973/2000 [27:40<00:12,  2.23it/s]\u001b[A\n",
      "Average Metric: 789 / 1975  (39.9):  99%|| 1974/2000 [27:40<00:11,  2.23it/s]\u001b[A\n",
      "Average Metric: 789 / 1975  (39.9):  99%|| 1975/2000 [27:40<00:07,  3.52it/s]\u001b[A\n",
      "Average Metric: 789 / 1976  (39.9):  99%|| 1975/2000 [27:40<00:07,  3.52it/s]\u001b[A\n",
      "Average Metric: 790 / 1977  (40.0):  99%|| 1976/2000 [27:40<00:06,  3.52it/s]\u001b[A\n",
      "Average Metric: 790 / 1977  (40.0):  99%|| 1977/2000 [27:40<00:04,  4.86it/s]\u001b[A\n",
      "Average Metric: 790 / 1978  (39.9):  99%|| 1977/2000 [27:41<00:04,  4.86it/s]\u001b[A\n",
      "Average Metric: 790 / 1978  (39.9):  99%|| 1978/2000 [27:41<00:09,  2.29it/s]\u001b[A\n",
      "Average Metric: 791 / 1979  (40.0):  99%|| 1978/2000 [27:42<00:09,  2.29it/s]\u001b[A\n",
      "Average Metric: 791 / 1979  (40.0):  99%|| 1979/2000 [27:42<00:10,  2.08it/s]\u001b[A\n",
      "Average Metric: 792 / 1980  (40.0):  99%|| 1979/2000 [27:43<00:10,  2.08it/s]\u001b[A\n",
      "Average Metric: 792 / 1980  (40.0):  99%|| 1980/2000 [27:43<00:13,  1.53it/s]\u001b[A\n",
      "Average Metric: 792 / 1981  (40.0):  99%|| 1980/2000 [27:43<00:13,  1.53it/s]\u001b[A\n",
      "Average Metric: 793 / 1982  (40.0):  99%|| 1981/2000 [27:43<00:12,  1.53it/s]\u001b[A\n",
      "Average Metric: 793 / 1982  (40.0):  99%|| 1982/2000 [27:43<00:09,  1.90it/s]\u001b[A\n",
      "Average Metric: 794 / 1983  (40.0):  99%|| 1982/2000 [27:44<00:09,  1.90it/s]\u001b[A\n",
      "Average Metric: 794 / 1983  (40.0):  99%|| 1983/2000 [27:44<00:08,  2.06it/s]\u001b[A\n",
      "Average Metric: 795 / 1984  (40.1):  99%|| 1983/2000 [27:45<00:08,  2.06it/s]\u001b[A\n",
      "Average Metric: 795 / 1984  (40.1):  99%|| 1984/2000 [27:45<00:09,  1.76it/s]\u001b[A\n",
      "Average Metric: 796 / 1985  (40.1):  99%|| 1984/2000 [27:45<00:09,  1.76it/s]\u001b[A\n",
      "Average Metric: 796 / 1985  (40.1):  99%|| 1985/2000 [27:45<00:09,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1986  (40.1):  99%|| 1985/2000 [27:46<00:09,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1986  (40.1):  99%|| 1986/2000 [27:46<00:08,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1987  (40.1):  99%|| 1986/2000 [27:46<00:08,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1988  (40.1):  99%|| 1987/2000 [27:52<00:08,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1988  (40.1):  99%|| 1988/2000 [27:52<00:20,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hmoes'? A: coming B: hood C: homes D: avril\n",
      "Answer: D: avril\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the smallest mammal? A: Elephant B: Whale C: Mouse D: Giraffe\n",
      "Answer: C: Mouse\n",
      "\n",
      "Question: What is the largest country in the world\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fahetr' to form the correct word. A: enabling B: fisher C: father D: limitations\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest value?  (a) 0.1  (b) 0.01  (c) 0.001  (d) 0.0001\n",
      "Answer: d\n",
      "\n",
      "Question: Which of the following is the capital of France?  (a) Berlin  (b) Madrid  (c) Paris  (d) Rome\n",
      "Answer: c\n",
      "\n",
      "Question: Which of the following is the largest value?  (a) 0.1  (b) 0.01  (c) 0.001  (d) 0.0001\n",
      "Answer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vmiitnas'? A: comprised B: major C: healthy D: vitamins\n",
      "Answer: D: vitamins\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Earth B: Mars C: Jupiter D: Venus\n",
      "Answer: C: Jupiter\n",
      "\n",
      "Question: What is the smallest country in the world? A: Australia B: Canada C: Monaco D: China\n",
      "Answer: D: China\n",
      "\n",
      "Question: What is the highest mountain in the world? A: Mount Everest B: Kangchenjunga C: K2 D: Lhotse\n",
      "Answer: A: Mount Everest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 797 / 1989  (40.1):  99%|| 1988/2000 [28:32<00:20,  1.71s/it]\u001b[A\n",
      "Average Metric: 797 / 1989  (40.1):  99%|| 1989/2000 [28:32<01:57, 10.68s/it]\u001b[A\n",
      "Average Metric: 797 / 1990  (40.1):  99%|| 1989/2000 [28:32<01:57, 10.68s/it]\u001b[A\n",
      "Average Metric: 797 / 1990  (40.1): 100%|| 1990/2000 [28:32<01:20,  8.02s/it]\u001b[A\n",
      "Average Metric: 797 / 1991  (40.0): 100%|| 1990/2000 [28:34<01:20,  8.02s/it]\u001b[A\n",
      "Average Metric: 797 / 1991  (40.0): 100%|| 1991/2000 [28:34<00:57,  6.36s/it]\u001b[A\n",
      "Average Metric: 797 / 1992  (40.0): 100%|| 1991/2000 [28:35<00:57,  6.36s/it]\u001b[A\n",
      "Average Metric: 797 / 1992  (40.0): 100%|| 1992/2000 [28:35<00:40,  5.09s/it]\u001b[A\n",
      "Average Metric: 797 / 1993  (40.0): 100%|| 1992/2000 [28:37<00:40,  5.09s/it]\u001b[A\n",
      "Average Metric: 797 / 1993  (40.0): 100%|| 1993/2000 [28:37<00:28,  4.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'afnfitceg'? A: infected B: ruled C: norman D: affecting\n",
      "Answer: D: affecting\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the capital of Spain? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 797 / 1994  (40.0): 100%|| 1993/2000 [28:39<00:28,  4.14s/it]\u001b[A\n",
      "Average Metric: 797 / 1994  (40.0): 100%|| 1994/2000 [28:39<00:20,  3.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vatil'? A: nebraska B: terrace C: testing D: vital\n",
      "Answer: D: vital\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which planet is closest to the sun? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: elephant B: whale C: bear D: giraffe\n",
      "Answer: B: whale\n",
      "\n",
      "Question: What is the smallest country in the world? A: vatican city B: monaco C: san marino D: liechtenstein\n",
      "Answer: A: vatican city\n",
      "\n",
      "Question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 797 / 1995  (39.9): 100%|| 1994/2000 [28:47<00:20,  3.35s/it]\u001b[A\n",
      "Average Metric: 797 / 1995  (39.9): 100%|| 1995/2000 [28:47<00:24,  4.89s/it]\u001b[A\n",
      "Average Metric: 798 / 1996  (40.0): 100%|| 1995/2000 [28:54<00:24,  4.89s/it]\u001b[A\n",
      "Average Metric: 798 / 1996  (40.0): 100%|| 1996/2000 [28:54<00:21,  5.33s/it]\u001b[A\n",
      "Average Metric: 799 / 1997  (40.0): 100%|| 1996/2000 [28:55<00:21,  5.33s/it]\u001b[A\n",
      "Average Metric: 799 / 1997  (40.0): 100%|| 1997/2000 [28:55<00:12,  4.25s/it]\u001b[A\n",
      "Average Metric: 799 / 1998  (40.0): 100%|| 1997/2000 [28:57<00:12,  4.25s/it]\u001b[A\n",
      "Average Metric: 799 / 1998  (40.0): 100%|| 1998/2000 [28:57<00:06,  3.38s/it]\u001b[A\n",
      "Average Metric: 799 / 1999  (40.0): 100%|| 1998/2000 [28:58<00:06,  3.38s/it]\u001b[A\n",
      "Average Metric: 799 / 1999  (40.0): 100%|| 1999/2000 [28:58<00:02,  2.81s/it]\u001b[A\n",
      "Average Metric: 799 / 2000  (40.0): 100%|| 1999/2000 [28:58<00:02,  2.81s/it]\u001b[A\n",
      "Average Metric: 799 / 2000  (40.0): 100%|| 2000/2000 [28:58<00:00,  1.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 799 / 2000  (40.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_31156 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_31156 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_31156_row0_col0, #T_31156_row0_col1, #T_31156_row0_col2, #T_31156_row0_col3, #T_31156_row0_col4, #T_31156_row0_col5, #T_31156_row1_col0, #T_31156_row1_col1, #T_31156_row1_col2, #T_31156_row1_col3, #T_31156_row1_col4, #T_31156_row1_col5, #T_31156_row2_col0, #T_31156_row2_col1, #T_31156_row2_col2, #T_31156_row2_col3, #T_31156_row2_col4, #T_31156_row2_col5, #T_31156_row3_col0, #T_31156_row3_col1, #T_31156_row3_col2, #T_31156_row3_col3, #T_31156_row3_col4, #T_31156_row3_col5, #T_31156_row4_col0, #T_31156_row4_col1, #T_31156_row4_col2, #T_31156_row4_col3, #T_31156_row4_col4, #T_31156_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_31156\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_31156_level0_col0\" class=\"col_heading level0 col0\" >example_answer</th>\n",
       "      <th id=\"T_31156_level0_col1\" class=\"col_heading level0 col1\" >word</th>\n",
       "      <th id=\"T_31156_level0_col2\" class=\"col_heading level0 col2\" >scrambled</th>\n",
       "      <th id=\"T_31156_level0_col3\" class=\"col_heading level0 col3\" >question</th>\n",
       "      <th id=\"T_31156_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_31156_level0_col5\" class=\"col_heading level0 col5\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_31156_row0_col0\" class=\"data row0 col0\" >B</td>\n",
       "      <td id=\"T_31156_row0_col1\" class=\"data row0 col1\" >knee</td>\n",
       "      <td id=\"T_31156_row0_col2\" class=\"data row0 col2\" >kene</td>\n",
       "      <td id=\"T_31156_row0_col3\" class=\"data row0 col3\" >Can you unscramble 'kene'?\n",
       "A: raymond\n",
       "B: knee\n",
       "C: take\n",
       "D: consumption</td>\n",
       "      <td id=\"T_31156_row0_col4\" class=\"data row0 col4\" >B</td>\n",
       "      <td id=\"T_31156_row0_col5\" class=\"data row0 col5\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_31156_row1_col0\" class=\"data row1 col0\" >D</td>\n",
       "      <td id=\"T_31156_row1_col1\" class=\"data row1 col1\" >camcorders</td>\n",
       "      <td id=\"T_31156_row1_col2\" class=\"data row1 col2\" >cmorarecds</td>\n",
       "      <td id=\"T_31156_row1_col3\" class=\"data row1 col3\" >Decode the word 'cmorarecds'.\n",
       "A: charitable\n",
       "B: thats\n",
       "C: univ\n",
       "D: camcorders</td>\n",
       "      <td id=\"T_31156_row1_col4\" class=\"data row1 col4\" >D</td>\n",
       "      <td id=\"T_31156_row1_col5\" class=\"data row1 col5\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_31156_row2_col0\" class=\"data row2 col0\" >C</td>\n",
       "      <td id=\"T_31156_row2_col1\" class=\"data row2 col1\" >heat</td>\n",
       "      <td id=\"T_31156_row2_col2\" class=\"data row2 col2\" >haet</td>\n",
       "      <td id=\"T_31156_row2_col3\" class=\"data row2 col3\" >Decode the word 'haet'.\n",
       "A: babes\n",
       "B: competent\n",
       "C: heat\n",
       "D: dogs</td>\n",
       "      <td id=\"T_31156_row2_col4\" class=\"data row2 col4\" >D</td>\n",
       "      <td id=\"T_31156_row2_col5\" class=\"data row2 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_31156_row3_col0\" class=\"data row3 col0\" >C</td>\n",
       "      <td id=\"T_31156_row3_col1\" class=\"data row3 col1\" >brochure</td>\n",
       "      <td id=\"T_31156_row3_col2\" class=\"data row3 col2\" >bruchore</td>\n",
       "      <td id=\"T_31156_row3_col3\" class=\"data row3 col3\" >Can you unscramble 'bruchore'?\n",
       "A: acrylic\n",
       "B: monroe\n",
       "C: brochure\n",
       "D: products</td>\n",
       "      <td id=\"T_31156_row3_col4\" class=\"data row3 col4\" >C</td>\n",
       "      <td id=\"T_31156_row3_col5\" class=\"data row3 col5\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_31156_row4_col0\" class=\"data row4 col0\" >B</td>\n",
       "      <td id=\"T_31156_row4_col1\" class=\"data row4 col1\" >grass</td>\n",
       "      <td id=\"T_31156_row4_col2\" class=\"data row4 col2\" >gasrs</td>\n",
       "      <td id=\"T_31156_row4_col3\" class=\"data row4 col3\" >Rearrange the letters in 'gasrs' to form the correct word.\n",
       "A: valuable\n",
       "B: grass\n",
       "C: fresno\n",
       "D: dept</td>\n",
       "      <td id=\"T_31156_row4_col4\" class=\"data row4 col4\" >D</td>\n",
       "      <td id=\"T_31156_row4_col5\" class=\"data row4 col5\" > [False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f46c855f280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1995 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "39.95"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=test_set, num_threads=32, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(generate_answer_with_chain_of_thought, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwpFBOZK6p0G",
    "outputId": "e778154a-cbf7-4998-e71f-6b43a358e1a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/6000 [00:00<00:05, 1175.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    return answer_EM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_cot = teleprompter.compile(CoT(), trainset=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANBEb8Ww9Ooy",
    "outputId": "98806449-8911-4200-cb00-352006f1b068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_answer\n",
      "Example({'augmented': True, 'question': \"Rearrange the letters in 'prohept' to form the correct word.\\nA: prophet\\nB: jessica\\nC: child\\nD: respected\", 'rationale': 'produce the answer. We can rearrange the letters to form the word \"prophet.\"', 'answer': 'A'}) (input_keys=None)\n",
      "Example({'augmented': True, 'question': \"Decode the word 'beer'.\\nA: eleven\\nB: exercise\\nC: birth\\nD: beer\", 'rationale': \"produce the answer. The word 'beer' is already decoded, so the answer is D.\", 'answer': 'D'}) (input_keys=None)\n",
      "Example({'augmented': True, 'question': \"Rearrange the letters in 'sumoibsinss' to form the correct word.\\nA: expires\\nB: participation\\nC: submissions\\nD: pierre\", 'rationale': \"produce the answer. We can see that the letters 'sumoibsinss' can be rearranged to form the word 'submissions'.\", 'answer': 'C'}) (input_keys=None)\n",
      "Example({'augmented': True, 'question': \"What word does 'mroetnss' represent when unscrambled?\\nA: gone\\nB: tunisia\\nC: monsters\\nD: love\", 'rationale': \"produce the answer. We can see that the letters 'm', 'r', 'o', 'e', 't', 'n', 's', 's' can be rearranged to form the word 'monsters'.\", 'answer': 'C'}) (input_keys=None)\n",
      "Example({'answer': 'B', 'word': 'available', 'scrambled': 'alibavlae', 'question': \"Can you unscramble 'alibavlae'?\\nA: routines\\nB: available\\nC: ebay\\nD: high\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'login', 'scrambled': 'ligon', 'question': \"Decode the word 'ligon'.\\nA: tablet\\nB: qualification\\nC: login\\nD: ratios\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'paula', 'scrambled': 'puala', 'question': \"Find the right word for 'puala'.\\nA: benefit\\nB: zimbabwe\\nC: paula\\nD: operative\"}) (input_keys={'question'})\n",
      "Example({'answer': 'D', 'word': 'larry', 'scrambled': 'lrray', 'question': \"Decode the word 'lrray'.\\nA: noaa\\nB: presence\\nC: flats\\nD: larry\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'handy', 'scrambled': 'hnday', 'question': \"What word does 'hnday' represent when unscrambled?\\nA: franchise\\nB: fight\\nC: handy\\nD: death\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'aging', 'scrambled': 'aingg', 'question': \"What word does 'aingg' represent when unscrambled?\\nA: wine\\nB: glucose\\nC: aging\\nD: motor\"}) (input_keys={'question'})\n",
      "Example({'answer': 'B', 'word': 'vitamin', 'scrambled': 'vimtian', 'question': \"Find the right word for 'vimtian'.\\nA: deviation\\nB: vitamin\\nC: bizrate\\nD: circuits\"}) (input_keys={'question'})\n",
      "Example({'answer': 'B', 'word': 'runs', 'scrambled': 'rnus', 'question': \"Decode the word 'rnus'.\\nA: anything\\nB: runs\\nC: contemporary\\nD: first\"}) (input_keys={'question'})\n",
      "Example({'answer': 'B', 'word': 'deficiency', 'scrambled': 'dnciifceey', 'question': \"Can you unscramble 'dnciifceey'?\\nA: http\\nB: deficiency\\nC: achieved\\nD: stakeholders\"}) (input_keys={'question'})\n",
      "Example({'answer': 'B', 'word': 'larger', 'scrambled': 'lgerar', 'question': \"What word does 'lgerar' represent when unscrambled?\\nA: existence\\nB: larger\\nC: donate\\nD: momentum\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'data', 'scrambled': 'dtaa', 'question': \"Decode the word 'dtaa'.\\nA: humor\\nB: icons\\nC: data\\nD: awful\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'composition', 'scrambled': 'cotioisopmn', 'question': \"Rearrange the letters in 'cotioisopmn' to form the correct word.\\nA: trees\\nB: tagged\\nC: composition\\nD: premises\"}) (input_keys={'question'})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in compiled_cot.named_predictors():\n",
    "    print(name)\n",
    "    for p in parameter.demos:\n",
    "        print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHRQWguG9Uy_",
    "outputId": "e36cd2bb-bc58-4c73-f1ae-f26cf4176d0c"
   },
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_scramble = Evaluate(devset=test_set, num_threads=2, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smHnvL6uePAl"
   },
   "source": [
    "## Finetune T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loS_39JFb7hG",
    "outputId": "0e8a9933-0146-492a-fa57-b1b159774696"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 4/50 [00:00<00:00, 1407.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tp = BootstrapFewShotWithRandomSearch(metric=validate_answer, max_bootstrapped_demos=2, num_threads=2)\n",
    "tp = BootstrapFewShot(metric=validate_answer, max_bootstrapped_demos=4)\n",
    "\n",
    "cot_bs = tp.compile(CoT(), trainset=train_set[:50], valset=validation_set[50:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_LZegl4-lSEC"
   },
   "outputs": [],
   "source": [
    "cot_bs.save(f'cot_gpt35.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lpo0iNekeCoR"
   },
   "outputs": [],
   "source": [
    "prog = CoT()\n",
    "prog.load(f'cot_gpt35.json')\n",
    "ensemble = [prog]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BpYYviEOek__"
   },
   "outputs": [],
   "source": [
    "always_true = lambda g, p, trace=None: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rsg29jXftl3i",
    "outputId": "ecc80090-2a13-40d3-a569-16a5d670ce50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (1.24.1)\n",
      "Requirement already satisfied: dill in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: packaging in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: rouge_score in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (2.0.0)\n",
      "Requirement already satisfied: nltk in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (4.66.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: accelerate in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (2.0.1+cu117)\n",
      "Requirement already satisfied: huggingface-hub in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (0.18.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorboardX in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from tensorboardX) (1.24.1)\n",
      "Requirement already satisfied: packaging in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from tensorboardX) (23.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from tensorboardX) (3.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d5869c5b82e9415c8b9c22ab8b2d9d02",
      "cb3bc20c19f54663a1b420c2b06365ba",
      "c13234152b4c477d88dd85844b5e712e",
      "c95483cbfca84905b44b1aaa32480615",
      "4571611d877e4d03a2aa0ffa364d635d",
      "9007cb683c264fa599648b008871d9a8",
      "88827a69dace443e9db9aaee06730ee0",
      "17156cb5ed9d4b4f9fe52b4286016752",
      "c328a618bad746c6855ca796b076ae0c",
      "25fe02c768e54238bf20540dbf311fa7",
      "2e21bc0c967f40148fb882c8692d3278",
      "77fd1da3e56a48ddb679433ed04fd954",
      "4fbe9e916c58498f94d1dbc39030736d",
      "8e2c8030ad78492ba390202aa7ef0d93",
      "1e374f032d0a44e0bcd20e3f06c78c83",
      "cb20de4cee8f4f74a92e3251a0202ea9",
      "9438276614d94569b36a1ccd8903927e",
      "9c8f103f3e92424e87ec527f06ce3783",
      "acfd7180cd984b2089632238c0cf080e",
      "8e1a494621894bfcad9418e6da0dff41",
      "1c5bde4646194721a2a30f2cc07335a5",
      "f4dd0c0980fc4c19bdeef3c1630c5312",
      "691b812bbacc46d3b9d8413d5ee8cbaa",
      "a905eb31b29343408c2923898845ac82",
      "45745800f73046a2b27efada4f8eb3e6",
      "f5a908ff6a5141e29c0f2adf1e4eb6f3",
      "714f7dc65d0b4f5f96c23326732bb1cb",
      "7f40feca3d4c41bf8bc62627ed1dc958",
      "35df6a1f32524ab1a0cb9dedcda968d9",
      "15a82a5784914ac08630e2f4071ba3bc",
      "b0752f1be3c2478c9464438fcadd0127",
      "9be50fdd5ace4151b9033fc53de6856b",
      "d7aadac4406b43d99549d088f9b6d24f",
      "d6d3f9489f62473a935de8e4f7ad5146",
      "0d8372e00adc4573914cd14a7435f9be",
      "deebf2522b3246b193bd00a8eb613807",
      "46eea712001e449b806537819ff208f8",
      "93558e5be6694ff1a3bfab6f0aea7d97",
      "c2f7cd716de84319be6b2fc47596e83b",
      "f756ff4c6a234b81aeffdbca9740120e",
      "8ec864e098ae4c09b41f74e37d011d40",
      "8645eb09632f4a3eb9660a18b7a22f3f",
      "7541ec8e9bc446a297e35442bc8cd2a9",
      "c7d92f41c2564ce9909d2fbb1ded4c24",
      "f5568b990cb8474d8ea7d880486a207b",
      "99919dbc154f4d289d2ae34f9bbecf54",
      "38f0319edfed473d8100d6ad3504ed75",
      "c34bead716714285833a9ab9328b2b52",
      "a00da28977b44a549906c98c14f7f97a",
      "c24d002c4d5d488c8ae49d158d3017af",
      "9d28d336e00d446bb7f7629b99c9b53d",
      "2645512b9ade44f6a74576ff0d6fa447",
      "a8167d6e1e3945e8993fb038c4ecc9ea",
      "1698a2b8f6e448e49e36c9c9962c7c95",
      "7e02b08cb22c4674acdb19ca61794894"
     ]
    },
    "id": "gEVotJX7e9Qo",
    "outputId": "d4e180ec-adf8-419c-d1d0-b576046160e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:00<00:00, 3776.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 100 full traces after 100 examples in round 0.\n",
      "all 100\n",
      "local_cache/compiler/all.cfeec7cbd49cfd3e.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f31252230e4015b8024f75f732025b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991cadbdb7924c86846b095ddf9ae586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35b81bec1a64515b6ffef5a322a6886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b1a1698cf8488d8d35beb21e83969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d75b89bc6a48b18aa11cc7a43745d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26e1dbfea0b4e21b2feee4469568b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9780f87859e84aae9d6a4ce55842e08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e73a6ed945c4cfb99d75a36e094f1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# examples skipped due to parsing error: 0 / 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ba1d0f7963435eb1be6ee47a8a590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5619fd72ebe4aca8fcc220519b19867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f20c07b6994a028069d2aae0835f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f6e37e68d4910b7da05b4d6767048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics: {'max_source_length': 44, 'max_target_length': 2}\n",
      "Keys of tokenized dataset: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels']\n",
      "Finetuning dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 90\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 10\n",
      "    })\n",
      "})\n",
      "{'eval_loss': 0.6288124322891235, 'eval_rouge1': 30.0, 'eval_rouge2': 0.0, 'eval_rougeL': 30.0, 'eval_rougeLsum': 30.0, 'eval_gen_len': 2.0, 'eval_runtime': 0.1223, 'eval_samples_per_second': 81.734, 'eval_steps_per_second': 16.347, 'epoch': 0.93}\n",
      "{'eval_loss': 0.6246126890182495, 'eval_rouge1': 30.0, 'eval_rouge2': 0.0, 'eval_rougeL': 30.0, 'eval_rougeLsum': 30.0, 'eval_gen_len': 2.0, 'eval_runtime': 0.1443, 'eval_samples_per_second': 69.281, 'eval_steps_per_second': 13.856, 'epoch': 1.87}\n",
      "{'train_runtime': 3.4201, 'train_samples_per_second': 52.63, 'train_steps_per_second': 4.093, 'train_loss': 0.6946390015738351, 'epoch': 1.87}\n",
      "Best checkpoint of model: ../finetuning_ckpts/S32P3WSDB9KH7.all/checkpoint-14\n",
      "#> Best checkpoint path: ../finetuning_ckpts/S32P3WSDB9KH7.all/checkpoint-14 for all\n",
      "Assigning the LM of predictor all.\n"
     ]
    }
   ],
   "source": [
    "config = dict(target='google/flan-t5-small', epochs=2, bf16=True, bsize=6, accumsteps=2, lr=5e-5)\n",
    "\n",
    "tp = BootstrapFinetune(metric=None)\n",
    "t5_program = tp.compile(CoT(), teacher=ensemble, trainset=test_set[:100], **config)\n",
    "\n",
    "# Deactivate chain of thought prompting. Let's use T5 to directly predict outputs. (Faster and similar quality.)\n",
    "for p in t5_program.predictors(): p.activated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "BoGeTm5xe_ZL"
   },
   "outputs": [],
   "source": [
    "t5_program_load = CoT()\n",
    "ckpt_path = '../finetuning_ckpts/S32P3WSDB9KH7.all/checkpoint-14'\n",
    "# ckpt_path = \"colbert-ir/dspy-Oct11-T5-Large-MH-3k-v1\"\n",
    "LM = dspy.HFModel(checkpoint=ckpt_path, model='google/flan-t5-small')\n",
    "\n",
    "for p in t5_program_load.predictors():\n",
    "    p.lm = LM\n",
    "    p.activated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dAoVLOSqm8nR"
   },
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_scramble = Evaluate(devset=test_set, num_threads=2, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yB3L0CNtfBj5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 916 / 2000  (45.8): 100%|| 2000/2000 [00:22<00:00, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 916 / 2000  (45.8%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aae0a th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aae0a td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aae0a_row0_col0, #T_aae0a_row0_col1, #T_aae0a_row0_col2, #T_aae0a_row0_col3, #T_aae0a_row0_col4, #T_aae0a_row0_col5, #T_aae0a_row1_col0, #T_aae0a_row1_col1, #T_aae0a_row1_col2, #T_aae0a_row1_col3, #T_aae0a_row1_col4, #T_aae0a_row1_col5, #T_aae0a_row2_col0, #T_aae0a_row2_col1, #T_aae0a_row2_col2, #T_aae0a_row2_col3, #T_aae0a_row2_col4, #T_aae0a_row2_col5, #T_aae0a_row3_col0, #T_aae0a_row3_col1, #T_aae0a_row3_col2, #T_aae0a_row3_col3, #T_aae0a_row3_col4, #T_aae0a_row3_col5, #T_aae0a_row4_col0, #T_aae0a_row4_col1, #T_aae0a_row4_col2, #T_aae0a_row4_col3, #T_aae0a_row4_col4, #T_aae0a_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aae0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aae0a_level0_col0\" class=\"col_heading level0 col0\" >example_answer</th>\n",
       "      <th id=\"T_aae0a_level0_col1\" class=\"col_heading level0 col1\" >word</th>\n",
       "      <th id=\"T_aae0a_level0_col2\" class=\"col_heading level0 col2\" >scrambled</th>\n",
       "      <th id=\"T_aae0a_level0_col3\" class=\"col_heading level0 col3\" >question</th>\n",
       "      <th id=\"T_aae0a_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_aae0a_level0_col5\" class=\"col_heading level0 col5\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aae0a_row0_col0\" class=\"data row0 col0\" >B</td>\n",
       "      <td id=\"T_aae0a_row0_col1\" class=\"data row0 col1\" >knee</td>\n",
       "      <td id=\"T_aae0a_row0_col2\" class=\"data row0 col2\" >kene</td>\n",
       "      <td id=\"T_aae0a_row0_col3\" class=\"data row0 col3\" >Can you unscramble 'kene'?\n",
       "A: raymond\n",
       "B: knee\n",
       "C: take\n",
       "D: consumption</td>\n",
       "      <td id=\"T_aae0a_row0_col4\" class=\"data row0 col4\" >C</td>\n",
       "      <td id=\"T_aae0a_row0_col5\" class=\"data row0 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aae0a_row1_col0\" class=\"data row1 col0\" >D</td>\n",
       "      <td id=\"T_aae0a_row1_col1\" class=\"data row1 col1\" >camcorders</td>\n",
       "      <td id=\"T_aae0a_row1_col2\" class=\"data row1 col2\" >cmorarecds</td>\n",
       "      <td id=\"T_aae0a_row1_col3\" class=\"data row1 col3\" >Decode the word 'cmorarecds'.\n",
       "A: charitable\n",
       "B: thats\n",
       "C: univ\n",
       "D: camcorders</td>\n",
       "      <td id=\"T_aae0a_row1_col4\" class=\"data row1 col4\" >A</td>\n",
       "      <td id=\"T_aae0a_row1_col5\" class=\"data row1 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aae0a_row2_col0\" class=\"data row2 col0\" >C</td>\n",
       "      <td id=\"T_aae0a_row2_col1\" class=\"data row2 col1\" >heat</td>\n",
       "      <td id=\"T_aae0a_row2_col2\" class=\"data row2 col2\" >haet</td>\n",
       "      <td id=\"T_aae0a_row2_col3\" class=\"data row2 col3\" >Decode the word 'haet'.\n",
       "A: babes\n",
       "B: competent\n",
       "C: heat\n",
       "D: dogs</td>\n",
       "      <td id=\"T_aae0a_row2_col4\" class=\"data row2 col4\" >B</td>\n",
       "      <td id=\"T_aae0a_row2_col5\" class=\"data row2 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aae0a_row3_col0\" class=\"data row3 col0\" >C</td>\n",
       "      <td id=\"T_aae0a_row3_col1\" class=\"data row3 col1\" >brochure</td>\n",
       "      <td id=\"T_aae0a_row3_col2\" class=\"data row3 col2\" >bruchore</td>\n",
       "      <td id=\"T_aae0a_row3_col3\" class=\"data row3 col3\" >Can you unscramble 'bruchore'?\n",
       "A: acrylic\n",
       "B: monroe\n",
       "C: brochure\n",
       "D: products</td>\n",
       "      <td id=\"T_aae0a_row3_col4\" class=\"data row3 col4\" >D</td>\n",
       "      <td id=\"T_aae0a_row3_col5\" class=\"data row3 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aae0a_row4_col0\" class=\"data row4 col0\" >B</td>\n",
       "      <td id=\"T_aae0a_row4_col1\" class=\"data row4 col1\" >grass</td>\n",
       "      <td id=\"T_aae0a_row4_col2\" class=\"data row4 col2\" >gasrs</td>\n",
       "      <td id=\"T_aae0a_row4_col3\" class=\"data row4 col3\" >Rearrange the letters in 'gasrs' to form the correct word.\n",
       "A: valuable\n",
       "B: grass\n",
       "C: fresno\n",
       "D: dept</td>\n",
       "      <td id=\"T_aae0a_row4_col4\" class=\"data row4 col4\" >A</td>\n",
       "      <td id=\"T_aae0a_row4_col5\" class=\"data row4 col5\" > [False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e79ac4af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1995 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = evaluate_on_scramble(t5_program_load, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Rearrange the letters in 'prohept' to form the correct word.\n",
      "A: prophet\n",
      "B: jessica\n",
      "C: child\n",
      "D: respected\n",
      "Predicted Answer: D\n"
     ]
    }
   ],
   "source": [
    "# Call the predictor on a particular input.\n",
    "pred = t5_program(question=example.question)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZS02QmYfDQK"
   },
   "outputs": [],
   "source": [
    "t5_program.predictors()[0].lm.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_HcWdZDrRXz"
   },
   "source": [
    "# Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model_Wranglers_DSPy (1).ipynb'   RACE.zip   local_cache\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-25ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 111 not upgraded.\n",
      "'Model_Wranglers_DSPy (1).ipynb'   RACE   RACE.zip   __MACOSX   local_cache\n"
     ]
    }
   ],
   "source": [
    "! ls\n",
    "! rm -rf RACE\n",
    "! apt install unzip\n",
    "! unzip -q RACE.zip\n",
    "! rm -rf __MACOSX\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmHc8qMkrSmv"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high  middle\n"
     ]
    }
   ],
   "source": [
    "! ls RACE/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle School Example:\n",
      "Example({'context': \"Do you know HFMD? It's short for Hand-Foot-Mouth Disease. This year, in China, thousands of children were suffering from it. What's HFMD? How to prevent it? Now, read the passage please.\\nHFMD usually affects babies who are 1~4 years old, but adults can also be infected. Both EV71 and Cox A16 can cause HFMD, which usually starts with a slight fever followed by blisters   and ulcers   in the mouth and rashes   on the hands and feet.\\nIt can be spread through people with the mucus   or feces   of an _ person. It usually appears during the summer and autumn months. HFMD isn't Bird Flu, SARS or Mad Cow Disease, but it's not a new one, either. It first appeared in New Zealand in 1957. About forty years later, it appears in Asia. It's reported that it breaks out every 2 or 3 years.\\nHFMD is very terrible and there is no vaccine   now, but we can do something helpful to prevent it. 'Children with HFMD should seek medical treatment as early as possible', experts say. They also suggest that parents keep the air fresh in a child's room, which should be kept clean, tidy and dry. Children should be taught to wash their hands regularly. Staying away from crowded public places is also basic.\", 'question': 'HFMD is usually spread with   _  .', 'options': \"['feces', 'feces of an infected person', 'water', 'mucus']\", 'answer_option': 'B', 'answer': 'feces of an infected person'}) (input_keys={'question', 'context', 'options'})\n",
      "\n",
      "High School Example:\n",
      "Example({'context': 'It\\'s cool, and it\\'s hot, and everyone is doing it. People talk about it often, and friends tell other friends how good they look. Sound like a fashion? It\\'s actually another trend : \"blog\". What\\'s a blog? A blog is a personal online diary. The word \"blogger\" means a person who writes diaries online.\\nMany bloggers are teens who\\'ve been logging  onto sites to discuss anything in their lives. Many of today\\'s teenagers are not afraid to openly discuss everything in their lives. Teens complain  about parents and homework. They share diaries, post songs from the latest bands and show pictures of theirs. They write their own poems, say something about their girlfriends or boyfriends and complain to each other or offer support. But mostly they just write down what they do every day.\\nHowever, many parents are afraid of these young bloggers. Parents see the kids talking about how they got drunk last weekend and how they don\\'t like studying. They are using language that is surprising to their parents. Besides hearing from their friends, teen bloggers also get message from strangers. Most of the time, it\\'s older men asking to meet teenage girls. \"These strange men are dangerous for my kids. They sometimes teach my kids bad words, \" said Cara Cabral, a mother of two.\\nMany teens and young adults know it\\'s not safe to use blogs on the Internet. They know they are putting information about themselves in a place they can be seen by anyone. But teens are unlikely to give up these new communication tools that have becomes a way of life for many of them.\\nAre you a bloggers? What do you think of the blog?', 'question': 'A blogger is a person   _  .', 'options': \"['who teaches kids bad words', 'who posts songs from the latest bands', 'who got drunk last weekend', 'who writes diaries online']\", 'answer_option': 'D', 'answer': 'who writes diaries online'}) (input_keys={'question', 'context', 'options'})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import dspy\n",
    "\n",
    "# Function to convert a RACE dataset row to DSPy format\n",
    "def convert_race_to_dspy_format(item):\n",
    "    context = item[\"article\"]\n",
    "    options = item[\"options\"]\n",
    "    questions = item[\"questions\"]\n",
    "    answers = item[\"answers\"]\n",
    "\n",
    "    # Assuming options, questions, and answers have the same length\n",
    "    examples = []\n",
    "    answer_to_index = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "    for i in range(len(options)):\n",
    "        example = dspy.Example(\n",
    "            context=context,\n",
    "            question=questions[i],\n",
    "            options=str(options[i]),\n",
    "            answer_option=answers[i],\n",
    "            answer = options[i][answer_to_index[answers[i]]]\n",
    "        )\n",
    "        examples.append(example)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Convert and combine all splits for middle and high school\n",
    "dspy_dataset = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for level in ['middle', 'high']:\n",
    "    for split in ['dev', 'test', 'train']:\n",
    "        folder_path = os.path.join(\"RACE\", split, level)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                dspy_examples = convert_race_to_dspy_format(data)\n",
    "                dspy_dataset[level][split].extend(dspy_examples)\n",
    "\n",
    "# Add inputs to the datasets\n",
    "for level in ['middle', 'high']:\n",
    "    for split in ['dev', 'test', 'train']:\n",
    "        dspy_dataset[level][split] = [x.with_inputs('context', 'question', 'options') for x in dspy_dataset[level][split]]\n",
    "\n",
    "# Check the first element of the datasets\n",
    "example_middle_school = dspy_dataset[\"middle\"][\"dev\"][0]\n",
    "example_high_school = dspy_dataset[\"high\"][\"dev\"][0]\n",
    "\n",
    "print(\"middle School Example:\")\n",
    "print(example_middle_school)\n",
    "print(\"\\nHigh School Example:\")\n",
    "print(example_high_school)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSPy Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Given the context, fill in the  _ by choosing from given options. Give one letter answer. A,B,C,D\"\"\"\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Given the context, answer the question by choosing from given options.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    question = dspy.InputField()\n",
    "    options = dspy.InputField(desc=\"4 options to select from\")\n",
    "    answer = dspy.OutputField()\n",
    "    \n",
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(BasicQA)\n",
    "    def postprocess(self, prediction):\n",
    "        # print(\"_______\")\n",
    "        # print(prediction)\n",
    "        # print(\"_______\")\n",
    "        return prediction.split(\"Answer: \")[-1].split('\\n')[0]\n",
    "\n",
    "    def forward(self, context, question, options):\n",
    "        prediction = self.generate_answer(context=context, question=question, options=options, kwargs={\"max_tokens\":2000})\n",
    "        prediction.answer = self.postprocess(prediction.answer)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: From the passage we know the fastest way traveling is  _  .\n",
      "Correct Answer: by air\n",
      "Predicted Answer: by air\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If we travel by car, we can  _  .\n",
      "Correct Answer: make our own timetable\n",
      "Predicted Answer: If we travel by car, we can make the longest journey enjoyable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What kind of beverage is NOT allowed to sell on campus?\n",
      "Correct Answer: High-sugar fizzy drinks.\n",
      "Predicted Answer: High-sugar fizzy drinks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the writer's attitude towards limits on junk food?\n",
      "Correct Answer: Positive.\n",
      "Predicted Answer: ${answer}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which of the following statements is WRONG?\n",
      "Correct Answer: Coca-Cola isn't very popular in the world.\n",
      "Predicted Answer: ${answer}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which is the best title of the passage?\n",
      "Correct Answer: Say \"Goodbye\" to Coca-Cola\n",
      "Predicted Answer: ${answer}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What did Mary want as her Christmas present?\n",
      "Correct Answer: A new bike.\n",
      "Predicted Answer: Mary wanted a clay model bike as her Christmas present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Mary's parents didn't buy her a bike because she   _  .\n",
      "Correct Answer: only asked for it again on December 24th\n",
      "Predicted Answer: Mary's parents didn't buy her\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Mary's father got the idea to   _  .\n",
      "Correct Answer: make a small bike out of clay\n",
      "Predicted Answer: Mary's father got the idea to make a small bike out of clay.\n",
      "Question: Lucy found a   _    in the library.\n",
      "Correct Answer: pen\n",
      "Predicted Answer: Lucy found a pen in the library.\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\n",
    "generate_answer_with_chain_of_thought = CoT()\n",
    "\n",
    "example = example_high_school\n",
    "for example in dspy_dataset[\"middle\"][\"train\"][:10]:\n",
    "    # Call the predictor on the same input.\n",
    "    pred = generate_answer_with_chain_of_thought(\n",
    "        context=example.context,\n",
    "        question=example.question,\n",
    "        options=example.options\n",
    "    )\n",
    "    \n",
    "    # Print the input, the chain of thought, and the prediction.\n",
    "    print(f\"Question: {example.question}\")\n",
    "    print(f\"Correct Answer: {example.answer}\")\n",
    "    # print(f\"Thought: {pred.rationale}\") #.split('.', 1)[1].strip()}\")\n",
    "    print(f\"Predicted Answer: {pred.answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 1  (100.0):  20%|        | 1/5 [00:01<00:05,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 2  (100.0):  40%|      | 2/5 [00:02<00:03,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 3  (66.7):  60%|    | 3/5 [00:06<00:05,  2.54s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 4  (50.0):  80%|  | 4/5 [00:10<00:02,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 5  (60.0): 100%|| 5/5 [00:14<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 5  (60.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:126: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ef061 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ef061 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ef061_row0_col0, #T_ef061_row0_col1, #T_ef061_row0_col2, #T_ef061_row0_col3, #T_ef061_row0_col4, #T_ef061_row0_col5, #T_ef061_row0_col6, #T_ef061_row0_col7, #T_ef061_row1_col0, #T_ef061_row1_col1, #T_ef061_row1_col2, #T_ef061_row1_col3, #T_ef061_row1_col4, #T_ef061_row1_col5, #T_ef061_row1_col6, #T_ef061_row1_col7, #T_ef061_row2_col0, #T_ef061_row2_col1, #T_ef061_row2_col2, #T_ef061_row2_col3, #T_ef061_row2_col4, #T_ef061_row2_col5, #T_ef061_row2_col6, #T_ef061_row2_col7, #T_ef061_row3_col0, #T_ef061_row3_col1, #T_ef061_row3_col2, #T_ef061_row3_col3, #T_ef061_row3_col4, #T_ef061_row3_col5, #T_ef061_row3_col6, #T_ef061_row3_col7, #T_ef061_row4_col0, #T_ef061_row4_col1, #T_ef061_row4_col2, #T_ef061_row4_col3, #T_ef061_row4_col4, #T_ef061_row4_col5, #T_ef061_row4_col6, #T_ef061_row4_col7 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ef061\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ef061_level0_col0\" class=\"col_heading level0 col0\" >context</th>\n",
       "      <th id=\"T_ef061_level0_col1\" class=\"col_heading level0 col1\" >question</th>\n",
       "      <th id=\"T_ef061_level0_col2\" class=\"col_heading level0 col2\" >options</th>\n",
       "      <th id=\"T_ef061_level0_col3\" class=\"col_heading level0 col3\" >answer_option</th>\n",
       "      <th id=\"T_ef061_level0_col4\" class=\"col_heading level0 col4\" >example_answer</th>\n",
       "      <th id=\"T_ef061_level0_col5\" class=\"col_heading level0 col5\" >rationale</th>\n",
       "      <th id=\"T_ef061_level0_col6\" class=\"col_heading level0 col6\" >pred_answer</th>\n",
       "      <th id=\"T_ef061_level0_col7\" class=\"col_heading level0 col7\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ef061_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ef061_row0_col0\" class=\"data row0 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_ef061_row0_col1\" class=\"data row0 col1\" >Where is Wendy from?</td>\n",
       "      <td id=\"T_ef061_row0_col2\" class=\"data row0 col2\" >['China.', 'England.', 'America.', 'Australia.']</td>\n",
       "      <td id=\"T_ef061_row0_col3\" class=\"data row0 col3\" >D</td>\n",
       "      <td id=\"T_ef061_row0_col4\" class=\"data row0 col4\" >Australia.</td>\n",
       "      <td id=\"T_ef061_row0_col5\" class=\"data row0 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_ef061_row0_col6\" class=\"data row0 col6\" >Australia.</td>\n",
       "      <td id=\"T_ef061_row0_col7\" class=\"data row0 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef061_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ef061_row1_col0\" class=\"data row1 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_ef061_row1_col1\" class=\"data row1 col1\" >What colours does Nancy like?</td>\n",
       "      <td id=\"T_ef061_row1_col2\" class=\"data row1 col2\" >['Red and blue.', 'Red and yellow.', 'Green and yellow.', 'Green and blue.']</td>\n",
       "      <td id=\"T_ef061_row1_col3\" class=\"data row1 col3\" >D</td>\n",
       "      <td id=\"T_ef061_row1_col4\" class=\"data row1 col4\" >Green and blue.</td>\n",
       "      <td id=\"T_ef061_row1_col5\" class=\"data row1 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_ef061_row1_col6\" class=\"data row1 col6\" >Green and blue.</td>\n",
       "      <td id=\"T_ef061_row1_col7\" class=\"data row1 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef061_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ef061_row2_col0\" class=\"data row2 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_ef061_row2_col1\" class=\"data row2 col1\" >What's Wendy's favourite sport?</td>\n",
       "      <td id=\"T_ef061_row2_col2\" class=\"data row2 col2\" >['Running.', 'Basketball.', 'Football.', 'Table tennis.']</td>\n",
       "      <td id=\"T_ef061_row2_col3\" class=\"data row2 col3\" >A</td>\n",
       "      <td id=\"T_ef061_row2_col4\" class=\"data row2 col4\" >Running.</td>\n",
       "      <td id=\"T_ef061_row2_col5\" class=\"data row2 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_ef061_row2_col6\" class=\"data row2 col6\" >We don't have enough information to answer the question.</td>\n",
       "      <td id=\"T_ef061_row2_col7\" class=\"data row2 col7\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef061_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ef061_row3_col0\" class=\"data row3 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_ef061_row3_col1\" class=\"data row3 col1\" >Which is TRUE ?</td>\n",
       "      <td id=\"T_ef061_row3_col2\" class=\"data row3 col2\" >['Nancy and Wendy are 12 years old.', 'Wendy is a student and she is English.', 'Everyone in Class Four likes Wendy.', 'Nancy has a cat...</td>\n",
       "      <td id=\"T_ef061_row3_col3\" class=\"data row3 col3\" >C</td>\n",
       "      <td id=\"T_ef061_row3_col4\" class=\"data row3 col4\" >Everyone in Class Four likes Wendy.</td>\n",
       "      <td id=\"T_ef061_row3_col5\" class=\"data row3 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_ef061_row3_col6\" class=\"data row3 col6\" >Nancy has a dog and Wendy has a cat.</td>\n",
       "      <td id=\"T_ef061_row3_col7\" class=\"data row3 col7\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef061_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ef061_row4_col0\" class=\"data row4 col0\" >June 5 is World Environment Day.This makes us pay more attention to our environment and the need to protect it. When Wang Baoxuan,a Beijing high...</td>\n",
       "      <td id=\"T_ef061_row4_col1\" class=\"data row4 col1\" >What do Wang Baoxuan and his schoolmates do with the waste exercise books?</td>\n",
       "      <td id=\"T_ef061_row4_col2\" class=\"data row4 col2\" >['Throw them away', 'Collect and sell them', 'Cut them into pieces', 'Give them to the students in Inner Mongolia']</td>\n",
       "      <td id=\"T_ef061_row4_col3\" class=\"data row4 col3\" >B</td>\n",
       "      <td id=\"T_ef061_row4_col4\" class=\"data row4 col4\" >Collect and sell them</td>\n",
       "      <td id=\"T_ef061_row4_col5\" class=\"data row4 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_ef061_row4_col6\" class=\"data row4 col6\" >Collect and sell them.</td>\n",
       "      <td id=\"T_ef061_row4_col7\" class=\"data row4 col7\" > [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7e00f08340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=dspy_dataset[\"middle\"][\"test\"][:5], num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(generate_answer_with_chain_of_thought, metric=metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 1  (100.0):  20%|        | 1/5 [00:03<00:12,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 2  (100.0):  40%|      | 2/5 [00:06<00:08,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 3  (66.7):  60%|    | 3/5 [00:10<00:07,  3.75s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 4  (50.0):  80%|  | 4/5 [00:15<00:04,  4.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 5  (40.0): 100%|| 5/5 [00:19<00:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 5  (40.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:126: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b813b th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b813b td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b813b_row0_col0, #T_b813b_row0_col1, #T_b813b_row0_col2, #T_b813b_row0_col3, #T_b813b_row0_col4, #T_b813b_row0_col5, #T_b813b_row0_col6, #T_b813b_row0_col7, #T_b813b_row1_col0, #T_b813b_row1_col1, #T_b813b_row1_col2, #T_b813b_row1_col3, #T_b813b_row1_col4, #T_b813b_row1_col5, #T_b813b_row1_col6, #T_b813b_row1_col7, #T_b813b_row2_col0, #T_b813b_row2_col1, #T_b813b_row2_col2, #T_b813b_row2_col3, #T_b813b_row2_col4, #T_b813b_row2_col5, #T_b813b_row2_col6, #T_b813b_row2_col7, #T_b813b_row3_col0, #T_b813b_row3_col1, #T_b813b_row3_col2, #T_b813b_row3_col3, #T_b813b_row3_col4, #T_b813b_row3_col5, #T_b813b_row3_col6, #T_b813b_row3_col7, #T_b813b_row4_col0, #T_b813b_row4_col1, #T_b813b_row4_col2, #T_b813b_row4_col3, #T_b813b_row4_col4, #T_b813b_row4_col5, #T_b813b_row4_col6, #T_b813b_row4_col7 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b813b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b813b_level0_col0\" class=\"col_heading level0 col0\" >context</th>\n",
       "      <th id=\"T_b813b_level0_col1\" class=\"col_heading level0 col1\" >question</th>\n",
       "      <th id=\"T_b813b_level0_col2\" class=\"col_heading level0 col2\" >options</th>\n",
       "      <th id=\"T_b813b_level0_col3\" class=\"col_heading level0 col3\" >answer_option</th>\n",
       "      <th id=\"T_b813b_level0_col4\" class=\"col_heading level0 col4\" >example_answer</th>\n",
       "      <th id=\"T_b813b_level0_col5\" class=\"col_heading level0 col5\" >rationale</th>\n",
       "      <th id=\"T_b813b_level0_col6\" class=\"col_heading level0 col6\" >pred_answer</th>\n",
       "      <th id=\"T_b813b_level0_col7\" class=\"col_heading level0 col7\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b813b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b813b_row0_col0\" class=\"data row0 col0\" >Alice's mother died when she was five. Although her brothers and sisters were loving and caring, their love couldn't take the place of a mother's....</td>\n",
       "      <td id=\"T_b813b_row0_col1\" class=\"data row0 col1\" >Why couldn't Alice get a doll as a child?</td>\n",
       "      <td id=\"T_b813b_row0_col2\" class=\"data row0 col2\" >['Because her mother died quite early.', 'Because her family disliked her.', 'Because her family was very poor.', \"Because Alice didn't love dolls.\"]</td>\n",
       "      <td id=\"T_b813b_row0_col3\" class=\"data row0 col3\" >C</td>\n",
       "      <td id=\"T_b813b_row0_col4\" class=\"data row0 col4\" >Because her family was very poor.</td>\n",
       "      <td id=\"T_b813b_row0_col5\" class=\"data row0 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_b813b_row0_col6\" class=\"data row0 col6\" >Because her family was very poor.</td>\n",
       "      <td id=\"T_b813b_row0_col7\" class=\"data row0 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b813b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b813b_row1_col0\" class=\"data row1 col0\" >Alice's mother died when she was five. Although her brothers and sisters were loving and caring, their love couldn't take the place of a mother's....</td>\n",
       "      <td id=\"T_b813b_row1_col1\" class=\"data row1 col1\" >What did the friend's father do that Christmas morning?</td>\n",
       "      <td id=\"T_b813b_row1_col2\" class=\"data row1 col2\" >['He acted as Santa Claus to send Christmas gifts.', 'He went to her home to see Alice.', 'He bought some Christmas gifts for Katie.', 'He...</td>\n",
       "      <td id=\"T_b813b_row1_col3\" class=\"data row1 col3\" >A</td>\n",
       "      <td id=\"T_b813b_row1_col4\" class=\"data row1 col4\" >He acted as Santa Claus to send Christmas gifts.</td>\n",
       "      <td id=\"T_b813b_row1_col5\" class=\"data row1 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_b813b_row1_col6\" class=\"data row1 col6\" >He acted as Santa Claus to send Christmas gifts.</td>\n",
       "      <td id=\"T_b813b_row1_col7\" class=\"data row1 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b813b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b813b_row2_col0\" class=\"data row2 col0\" >Alice's mother died when she was five. Although her brothers and sisters were loving and caring, their love couldn't take the place of a mother's....</td>\n",
       "      <td id=\"T_b813b_row2_col1\" class=\"data row2 col1\" >Why didn't Alice expect there was also a gift for her?</td>\n",
       "      <td id=\"T_b813b_row2_col2\" class=\"data row2 col2\" >['The gifts from Santa Claus were usually for children.', 'The gift was forgotten many years ago.', 'The gift for her was bought by accident on...</td>\n",
       "      <td id=\"T_b813b_row2_col3\" class=\"data row2 col3\" >A</td>\n",
       "      <td id=\"T_b813b_row2_col4\" class=\"data row2 col4\" >The gifts from Santa Claus were usually for children.</td>\n",
       "      <td id=\"T_b813b_row2_col5\" class=\"data row2 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_b813b_row2_col6\" class=\"data row2 col6\" >The gift for her was forgotten many years ago.</td>\n",
       "      <td id=\"T_b813b_row2_col7\" class=\"data row2 col7\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b813b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b813b_row3_col0\" class=\"data row3 col0\" >Alice's mother died when she was five. Although her brothers and sisters were loving and caring, their love couldn't take the place of a mother's....</td>\n",
       "      <td id=\"T_b813b_row3_col1\" class=\"data row3 col1\" >The author wrote the message card in order to   _  .</td>\n",
       "      <td id=\"T_b813b_row3_col2\" class=\"data row3 col2\" >['show her deep apology to her mother', \"make it clear that Santa Claus didn't forget her\", 'show that Santa Claus was hard-working', 'make Alice believe...</td>\n",
       "      <td id=\"T_b813b_row3_col3\" class=\"data row3 col3\" >D</td>\n",
       "      <td id=\"T_b813b_row3_col4\" class=\"data row3 col4\" >make Alice believe the gift was exactly for her</td>\n",
       "      <td id=\"T_b813b_row3_col5\" class=\"data row3 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_b813b_row3_col6\" class=\"data row3 col6\" >The author wrote the message card in order to show her deep apology to</td>\n",
       "      <td id=\"T_b813b_row3_col7\" class=\"data row3 col7\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b813b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b813b_row4_col0\" class=\"data row4 col0\" >Science isn't something mysterious, only for the few. Every one of us--whether a poet, worker, or physicist has to be able to think scientifically, and...</td>\n",
       "      <td id=\"T_b813b_row4_col1\" class=\"data row4 col1\" >What does the author mean by saying that \"a strong scientific spirit is basic to the economy, educational system and society\"?</td>\n",
       "      <td id=\"T_b813b_row4_col2\" class=\"data row4 col2\" >['School and society should encourage young people to become professional scientists.', 'The school should only teach lessons of economy and education*', 'A scientifically educated public...</td>\n",
       "      <td id=\"T_b813b_row4_col3\" class=\"data row4 col3\" >A</td>\n",
       "      <td id=\"T_b813b_row4_col4\" class=\"data row4 col4\" >School and society should encourage young people to become professional scientists.</td>\n",
       "      <td id=\"T_b813b_row4_col5\" class=\"data row4 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_b813b_row4_col6\" class=\"data row4 col6\" >A scientifically educated public is basic to the economy, educational system and society.</td>\n",
       "      <td id=\"T_b813b_row4_col7\" class=\"data row4 col7\" > [False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7d11976ec0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=dspy_dataset[\"high\"][\"test\"][:5], num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(generate_answer_with_chain_of_thought, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|         | 1/10 [00:04<00:41,  4.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|        | 2/10 [00:12<00:54,  6.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|       | 3/10 [00:17<00:39,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|      | 4/10 [00:21<00:30,  5.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|     | 5/10 [00:25<00:25,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    return answer_EM\n",
    "\n",
    "uncompiled_cot = CoT()\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_answer, max_bootstrapped_demos=4)\n",
    "\n",
    "# Compile!\n",
    "compiled_cot = teleprompter.compile(uncompiled_cot, trainset=dspy_dataset[\"middle\"][\"train\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1436 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 1/1436 [00:09<3:36:02,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 2  (100.0):   0%|          | 2/1436 [00:18<3:36:01,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 3  (100.0):   0%|          | 3/1436 [00:24<3:06:05,  7.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 4  (75.0):   0%|          | 4/1436 [00:31<2:55:28,  7.35s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 5  (80.0):   0%|          | 5/1436 [00:40<3:12:15,  8.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 5 / 6  (83.3):   0%|          | 6/1436 [00:49<3:21:53,  8.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 5 / 7  (71.4):   0%|          | 7/1436 [00:58<3:26:51,  8.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 8  (75.0):   1%|          | 8/1436 [01:07<3:30:00,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 9  (66.7):   1%|          | 9/1436 [01:17<3:32:04,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 10  (60.0):   1%|          | 10/1436 [01:23<3:15:36,  8.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 7 / 11  (63.6):   1%|          | 11/1436 [01:32<3:21:51,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 12  (66.7):   1%|          | 12/1436 [01:41<3:26:04,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 13  (69.2):   1%|          | 13/1436 [01:51<3:29:04,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 10 / 14  (71.4):   1%|          | 14/1436 [02:00<3:30:59,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 15  (73.3):   1%|          | 15/1436 [02:09<3:32:22,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 12 / 16  (75.0):   1%|          | 16/1436 [02:18<3:34:20,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 17  (76.5):   1%|          | 17/1436 [02:27<3:36:03,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 18  (72.2):   1%|         | 18/1436 [02:37<3:37:11,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 19  (68.4):   1%|         | 19/1436 [02:46<3:38:03,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 20  (65.0):   1%|         | 20/1436 [02:53<3:21:30,  8.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 21  (66.7):   1%|         | 21/1436 [03:03<3:28:47,  8.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 22  (63.6):   2%|         | 22/1436 [03:12<3:33:50,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 23  (60.9):   2%|         | 23/1436 [03:19<3:18:34,  8.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 24  (62.5):   2%|         | 24/1436 [03:26<3:08:13,  8.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 25  (60.0):   2%|         | 25/1436 [03:35<3:15:50,  8.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 26  (57.7):   2%|         | 26/1436 [03:44<3:21:14,  8.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 16 / 27  (59.3):   2%|         | 27/1436 [03:53<3:24:51,  8.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 16 / 28  (57.1):   2%|         | 28/1436 [04:02<3:27:25,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 16 / 29  (55.2):   2%|         | 29/1436 [04:12<3:29:11,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 17 / 30  (56.7):   2%|         | 30/1436 [04:21<3:32:01,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 18 / 31  (58.1):   2%|         | 31/1436 [04:30<3:33:56,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 32  (59.4):   2%|         | 32/1436 [04:40<3:35:17,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 33  (60.6):   2%|         | 33/1436 [04:49<3:36:13,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 21 / 34  (61.8):   2%|         | 34/1436 [04:58<3:35:14,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 22 / 35  (62.9):   2%|         | 35/1436 [05:07<3:35:40,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 23 / 36  (63.9):   3%|         | 36/1436 [05:17<3:35:56,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 37  (64.9):   3%|         | 37/1436 [05:26<3:34:48,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 25 / 38  (65.8):   3%|         | 38/1436 [05:35<3:33:52,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 25 / 39  (64.1):   3%|         | 39/1436 [05:44<3:33:20,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 40  (65.0):   3%|         | 40/1436 [05:53<3:32:53,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 41  (65.9):   3%|         | 41/1436 [06:02<3:32:30,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 42  (66.7):   3%|         | 42/1436 [06:11<3:32:08,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 43  (67.4):   3%|         | 43/1436 [06:21<3:33:06,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 44  (68.2):   3%|         | 44/1436 [06:30<3:32:33,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 45  (66.7):   3%|         | 45/1436 [06:39<3:33:33,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 46  (67.4):   3%|         | 46/1436 [06:48<3:34:15,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 47  (66.0):   3%|         | 47/1436 [06:58<3:34:47,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 48  (64.6):   3%|         | 48/1436 [07:07<3:35:03,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 32 / 49  (65.3):   3%|         | 49/1436 [07:16<3:33:38,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 33 / 50  (66.0):   3%|         | 50/1436 [07:25<3:32:40,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 33 / 51  (64.7):   4%|         | 51/1436 [07:34<3:31:55,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 33 / 52  (63.5):   4%|         | 52/1436 [07:44<3:31:25,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 33 / 53  (62.3):   4%|         | 53/1436 [07:53<3:32:49,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 34 / 54  (63.0):   4%|         | 54/1436 [08:02<3:33:39,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 35 / 55  (63.6):   4%|         | 55/1436 [08:12<3:34:25,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 36 / 56  (64.3):   4%|         | 56/1436 [08:21<3:34:50,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 57  (64.9):   4%|         | 57/1436 [08:30<3:33:07,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 58  (63.8):   4%|         | 58/1436 [08:39<3:31:58,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 38 / 59  (64.4):   4%|         | 59/1436 [08:49<3:32:23,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 60  (65.0):   4%|         | 60/1436 [08:58<3:33:06,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 61  (63.9):   4%|         | 61/1436 [09:05<3:15:20,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 40 / 62  (64.5):   4%|         | 62/1436 [09:14<3:21:15,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 40 / 63  (63.5):   4%|         | 63/1436 [09:24<3:25:20,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 64  (64.1):   4%|         | 64/1436 [09:30<3:10:36,  8.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 65  (64.6):   5%|         | 65/1436 [09:40<3:16:55,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 43 / 66  (65.2):   5%|         | 66/1436 [09:49<3:21:36,  8.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 43 / 67  (64.2):   5%|         | 67/1436 [09:58<3:24:28,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 68  (64.7):   5%|         | 68/1436 [10:08<3:26:44,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 69  (63.8):   5%|         | 69/1436 [10:17<3:27:01,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 45 / 70  (64.3):   5%|         | 70/1436 [10:23<3:09:18,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 46 / 71  (64.8):   5%|         | 71/1436 [10:32<3:14:34,  8.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 47 / 72  (65.3):   5%|         | 72/1436 [10:39<3:01:54,  8.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 48 / 73  (65.8):   5%|         | 73/1436 [10:48<3:08:42,  8.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 48 / 74  (64.9):   5%|         | 74/1436 [10:57<3:13:27,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 75  (65.3):   5%|         | 75/1436 [11:06<3:16:44,  8.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 76  (65.8):   5%|         | 76/1436 [11:13<3:03:05,  8.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 77  (64.9):   5%|         | 77/1436 [11:23<3:14:21,  8.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 78  (65.4):   5%|         | 78/1436 [11:32<3:20:47,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 52 / 79  (65.8):   6%|         | 79/1436 [11:42<3:25:19,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 80  (66.2):   6%|         | 80/1436 [11:49<3:11:29,  8.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 81  (66.7):   6%|         | 81/1436 [11:58<3:17:17,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 82  (67.1):   6%|         | 82/1436 [12:08<3:21:38,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 83  (66.3):   6%|         | 83/1436 [12:17<3:24:17,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 84  (66.7):   6%|         | 84/1436 [12:27<3:27:42,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 85  (65.9):   6%|         | 85/1436 [12:36<3:29:58,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 86  (65.1):   6%|         | 86/1436 [12:46<3:31:38,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 87  (64.4):   6%|         | 87/1436 [12:55<3:31:32,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 88  (64.8):   6%|         | 88/1436 [13:05<3:32:44,  9.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 89  (64.0):   6%|         | 89/1436 [13:14<3:30:09,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 90  (63.3):   6%|         | 90/1436 [13:23<3:27:45,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 58 / 91  (63.7):   6%|         | 91/1436 [13:32<3:26:36,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 92  (64.1):   6%|         | 92/1436 [13:41<3:25:44,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 93  (63.4):   6%|         | 93/1436 [13:50<3:25:01,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 94  (63.8):   7%|         | 94/1436 [13:57<3:07:57,  8.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 95  (64.2):   7%|         | 95/1436 [14:04<2:57:13,  7.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 62 / 96  (64.6):   7%|         | 96/1436 [14:13<3:06:39,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 97  (64.9):   7%|         | 97/1436 [14:22<3:12:55,  8.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 64 / 98  (65.3):   7%|         | 98/1436 [14:32<3:17:23,  8.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 64 / 99  (64.6):   7%|         | 99/1436 [14:41<3:20:33,  9.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 64 / 100  (64.0):   7%|         | 100/1436 [14:50<3:20:54,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 101  (64.4):   7%|         | 101/1436 [14:56<3:03:24,  8.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 66 / 102  (64.7):   7%|         | 102/1436 [15:06<3:08:48,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 66 / 103  (64.1):   7%|         | 103/1436 [15:15<3:12:29,  8.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 66 / 104  (63.5):   7%|         | 104/1436 [15:24<3:17:13,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 66 / 105  (62.9):   7%|         | 105/1436 [15:33<3:20:31,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 106  (63.2):   7%|         | 106/1436 [15:43<3:22:41,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 68 / 107  (63.6):   7%|         | 107/1436 [15:50<3:07:29,  8.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 69 / 108  (63.9):   8%|         | 108/1436 [15:59<3:13:07,  8.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 70 / 109  (64.2):   8%|         | 109/1436 [16:08<3:17:28,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 71 / 110  (64.5):   8%|         | 110/1436 [16:18<3:20:31,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 72 / 111  (64.9):   8%|         | 111/1436 [16:27<3:22:26,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 72 / 112  (64.3):   8%|         | 112/1436 [16:37<3:23:51,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 73 / 113  (64.6):   8%|         | 113/1436 [16:46<3:24:49,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 73 / 114  (64.0):   8%|         | 114/1436 [16:56<3:26:38,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 73 / 115  (63.5):   8%|         | 115/1436 [17:05<3:24:43,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 74 / 116  (63.8):   8%|         | 116/1436 [17:14<3:22:48,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 117  (64.1):   8%|         | 117/1436 [17:20<3:05:45,  8.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 76 / 118  (64.4):   8%|         | 118/1436 [17:30<3:09:55,  8.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 119  (64.7):   8%|         | 119/1436 [17:39<3:12:49,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 78 / 120  (65.0):   8%|         | 120/1436 [17:48<3:16:24,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 78 / 121  (64.5):   8%|         | 121/1436 [17:57<3:18:48,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 78 / 122  (63.9):   8%|         | 122/1436 [18:07<3:20:24,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 123  (64.2):   9%|         | 123/1436 [18:16<3:21:37,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 124  (63.7):   9%|         | 124/1436 [18:23<3:05:18,  8.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 80 / 125  (64.0):   9%|         | 125/1436 [18:32<3:10:33,  8.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 81 / 126  (64.3):   9%|         | 126/1436 [18:41<3:13:58,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 82 / 127  (64.6):   9%|         | 127/1436 [18:51<3:18:23,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 82 / 128  (64.1):   9%|         | 128/1436 [19:00<3:21:14,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 83 / 129  (64.3):   9%|         | 129/1436 [19:10<3:21:40,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 130  (64.6):   9%|         | 130/1436 [19:19<3:21:57,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 85 / 131  (64.9):   9%|         | 131/1436 [19:28<3:22:08,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 132  (65.2):   9%|         | 132/1436 [19:38<3:23:54,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 133  (64.7):   9%|         | 133/1436 [19:47<3:23:59,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 134  (64.9):   9%|         | 134/1436 [19:57<3:25:05,  9.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 135  (64.4):   9%|         | 135/1436 [20:06<3:24:55,  9.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 136  (64.0):   9%|         | 136/1436 [20:16<3:24:42,  9.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 137  (64.2):  10%|         | 137/1436 [20:25<3:24:23,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 138  (64.5):  10%|         | 138/1436 [20:35<3:24:06,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 139  (64.7):  10%|         | 139/1436 [20:44<3:23:18,  9.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 140  (65.0):  10%|         | 140/1436 [20:53<3:22:46,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 141  (64.5):  10%|         | 141/1436 [21:00<3:06:11,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 92 / 142  (64.8):  10%|         | 142/1436 [21:10<3:10:36,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 143  (65.0):  10%|         | 143/1436 [21:19<3:13:38,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 144  (65.3):  10%|         | 144/1436 [21:28<3:14:18,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 145  (64.8):  10%|         | 145/1436 [21:35<2:57:55,  8.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 95 / 146  (65.1):  10%|         | 146/1436 [21:44<3:03:11,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 96 / 147  (65.3):  10%|         | 147/1436 [21:53<3:08:45,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 148  (65.5):  10%|         | 148/1436 [22:03<3:12:41,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 149  (65.1):  10%|         | 149/1436 [22:12<3:16:25,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 98 / 150  (65.3):  10%|         | 150/1436 [22:22<3:19:02,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 151  (65.6):  11%|         | 151/1436 [22:31<3:20:41,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 152  (65.8):  11%|         | 152/1436 [22:41<3:21:52,  9.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 153  (65.4):  11%|         | 153/1436 [22:50<3:20:42,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 154  (64.9):  11%|         | 154/1436 [22:59<3:19:57,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 155  (64.5):  11%|         | 155/1436 [23:09<3:19:20,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 156  (64.1):  11%|         | 156/1436 [23:18<3:18:55,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 157  (63.7):  11%|         | 157/1436 [23:27<3:18:33,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 158  (63.3):  11%|         | 158/1436 [23:37<3:18:29,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 159  (63.5):  11%|         | 159/1436 [23:46<3:18:25,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 102 / 160  (63.8):  11%|         | 160/1436 [23:55<3:18:21,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 102 / 161  (63.4):  11%|         | 161/1436 [24:05<3:18:21,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 103 / 162  (63.6):  11%|        | 162/1436 [24:14<3:18:36,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 163  (63.8):  11%|        | 163/1436 [24:21<3:01:56,  8.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 164  (63.4):  11%|        | 164/1436 [24:30<3:06:58,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 165  (63.0):  11%|        | 165/1436 [24:37<2:54:53,  8.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 166  (62.7):  12%|        | 166/1436 [24:44<2:48:06,  7.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 167  (62.9):  12%|        | 167/1436 [24:54<2:56:24,  8.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 168  (63.1):  12%|        | 168/1436 [25:03<3:02:09,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 169  (63.3):  12%|        | 169/1436 [25:12<3:06:10,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 170  (62.9):  12%|        | 170/1436 [25:21<3:08:53,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 171  (62.6):  12%|        | 171/1436 [25:28<2:54:20,  8.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 172  (62.2):  12%|        | 172/1436 [25:37<3:01:04,  8.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 173  (62.4):  12%|        | 173/1436 [25:47<3:05:38,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 174  (62.6):  12%|        | 174/1436 [25:56<3:08:49,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 175  (62.9):  12%|        | 175/1436 [26:05<3:11:01,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 111 / 176  (63.1):  12%|        | 176/1436 [26:15<3:12:30,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 112 / 177  (63.3):  12%|        | 177/1436 [26:24<3:13:30,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 113 / 178  (63.5):  12%|        | 178/1436 [26:34<3:14:10,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 179  (63.7):  12%|        | 179/1436 [26:43<3:14:34,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 180  (63.9):  13%|        | 180/1436 [26:52<3:15:04,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 116 / 181  (64.1):  13%|        | 181/1436 [27:02<3:16:50,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 116 / 182  (63.7):  13%|        | 182/1436 [27:11<3:17:42,  9.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 116 / 183  (63.4):  13%|        | 183/1436 [27:21<3:18:22,  9.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 184  (63.6):  13%|        | 184/1436 [27:30<3:15:20,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 185  (63.8):  13%|        | 185/1436 [27:39<3:13:33,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 186  (64.0):  13%|        | 186/1436 [27:48<3:12:21,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 187  (63.6):  13%|        | 187/1436 [27:57<3:11:27,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 188  (63.8):  13%|        | 188/1436 [28:06<3:10:16,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 189  (63.5):  13%|        | 189/1436 [28:16<3:09:54,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 190  (63.2):  13%|        | 190/1436 [28:25<3:09:36,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 191  (62.8):  13%|        | 191/1436 [28:31<2:54:03,  8.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 192  (62.5):  13%|        | 192/1436 [28:40<2:58:20,  8.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 121 / 193  (62.7):  13%|        | 193/1436 [28:50<3:02:31,  8.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 121 / 194  (62.4):  14%|        | 194/1436 [28:59<3:04:19,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 122 / 195  (62.6):  14%|        | 195/1436 [29:08<3:06:35,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 123 / 196  (62.8):  14%|        | 196/1436 [29:17<3:08:08,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 124 / 197  (62.9):  14%|        | 197/1436 [29:27<3:09:12,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 198  (63.1):  14%|        | 198/1436 [29:33<2:53:55,  8.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 199  (63.3):  14%|        | 199/1436 [29:43<2:59:18,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 127 / 200  (63.5):  14%|        | 200/1436 [29:52<3:02:42,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 201  (63.7):  14%|        | 201/1436 [30:01<3:04:57,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 129 / 202  (63.9):  14%|        | 202/1436 [30:11<3:06:49,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 129 / 203  (63.5):  14%|        | 203/1436 [30:20<3:07:49,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 204  (63.7):  14%|        | 204/1436 [30:29<3:07:33,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 205  (63.9):  14%|        | 205/1436 [30:36<2:51:57,  8.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 206  (63.6):  14%|        | 206/1436 [30:43<2:42:30,  7.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 207  (63.3):  14%|        | 207/1436 [30:52<2:50:44,  8.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 132 / 208  (63.5):  14%|        | 208/1436 [31:01<2:56:22,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 133 / 209  (63.6):  15%|        | 209/1436 [31:10<3:00:10,  8.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 210  (63.8):  15%|        | 210/1436 [31:20<3:03:12,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 135 / 211  (64.0):  15%|        | 211/1436 [31:29<3:05:17,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 136 / 212  (64.2):  15%|        | 212/1436 [31:38<3:06:35,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 136 / 213  (63.8):  15%|        | 213/1436 [31:47<3:06:13,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 137 / 214  (64.0):  15%|        | 214/1436 [31:57<3:05:55,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 138 / 215  (64.2):  15%|        | 215/1436 [32:03<2:51:41,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 139 / 216  (64.4):  15%|        | 216/1436 [32:12<2:55:33,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 139 / 217  (64.1):  15%|        | 217/1436 [32:21<2:57:46,  8.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 139 / 218  (63.8):  15%|        | 218/1436 [32:31<2:59:41,  8.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 139 / 219  (63.5):  15%|        | 219/1436 [32:40<3:00:34,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 140 / 220  (63.6):  15%|        | 220/1436 [32:49<3:01:04,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 221  (63.8):  15%|        | 221/1436 [32:58<3:03:08,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 142 / 222  (64.0):  15%|        | 222/1436 [33:07<3:04:26,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 223  (64.1):  16%|        | 223/1436 [33:16<3:05:16,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 224  (63.8):  16%|        | 224/1436 [33:26<3:05:47,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 144 / 225  (64.0):  16%|        | 225/1436 [33:35<3:06:12,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 145 / 226  (64.2):  16%|        | 226/1436 [33:44<3:06:21,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 146 / 227  (64.3):  16%|        | 227/1436 [33:54<3:06:31,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 146 / 228  (64.0):  16%|        | 228/1436 [34:03<3:06:32,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 147 / 229  (64.2):  16%|        | 229/1436 [34:12<3:06:39,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 230  (64.3):  16%|        | 230/1436 [34:21<3:05:03,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 149 / 231  (64.5):  16%|        | 231/1436 [34:30<3:04:12,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 150 / 232  (64.7):  16%|        | 232/1436 [34:39<3:03:08,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 150 / 233  (64.4):  16%|        | 233/1436 [34:48<3:02:52,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 234  (64.5):  16%|        | 234/1436 [34:58<3:02:39,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 235  (64.7):  16%|        | 235/1436 [35:07<3:03:49,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 236  (64.8):  16%|        | 236/1436 [35:16<3:04:25,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 154 / 237  (65.0):  17%|        | 237/1436 [35:26<3:05:00,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 154 / 238  (64.7):  17%|        | 238/1436 [35:35<3:05:18,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 239  (64.9):  17%|        | 239/1436 [35:44<3:05:04,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 240  (65.0):  17%|        | 240/1436 [35:53<3:04:52,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 241  (65.1):  17%|        | 241/1436 [36:03<3:04:41,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 158 / 242  (65.3):  17%|        | 242/1436 [36:09<2:48:17,  8.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 243  (65.4):  17%|        | 243/1436 [36:19<2:53:00,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 244  (65.6):  17%|        | 244/1436 [36:28<2:56:13,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 245  (65.7):  17%|        | 245/1436 [36:37<2:58:45,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 246  (65.4):  17%|        | 246/1436 [36:46<3:00:06,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 247  (65.6):  17%|        | 247/1436 [36:56<3:01:06,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 248  (65.3):  17%|        | 248/1436 [37:05<3:02:25,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 249  (65.1):  17%|        | 249/1436 [37:14<3:03:21,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 250  (64.8):  17%|        | 250/1436 [37:21<2:48:42,  8.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 251  (64.9):  17%|        | 251/1436 [37:31<2:53:45,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 164 / 252  (65.1):  18%|        | 252/1436 [37:40<2:57:18,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 253  (65.2):  18%|        | 253/1436 [37:47<2:44:53,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 254  (65.0):  18%|        | 254/1436 [37:56<2:51:00,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 255  (64.7):  18%|        | 255/1436 [38:06<2:56:10,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 166 / 256  (64.8):  18%|        | 256/1436 [38:15<2:56:49,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 166 / 257  (64.6):  18%|        | 257/1436 [38:24<2:57:20,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 166 / 258  (64.3):  18%|        | 258/1436 [38:33<2:57:38,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 166 / 259  (64.1):  18%|        | 259/1436 [38:42<2:57:49,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 260  (64.2):  18%|        | 260/1436 [38:52<2:57:57,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 168 / 261  (64.4):  18%|        | 261/1436 [39:01<2:57:57,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 169 / 262  (64.5):  18%|        | 262/1436 [39:10<2:57:55,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 263  (64.6):  18%|        | 263/1436 [39:19<2:57:53,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 264  (64.8):  18%|        | 264/1436 [39:28<2:57:45,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 172 / 265  (64.9):  18%|        | 265/1436 [39:37<2:57:36,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 266  (65.0):  19%|        | 266/1436 [39:46<2:57:28,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 174 / 267  (65.2):  19%|        | 267/1436 [39:55<2:57:15,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 175 / 268  (65.3):  19%|        | 268/1436 [40:04<2:57:05,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 176 / 269  (65.4):  19%|        | 269/1436 [40:13<2:56:58,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 270  (65.6):  19%|        | 270/1436 [40:23<2:57:00,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 271  (65.7):  19%|        | 271/1436 [40:32<2:56:52,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 179 / 272  (65.8):  19%|        | 272/1436 [40:41<2:57:44,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 180 / 273  (65.9):  19%|        | 273/1436 [40:50<2:58:27,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 181 / 274  (66.1):  19%|        | 274/1436 [40:59<2:57:17,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 182 / 275  (66.2):  19%|        | 275/1436 [41:08<2:56:52,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 276  (66.3):  19%|        | 276/1436 [41:17<2:56:08,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 277  (66.1):  19%|        | 277/1436 [41:26<2:55:31,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 278  (66.2):  19%|        | 278/1436 [41:36<2:55:03,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 185 / 279  (66.3):  19%|        | 279/1436 [41:42<2:39:06,  8.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 280  (66.4):  19%|        | 280/1436 [41:51<2:43:54,  8.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 281  (66.2):  20%|        | 281/1436 [42:00<2:46:48,  8.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 282  (66.3):  20%|        | 282/1436 [42:09<2:50:28,  8.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 283  (66.1):  20%|        | 283/1436 [42:19<2:53:04,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 188 / 284  (66.2):  20%|        | 284/1436 [42:28<2:54:51,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 285  (66.3):  20%|        | 285/1436 [42:37<2:56:00,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 286  (66.4):  20%|        | 286/1436 [42:47<2:56:44,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 287  (66.6):  20%|        | 287/1436 [42:56<2:57:16,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 288  (66.3):  20%|        | 288/1436 [43:05<2:57:32,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 289  (66.4):  20%|        | 289/1436 [43:15<2:57:41,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 290  (66.2):  20%|        | 290/1436 [43:24<2:57:48,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 291  (66.0):  20%|        | 291/1436 [43:33<2:57:55,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 292  (66.1):  20%|        | 292/1436 [43:43<2:57:50,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 194 / 293  (66.2):  20%|        | 293/1436 [43:52<2:57:49,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 195 / 294  (66.3):  20%|        | 294/1436 [44:01<2:57:36,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 196 / 295  (66.4):  21%|        | 295/1436 [44:11<2:57:24,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 197 / 296  (66.6):  21%|        | 296/1436 [44:20<2:57:14,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 297  (66.7):  21%|        | 297/1436 [44:29<2:55:52,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 298  (66.8):  21%|        | 298/1436 [44:38<2:54:49,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 299  (66.9):  21%|        | 299/1436 [44:47<2:54:05,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 300  (67.0):  21%|        | 300/1436 [44:57<2:53:38,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 202 / 301  (67.1):  21%|        | 301/1436 [45:06<2:53:06,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 203 / 302  (67.2):  21%|        | 302/1436 [45:15<2:54:03,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 203 / 303  (67.0):  21%|        | 303/1436 [45:24<2:55:00,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 304  (67.1):  21%|        | 304/1436 [45:31<2:40:16,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 305  (67.2):  21%|        | 305/1436 [45:38<2:31:54,  8.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 306  (67.3):  21%|       | 306/1436 [45:47<2:37:43,  8.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 207 / 307  (67.4):  21%|       | 307/1436 [45:56<2:41:49,  8.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 308  (67.5):  21%|       | 308/1436 [46:05<2:44:36,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 309  (67.3):  22%|       | 309/1436 [46:15<2:47:25,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 310  (67.1):  22%|       | 310/1436 [46:24<2:48:29,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 311  (67.2):  22%|       | 311/1436 [46:33<2:50:48,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 312  (67.0):  22%|       | 312/1436 [46:43<2:52:23,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 313  (66.8):  22%|       | 313/1436 [46:52<2:54:21,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 314  (66.9):  22%|       | 314/1436 [47:02<2:54:43,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 315  (66.7):  22%|       | 315/1436 [47:11<2:55:02,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 316  (66.8):  22%|       | 316/1436 [47:20<2:54:45,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 317  (66.9):  22%|       | 317/1436 [47:30<2:54:33,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 213 / 318  (67.0):  22%|       | 318/1436 [47:39<2:54:34,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 213 / 319  (66.8):  22%|       | 319/1436 [47:49<2:54:31,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 214 / 320  (66.9):  22%|       | 320/1436 [47:58<2:53:56,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 321  (67.0):  22%|       | 321/1436 [48:07<2:53:20,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 216 / 322  (67.1):  22%|       | 322/1436 [48:16<2:52:48,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 216 / 323  (66.9):  22%|       | 323/1436 [48:26<2:51:40,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 216 / 324  (66.7):  23%|       | 324/1436 [48:35<2:50:50,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 216 / 325  (66.5):  23%|       | 325/1436 [48:44<2:50:10,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 217 / 326  (66.6):  23%|       | 326/1436 [48:53<2:49:34,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 218 / 327  (66.7):  23%|       | 327/1436 [49:02<2:49:06,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 219 / 328  (66.8):  23%|       | 328/1436 [49:11<2:48:46,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 329  (66.9):  23%|       | 329/1436 [49:20<2:48:30,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 330  (66.7):  23%|       | 330/1436 [49:29<2:48:15,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 221 / 331  (66.8):  23%|       | 331/1436 [49:38<2:48:01,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 332  (66.9):  23%|       | 332/1436 [49:45<2:34:44,  8.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 333  (66.7):  23%|       | 333/1436 [49:54<2:37:56,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 334  (66.5):  23%|       | 334/1436 [50:03<2:40:33,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 223 / 335  (66.6):  23%|       | 335/1436 [50:12<2:41:59,  8.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 223 / 336  (66.4):  23%|       | 336/1436 [50:21<2:43:17,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 223 / 337  (66.2):  23%|       | 337/1436 [50:28<2:30:06,  8.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 338  (66.3):  24%|       | 338/1436 [50:37<2:34:31,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 339  (66.1):  24%|       | 339/1436 [50:46<2:37:32,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 340  (65.9):  24%|       | 340/1436 [50:55<2:39:41,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 341  (65.7):  24%|       | 341/1436 [51:04<2:41:02,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 342  (65.5):  24%|       | 342/1436 [51:13<2:42:01,  8.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 225 / 343  (65.6):  24%|       | 343/1436 [51:22<2:44:17,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 344  (65.7):  24%|       | 344/1436 [51:29<2:31:04,  8.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 227 / 345  (65.8):  24%|       | 345/1436 [51:36<2:22:20,  7.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 346  (65.9):  24%|       | 346/1436 [51:45<2:30:04,  8.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 347  (66.0):  24%|       | 347/1436 [51:52<2:22:21,  7.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 348  (66.1):  24%|       | 348/1436 [52:01<2:29:06,  8.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 349  (65.9):  24%|       | 349/1436 [52:10<2:33:49,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 231 / 350  (66.0):  24%|       | 350/1436 [52:19<2:37:01,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 231 / 351  (65.8):  24%|       | 351/1436 [52:28<2:39:16,  8.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 232 / 352  (65.9):  25%|       | 352/1436 [52:37<2:40:45,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 232 / 353  (65.7):  25%|       | 353/1436 [52:47<2:43:13,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 232 / 354  (65.5):  25%|       | 354/1436 [52:56<2:45:02,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 233 / 355  (65.6):  25%|       | 355/1436 [53:06<2:46:14,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 356  (65.7):  25%|       | 356/1436 [53:15<2:47:06,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 235 / 357  (65.8):  25%|       | 357/1436 [53:24<2:45:57,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 358  (65.9):  25%|       | 358/1436 [53:33<2:45:14,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 359  (65.7):  25%|       | 359/1436 [53:42<2:44:43,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 360  (65.8):  25%|       | 360/1436 [53:52<2:44:13,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 361  (65.7):  25%|       | 361/1436 [54:01<2:45:30,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 238 / 362  (65.7):  25%|       | 362/1436 [54:11<2:47:08,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 239 / 363  (65.8):  25%|       | 363/1436 [54:20<2:48:20,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 239 / 364  (65.7):  25%|       | 364/1436 [54:30<2:49:04,  9.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 365  (65.8):  25%|       | 365/1436 [54:39<2:46:36,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 366  (65.8):  25%|       | 366/1436 [54:48<2:45:13,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 242 / 367  (65.9):  26%|       | 367/1436 [54:57<2:44:09,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 243 / 368  (66.0):  26%|       | 368/1436 [55:06<2:43:29,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 244 / 369  (66.1):  26%|       | 369/1436 [55:16<2:45:25,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 370  (66.2):  26%|       | 370/1436 [55:25<2:46:46,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 371  (66.3):  26%|       | 371/1436 [55:34<2:45:06,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 372  (66.4):  26%|       | 372/1436 [55:43<2:43:57,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 373  (66.5):  26%|       | 373/1436 [55:53<2:43:04,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 249 / 374  (66.6):  26%|       | 374/1436 [56:02<2:42:26,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 250 / 375  (66.7):  26%|       | 375/1436 [56:11<2:41:52,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 376  (66.8):  26%|       | 376/1436 [56:20<2:41:00,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 252 / 377  (66.8):  26%|       | 377/1436 [56:29<2:40:26,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 253 / 378  (66.9):  26%|       | 378/1436 [56:35<2:26:05,  8.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 254 / 379  (67.0):  26%|       | 379/1436 [56:44<2:29:55,  8.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 380  (67.1):  26%|       | 380/1436 [56:51<2:19:10,  7.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 381  (66.9):  27%|       | 381/1436 [56:58<2:17:46,  7.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 382  (66.8):  27%|       | 382/1436 [57:08<2:26:52,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 256 / 383  (66.8):  27%|       | 383/1436 [57:17<2:31:31,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 256 / 384  (66.7):  27%|       | 384/1436 [57:27<2:35:04,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 385  (66.8):  27%|       | 385/1436 [57:36<2:37:29,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 386  (66.8):  27%|       | 386/1436 [57:45<2:39:06,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 259 / 387  (66.9):  27%|       | 387/1436 [57:55<2:39:54,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 388  (67.0):  27%|       | 388/1436 [58:04<2:40:26,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 389  (67.1):  27%|       | 389/1436 [58:13<2:41:02,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 262 / 390  (67.2):  27%|       | 390/1436 [58:22<2:41:03,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 391  (67.3):  27%|       | 391/1436 [58:32<2:40:16,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 392  (67.3):  27%|       | 392/1436 [58:41<2:39:39,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 393  (67.2):  27%|       | 393/1436 [58:50<2:40:07,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 265 / 394  (67.3):  27%|       | 394/1436 [58:57<2:28:31,  8.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 266 / 395  (67.3):  28%|       | 395/1436 [59:06<2:31:06,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 396  (67.4):  28%|       | 396/1436 [59:12<2:18:44,  8.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 397  (67.3):  28%|       | 397/1436 [59:21<2:23:55,  8.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 268 / 398  (67.3):  28%|       | 398/1436 [59:28<2:13:40,  7.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 269 / 399  (67.4):  28%|       | 399/1436 [59:37<2:20:14,  8.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 400  (67.5):  28%|       | 400/1436 [59:46<2:26:53,  8.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 401  (67.3):  28%|       | 401/1436 [59:53<2:19:33,  8.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 402  (67.4):  28%|       | 402/1436 [1:00:03<2:27:10,  8.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 403  (67.2):  28%|       | 403/1436 [1:00:13<2:32:28,  8.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 272 / 404  (67.3):  28%|       | 404/1436 [1:00:22<2:36:03,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 405  (67.4):  28%|       | 405/1436 [1:00:31<2:35:59,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 406  (67.2):  28%|       | 406/1436 [1:00:40<2:35:33,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 407  (67.3):  28%|       | 407/1436 [1:00:49<2:35:33,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 408  (67.2):  28%|       | 408/1436 [1:00:58<2:35:11,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 409  (67.2):  28%|       | 409/1436 [1:01:07<2:35:10,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 410  (67.1):  29%|       | 410/1436 [1:01:17<2:35:01,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 411  (66.9):  29%|       | 411/1436 [1:01:26<2:34:58,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 412  (67.0):  29%|       | 412/1436 [1:01:32<2:21:49,  8.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 413  (67.1):  29%|       | 413/1436 [1:01:41<2:25:39,  8.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 414  (66.9):  29%|       | 414/1436 [1:01:51<2:29:32,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 415  (67.0):  29%|       | 415/1436 [1:02:00<2:31:52,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 416  (66.8):  29%|       | 416/1436 [1:02:09<2:33:46,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 417  (66.7):  29%|       | 417/1436 [1:02:16<2:23:37,  8.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 279 / 418  (66.7):  29%|       | 418/1436 [1:02:26<2:28:20,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 419  (66.8):  29%|       | 419/1436 [1:02:35<2:31:30,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 420  (66.7):  29%|       | 420/1436 [1:02:44<2:33:45,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 421  (66.5):  29%|       | 421/1436 [1:02:54<2:35:19,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 281 / 422  (66.6):  29%|       | 422/1436 [1:03:03<2:35:34,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 282 / 423  (66.7):  29%|       | 423/1436 [1:03:12<2:35:41,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 282 / 424  (66.5):  30%|       | 424/1436 [1:03:22<2:35:49,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 283 / 425  (66.6):  30%|       | 425/1436 [1:03:31<2:35:45,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 426  (66.7):  30%|       | 426/1436 [1:03:40<2:34:56,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 427  (66.5):  30%|       | 427/1436 [1:03:49<2:34:23,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 428  (66.4):  30%|       | 428/1436 [1:03:58<2:33:57,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 429  (66.2):  30%|       | 429/1436 [1:04:08<2:34:33,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 430  (66.3):  30%|       | 430/1436 [1:04:17<2:35:00,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 286 / 431  (66.4):  30%|       | 431/1436 [1:04:26<2:34:56,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 432  (66.4):  30%|       | 432/1436 [1:04:35<2:34:54,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 433  (66.3):  30%|       | 433/1436 [1:04:45<2:35:04,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 434  (66.4):  30%|       | 434/1436 [1:04:54<2:34:49,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 289 / 435  (66.4):  30%|       | 435/1436 [1:05:03<2:34:42,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 290 / 436  (66.5):  30%|       | 436/1436 [1:05:13<2:34:41,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 437  (66.6):  30%|       | 437/1436 [1:05:22<2:34:47,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 292 / 438  (66.7):  31%|       | 438/1436 [1:05:31<2:34:49,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 293 / 439  (66.7):  31%|       | 439/1436 [1:05:41<2:34:49,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 293 / 440  (66.6):  31%|       | 440/1436 [1:05:50<2:34:31,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 294 / 441  (66.7):  31%|       | 441/1436 [1:05:59<2:34:24,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 442  (66.7):  31%|       | 442/1436 [1:06:09<2:34:19,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 443  (66.8):  31%|       | 443/1436 [1:06:18<2:34:09,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 444  (66.7):  31%|       | 444/1436 [1:06:27<2:34:06,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 445  (66.5):  31%|       | 445/1436 [1:06:37<2:34:17,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 297 / 446  (66.6):  31%|       | 446/1436 [1:06:46<2:34:23,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 298 / 447  (66.7):  31%|       | 447/1436 [1:06:55<2:34:14,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 448  (66.7):  31%|       | 448/1436 [1:07:05<2:34:11,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 300 / 449  (66.8):  31%|      | 449/1436 [1:07:14<2:34:09,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 300 / 450  (66.7):  31%|      | 450/1436 [1:07:23<2:32:35,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 301 / 451  (66.7):  31%|      | 451/1436 [1:07:32<2:31:24,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 302 / 452  (66.8):  31%|      | 452/1436 [1:07:41<2:30:29,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 303 / 453  (66.9):  32%|      | 453/1436 [1:07:50<2:29:52,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 304 / 454  (67.0):  32%|      | 454/1436 [1:08:00<2:29:23,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 455  (67.0):  32%|      | 455/1436 [1:08:09<2:29:07,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 306 / 456  (67.1):  32%|      | 456/1436 [1:08:18<2:29:00,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 457  (67.2):  32%|      | 457/1436 [1:08:27<2:28:45,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 458  (67.0):  32%|      | 458/1436 [1:08:33<2:16:05,  8.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 308 / 459  (67.1):  32%|      | 459/1436 [1:08:43<2:19:40,  8.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 308 / 460  (67.0):  32%|      | 460/1436 [1:08:52<2:23:12,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 461  (67.0):  32%|      | 461/1436 [1:09:01<2:25:36,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 462  (67.1):  32%|      | 462/1436 [1:09:10<2:26:56,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 463  (67.2):  32%|      | 463/1436 [1:09:20<2:28:27,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 464  (67.0):  32%|      | 464/1436 [1:09:27<2:19:56,  8.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 465  (67.1):  32%|      | 465/1436 [1:09:37<2:23:24,  8.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 466  (67.0):  32%|      | 466/1436 [1:09:46<2:25:54,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 467  (66.8):  33%|      | 467/1436 [1:09:55<2:27:14,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 468  (66.7):  33%|      | 468/1436 [1:10:05<2:28:09,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 469  (66.5):  33%|      | 469/1436 [1:10:14<2:28:49,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 470  (66.4):  33%|      | 470/1436 [1:10:23<2:29:10,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 471  (66.5):  33%|      | 471/1436 [1:10:33<2:30:39,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 472  (66.5):  33%|      | 472/1436 [1:10:43<2:31:40,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 473  (66.6):  33%|      | 473/1436 [1:10:52<2:32:15,  9.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 474  (66.5):  33%|      | 474/1436 [1:11:02<2:32:59,  9.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 475  (66.3):  33%|      | 475/1436 [1:11:11<2:30:39,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 476  (66.4):  33%|      | 476/1436 [1:11:20<2:29:00,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 477  (66.5):  33%|      | 477/1436 [1:11:29<2:28:54,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 478  (66.5):  33%|      | 478/1436 [1:11:39<2:28:44,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 479  (66.6):  33%|      | 479/1436 [1:11:46<2:17:40,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 480  (66.5):  33%|      | 480/1436 [1:11:55<2:22:03,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 481  (66.5):  33%|      | 481/1436 [1:12:04<2:22:51,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 482  (66.4):  34%|      | 482/1436 [1:12:14<2:23:18,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 483  (66.3):  34%|      | 483/1436 [1:12:23<2:23:35,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 484  (66.1):  34%|      | 484/1436 [1:12:32<2:24:27,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 485  (66.0):  34%|      | 485/1436 [1:12:41<2:25:00,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 321 / 486  (66.0):  34%|      | 486/1436 [1:12:50<2:25:31,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 321 / 487  (65.9):  34%|      | 487/1436 [1:13:00<2:27:18,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 321 / 488  (65.8):  34%|      | 488/1436 [1:13:07<2:16:28,  8.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 322 / 489  (65.8):  34%|      | 489/1436 [1:13:15<2:10:42,  8.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 490  (65.9):  34%|      | 490/1436 [1:13:24<2:14:33,  8.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 491  (66.0):  34%|      | 491/1436 [1:13:33<2:17:13,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 492  (66.1):  34%|      | 492/1436 [1:13:42<2:19:01,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 326 / 493  (66.1):  34%|      | 493/1436 [1:13:51<2:20:15,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 326 / 494  (66.0):  34%|      | 494/1436 [1:14:00<2:21:01,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 326 / 495  (65.9):  34%|      | 495/1436 [1:14:09<2:22:14,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 327 / 496  (65.9):  35%|      | 496/1436 [1:14:19<2:23:15,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 328 / 497  (66.0):  35%|      | 497/1436 [1:14:28<2:23:45,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 329 / 498  (66.1):  35%|      | 498/1436 [1:14:37<2:23:57,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 499  (66.1):  35%|      | 499/1436 [1:14:47<2:24:06,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 500  (66.2):  35%|      | 500/1436 [1:14:56<2:24:33,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 332 / 501  (66.3):  35%|      | 501/1436 [1:15:05<2:24:43,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 332 / 502  (66.1):  35%|      | 502/1436 [1:15:15<2:25:02,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 503  (66.2):  35%|      | 503/1436 [1:15:24<2:25:01,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 504  (66.3):  35%|      | 504/1436 [1:15:33<2:24:39,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 505  (66.3):  35%|      | 505/1436 [1:15:43<2:24:32,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 506  (66.2):  35%|      | 506/1436 [1:15:52<2:24:25,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 507  (66.1):  35%|      | 507/1436 [1:16:01<2:24:20,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 508  (65.9):  35%|      | 508/1436 [1:16:11<2:24:12,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 336 / 509  (66.0):  35%|      | 509/1436 [1:16:20<2:24:04,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 337 / 510  (66.1):  36%|      | 510/1436 [1:16:29<2:23:58,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 338 / 511  (66.1):  36%|      | 511/1436 [1:16:39<2:23:48,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 338 / 512  (66.0):  36%|      | 512/1436 [1:16:48<2:24:01,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 338 / 513  (65.9):  36%|      | 513/1436 [1:16:57<2:24:15,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 339 / 514  (66.0):  36%|      | 514/1436 [1:17:07<2:25:11,  9.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 339 / 515  (65.8):  36%|      | 515/1436 [1:17:16<2:24:56,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 516  (65.9):  36%|      | 516/1436 [1:17:26<2:23:58,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 517  (65.8):  36%|      | 517/1436 [1:17:35<2:23:12,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 518  (65.6):  36%|      | 518/1436 [1:17:42<2:11:10,  8.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 519  (65.5):  36%|      | 519/1436 [1:17:51<2:14:09,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 520  (65.6):  36%|      | 520/1436 [1:17:58<2:04:28,  8.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 342 / 521  (65.6):  36%|      | 521/1436 [1:18:07<2:08:45,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 343 / 522  (65.7):  36%|      | 522/1436 [1:18:16<2:11:42,  8.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 523  (65.8):  36%|      | 523/1436 [1:18:25<2:13:44,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 524  (65.6):  36%|      | 524/1436 [1:18:32<2:03:43,  8.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 345 / 525  (65.7):  37%|      | 525/1436 [1:18:41<2:07:59,  8.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 346 / 526  (65.8):  37%|      | 526/1436 [1:18:50<2:10:59,  8.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 347 / 527  (65.8):  37%|      | 527/1436 [1:18:59<2:13:01,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 348 / 528  (65.9):  37%|      | 528/1436 [1:19:08<2:14:27,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 529  (66.0):  37%|      | 529/1436 [1:19:18<2:16:23,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 530  (65.8):  37%|      | 530/1436 [1:19:27<2:17:56,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 531  (65.7):  37%|      | 531/1436 [1:19:36<2:18:47,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 532  (65.6):  37%|      | 532/1436 [1:19:46<2:19:21,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 533  (65.5):  37%|      | 533/1436 [1:19:55<2:19:47,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 350 / 534  (65.5):  37%|      | 534/1436 [1:20:04<2:20:07,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 535  (65.6):  37%|      | 535/1436 [1:20:11<2:09:19,  8.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 536  (65.5):  37%|      | 536/1436 [1:20:19<2:02:58,  8.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 352 / 537  (65.5):  37%|      | 537/1436 [1:20:28<2:08:11,  8.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 353 / 538  (65.6):  37%|      | 538/1436 [1:20:37<2:11:32,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 353 / 539  (65.5):  38%|      | 539/1436 [1:20:47<2:13:56,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 353 / 540  (65.4):  38%|      | 540/1436 [1:20:56<2:15:33,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 353 / 541  (65.2):  38%|      | 541/1436 [1:21:05<2:16:39,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 542  (65.3):  38%|      | 542/1436 [1:21:15<2:17:18,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 543  (65.4):  38%|      | 543/1436 [1:21:24<2:18:00,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 544  (65.3):  38%|      | 544/1436 [1:21:30<2:00:56,  8.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 545  (65.3):  38%|      | 545/1436 [1:21:39<2:06:23,  8.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 546  (65.2):  38%|      | 546/1436 [1:21:46<1:59:12,  8.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 547  (65.3):  38%|      | 547/1436 [1:21:55<2:05:03,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 358 / 548  (65.3):  38%|      | 548/1436 [1:22:05<2:09:50,  8.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 358 / 549  (65.2):  38%|      | 549/1436 [1:22:14<2:13:18,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 550  (65.3):  38%|      | 550/1436 [1:22:24<2:15:41,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 551  (65.2):  38%|      | 551/1436 [1:22:34<2:17:04,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 552  (65.2):  38%|      | 552/1436 [1:22:43<2:16:02,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 553  (65.1):  39%|      | 553/1436 [1:22:52<2:15:00,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 361 / 554  (65.2):  39%|      | 554/1436 [1:23:01<2:14:27,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 555  (65.2):  39%|      | 555/1436 [1:23:10<2:13:47,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 556  (65.1):  39%|      | 556/1436 [1:23:19<2:13:16,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 363 / 557  (65.2):  39%|      | 557/1436 [1:23:28<2:14:16,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 364 / 558  (65.2):  39%|      | 558/1436 [1:23:38<2:14:53,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 559  (65.3):  39%|      | 559/1436 [1:23:47<2:15:19,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 366 / 560  (65.4):  39%|      | 560/1436 [1:23:56<2:15:29,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 561  (65.4):  39%|      | 561/1436 [1:24:06<2:15:32,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 562  (65.3):  39%|      | 562/1436 [1:24:12<2:04:42,  8.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 563  (65.4):  39%|      | 563/1436 [1:24:19<1:56:53,  8.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 564  (65.2):  39%|      | 564/1436 [1:24:29<2:02:27,  8.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 565  (65.3):  39%|      | 565/1436 [1:24:38<2:06:19,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 566  (65.4):  39%|      | 566/1436 [1:24:47<2:08:58,  8.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 371 / 567  (65.4):  39%|      | 567/1436 [1:24:57<2:10:44,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 371 / 568  (65.3):  40%|      | 568/1436 [1:25:06<2:12:15,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 371 / 569  (65.2):  40%|      | 569/1436 [1:25:15<2:13:10,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 570  (65.3):  40%|      | 570/1436 [1:25:25<2:13:50,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 571  (65.1):  40%|      | 571/1436 [1:25:34<2:14:13,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 572  (65.0):  40%|      | 572/1436 [1:25:44<2:14:29,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 573  (65.1):  40%|      | 573/1436 [1:25:53<2:14:04,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 574  (65.0):  40%|      | 574/1436 [1:26:02<2:13:42,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 575  (65.0):  40%|      | 575/1436 [1:26:11<2:13:24,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 375 / 576  (65.1):  40%|      | 576/1436 [1:26:21<2:13:23,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 375 / 577  (65.0):  40%|      | 577/1436 [1:26:30<2:13:23,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 578  (65.1):  40%|      | 578/1436 [1:26:37<2:02:49,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 579  (64.9):  40%|      | 579/1436 [1:26:46<2:05:41,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 580  (64.8):  40%|      | 580/1436 [1:26:56<2:07:34,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 581  (64.7):  40%|      | 581/1436 [1:27:05<2:08:47,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 582  (64.6):  41%|      | 582/1436 [1:27:14<2:09:44,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 583  (64.5):  41%|      | 583/1436 [1:27:23<2:10:27,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 584  (64.6):  41%|      | 584/1436 [1:27:33<2:10:54,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 585  (64.4):  41%|      | 585/1436 [1:27:42<2:11:10,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 378 / 586  (64.5):  41%|      | 586/1436 [1:27:51<2:11:25,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 378 / 587  (64.4):  41%|      | 587/1436 [1:28:01<2:11:29,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 588  (64.5):  41%|      | 588/1436 [1:28:10<2:11:49,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 589  (64.3):  41%|      | 589/1436 [1:28:20<2:11:58,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 590  (64.4):  41%|      | 590/1436 [1:28:26<2:01:30,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 591  (64.3):  41%|      | 591/1436 [1:28:36<2:04:42,  8.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 592  (64.2):  41%|      | 592/1436 [1:28:45<2:06:52,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 381 / 593  (64.2):  41%|     | 593/1436 [1:28:54<2:06:43,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 382 / 594  (64.3):  41%|     | 594/1436 [1:29:01<1:56:00,  8.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 595  (64.4):  41%|     | 595/1436 [1:29:07<1:48:27,  7.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 596  (64.4):  42%|     | 596/1436 [1:29:14<1:43:01,  7.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 597  (64.5):  42%|     | 597/1436 [1:29:20<1:39:08,  7.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 598  (64.5):  42%|     | 598/1436 [1:29:30<1:48:40,  7.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 599  (64.4):  42%|     | 599/1436 [1:29:36<1:44:33,  7.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 600  (64.3):  42%|     | 600/1436 [1:29:46<1:52:25,  8.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 601  (64.2):  42%|     | 601/1436 [1:29:53<1:47:23,  7.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 602  (64.1):  42%|     | 602/1436 [1:30:02<1:53:40,  8.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 387 / 603  (64.2):  42%|     | 603/1436 [1:30:11<1:58:04,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 388 / 604  (64.2):  42%|     | 604/1436 [1:30:21<2:01:13,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 388 / 605  (64.1):  42%|     | 605/1436 [1:30:30<2:03:15,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 389 / 606  (64.2):  42%|     | 606/1436 [1:30:39<2:04:38,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 390 / 607  (64.3):  42%|     | 607/1436 [1:30:49<2:07:14,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 390 / 608  (64.1):  42%|     | 608/1436 [1:30:58<2:08:58,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 391 / 609  (64.2):  42%|     | 609/1436 [1:31:08<2:10:09,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 391 / 610  (64.1):  42%|     | 610/1436 [1:31:18<2:10:54,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 611  (64.2):  43%|     | 611/1436 [1:31:27<2:10:03,  9.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 612  (64.2):  43%|     | 612/1436 [1:31:36<2:09:25,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 613  (64.3):  43%|     | 613/1436 [1:31:46<2:08:57,  9.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 614  (64.2):  43%|     | 614/1436 [1:31:53<1:59:25,  8.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 615  (64.1):  43%|     | 615/1436 [1:32:02<2:02:09,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 616  (64.0):  43%|     | 616/1436 [1:32:08<1:48:03,  7.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 395 / 617  (64.0):  43%|     | 617/1436 [1:32:17<1:54:48,  8.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 618  (64.1):  43%|     | 618/1436 [1:32:27<1:58:26,  8.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 619  (64.0):  43%|     | 619/1436 [1:32:36<2:00:58,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 397 / 620  (64.0):  43%|     | 620/1436 [1:32:45<2:02:43,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 398 / 621  (64.1):  43%|     | 621/1436 [1:32:55<2:03:56,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 622  (64.1):  43%|     | 622/1436 [1:33:04<2:04:40,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 400 / 623  (64.2):  43%|     | 623/1436 [1:33:13<2:04:08,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 624  (64.3):  43%|     | 624/1436 [1:33:22<2:03:45,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 402 / 625  (64.3):  44%|     | 625/1436 [1:33:31<2:03:25,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 403 / 626  (64.4):  44%|     | 626/1436 [1:33:41<2:03:08,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 404 / 627  (64.4):  44%|     | 627/1436 [1:33:47<1:52:07,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 628  (64.5):  44%|     | 628/1436 [1:33:56<1:54:51,  8.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 406 / 629  (64.5):  44%|     | 629/1436 [1:34:05<1:56:42,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 630  (64.6):  44%|     | 630/1436 [1:34:14<1:58:16,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 631  (64.7):  44%|     | 631/1436 [1:34:23<1:59:04,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 632  (64.6):  44%|     | 632/1436 [1:34:33<2:00:36,  9.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 409 / 633  (64.6):  44%|     | 633/1436 [1:34:42<2:01:42,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 410 / 634  (64.7):  44%|     | 634/1436 [1:34:51<2:02:27,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 411 / 635  (64.7):  44%|     | 635/1436 [1:35:00<2:02:48,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 412 / 636  (64.8):  44%|     | 636/1436 [1:35:10<2:03:05,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 413 / 637  (64.8):  44%|     | 637/1436 [1:35:19<2:03:13,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 414 / 638  (64.9):  44%|     | 638/1436 [1:35:28<2:03:10,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 414 / 639  (64.8):  44%|     | 639/1436 [1:35:38<2:03:14,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 414 / 640  (64.7):  45%|     | 640/1436 [1:35:47<2:03:02,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 415 / 641  (64.7):  45%|     | 641/1436 [1:35:56<2:03:05,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 415 / 642  (64.6):  45%|     | 642/1436 [1:36:06<2:03:02,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 643  (64.7):  45%|     | 643/1436 [1:36:12<1:52:44,  8.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 417 / 644  (64.8):  45%|     | 644/1436 [1:36:19<1:45:33,  8.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 418 / 645  (64.8):  45%|     | 645/1436 [1:36:28<1:50:42,  8.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 646  (64.9):  45%|     | 646/1436 [1:36:38<1:54:17,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 647  (64.8):  45%|     | 647/1436 [1:36:44<1:46:24,  8.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 420 / 648  (64.8):  45%|     | 648/1436 [1:36:54<1:51:10,  8.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 649  (64.9):  45%|     | 649/1436 [1:37:00<1:43:56,  7.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 650  (64.9):  45%|     | 650/1436 [1:37:10<1:49:25,  8.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 651  (64.8):  45%|     | 651/1436 [1:37:19<1:53:14,  8.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 652  (64.7):  45%|     | 652/1436 [1:37:29<1:55:59,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 423 / 653  (64.8):  45%|     | 653/1436 [1:37:35<1:47:09,  8.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 654  (64.8):  46%|     | 654/1436 [1:37:45<1:52:25,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 425 / 655  (64.9):  46%|     | 655/1436 [1:37:54<1:56:00,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 425 / 656  (64.8):  46%|     | 656/1436 [1:38:02<1:49:12,  8.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 426 / 657  (64.8):  46%|     | 657/1436 [1:38:11<1:51:35,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 658  (64.9):  46%|     | 658/1436 [1:38:20<1:53:12,  8.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 659  (64.8):  46%|     | 659/1436 [1:38:29<1:54:23,  8.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 660  (64.7):  46%|     | 660/1436 [1:38:38<1:55:09,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 661  (64.6):  46%|     | 661/1436 [1:38:47<1:55:33,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 662  (64.7):  46%|     | 662/1436 [1:38:56<1:56:07,  9.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 663  (64.7):  46%|     | 663/1436 [1:39:05<1:56:27,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 664  (64.6):  46%|     | 664/1436 [1:39:14<1:56:38,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 665  (64.7):  46%|     | 665/1436 [1:39:24<1:58:19,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 666  (64.6):  46%|     | 666/1436 [1:39:33<1:59:40,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 667  (64.6):  46%|     | 667/1436 [1:39:43<2:00:33,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 668  (64.7):  47%|     | 668/1436 [1:39:53<2:00:59,  9.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 433 / 669  (64.7):  47%|     | 669/1436 [1:40:02<2:01:22,  9.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 433 / 670  (64.6):  47%|     | 670/1436 [1:40:11<1:59:44,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 433 / 671  (64.5):  47%|     | 671/1436 [1:40:20<1:58:35,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 433 / 672  (64.4):  47%|     | 672/1436 [1:40:29<1:57:42,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 434 / 673  (64.5):  47%|     | 673/1436 [1:40:39<1:57:04,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 674  (64.5):  47%|     | 674/1436 [1:40:48<1:56:34,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 436 / 675  (64.6):  47%|     | 675/1436 [1:40:57<1:56:14,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 676  (64.6):  47%|     | 676/1436 [1:41:06<1:55:58,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 677  (64.5):  47%|     | 677/1436 [1:41:15<1:55:41,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 438 / 678  (64.6):  47%|     | 678/1436 [1:41:24<1:55:26,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 438 / 679  (64.5):  47%|     | 679/1436 [1:41:33<1:55:16,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 438 / 680  (64.4):  47%|     | 680/1436 [1:41:43<1:55:34,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 438 / 681  (64.3):  47%|     | 681/1436 [1:41:52<1:55:58,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 682  (64.4):  47%|     | 682/1436 [1:42:01<1:56:00,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 683  (64.4):  48%|     | 683/1436 [1:42:11<1:57:12,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 441 / 684  (64.5):  48%|     | 684/1436 [1:42:18<1:49:01,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 442 / 685  (64.5):  48%|     | 685/1436 [1:42:25<1:44:10,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 686  (64.6):  48%|     | 686/1436 [1:42:35<1:48:54,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 687  (64.6):  48%|     | 687/1436 [1:42:44<1:50:17,  8.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 688  (64.5):  48%|     | 688/1436 [1:42:53<1:51:10,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 689  (64.6):  48%|     | 689/1436 [1:43:03<1:53:34,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 446 / 690  (64.6):  48%|     | 690/1436 [1:43:12<1:55:08,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 446 / 691  (64.5):  48%|     | 691/1436 [1:43:20<1:47:31,  8.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 692  (64.6):  48%|     | 692/1436 [1:43:29<1:49:40,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 448 / 693  (64.6):  48%|     | 693/1436 [1:43:38<1:51:10,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 449 / 694  (64.7):  48%|     | 694/1436 [1:43:48<1:52:15,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 695  (64.7):  48%|     | 695/1436 [1:43:57<1:52:59,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 696  (64.7):  48%|     | 696/1436 [1:44:06<1:53:41,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 697  (64.6):  49%|     | 697/1436 [1:44:16<1:54:13,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 698  (64.6):  49%|     | 698/1436 [1:44:25<1:54:30,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 699  (64.7):  49%|     | 699/1436 [1:44:34<1:54:41,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 453 / 700  (64.7):  49%|     | 700/1436 [1:44:44<1:53:25,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 454 / 701  (64.8):  49%|     | 701/1436 [1:44:53<1:52:44,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 702  (64.8):  49%|     | 702/1436 [1:45:02<1:51:59,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 456 / 703  (64.9):  49%|     | 703/1436 [1:45:11<1:51:23,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 457 / 704  (64.9):  49%|     | 704/1436 [1:45:20<1:51:47,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 705  (65.0):  49%|     | 705/1436 [1:45:29<1:52:02,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 706  (64.9):  49%|     | 706/1436 [1:45:39<1:52:09,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 459 / 707  (64.9):  49%|     | 707/1436 [1:45:48<1:52:36,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 708  (65.0):  49%|     | 708/1436 [1:45:55<1:43:02,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 461 / 709  (65.0):  49%|     | 709/1436 [1:46:04<1:46:02,  8.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 461 / 710  (64.9):  49%|     | 710/1436 [1:46:13<1:48:01,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 462 / 711  (65.0):  50%|     | 711/1436 [1:46:20<1:40:30,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 463 / 712  (65.0):  50%|     | 712/1436 [1:46:30<1:44:59,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 463 / 713  (64.9):  50%|     | 713/1436 [1:46:39<1:48:03,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 714  (65.0):  50%|     | 714/1436 [1:46:49<1:50:08,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 715  (65.0):  50%|     | 715/1436 [1:46:59<1:51:39,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 466 / 716  (65.1):  50%|     | 716/1436 [1:47:08<1:51:59,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 717  (65.1):  50%|     | 717/1436 [1:47:15<1:44:23,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 718  (65.2):  50%|     | 718/1436 [1:47:25<1:47:21,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 469 / 719  (65.2):  50%|     | 719/1436 [1:47:34<1:48:25,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 720  (65.3):  50%|     | 720/1436 [1:47:43<1:48:59,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 721  (65.3):  50%|     | 721/1436 [1:47:53<1:49:28,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 472 / 722  (65.4):  50%|     | 722/1436 [1:48:02<1:49:46,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 723  (65.4):  50%|     | 723/1436 [1:48:11<1:50:03,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 474 / 724  (65.5):  50%|     | 724/1436 [1:48:21<1:50:11,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 725  (65.5):  50%|     | 725/1436 [1:48:30<1:50:15,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 476 / 726  (65.6):  51%|     | 726/1436 [1:48:39<1:50:13,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 476 / 727  (65.5):  51%|     | 727/1436 [1:48:49<1:50:07,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 728  (65.5):  51%|     | 728/1436 [1:48:58<1:49:18,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 478 / 729  (65.6):  51%|     | 729/1436 [1:49:07<1:49:19,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 730  (65.6):  51%|     | 730/1436 [1:49:16<1:49:13,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 731  (65.7):  51%|     | 731/1436 [1:49:26<1:49:06,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 732  (65.7):  51%|     | 732/1436 [1:49:35<1:48:03,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 733  (65.6):  51%|     | 733/1436 [1:49:44<1:47:16,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 734  (65.5):  51%|     | 734/1436 [1:49:53<1:46:40,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 482 / 735  (65.6):  51%|     | 735/1436 [1:50:02<1:46:09,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 483 / 736  (65.6):  51%|    | 736/1436 [1:50:11<1:45:47,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 484 / 737  (65.7):  51%|    | 737/1436 [1:50:20<1:45:45,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 484 / 738  (65.6):  51%|    | 738/1436 [1:50:29<1:45:26,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 739  (65.6):  51%|    | 739/1436 [1:50:38<1:45:26,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 740  (65.5):  52%|    | 740/1436 [1:50:47<1:45:22,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 741  (65.5):  52%|    | 741/1436 [1:50:56<1:45:15,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 742  (65.4):  52%|    | 742/1436 [1:51:06<1:45:43,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 743  (65.3):  52%|    | 743/1436 [1:51:15<1:46:01,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 744  (65.2):  52%|    | 744/1436 [1:51:22<1:37:56,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 745  (65.1):  52%|    | 745/1436 [1:51:31<1:40:36,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 486 / 746  (65.1):  52%|    | 746/1436 [1:51:37<1:32:32,  8.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 487 / 747  (65.2):  52%|    | 747/1436 [1:51:47<1:37:36,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 748  (65.2):  52%|    | 748/1436 [1:51:57<1:41:06,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 489 / 749  (65.3):  52%|    | 749/1436 [1:52:06<1:43:50,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 750  (65.3):  52%|    | 750/1436 [1:52:13<1:36:43,  8.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 491 / 751  (65.4):  52%|    | 751/1436 [1:52:23<1:40:41,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 492 / 752  (65.4):  52%|    | 752/1436 [1:52:33<1:43:27,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 753  (65.5):  52%|    | 753/1436 [1:52:42<1:43:28,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 494 / 754  (65.5):  53%|    | 754/1436 [1:52:51<1:44:00,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 755  (65.6):  53%|    | 755/1436 [1:53:00<1:43:44,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 756  (65.5):  53%|    | 756/1436 [1:53:09<1:43:32,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 757  (65.5):  53%|    | 757/1436 [1:53:18<1:43:22,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 758  (65.4):  53%|    | 758/1436 [1:53:28<1:43:44,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 759  (65.5):  53%|    | 759/1436 [1:53:37<1:43:22,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 498 / 760  (65.5):  53%|    | 760/1436 [1:53:46<1:43:38,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 499 / 761  (65.6):  53%|    | 761/1436 [1:53:55<1:43:53,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 762  (65.6):  53%|    | 762/1436 [1:54:02<1:34:54,  8.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 501 / 763  (65.7):  53%|    | 763/1436 [1:54:11<1:37:35,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 501 / 764  (65.6):  53%|    | 764/1436 [1:54:21<1:39:27,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 502 / 765  (65.6):  53%|    | 765/1436 [1:54:30<1:40:35,  9.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 766  (65.7):  53%|    | 766/1436 [1:54:39<1:40:36,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 767  (65.7):  53%|    | 767/1436 [1:54:48<1:40:31,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 768  (65.8):  53%|    | 768/1436 [1:54:57<1:41:32,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 769  (65.7):  54%|    | 769/1436 [1:55:07<1:42:19,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 770  (65.6):  54%|    | 770/1436 [1:55:16<1:42:51,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 771  (65.6):  54%|    | 771/1436 [1:55:26<1:43:07,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 507 / 772  (65.7):  54%|    | 772/1436 [1:55:35<1:43:14,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 508 / 773  (65.7):  54%|    | 773/1436 [1:55:44<1:43:19,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 509 / 774  (65.8):  54%|    | 774/1436 [1:55:54<1:43:12,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 510 / 775  (65.8):  54%|    | 775/1436 [1:56:03<1:43:11,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 511 / 776  (65.9):  54%|    | 776/1436 [1:56:12<1:43:07,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 511 / 777  (65.8):  54%|    | 777/1436 [1:56:20<1:35:46,  8.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 511 / 778  (65.7):  54%|    | 778/1436 [1:56:29<1:38:31,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 511 / 779  (65.6):  54%|    | 779/1436 [1:56:36<1:32:19,  8.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 511 / 780  (65.5):  54%|    | 780/1436 [1:56:46<1:35:26,  8.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 511 / 781  (65.4):  54%|    | 781/1436 [1:56:53<1:30:25,  8.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 511 / 782  (65.3):  54%|    | 782/1436 [1:57:03<1:34:00,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 512 / 783  (65.4):  55%|    | 783/1436 [1:57:10<1:29:02,  8.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 513 / 784  (65.4):  55%|    | 784/1436 [1:57:16<1:24:19,  7.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 514 / 785  (65.5):  55%|    | 785/1436 [1:57:26<1:29:35,  8.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 515 / 786  (65.5):  55%|    | 786/1436 [1:57:35<1:33:12,  8.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 516 / 787  (65.6):  55%|    | 787/1436 [1:57:45<1:36:13,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 517 / 788  (65.6):  55%|    | 788/1436 [1:57:54<1:38:12,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 518 / 789  (65.7):  55%|    | 789/1436 [1:58:04<1:39:41,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 518 / 790  (65.6):  55%|    | 790/1436 [1:58:14<1:40:31,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 518 / 791  (65.5):  55%|    | 791/1436 [1:58:23<1:40:20,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 519 / 792  (65.5):  55%|    | 792/1436 [1:58:32<1:40:01,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 520 / 793  (65.6):  55%|    | 793/1436 [1:58:41<1:39:53,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 520 / 794  (65.5):  55%|    | 794/1436 [1:58:51<1:39:35,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 521 / 795  (65.5):  55%|    | 795/1436 [1:59:00<1:38:51,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 521 / 796  (65.5):  55%|    | 796/1436 [1:59:09<1:38:16,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 522 / 797  (65.5):  56%|    | 797/1436 [1:59:18<1:38:23,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 522 / 798  (65.4):  56%|    | 798/1436 [1:59:25<1:31:19,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 522 / 799  (65.3):  56%|    | 799/1436 [1:59:35<1:33:24,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 523 / 800  (65.4):  56%|    | 800/1436 [1:59:44<1:34:49,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 523 / 801  (65.3):  56%|    | 801/1436 [1:59:51<1:27:45,  8.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 524 / 802  (65.3):  56%|    | 802/1436 [2:00:00<1:30:46,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 525 / 803  (65.4):  56%|    | 803/1436 [2:00:09<1:32:50,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 526 / 804  (65.4):  56%|    | 804/1436 [2:00:19<1:34:13,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 527 / 805  (65.5):  56%|    | 805/1436 [2:00:28<1:35:07,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 528 / 806  (65.5):  56%|    | 806/1436 [2:00:37<1:35:53,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 807  (65.6):  56%|    | 807/1436 [2:00:47<1:36:25,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 530 / 808  (65.6):  56%|    | 808/1436 [2:00:53<1:28:09,  8.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 531 / 809  (65.6):  56%|    | 809/1436 [2:01:03<1:30:57,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 532 / 810  (65.7):  56%|    | 810/1436 [2:01:12<1:32:51,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 533 / 811  (65.7):  56%|    | 811/1436 [2:01:21<1:34:08,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 533 / 812  (65.6):  57%|    | 812/1436 [2:01:31<1:35:08,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 534 / 813  (65.7):  57%|    | 813/1436 [2:01:40<1:35:38,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 534 / 814  (65.6):  57%|    | 814/1436 [2:01:49<1:36:03,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 535 / 815  (65.6):  57%|    | 815/1436 [2:01:59<1:36:15,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 535 / 816  (65.6):  57%|    | 816/1436 [2:02:08<1:36:26,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 536 / 817  (65.6):  57%|    | 817/1436 [2:02:17<1:35:37,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 537 / 818  (65.6):  57%|    | 818/1436 [2:02:26<1:35:01,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 538 / 819  (65.7):  57%|    | 819/1436 [2:02:36<1:34:35,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 539 / 820  (65.7):  57%|    | 820/1436 [2:02:42<1:27:29,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 540 / 821  (65.8):  57%|    | 821/1436 [2:02:49<1:21:36,  7.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 541 / 822  (65.8):  57%|    | 822/1436 [2:02:58<1:25:43,  8.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 542 / 823  (65.9):  57%|    | 823/1436 [2:03:05<1:20:29,  7.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 543 / 824  (65.9):  57%|    | 824/1436 [2:03:12<1:17:54,  7.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 543 / 825  (65.8):  57%|    | 825/1436 [2:03:22<1:23:10,  8.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 543 / 826  (65.7):  58%|    | 826/1436 [2:03:28<1:18:03,  7.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 543 / 827  (65.7):  58%|    | 827/1436 [2:03:37<1:22:16,  8.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 544 / 828  (65.7):  58%|    | 828/1436 [2:03:44<1:17:17,  7.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 545 / 829  (65.7):  58%|    | 829/1436 [2:03:53<1:21:26,  8.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 545 / 830  (65.7):  58%|    | 830/1436 [2:04:02<1:24:28,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 546 / 831  (65.7):  58%|    | 831/1436 [2:04:11<1:27:13,  8.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 546 / 832  (65.6):  58%|    | 832/1436 [2:04:21<1:29:06,  8.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 547 / 833  (65.7):  58%|    | 833/1436 [2:04:30<1:30:23,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 548 / 834  (65.7):  58%|    | 834/1436 [2:04:39<1:31:11,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 549 / 835  (65.7):  58%|    | 835/1436 [2:04:49<1:31:54,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 550 / 836  (65.8):  58%|    | 836/1436 [2:04:58<1:32:12,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 551 / 837  (65.8):  58%|    | 837/1436 [2:05:07<1:32:23,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 552 / 838  (65.9):  58%|    | 838/1436 [2:05:17<1:32:28,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 839  (65.9):  58%|    | 839/1436 [2:05:26<1:32:28,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 840  (65.8):  58%|    | 840/1436 [2:05:35<1:32:27,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 554 / 841  (65.9):  59%|    | 841/1436 [2:05:42<1:24:53,  8.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 554 / 842  (65.8):  59%|    | 842/1436 [2:05:49<1:19:20,  8.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 555 / 843  (65.8):  59%|    | 843/1436 [2:05:56<1:15:25,  7.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 555 / 844  (65.8):  59%|    | 844/1436 [2:06:05<1:20:10,  8.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 555 / 845  (65.7):  59%|    | 845/1436 [2:06:14<1:23:32,  8.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 556 / 846  (65.7):  59%|    | 846/1436 [2:06:24<1:25:55,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 557 / 847  (65.8):  59%|    | 847/1436 [2:06:33<1:27:21,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 848  (65.8):  59%|    | 848/1436 [2:06:42<1:28:18,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 559 / 849  (65.8):  59%|    | 849/1436 [2:06:51<1:28:13,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 560 / 850  (65.9):  59%|    | 850/1436 [2:07:00<1:28:19,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 561 / 851  (65.9):  59%|    | 851/1436 [2:07:09<1:28:19,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 562 / 852  (66.0):  59%|    | 852/1436 [2:07:18<1:28:19,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 853  (66.0):  59%|    | 853/1436 [2:07:27<1:28:12,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 564 / 854  (66.0):  59%|    | 854/1436 [2:07:37<1:27:53,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 565 / 855  (66.1):  60%|    | 855/1436 [2:07:43<1:19:58,  8.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 566 / 856  (66.1):  60%|    | 856/1436 [2:07:52<1:22:13,  8.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 567 / 857  (66.2):  60%|    | 857/1436 [2:08:01<1:23:46,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 568 / 858  (66.2):  60%|    | 858/1436 [2:08:10<1:25:44,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 568 / 859  (66.1):  60%|    | 859/1436 [2:08:20<1:27:05,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 568 / 860  (66.0):  60%|    | 860/1436 [2:08:29<1:27:42,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 861  (66.1):  60%|    | 861/1436 [2:08:39<1:28:06,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 570 / 862  (66.1):  60%|    | 862/1436 [2:08:48<1:28:10,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 570 / 863  (66.0):  60%|    | 863/1436 [2:08:57<1:28:10,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 570 / 864  (66.0):  60%|    | 864/1436 [2:09:06<1:28:18,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 865  (66.0):  60%|    | 865/1436 [2:09:16<1:27:47,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 866  (65.9):  60%|    | 866/1436 [2:09:25<1:27:47,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 867  (65.9):  60%|    | 867/1436 [2:09:32<1:21:18,  8.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 868  (65.8):  60%|    | 868/1436 [2:09:41<1:23:08,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 869  (65.7):  61%|    | 869/1436 [2:09:50<1:24:26,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 572 / 870  (65.7):  61%|    | 870/1436 [2:10:00<1:25:18,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 572 / 871  (65.7):  61%|    | 871/1436 [2:10:09<1:25:55,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 573 / 872  (65.7):  61%|    | 872/1436 [2:10:18<1:26:15,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 873  (65.8):  61%|    | 873/1436 [2:10:25<1:19:47,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 874  (65.8):  61%|    | 874/1436 [2:10:34<1:21:21,  8.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 875  (65.7):  61%|    | 875/1436 [2:10:44<1:22:26,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 576 / 876  (65.8):  61%|    | 876/1436 [2:10:53<1:23:06,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 576 / 877  (65.7):  61%|    | 877/1436 [2:11:02<1:23:35,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 576 / 878  (65.6):  61%|    | 878/1436 [2:11:11<1:23:53,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 577 / 879  (65.6):  61%|    | 879/1436 [2:11:20<1:23:56,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 578 / 880  (65.7):  61%|   | 880/1436 [2:11:29<1:23:57,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 579 / 881  (65.7):  61%|   | 881/1436 [2:11:38<1:23:44,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 579 / 882  (65.6):  61%|   | 882/1436 [2:11:47<1:23:31,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 883  (65.7):  61%|   | 883/1436 [2:11:56<1:23:20,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 581 / 884  (65.7):  62%|   | 884/1436 [2:12:05<1:23:08,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 582 / 885  (65.8):  62%|   | 885/1436 [2:12:14<1:23:09,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 583 / 886  (65.8):  62%|   | 886/1436 [2:12:23<1:22:54,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 584 / 887  (65.8):  62%|   | 887/1436 [2:12:33<1:23:26,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 585 / 888  (65.9):  62%|   | 888/1436 [2:12:42<1:23:49,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 586 / 889  (65.9):  62%|   | 889/1436 [2:12:51<1:23:59,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 586 / 890  (65.8):  62%|   | 890/1436 [2:13:00<1:24:00,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 587 / 891  (65.9):  62%|   | 891/1436 [2:13:10<1:23:55,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 587 / 892  (65.8):  62%|   | 892/1436 [2:13:19<1:23:52,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 587 / 893  (65.7):  62%|   | 893/1436 [2:13:28<1:23:55,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 588 / 894  (65.8):  62%|   | 894/1436 [2:13:37<1:23:21,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 589 / 895  (65.8):  62%|   | 895/1436 [2:13:47<1:22:56,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 590 / 896  (65.8):  62%|   | 896/1436 [2:13:56<1:22:34,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 591 / 897  (65.9):  62%|   | 897/1436 [2:14:05<1:22:16,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 591 / 898  (65.8):  63%|   | 898/1436 [2:14:14<1:22:27,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 592 / 899  (65.9):  63%|   | 899/1436 [2:14:24<1:22:51,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 593 / 900  (65.9):  63%|   | 900/1436 [2:14:30<1:15:45,  8.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 594 / 901  (65.9):  63%|   | 901/1436 [2:14:40<1:18:05,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 595 / 902  (66.0):  63%|   | 902/1436 [2:14:49<1:19:33,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 595 / 903  (65.9):  63%|   | 903/1436 [2:14:58<1:20:37,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 596 / 904  (65.9):  63%|   | 904/1436 [2:15:08<1:21:17,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 597 / 905  (66.0):  63%|   | 905/1436 [2:15:15<1:15:15,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 598 / 906  (66.0):  63%|   | 906/1436 [2:15:24<1:17:20,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 598 / 907  (65.9):  63%|   | 907/1436 [2:15:33<1:18:35,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 599 / 908  (66.0):  63%|   | 908/1436 [2:15:43<1:19:21,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 600 / 909  (66.0):  63%|   | 909/1436 [2:15:52<1:20:02,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 600 / 910  (65.9):  63%|   | 910/1436 [2:16:01<1:20:28,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 601 / 911  (66.0):  63%|   | 911/1436 [2:16:11<1:20:42,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 602 / 912  (66.0):  64%|   | 912/1436 [2:16:20<1:20:03,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 603 / 913  (66.0):  64%|   | 913/1436 [2:16:29<1:19:33,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 914  (66.1):  64%|   | 914/1436 [2:16:38<1:19:08,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 915  (66.0):  64%|   | 915/1436 [2:16:47<1:18:47,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 916  (65.9):  64%|   | 916/1436 [2:16:56<1:19:19,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 917  (65.9):  64%|   | 917/1436 [2:17:05<1:19:37,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 918  (65.9):  64%|   | 918/1436 [2:17:15<1:19:45,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 919  (65.8):  64%|   | 919/1436 [2:17:22<1:13:41,  8.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 920  (65.9):  64%|   | 920/1436 [2:17:31<1:15:34,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 921  (65.8):  64%|   | 921/1436 [2:17:40<1:16:47,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 607 / 922  (65.8):  64%|   | 922/1436 [2:17:50<1:17:30,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 608 / 923  (65.9):  64%|   | 923/1436 [2:17:56<1:11:35,  8.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 609 / 924  (65.9):  64%|   | 924/1436 [2:18:06<1:13:54,  8.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 609 / 925  (65.8):  64%|   | 925/1436 [2:18:15<1:15:32,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 610 / 926  (65.9):  64%|   | 926/1436 [2:18:24<1:16:35,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 611 / 927  (65.9):  65%|   | 927/1436 [2:18:34<1:17:18,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 611 / 928  (65.8):  65%|   | 928/1436 [2:18:43<1:17:11,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 612 / 929  (65.9):  65%|   | 929/1436 [2:18:52<1:17:02,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 612 / 930  (65.8):  65%|   | 930/1436 [2:18:59<1:10:27,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 612 / 931  (65.7):  65%|   | 931/1436 [2:19:08<1:12:17,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 612 / 932  (65.7):  65%|   | 932/1436 [2:19:14<1:06:46,  7.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 933  (65.7):  65%|   | 933/1436 [2:19:23<1:09:18,  8.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 614 / 934  (65.7):  65%|   | 934/1436 [2:19:33<1:11:52,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 615 / 935  (65.8):  65%|   | 935/1436 [2:19:39<1:07:13,  8.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 616 / 936  (65.8):  65%|   | 936/1436 [2:19:49<1:10:17,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 617 / 937  (65.8):  65%|   | 937/1436 [2:19:58<1:12:36,  8.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 617 / 938  (65.8):  65%|   | 938/1436 [2:20:05<1:09:10,  8.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 618 / 939  (65.8):  65%|   | 939/1436 [2:20:15<1:12:08,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 619 / 940  (65.9):  65%|   | 940/1436 [2:20:25<1:14:08,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 620 / 941  (65.9):  66%|   | 941/1436 [2:20:34<1:15:32,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 621 / 942  (65.9):  66%|   | 942/1436 [2:20:44<1:15:47,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 621 / 943  (65.9):  66%|   | 943/1436 [2:20:53<1:15:49,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 622 / 944  (65.9):  66%|   | 944/1436 [2:21:02<1:15:53,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 623 / 945  (65.9):  66%|   | 945/1436 [2:21:11<1:15:46,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 624 / 946  (66.0):  66%|   | 946/1436 [2:21:21<1:15:50,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 947  (66.0):  66%|   | 947/1436 [2:21:30<1:15:48,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 948  (65.9):  66%|   | 948/1436 [2:21:39<1:15:45,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 949  (66.0):  66%|   | 949/1436 [2:21:49<1:15:41,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 950  (65.9):  66%|   | 950/1436 [2:21:58<1:15:33,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 627 / 951  (65.9):  66%|   | 951/1436 [2:22:07<1:15:24,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 952  (66.0):  66%|   | 952/1436 [2:22:17<1:15:13,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 953  (65.9):  66%|   | 953/1436 [2:22:26<1:15:04,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 954  (65.9):  66%|   | 954/1436 [2:22:35<1:14:12,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 955  (65.9):  67%|   | 955/1436 [2:22:44<1:13:34,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 956  (65.8):  67%|   | 956/1436 [2:22:53<1:13:02,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 630 / 957  (65.8):  67%|   | 957/1436 [2:23:02<1:12:39,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 631 / 958  (65.9):  67%|   | 958/1436 [2:23:11<1:12:29,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 632 / 959  (65.9):  67%|   | 959/1436 [2:23:20<1:12:10,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 633 / 960  (65.9):  67%|   | 960/1436 [2:23:29<1:11:54,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 634 / 961  (66.0):  67%|   | 961/1436 [2:23:38<1:11:40,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 635 / 962  (66.0):  67%|   | 962/1436 [2:23:47<1:11:28,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 635 / 963  (65.9):  67%|   | 963/1436 [2:23:56<1:11:16,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 964  (66.0):  67%|   | 964/1436 [2:24:06<1:11:49,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 965  (65.9):  67%|   | 965/1436 [2:24:15<1:12:08,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 966  (65.8):  67%|   | 966/1436 [2:24:24<1:12:11,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 637 / 967  (65.9):  67%|   | 967/1436 [2:24:31<1:05:30,  8.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 637 / 968  (65.8):  67%|   | 968/1436 [2:24:40<1:07:30,  8.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 637 / 969  (65.7):  67%|   | 969/1436 [2:24:49<1:08:49,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 637 / 970  (65.7):  68%|   | 970/1436 [2:24:59<1:09:53,  9.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 637 / 971  (65.6):  68%|   | 971/1436 [2:25:08<1:10:40,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 638 / 972  (65.6):  68%|   | 972/1436 [2:25:18<1:11:05,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 638 / 973  (65.6):  68%|   | 973/1436 [2:25:27<1:11:18,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 639 / 974  (65.6):  68%|   | 974/1436 [2:25:36<1:11:24,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 639 / 975  (65.5):  68%|   | 975/1436 [2:25:43<1:06:00,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 639 / 976  (65.5):  68%|   | 976/1436 [2:25:53<1:07:37,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 640 / 977  (65.5):  68%|   | 977/1436 [2:26:02<1:08:40,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 640 / 978  (65.4):  68%|   | 978/1436 [2:26:11<1:09:14,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 641 / 979  (65.5):  68%|   | 979/1436 [2:26:21<1:09:36,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 642 / 980  (65.5):  68%|   | 980/1436 [2:26:30<1:09:43,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 643 / 981  (65.5):  68%|   | 981/1436 [2:26:39<1:09:50,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 643 / 982  (65.5):  68%|   | 982/1436 [2:26:46<1:04:28,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 644 / 983  (65.5):  68%|   | 983/1436 [2:26:56<1:06:46,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 645 / 984  (65.5):  69%|   | 984/1436 [2:27:03<1:02:38,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 646 / 985  (65.6):  69%|   | 985/1436 [2:27:12<1:04:16,  8.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 647 / 986  (65.6):  69%|   | 986/1436 [2:27:21<1:05:10,  8.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 648 / 987  (65.7):  69%|   | 987/1436 [2:27:30<1:05:46,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 648 / 988  (65.6):  69%|   | 988/1436 [2:27:39<1:06:09,  8.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 648 / 989  (65.5):  69%|   | 989/1436 [2:27:48<1:06:32,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 649 / 990  (65.6):  69%|   | 990/1436 [2:27:57<1:06:47,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 650 / 991  (65.6):  69%|   | 991/1436 [2:28:06<1:06:55,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 651 / 992  (65.6):  69%|   | 992/1436 [2:28:15<1:06:58,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 652 / 993  (65.7):  69%|   | 993/1436 [2:28:24<1:06:55,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 653 / 994  (65.7):  69%|   | 994/1436 [2:28:34<1:06:55,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 653 / 995  (65.6):  69%|   | 995/1436 [2:28:43<1:06:51,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 654 / 996  (65.7):  69%|   | 996/1436 [2:28:52<1:06:43,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 654 / 997  (65.6):  69%|   | 997/1436 [2:29:01<1:06:38,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 655 / 998  (65.6):  69%|   | 998/1436 [2:29:07<1:00:29,  8.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 656 / 999  (65.7):  70%|   | 999/1436 [2:29:16<1:02:06,  8.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 656 / 1000  (65.6):  70%|   | 1000/1436 [2:29:23<57:08,  7.86s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 657 / 1001  (65.6):  70%|   | 1001/1436 [2:29:32<59:40,  8.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 658 / 1002  (65.7):  70%|   | 1002/1436 [2:29:41<1:01:24,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 659 / 1003  (65.7):  70%|   | 1003/1436 [2:29:50<1:03:42,  8.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 659 / 1004  (65.6):  70%|   | 1004/1436 [2:30:00<1:05:15,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 659 / 1005  (65.6):  70%|   | 1005/1436 [2:30:10<1:06:17,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 659 / 1006  (65.5):  70%|   | 1006/1436 [2:30:17<1:01:50,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 660 / 1007  (65.5):  70%|   | 1007/1436 [2:30:27<1:03:47,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1008  (65.6):  70%|   | 1008/1436 [2:30:36<1:04:40,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1009  (65.5):  70%|   | 1009/1436 [2:30:45<1:05:14,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 662 / 1010  (65.5):  70%|   | 1010/1436 [2:30:55<1:05:34,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 663 / 1011  (65.6):  70%|   | 1011/1436 [2:31:04<1:04:58,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 664 / 1012  (65.6):  70%|   | 1012/1436 [2:31:13<1:04:31,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 664 / 1013  (65.5):  71%|   | 1013/1436 [2:31:22<1:04:09,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 665 / 1014  (65.6):  71%|   | 1014/1436 [2:31:31<1:03:51,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 665 / 1015  (65.5):  71%|   | 1015/1436 [2:31:40<1:03:36,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1016  (65.6):  71%|   | 1016/1436 [2:31:49<1:03:23,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1017  (65.5):  71%|   | 1017/1436 [2:31:58<1:03:09,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1018  (65.4):  71%|   | 1018/1436 [2:32:07<1:02:58,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1019  (65.4):  71%|   | 1019/1436 [2:32:16<1:02:45,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1020  (65.3):  71%|   | 1020/1436 [2:32:25<1:02:36,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 667 / 1021  (65.3):  71%|   | 1021/1436 [2:32:34<1:02:35,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 668 / 1022  (65.4):  71%|   | 1022/1436 [2:32:43<1:02:22,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 669 / 1023  (65.4):  71%|   | 1023/1436 [2:32:52<1:02:19,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 669 / 1024  (65.3):  71%|  | 1024/1436 [2:33:01<1:02:14,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 670 / 1025  (65.4):  71%|  | 1025/1436 [2:33:10<1:02:01,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 671 / 1026  (65.4):  71%|  | 1026/1436 [2:33:20<1:02:34,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1027  (65.4):  72%|  | 1027/1436 [2:33:29<1:02:53,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 673 / 1028  (65.5):  72%|  | 1028/1436 [2:33:38<1:03:04,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 673 / 1029  (65.4):  72%|  | 1029/1436 [2:33:48<1:03:09,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 674 / 1030  (65.4):  72%|  | 1030/1436 [2:33:57<1:02:37,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 675 / 1031  (65.5):  72%|  | 1031/1436 [2:34:06<1:02:12,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 676 / 1032  (65.5):  72%|  | 1032/1436 [2:34:15<1:01:52,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 677 / 1033  (65.5):  72%|  | 1033/1436 [2:34:22<56:56,  8.48s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 677 / 1034  (65.5):  72%|  | 1034/1436 [2:34:31<58:07,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 677 / 1035  (65.4):  72%|  | 1035/1436 [2:34:38<54:53,  8.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 678 / 1036  (65.4):  72%|  | 1036/1436 [2:34:45<52:15,  7.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 679 / 1037  (65.5):  72%|  | 1037/1436 [2:34:55<55:07,  8.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 680 / 1038  (65.5):  72%|  | 1038/1436 [2:35:04<57:05,  8.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 681 / 1039  (65.5):  72%|  | 1039/1436 [2:35:13<58:26,  8.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 682 / 1040  (65.6):  72%|  | 1040/1436 [2:35:23<59:17,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 683 / 1041  (65.6):  72%|  | 1041/1436 [2:35:32<59:49,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 684 / 1042  (65.6):  73%|  | 1042/1436 [2:35:41<1:00:11,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 684 / 1043  (65.6):  73%|  | 1043/1436 [2:35:51<1:00:22,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 685 / 1044  (65.6):  73%|  | 1044/1436 [2:36:00<1:00:35,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 686 / 1045  (65.6):  73%|  | 1045/1436 [2:36:09<1:00:09,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 687 / 1046  (65.7):  73%|  | 1046/1436 [2:36:18<59:47,  9.20s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 688 / 1047  (65.7):  73%|  | 1047/1436 [2:36:27<59:29,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 689 / 1048  (65.7):  73%|  | 1048/1436 [2:36:34<54:45,  8.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 689 / 1049  (65.7):  73%|  | 1049/1436 [2:36:44<56:11,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 690 / 1050  (65.7):  73%|  | 1050/1436 [2:36:50<52:27,  8.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 690 / 1051  (65.7):  73%|  | 1051/1436 [2:37:00<54:30,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 691 / 1052  (65.7):  73%|  | 1052/1436 [2:37:09<55:54,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 692 / 1053  (65.7):  73%|  | 1053/1436 [2:37:18<56:48,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 693 / 1054  (65.7):  73%|  | 1054/1436 [2:37:28<57:22,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 694 / 1055  (65.8):  73%|  | 1055/1436 [2:37:34<52:39,  8.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 695 / 1056  (65.8):  74%|  | 1056/1436 [2:37:43<54:23,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 696 / 1057  (65.8):  74%|  | 1057/1436 [2:37:53<55:34,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 697 / 1058  (65.9):  74%|  | 1058/1436 [2:38:02<56:26,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 697 / 1059  (65.8):  74%|  | 1059/1436 [2:38:11<56:58,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 697 / 1060  (65.8):  74%|  | 1060/1436 [2:38:21<57:19,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 697 / 1061  (65.7):  74%|  | 1061/1436 [2:38:30<57:23,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 697 / 1062  (65.6):  74%|  | 1062/1436 [2:38:39<57:31,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 698 / 1063  (65.7):  74%|  | 1063/1436 [2:38:49<57:41,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1064  (65.7):  74%|  | 1064/1436 [2:38:58<57:45,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 700 / 1065  (65.7):  74%|  | 1065/1436 [2:39:08<57:46,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 700 / 1066  (65.7):  74%|  | 1066/1436 [2:39:17<57:43,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 701 / 1067  (65.7):  74%|  | 1067/1436 [2:39:26<57:27,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 702 / 1068  (65.7):  74%|  | 1068/1436 [2:39:36<57:11,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 702 / 1069  (65.7):  74%|  | 1069/1436 [2:39:45<56:59,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 702 / 1070  (65.6):  75%|  | 1070/1436 [2:39:54<56:48,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 702 / 1071  (65.5):  75%|  | 1071/1436 [2:40:03<56:35,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 703 / 1072  (65.6):  75%|  | 1072/1436 [2:40:13<56:08,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1073  (65.6):  75%|  | 1073/1436 [2:40:22<56:03,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 705 / 1074  (65.6):  75%|  | 1074/1436 [2:40:31<55:59,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 706 / 1075  (65.7):  75%|  | 1075/1436 [2:40:40<55:33,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 707 / 1076  (65.7):  75%|  | 1076/1436 [2:40:49<55:13,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 707 / 1077  (65.6):  75%|  | 1077/1436 [2:40:59<55:18,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 708 / 1078  (65.7):  75%|  | 1078/1436 [2:41:08<55:18,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 708 / 1079  (65.6):  75%|  | 1079/1436 [2:41:17<55:15,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 708 / 1080  (65.6):  75%|  | 1080/1436 [2:41:27<55:11,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 709 / 1081  (65.6):  75%|  | 1081/1436 [2:41:36<54:42,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 709 / 1082  (65.5):  75%|  | 1082/1436 [2:41:45<54:18,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1083  (65.6):  75%|  | 1083/1436 [2:41:54<53:58,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 711 / 1084  (65.6):  75%|  | 1084/1436 [2:42:03<54:08,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 712 / 1085  (65.6):  76%|  | 1085/1436 [2:42:13<54:16,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 712 / 1086  (65.6):  76%|  | 1086/1436 [2:42:22<54:15,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 713 / 1087  (65.6):  76%|  | 1087/1436 [2:42:32<54:11,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 713 / 1088  (65.5):  76%|  | 1088/1436 [2:42:38<49:39,  8.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 713 / 1089  (65.5):  76%|  | 1089/1436 [2:42:48<50:50,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 713 / 1090  (65.4):  76%|  | 1090/1436 [2:42:57<51:37,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 713 / 1091  (65.4):  76%|  | 1091/1436 [2:43:06<52:07,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 714 / 1092  (65.4):  76%|  | 1092/1436 [2:43:16<52:26,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1093  (65.4):  76%|  | 1093/1436 [2:43:25<52:35,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 716 / 1094  (65.4):  76%|  | 1094/1436 [2:43:34<52:40,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 717 / 1095  (65.5):  76%|  | 1095/1436 [2:43:44<52:40,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 718 / 1096  (65.5):  76%|  | 1096/1436 [2:43:53<52:38,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 719 / 1097  (65.5):  76%|  | 1097/1436 [2:44:02<52:34,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 720 / 1098  (65.6):  76%|  | 1098/1436 [2:44:12<52:35,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 721 / 1099  (65.6):  77%|  | 1099/1436 [2:44:21<52:32,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 722 / 1100  (65.6):  77%|  | 1100/1436 [2:44:31<52:27,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 723 / 1101  (65.7):  77%|  | 1101/1436 [2:44:40<52:21,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 724 / 1102  (65.7):  77%|  | 1102/1436 [2:44:49<52:16,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 725 / 1103  (65.7):  77%|  | 1103/1436 [2:44:59<52:10,  9.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1104  (65.8):  77%|  | 1104/1436 [2:45:06<48:12,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 727 / 1105  (65.8):  77%|  | 1105/1436 [2:45:13<45:24,  8.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 727 / 1106  (65.7):  77%|  | 1106/1436 [2:45:20<43:49,  7.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 727 / 1107  (65.7):  77%|  | 1107/1436 [2:45:27<41:15,  7.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 728 / 1108  (65.7):  77%|  | 1108/1436 [2:45:36<43:41,  7.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 729 / 1109  (65.7):  77%|  | 1109/1436 [2:45:45<45:20,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 729 / 1110  (65.7):  77%|  | 1110/1436 [2:45:54<46:25,  8.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 730 / 1111  (65.7):  77%|  | 1111/1436 [2:46:03<47:08,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 731 / 1112  (65.7):  77%|  | 1112/1436 [2:46:12<47:38,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 731 / 1113  (65.7):  78%|  | 1113/1436 [2:46:21<47:57,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 732 / 1114  (65.7):  78%|  | 1114/1436 [2:46:30<48:09,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 732 / 1115  (65.7):  78%|  | 1115/1436 [2:46:37<44:13,  8.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 733 / 1116  (65.7):  78%|  | 1116/1436 [2:46:46<45:40,  8.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 734 / 1117  (65.7):  78%|  | 1117/1436 [2:46:56<46:40,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 735 / 1118  (65.7):  78%|  | 1118/1436 [2:47:05<47:17,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 736 / 1119  (65.8):  78%|  | 1119/1436 [2:47:14<47:40,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 737 / 1120  (65.8):  78%|  | 1120/1436 [2:47:23<47:54,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 738 / 1121  (65.8):  78%|  | 1121/1436 [2:47:33<48:08,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 739 / 1122  (65.9):  78%|  | 1122/1436 [2:47:42<48:16,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 739 / 1123  (65.8):  78%|  | 1123/1436 [2:47:49<44:42,  8.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 739 / 1124  (65.7):  78%|  | 1124/1436 [2:47:58<45:45,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 740 / 1125  (65.8):  78%|  | 1125/1436 [2:48:08<46:26,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 741 / 1126  (65.8):  78%|  | 1126/1436 [2:48:17<46:52,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 742 / 1127  (65.8):  78%|  | 1127/1436 [2:48:27<47:09,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 743 / 1128  (65.9):  79%|  | 1128/1436 [2:48:36<47:18,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 743 / 1129  (65.8):  79%|  | 1129/1436 [2:48:45<47:26,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1130  (65.8):  79%|  | 1130/1436 [2:48:55<47:18,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 745 / 1131  (65.9):  79%|  | 1131/1436 [2:49:04<47:11,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 746 / 1132  (65.9):  79%|  | 1132/1436 [2:49:13<47:04,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1133  (65.9):  79%|  | 1133/1436 [2:49:23<46:59,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 748 / 1134  (66.0):  79%|  | 1134/1436 [2:49:32<46:52,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 748 / 1135  (65.9):  79%|  | 1135/1436 [2:49:41<46:46,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1136  (65.9):  79%|  | 1136/1436 [2:49:50<46:18,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1137  (65.9):  79%|  | 1137/1436 [2:49:59<45:56,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 750 / 1138  (65.9):  79%|  | 1138/1436 [2:50:09<45:39,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 751 / 1139  (65.9):  79%|  | 1139/1436 [2:50:18<45:23,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 752 / 1140  (66.0):  79%|  | 1140/1436 [2:50:27<45:28,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 753 / 1141  (66.0):  79%|  | 1141/1436 [2:50:36<45:28,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 754 / 1142  (66.0):  80%|  | 1142/1436 [2:50:46<45:26,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 755 / 1143  (66.1):  80%|  | 1143/1436 [2:50:52<41:38,  8.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 756 / 1144  (66.1):  80%|  | 1144/1436 [2:51:02<42:40,  8.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 757 / 1145  (66.1):  80%|  | 1145/1436 [2:51:11<43:15,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 758 / 1146  (66.1):  80%|  | 1146/1436 [2:51:20<43:40,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 758 / 1147  (66.1):  80%|  | 1147/1436 [2:51:30<43:52,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 758 / 1148  (66.0):  80%|  | 1148/1436 [2:51:39<43:57,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 758 / 1149  (66.0):  80%|  | 1149/1436 [2:51:48<43:59,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 758 / 1150  (65.9):  80%|  | 1150/1436 [2:51:57<43:44,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 759 / 1151  (65.9):  80%|  | 1151/1436 [2:52:07<43:44,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 760 / 1152  (66.0):  80%|  | 1152/1436 [2:52:16<43:28,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 761 / 1153  (66.0):  80%|  | 1153/1436 [2:52:25<43:15,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 762 / 1154  (66.0):  80%|  | 1154/1436 [2:52:34<43:14,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 763 / 1155  (66.1):  80%|  | 1155/1436 [2:52:43<43:11,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 764 / 1156  (66.1):  81%|  | 1156/1436 [2:52:53<43:05,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 765 / 1157  (66.1):  81%|  | 1157/1436 [2:53:02<42:58,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 766 / 1158  (66.1):  81%|  | 1158/1436 [2:53:11<42:51,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 767 / 1159  (66.2):  81%|  | 1159/1436 [2:53:20<42:30,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 768 / 1160  (66.2):  81%|  | 1160/1436 [2:53:29<42:11,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 769 / 1161  (66.2):  81%|  | 1161/1436 [2:53:39<41:57,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 769 / 1162  (66.2):  81%|  | 1162/1436 [2:53:48<41:44,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1163  (66.2):  81%|  | 1163/1436 [2:53:57<41:51,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 771 / 1164  (66.2):  81%|  | 1164/1436 [2:54:04<38:17,  8.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 771 / 1165  (66.2):  81%|  | 1165/1436 [2:54:11<36:03,  7.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 771 / 1166  (66.1):  81%|  | 1166/1436 [2:54:20<37:45,  8.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 772 / 1167  (66.2):  81%| | 1167/1436 [2:54:27<35:36,  7.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1168  (66.2):  81%| | 1168/1436 [2:54:36<37:21,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 774 / 1169  (66.2):  81%| | 1169/1436 [2:54:45<38:30,  8.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1170  (66.2):  81%| | 1170/1436 [2:54:52<35:52,  8.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 776 / 1171  (66.3):  82%| | 1171/1436 [2:54:59<34:10,  7.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 777 / 1172  (66.3):  82%| | 1172/1436 [2:55:08<36:06,  8.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 778 / 1173  (66.3):  82%| | 1173/1436 [2:55:18<37:21,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1174  (66.4):  82%| | 1174/1436 [2:55:27<38:10,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 780 / 1175  (66.4):  82%| | 1175/1436 [2:55:36<38:44,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 781 / 1176  (66.4):  82%| | 1176/1436 [2:55:46<39:06,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 782 / 1177  (66.4):  82%| | 1177/1436 [2:55:55<39:39,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 782 / 1178  (66.4):  82%| | 1178/1436 [2:56:02<36:47,  8.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 782 / 1179  (66.3):  82%| | 1179/1436 [2:56:12<37:55,  8.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 783 / 1180  (66.4):  82%| | 1180/1436 [2:56:21<38:28,  9.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 784 / 1181  (66.4):  82%| | 1181/1436 [2:56:31<38:48,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 785 / 1182  (66.4):  82%| | 1182/1436 [2:56:40<38:58,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 785 / 1183  (66.4):  82%| | 1183/1436 [2:56:47<36:00,  8.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 786 / 1184  (66.4):  82%| | 1184/1436 [2:56:56<36:56,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 787 / 1185  (66.4):  83%| | 1185/1436 [2:57:05<37:06,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 787 / 1186  (66.4):  83%| | 1186/1436 [2:57:14<37:08,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 788 / 1187  (66.4):  83%| | 1187/1436 [2:57:23<37:07,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 788 / 1188  (66.3):  83%| | 1188/1436 [2:57:32<37:04,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 789 / 1189  (66.4):  83%| | 1189/1436 [2:57:41<37:00,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 790 / 1190  (66.4):  83%| | 1190/1436 [2:57:48<34:11,  8.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 790 / 1191  (66.3):  83%| | 1191/1436 [2:57:58<35:12,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 791 / 1192  (66.4):  83%| | 1192/1436 [2:58:07<35:54,  8.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 792 / 1193  (66.4):  83%| | 1193/1436 [2:58:16<36:18,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 792 / 1194  (66.3):  83%| | 1194/1436 [2:58:26<36:36,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 793 / 1195  (66.4):  83%| | 1195/1436 [2:58:35<36:29,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 794 / 1196  (66.4):  83%| | 1196/1436 [2:58:44<36:22,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 795 / 1197  (66.4):  83%| | 1197/1436 [2:58:53<36:14,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 796 / 1198  (66.4):  83%| | 1198/1436 [2:59:02<36:05,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 796 / 1199  (66.4):  83%| | 1199/1436 [2:59:11<35:57,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 797 / 1200  (66.4):  84%| | 1200/1436 [2:59:20<36:03,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 798 / 1201  (66.4):  84%| | 1201/1436 [2:59:30<36:05,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 798 / 1202  (66.4):  84%| | 1202/1436 [2:59:39<36:04,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 799 / 1203  (66.4):  84%| | 1203/1436 [2:59:48<36:02,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 800 / 1204  (66.4):  84%| | 1204/1436 [2:59:55<32:56,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 801 / 1205  (66.5):  84%| | 1205/1436 [3:00:05<33:48,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 802 / 1206  (66.5):  84%| | 1206/1436 [3:00:14<34:23,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 803 / 1207  (66.5):  84%| | 1207/1436 [3:00:23<34:44,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 803 / 1208  (66.5):  84%| | 1208/1436 [3:00:33<34:55,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 803 / 1209  (66.4):  84%| | 1209/1436 [3:00:42<35:00,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 804 / 1210  (66.4):  84%| | 1210/1436 [3:00:51<34:52,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 805 / 1211  (66.5):  84%| | 1211/1436 [3:00:58<32:01,  8.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 805 / 1212  (66.4):  84%| | 1212/1436 [3:01:08<32:42,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 806 / 1213  (66.4):  84%| | 1213/1436 [3:01:17<32:57,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 807 / 1214  (66.5):  85%| | 1214/1436 [3:01:26<33:05,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 808 / 1215  (66.5):  85%| | 1215/1436 [3:01:35<33:08,  9.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 808 / 1216  (66.4):  85%| | 1216/1436 [3:01:44<33:06,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 809 / 1217  (66.5):  85%| | 1217/1436 [3:01:53<33:03,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 809 / 1218  (66.4):  85%| | 1218/1436 [3:02:02<32:57,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 810 / 1219  (66.4):  85%| | 1219/1436 [3:02:11<32:50,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 810 / 1220  (66.4):  85%| | 1220/1436 [3:02:20<32:43,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 811 / 1221  (66.4):  85%| | 1221/1436 [3:02:30<32:36,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 812 / 1222  (66.4):  85%| | 1222/1436 [3:02:39<32:27,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 813 / 1223  (66.5):  85%| | 1223/1436 [3:02:48<32:18,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 814 / 1224  (66.5):  85%| | 1224/1436 [3:02:57<32:10,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 815 / 1225  (66.5):  85%| | 1225/1436 [3:03:06<32:00,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 816 / 1226  (66.6):  85%| | 1226/1436 [3:03:15<31:51,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 816 / 1227  (66.5):  85%| | 1227/1436 [3:03:24<31:56,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 817 / 1228  (66.5):  86%| | 1228/1436 [3:03:34<31:57,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 818 / 1229  (66.6):  86%| | 1229/1436 [3:03:43<31:55,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 818 / 1230  (66.5):  86%| | 1230/1436 [3:03:52<31:47,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 819 / 1231  (66.5):  86%| | 1231/1436 [3:04:02<31:42,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 820 / 1232  (66.6):  86%| | 1232/1436 [3:04:11<31:36,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 821 / 1233  (66.6):  86%| | 1233/1436 [3:04:20<31:29,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 822 / 1234  (66.6):  86%| | 1234/1436 [3:04:27<28:37,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 823 / 1235  (66.6):  86%| | 1235/1436 [3:04:34<27:14,  8.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 824 / 1236  (66.7):  86%| | 1236/1436 [3:04:44<28:22,  8.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 825 / 1237  (66.7):  86%| | 1237/1436 [3:04:53<29:04,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 826 / 1238  (66.7):  86%| | 1238/1436 [3:05:02<29:29,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 827 / 1239  (66.7):  86%| | 1239/1436 [3:05:12<29:46,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 827 / 1240  (66.7):  86%| | 1240/1436 [3:05:21<29:57,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 827 / 1241  (66.6):  86%| | 1241/1436 [3:05:30<29:58,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 828 / 1242  (66.7):  86%| | 1242/1436 [3:05:40<29:54,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 828 / 1243  (66.6):  87%| | 1243/1436 [3:05:49<29:47,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 828 / 1244  (66.6):  87%| | 1244/1436 [3:05:56<27:07,  8.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 829 / 1245  (66.6):  87%| | 1245/1436 [3:06:05<27:48,  8.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 829 / 1246  (66.5):  87%| | 1246/1436 [3:06:14<28:10,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 830 / 1247  (66.6):  87%| | 1247/1436 [3:06:24<28:26,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 831 / 1248  (66.6):  87%| | 1248/1436 [3:06:33<28:30,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 832 / 1249  (66.6):  87%| | 1249/1436 [3:06:42<28:30,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 833 / 1250  (66.6):  87%| | 1250/1436 [3:06:51<28:30,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 834 / 1251  (66.7):  87%| | 1251/1436 [3:07:01<28:25,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 834 / 1252  (66.6):  87%| | 1252/1436 [3:07:10<28:20,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 835 / 1253  (66.6):  87%| | 1253/1436 [3:07:19<28:13,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 835 / 1254  (66.6):  87%| | 1254/1436 [3:07:29<28:05,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 836 / 1255  (66.6):  87%| | 1255/1436 [3:07:38<28:04,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 836 / 1256  (66.6):  87%| | 1256/1436 [3:07:47<27:59,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 837 / 1257  (66.6):  88%| | 1257/1436 [3:07:57<27:46,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 838 / 1258  (66.6):  88%| | 1258/1436 [3:08:06<27:34,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 839 / 1259  (66.6):  88%| | 1259/1436 [3:08:15<27:24,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 840 / 1260  (66.7):  88%| | 1260/1436 [3:08:25<27:14,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 841 / 1261  (66.7):  88%| | 1261/1436 [3:08:34<27:06,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 842 / 1262  (66.7):  88%| | 1262/1436 [3:08:43<26:46,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 843 / 1263  (66.7):  88%| | 1263/1436 [3:08:52<26:28,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 844 / 1264  (66.8):  88%| | 1264/1436 [3:09:01<26:13,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 845 / 1265  (66.8):  88%| | 1265/1436 [3:09:10<26:01,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 845 / 1266  (66.7):  88%| | 1266/1436 [3:09:19<25:48,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 846 / 1267  (66.8):  88%| | 1267/1436 [3:09:28<25:35,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 847 / 1268  (66.8):  88%| | 1268/1436 [3:09:35<23:14,  8.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 847 / 1269  (66.7):  88%| | 1269/1436 [3:09:44<23:46,  8.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 848 / 1270  (66.8):  88%| | 1270/1436 [3:09:53<24:17,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 849 / 1271  (66.8):  89%| | 1271/1436 [3:10:02<24:36,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 850 / 1272  (66.8):  89%| | 1272/1436 [3:10:12<24:46,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 851 / 1273  (66.8):  89%| | 1273/1436 [3:10:21<24:51,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 852 / 1274  (66.9):  89%| | 1274/1436 [3:10:30<24:48,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 852 / 1275  (66.8):  89%| | 1275/1436 [3:10:40<24:43,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 852 / 1276  (66.8):  89%| | 1276/1436 [3:10:47<22:40,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 853 / 1277  (66.8):  89%| | 1277/1436 [3:10:56<23:08,  8.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 853 / 1278  (66.7):  89%| | 1278/1436 [3:11:05<23:32,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 853 / 1279  (66.7):  89%| | 1279/1436 [3:11:15<23:46,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 853 / 1280  (66.6):  89%| | 1280/1436 [3:11:24<23:49,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 853 / 1281  (66.6):  89%| | 1281/1436 [3:11:31<21:48,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 854 / 1282  (66.6):  89%| | 1282/1436 [3:11:40<22:11,  8.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 855 / 1283  (66.6):  89%| | 1283/1436 [3:11:49<22:24,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 856 / 1284  (66.7):  89%| | 1284/1436 [3:11:58<22:29,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 857 / 1285  (66.7):  89%| | 1285/1436 [3:12:07<22:32,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 858 / 1286  (66.7):  90%| | 1286/1436 [3:12:16<22:30,  9.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 858 / 1287  (66.7):  90%| | 1287/1436 [3:12:26<22:45,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 858 / 1288  (66.6):  90%| | 1288/1436 [3:12:35<22:53,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 859 / 1289  (66.6):  90%| | 1289/1436 [3:12:45<22:57,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 859 / 1290  (66.6):  90%| | 1290/1436 [3:12:54<22:44,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 860 / 1291  (66.6):  90%| | 1291/1436 [3:13:04<22:31,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 861 / 1292  (66.6):  90%| | 1292/1436 [3:13:13<22:21,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 862 / 1293  (66.7):  90%| | 1293/1436 [3:13:22<22:09,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 862 / 1294  (66.6):  90%| | 1294/1436 [3:13:31<21:59,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 862 / 1295  (66.6):  90%| | 1295/1436 [3:13:41<21:49,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 863 / 1296  (66.6):  90%| | 1296/1436 [3:13:50<21:39,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 863 / 1297  (66.5):  90%| | 1297/1436 [3:13:59<21:30,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 864 / 1298  (66.6):  90%| | 1298/1436 [3:14:09<21:20,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 865 / 1299  (66.6):  90%| | 1299/1436 [3:14:18<21:12,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 866 / 1300  (66.6):  91%| | 1300/1436 [3:14:27<21:05,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 867 / 1301  (66.6):  91%| | 1301/1436 [3:14:37<20:57,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 867 / 1302  (66.6):  91%| | 1302/1436 [3:14:46<20:49,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 867 / 1303  (66.5):  91%| | 1303/1436 [3:14:55<20:41,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 868 / 1304  (66.6):  91%| | 1304/1436 [3:15:05<20:30,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 869 / 1305  (66.6):  91%| | 1305/1436 [3:15:14<20:20,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 870 / 1306  (66.6):  91%| | 1306/1436 [3:15:23<20:11,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 871 / 1307  (66.6):  91%| | 1307/1436 [3:15:32<20:00,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 871 / 1308  (66.6):  91%| | 1308/1436 [3:15:42<19:52,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 872 / 1309  (66.6):  91%| | 1309/1436 [3:15:51<19:43,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 873 / 1310  (66.6):  91%| | 1310/1436 [3:16:00<19:26,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 874 / 1311  (66.7):  91%|| 1311/1436 [3:16:09<19:12,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 875 / 1312  (66.7):  91%|| 1312/1436 [3:16:18<18:59,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 876 / 1313  (66.7):  91%|| 1313/1436 [3:16:25<17:07,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 877 / 1314  (66.7):  92%|| 1314/1436 [3:16:34<17:27,  8.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 878 / 1315  (66.8):  92%|| 1315/1436 [3:16:40<15:57,  7.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 879 / 1316  (66.8):  92%|| 1316/1436 [3:16:47<14:51,  7.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 880 / 1317  (66.8):  92%|| 1317/1436 [3:16:53<14:13,  7.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 881 / 1318  (66.8):  92%|| 1318/1436 [3:17:02<15:21,  7.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 881 / 1319  (66.8):  92%|| 1319/1436 [3:17:12<16:05,  8.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 881 / 1320  (66.7):  92%|| 1320/1436 [3:17:21<16:32,  8.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 881 / 1321  (66.7):  92%|| 1321/1436 [3:17:30<16:49,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 882 / 1322  (66.7):  92%|| 1322/1436 [3:17:40<16:57,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 883 / 1323  (66.7):  92%|| 1323/1436 [3:17:49<16:59,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 883 / 1324  (66.7):  92%|| 1324/1436 [3:17:58<16:59,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 883 / 1325  (66.6):  92%|| 1325/1436 [3:18:07<16:55,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 884 / 1326  (66.7):  92%|| 1326/1436 [3:18:17<16:53,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 885 / 1327  (66.7):  92%|| 1327/1436 [3:18:24<15:28,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 886 / 1328  (66.7):  92%|| 1328/1436 [3:18:33<15:48,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 886 / 1329  (66.7):  93%|| 1329/1436 [3:18:42<15:59,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 887 / 1330  (66.7):  93%|| 1330/1436 [3:18:52<16:01,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 887 / 1331  (66.6):  93%|| 1331/1436 [3:19:01<15:59,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 888 / 1332  (66.7):  93%|| 1332/1436 [3:19:10<15:54,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 889 / 1333  (66.7):  93%|| 1333/1436 [3:19:20<15:49,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 890 / 1334  (66.7):  93%|| 1334/1436 [3:19:29<15:44,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 890 / 1335  (66.7):  93%|| 1335/1436 [3:19:38<15:37,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 891 / 1336  (66.7):  93%|| 1336/1436 [3:19:45<14:16,  8.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 892 / 1337  (66.7):  93%|| 1337/1436 [3:19:55<14:31,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 892 / 1338  (66.7):  93%|| 1338/1436 [3:20:02<13:28,  8.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 893 / 1339  (66.7):  93%|| 1339/1436 [3:20:11<13:52,  8.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 894 / 1340  (66.7):  93%|| 1340/1436 [3:20:20<13:59,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 894 / 1341  (66.7):  93%|| 1341/1436 [3:20:29<14:01,  8.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 894 / 1342  (66.6):  93%|| 1342/1436 [3:20:38<14:00,  8.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 895 / 1343  (66.6):  94%|| 1343/1436 [3:20:47<13:56,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 896 / 1344  (66.7):  94%|| 1344/1436 [3:20:57<13:56,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 896 / 1345  (66.6):  94%|| 1345/1436 [3:21:06<13:53,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 897 / 1346  (66.6):  94%|| 1346/1436 [3:21:15<13:47,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 897 / 1347  (66.6):  94%|| 1347/1436 [3:21:25<13:42,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 898 / 1348  (66.6):  94%|| 1348/1436 [3:21:31<12:18,  8.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 899 / 1349  (66.6):  94%|| 1349/1436 [3:21:40<12:28,  8.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 900 / 1350  (66.7):  94%|| 1350/1436 [3:21:47<11:25,  7.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 901 / 1351  (66.7):  94%|| 1351/1436 [3:21:56<11:46,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 902 / 1352  (66.7):  94%|| 1352/1436 [3:22:05<11:58,  8.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 903 / 1353  (66.7):  94%|| 1353/1436 [3:22:14<12:01,  8.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 904 / 1354  (66.8):  94%|| 1354/1436 [3:22:23<12:03,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 905 / 1355  (66.8):  94%|| 1355/1436 [3:22:32<11:59,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 906 / 1356  (66.8):  94%|| 1356/1436 [3:22:41<11:54,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 907 / 1357  (66.8):  94%|| 1357/1436 [3:22:50<11:47,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 908 / 1358  (66.9):  95%|| 1358/1436 [3:23:00<11:48,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 909 / 1359  (66.9):  95%|| 1359/1436 [3:23:09<11:47,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 910 / 1360  (66.9):  95%|| 1360/1436 [3:23:18<11:43,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 911 / 1361  (66.9):  95%|| 1361/1436 [3:23:28<11:37,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 912 / 1362  (67.0):  95%|| 1362/1436 [3:23:37<11:30,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 913 / 1363  (67.0):  95%|| 1363/1436 [3:23:47<11:22,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 913 / 1364  (66.9):  95%|| 1364/1436 [3:23:56<11:14,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 914 / 1365  (67.0):  95%|| 1365/1436 [3:24:05<11:05,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 915 / 1366  (67.0):  95%|| 1366/1436 [3:24:15<10:53,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 915 / 1367  (66.9):  95%|| 1367/1436 [3:24:24<10:43,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 916 / 1368  (67.0):  95%|| 1368/1436 [3:24:33<10:32,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 916 / 1369  (66.9):  95%|| 1369/1436 [3:24:42<10:23,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 917 / 1370  (66.9):  95%|| 1370/1436 [3:24:52<10:13,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 918 / 1371  (67.0):  95%|| 1371/1436 [3:25:01<10:00,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 919 / 1372  (67.0):  96%|| 1372/1436 [3:25:10<09:52,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 919 / 1373  (66.9):  96%|| 1373/1436 [3:25:19<09:40,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 920 / 1374  (67.0):  96%|| 1374/1436 [3:25:28<09:29,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 921 / 1375  (67.0):  96%|| 1375/1436 [3:25:38<09:22,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 922 / 1376  (67.0):  96%|| 1376/1436 [3:25:47<09:19,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 923 / 1377  (67.0):  96%|| 1377/1436 [3:25:57<09:12,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 924 / 1378  (67.1):  96%|| 1378/1436 [3:26:04<08:21,  8.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 924 / 1379  (67.0):  96%|| 1379/1436 [3:26:11<07:43,  8.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 924 / 1380  (67.0):  96%|| 1380/1436 [3:26:20<07:59,  8.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 925 / 1381  (67.0):  96%|| 1381/1436 [3:26:30<08:07,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 925 / 1382  (66.9):  96%|| 1382/1436 [3:26:39<08:10,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 926 / 1383  (67.0):  96%|| 1383/1436 [3:26:49<08:08,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 927 / 1384  (67.0):  96%|| 1384/1436 [3:26:58<08:05,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 928 / 1385  (67.0):  96%|| 1385/1436 [3:27:08<07:55,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 928 / 1386  (67.0):  97%|| 1386/1436 [3:27:17<07:45,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 929 / 1387  (67.0):  97%|| 1387/1436 [3:27:26<07:35,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 929 / 1388  (66.9):  97%|| 1388/1436 [3:27:36<07:26,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 930 / 1389  (67.0):  97%|| 1389/1436 [3:27:45<07:17,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 931 / 1390  (67.0):  97%|| 1390/1436 [3:27:52<06:40,  8.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 932 / 1391  (67.0):  97%|| 1391/1436 [3:28:02<06:40,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 932 / 1392  (67.0):  97%|| 1392/1436 [3:28:11<06:38,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 933 / 1393  (67.0):  97%|| 1393/1436 [3:28:20<06:33,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 934 / 1394  (67.0):  97%|| 1394/1436 [3:28:29<06:22,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 935 / 1395  (67.0):  97%|| 1395/1436 [3:28:38<06:12,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 936 / 1396  (67.0):  97%|| 1396/1436 [3:28:47<06:02,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 936 / 1397  (67.0):  97%|| 1397/1436 [3:28:56<05:53,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 937 / 1398  (67.0):  97%|| 1398/1436 [3:29:06<05:43,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 937 / 1399  (67.0):  97%|| 1399/1436 [3:29:15<05:34,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 938 / 1400  (67.0):  97%|| 1400/1436 [3:29:24<05:25,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 939 / 1401  (67.0):  98%|| 1401/1436 [3:29:33<05:17,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 940 / 1402  (67.0):  98%|| 1402/1436 [3:29:42<05:08,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 941 / 1403  (67.1):  98%|| 1403/1436 [3:29:51<05:02,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 942 / 1404  (67.1):  98%|| 1404/1436 [3:29:58<04:30,  8.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 942 / 1405  (67.0):  98%|| 1405/1436 [3:30:07<04:30,  8.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 942 / 1406  (67.0):  98%|| 1406/1436 [3:30:17<04:27,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 943 / 1407  (67.0):  98%|| 1407/1436 [3:30:26<04:22,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 944 / 1408  (67.0):  98%|| 1408/1436 [3:30:35<04:15,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 944 / 1409  (67.0):  98%|| 1409/1436 [3:30:45<04:08,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 945 / 1410  (67.0):  98%|| 1410/1436 [3:30:54<04:00,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 946 / 1411  (67.0):  98%|| 1411/1436 [3:31:03<03:49,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 947 / 1412  (67.1):  98%|| 1412/1436 [3:31:12<03:39,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 948 / 1413  (67.1):  98%|| 1413/1436 [3:31:21<03:29,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 949 / 1414  (67.1):  98%|| 1414/1436 [3:31:30<03:19,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 949 / 1415  (67.1):  99%|| 1415/1436 [3:31:39<03:10,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1416  (67.1):  99%|| 1416/1436 [3:31:48<03:02,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1417  (67.0):  99%|| 1417/1436 [3:31:58<02:54,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1418  (67.0):  99%|| 1418/1436 [3:32:07<02:45,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1419  (66.9):  99%|| 1419/1436 [3:32:14<02:24,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1420  (66.9):  99%|| 1420/1436 [3:32:24<02:21,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1421  (66.9):  99%|| 1421/1436 [3:32:33<02:16,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1422  (66.8):  99%|| 1422/1436 [3:32:43<02:10,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 950 / 1423  (66.8):  99%|| 1423/1436 [3:32:53<02:02,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 951 / 1424  (66.8):  99%|| 1424/1436 [3:33:02<01:52,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 952 / 1425  (66.8):  99%|| 1425/1436 [3:33:11<01:41,  9.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 953 / 1426  (66.8):  99%|| 1426/1436 [3:33:17<01:23,  8.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 953 / 1427  (66.8):  99%|| 1427/1436 [3:33:26<01:17,  8.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 954 / 1428  (66.8):  99%|| 1428/1436 [3:33:35<01:09,  8.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 954 / 1429  (66.8): 100%|| 1429/1436 [3:33:44<01:01,  8.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 954 / 1430  (66.7): 100%|| 1430/1436 [3:33:53<00:53,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 954 / 1431  (66.7): 100%|| 1431/1436 [3:34:02<00:44,  8.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 955 / 1432  (66.7): 100%|| 1432/1436 [3:34:11<00:35,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 956 / 1433  (66.7): 100%|| 1433/1436 [3:34:20<00:26,  8.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 957 / 1434  (66.7): 100%|| 1434/1436 [3:34:30<00:18,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 958 / 1435  (66.8): 100%|| 1435/1436 [3:34:39<00:09,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 959 / 1436  (66.8): 100%|| 1436/1436 [3:34:48<00:00,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 959 / 1436  (66.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_11038 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_11038 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_11038_row0_col0, #T_11038_row0_col1, #T_11038_row0_col2, #T_11038_row0_col3, #T_11038_row0_col4, #T_11038_row0_col5, #T_11038_row0_col6, #T_11038_row0_col7, #T_11038_row1_col0, #T_11038_row1_col1, #T_11038_row1_col2, #T_11038_row1_col3, #T_11038_row1_col4, #T_11038_row1_col5, #T_11038_row1_col6, #T_11038_row1_col7, #T_11038_row2_col0, #T_11038_row2_col1, #T_11038_row2_col2, #T_11038_row2_col3, #T_11038_row2_col4, #T_11038_row2_col5, #T_11038_row2_col6, #T_11038_row2_col7, #T_11038_row3_col0, #T_11038_row3_col1, #T_11038_row3_col2, #T_11038_row3_col3, #T_11038_row3_col4, #T_11038_row3_col5, #T_11038_row3_col6, #T_11038_row3_col7, #T_11038_row4_col0, #T_11038_row4_col1, #T_11038_row4_col2, #T_11038_row4_col3, #T_11038_row4_col4, #T_11038_row4_col5, #T_11038_row4_col6, #T_11038_row4_col7 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_11038\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_11038_level0_col0\" class=\"col_heading level0 col0\" >context</th>\n",
       "      <th id=\"T_11038_level0_col1\" class=\"col_heading level0 col1\" >question</th>\n",
       "      <th id=\"T_11038_level0_col2\" class=\"col_heading level0 col2\" >options</th>\n",
       "      <th id=\"T_11038_level0_col3\" class=\"col_heading level0 col3\" >answer_option</th>\n",
       "      <th id=\"T_11038_level0_col4\" class=\"col_heading level0 col4\" >example_answer</th>\n",
       "      <th id=\"T_11038_level0_col5\" class=\"col_heading level0 col5\" >rationale</th>\n",
       "      <th id=\"T_11038_level0_col6\" class=\"col_heading level0 col6\" >pred_answer</th>\n",
       "      <th id=\"T_11038_level0_col7\" class=\"col_heading level0 col7\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_11038_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_11038_row0_col0\" class=\"data row0 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_11038_row0_col1\" class=\"data row0 col1\" >Where is Wendy from?</td>\n",
       "      <td id=\"T_11038_row0_col2\" class=\"data row0 col2\" >['China.', 'England.', 'America.', 'Australia.']</td>\n",
       "      <td id=\"T_11038_row0_col3\" class=\"data row0 col3\" >D</td>\n",
       "      <td id=\"T_11038_row0_col4\" class=\"data row0 col4\" >Australia.</td>\n",
       "      <td id=\"T_11038_row0_col5\" class=\"data row0 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_11038_row0_col6\" class=\"data row0 col6\" >Australia.</td>\n",
       "      <td id=\"T_11038_row0_col7\" class=\"data row0 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11038_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_11038_row1_col0\" class=\"data row1 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_11038_row1_col1\" class=\"data row1 col1\" >What colours does Nancy like?</td>\n",
       "      <td id=\"T_11038_row1_col2\" class=\"data row1 col2\" >['Red and blue.', 'Red and yellow.', 'Green and yellow.', 'Green and blue.']</td>\n",
       "      <td id=\"T_11038_row1_col3\" class=\"data row1 col3\" >D</td>\n",
       "      <td id=\"T_11038_row1_col4\" class=\"data row1 col4\" >Green and blue.</td>\n",
       "      <td id=\"T_11038_row1_col5\" class=\"data row1 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_11038_row1_col6\" class=\"data row1 col6\" >Green and blue.</td>\n",
       "      <td id=\"T_11038_row1_col7\" class=\"data row1 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11038_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_11038_row2_col0\" class=\"data row2 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_11038_row2_col1\" class=\"data row2 col1\" >What's Wendy's favourite sport?</td>\n",
       "      <td id=\"T_11038_row2_col2\" class=\"data row2 col2\" >['Running.', 'Basketball.', 'Football.', 'Table tennis.']</td>\n",
       "      <td id=\"T_11038_row2_col3\" class=\"data row2 col3\" >A</td>\n",
       "      <td id=\"T_11038_row2_col4\" class=\"data row2 col4\" >Running.</td>\n",
       "      <td id=\"T_11038_row2_col5\" class=\"data row2 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_11038_row2_col6\" class=\"data row2 col6\" >Running.</td>\n",
       "      <td id=\"T_11038_row2_col7\" class=\"data row2 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11038_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_11038_row3_col0\" class=\"data row3 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_11038_row3_col1\" class=\"data row3 col1\" >Which is TRUE ?</td>\n",
       "      <td id=\"T_11038_row3_col2\" class=\"data row3 col2\" >['Nancy and Wendy are 12 years old.', 'Wendy is a student and she is English.', 'Everyone in Class Four likes Wendy.', 'Nancy has a cat...</td>\n",
       "      <td id=\"T_11038_row3_col3\" class=\"data row3 col3\" >C</td>\n",
       "      <td id=\"T_11038_row3_col4\" class=\"data row3 col4\" >Everyone in Class Four likes Wendy.</td>\n",
       "      <td id=\"T_11038_row3_col5\" class=\"data row3 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_11038_row3_col6\" class=\"data row3 col6\" >Nancy and Wendy are 12 years old.</td>\n",
       "      <td id=\"T_11038_row3_col7\" class=\"data row3 col7\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11038_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_11038_row4_col0\" class=\"data row4 col0\" >June 5 is World Environment Day.This makes us pay more attention to our environment and the need to protect it. When Wang Baoxuan,a Beijing high...</td>\n",
       "      <td id=\"T_11038_row4_col1\" class=\"data row4 col1\" >What do Wang Baoxuan and his schoolmates do with the waste exercise books?</td>\n",
       "      <td id=\"T_11038_row4_col2\" class=\"data row4 col2\" >['Throw them away', 'Collect and sell them', 'Cut them into pieces', 'Give them to the students in Inner Mongolia']</td>\n",
       "      <td id=\"T_11038_row4_col3\" class=\"data row4 col3\" >B</td>\n",
       "      <td id=\"T_11038_row4_col4\" class=\"data row4 col4\" >Collect and sell them</td>\n",
       "      <td id=\"T_11038_row4_col5\" class=\"data row4 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_11038_row4_col6\" class=\"data row4 col6\" >Collect and sell them</td>\n",
       "      <td id=\"T_11038_row4_col7\" class=\"data row4 col7\" > [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7d127f48e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1431 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "66.78"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=dspy_dataset[\"middle\"][\"test\"], num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(compiled_cot, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d8372e00adc4573914cd14a7435f9be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2f7cd716de84319be6b2fc47596e83b",
      "placeholder": "",
      "style": "IPY_MODEL_f756ff4c6a234b81aeffdbca9740120e",
      "value": "Map: 100%"
     }
    },
    "15a82a5784914ac08630e2f4071ba3bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1698a2b8f6e448e49e36c9c9962c7c95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17156cb5ed9d4b4f9fe52b4286016752": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c5bde4646194721a2a30f2cc07335a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e374f032d0a44e0bcd20e3f06c78c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c5bde4646194721a2a30f2cc07335a5",
      "placeholder": "",
      "style": "IPY_MODEL_f4dd0c0980fc4c19bdeef3c1630c5312",
      "value": " 2000/2000 [00:00&lt;00:00, 46490.25 examples/s]"
     }
    },
    "25fe02c768e54238bf20540dbf311fa7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2645512b9ade44f6a74576ff0d6fa447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e21bc0c967f40148fb882c8692d3278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35df6a1f32524ab1a0cb9dedcda968d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38f0319edfed473d8100d6ad3504ed75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2645512b9ade44f6a74576ff0d6fa447",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8167d6e1e3945e8993fb038c4ecc9ea",
      "value": 2000
     }
    },
    "4571611d877e4d03a2aa0ffa364d635d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45745800f73046a2b27efada4f8eb3e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15a82a5784914ac08630e2f4071ba3bc",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0752f1be3c2478c9464438fcadd0127",
      "value": 2000
     }
    },
    "46eea712001e449b806537819ff208f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7541ec8e9bc446a297e35442bc8cd2a9",
      "placeholder": "",
      "style": "IPY_MODEL_c7d92f41c2564ce9909d2fbb1ded4c24",
      "value": " 2000/2000 [00:00&lt;00:00, 18845.98 examples/s]"
     }
    },
    "4fbe9e916c58498f94d1dbc39030736d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9438276614d94569b36a1ccd8903927e",
      "placeholder": "",
      "style": "IPY_MODEL_9c8f103f3e92424e87ec527f06ce3783",
      "value": "Filter: 100%"
     }
    },
    "691b812bbacc46d3b9d8413d5ee8cbaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a905eb31b29343408c2923898845ac82",
       "IPY_MODEL_45745800f73046a2b27efada4f8eb3e6",
       "IPY_MODEL_f5a908ff6a5141e29c0f2adf1e4eb6f3"
      ],
      "layout": "IPY_MODEL_714f7dc65d0b4f5f96c23326732bb1cb"
     }
    },
    "714f7dc65d0b4f5f96c23326732bb1cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7541ec8e9bc446a297e35442bc8cd2a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77fd1da3e56a48ddb679433ed04fd954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4fbe9e916c58498f94d1dbc39030736d",
       "IPY_MODEL_8e2c8030ad78492ba390202aa7ef0d93",
       "IPY_MODEL_1e374f032d0a44e0bcd20e3f06c78c83"
      ],
      "layout": "IPY_MODEL_cb20de4cee8f4f74a92e3251a0202ea9"
     }
    },
    "7e02b08cb22c4674acdb19ca61794894": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f40feca3d4c41bf8bc62627ed1dc958": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8645eb09632f4a3eb9660a18b7a22f3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88827a69dace443e9db9aaee06730ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e1a494621894bfcad9418e6da0dff41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e2c8030ad78492ba390202aa7ef0d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acfd7180cd984b2089632238c0cf080e",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e1a494621894bfcad9418e6da0dff41",
      "value": 2000
     }
    },
    "8ec864e098ae4c09b41f74e37d011d40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9007cb683c264fa599648b008871d9a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93558e5be6694ff1a3bfab6f0aea7d97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9438276614d94569b36a1ccd8903927e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99919dbc154f4d289d2ae34f9bbecf54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c24d002c4d5d488c8ae49d158d3017af",
      "placeholder": "",
      "style": "IPY_MODEL_9d28d336e00d446bb7f7629b99c9b53d",
      "value": "Map: 100%"
     }
    },
    "9be50fdd5ace4151b9033fc53de6856b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c8f103f3e92424e87ec527f06ce3783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d28d336e00d446bb7f7629b99c9b53d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a00da28977b44a549906c98c14f7f97a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8167d6e1e3945e8993fb038c4ecc9ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a905eb31b29343408c2923898845ac82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f40feca3d4c41bf8bc62627ed1dc958",
      "placeholder": "",
      "style": "IPY_MODEL_35df6a1f32524ab1a0cb9dedcda968d9",
      "value": "Map: 100%"
     }
    },
    "acfd7180cd984b2089632238c0cf080e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0752f1be3c2478c9464438fcadd0127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c13234152b4c477d88dd85844b5e712e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17156cb5ed9d4b4f9fe52b4286016752",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c328a618bad746c6855ca796b076ae0c",
      "value": 2000
     }
    },
    "c24d002c4d5d488c8ae49d158d3017af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f7cd716de84319be6b2fc47596e83b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c328a618bad746c6855ca796b076ae0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c34bead716714285833a9ab9328b2b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1698a2b8f6e448e49e36c9c9962c7c95",
      "placeholder": "",
      "style": "IPY_MODEL_7e02b08cb22c4674acdb19ca61794894",
      "value": " 2000/2000 [00:00&lt;00:00, 5516.08 examples/s]"
     }
    },
    "c7d92f41c2564ce9909d2fbb1ded4c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95483cbfca84905b44b1aaa32480615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25fe02c768e54238bf20540dbf311fa7",
      "placeholder": "",
      "style": "IPY_MODEL_2e21bc0c967f40148fb882c8692d3278",
      "value": " 2000/2000 [00:00&lt;00:00, 8521.81 examples/s]"
     }
    },
    "cb20de4cee8f4f74a92e3251a0202ea9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb3bc20c19f54663a1b420c2b06365ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9007cb683c264fa599648b008871d9a8",
      "placeholder": "",
      "style": "IPY_MODEL_88827a69dace443e9db9aaee06730ee0",
      "value": "Map: 100%"
     }
    },
    "d5869c5b82e9415c8b9c22ab8b2d9d02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb3bc20c19f54663a1b420c2b06365ba",
       "IPY_MODEL_c13234152b4c477d88dd85844b5e712e",
       "IPY_MODEL_c95483cbfca84905b44b1aaa32480615"
      ],
      "layout": "IPY_MODEL_4571611d877e4d03a2aa0ffa364d635d"
     }
    },
    "d6d3f9489f62473a935de8e4f7ad5146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d8372e00adc4573914cd14a7435f9be",
       "IPY_MODEL_deebf2522b3246b193bd00a8eb613807",
       "IPY_MODEL_46eea712001e449b806537819ff208f8"
      ],
      "layout": "IPY_MODEL_93558e5be6694ff1a3bfab6f0aea7d97"
     }
    },
    "d7aadac4406b43d99549d088f9b6d24f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "deebf2522b3246b193bd00a8eb613807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ec864e098ae4c09b41f74e37d011d40",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8645eb09632f4a3eb9660a18b7a22f3f",
      "value": 2000
     }
    },
    "f4dd0c0980fc4c19bdeef3c1630c5312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5568b990cb8474d8ea7d880486a207b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99919dbc154f4d289d2ae34f9bbecf54",
       "IPY_MODEL_38f0319edfed473d8100d6ad3504ed75",
       "IPY_MODEL_c34bead716714285833a9ab9328b2b52"
      ],
      "layout": "IPY_MODEL_a00da28977b44a549906c98c14f7f97a"
     }
    },
    "f5a908ff6a5141e29c0f2adf1e4eb6f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9be50fdd5ace4151b9033fc53de6856b",
      "placeholder": "",
      "style": "IPY_MODEL_d7aadac4406b43d99549d088f9b6d24f",
      "value": " 2000/2000 [00:00&lt;00:00, 5667.09 examples/s]"
     }
    },
    "f756ff4c6a234b81aeffdbca9740120e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
