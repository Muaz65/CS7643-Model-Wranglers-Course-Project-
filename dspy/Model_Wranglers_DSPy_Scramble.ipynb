{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqgkJdlqp17D"
   },
   "outputs": [],
   "source": [
    "! pip install dspy-ai\n",
    "! pip install transformers\n",
    "! pip install accelerate\n",
    "# !pip install \"openai<1.0.0\"\n",
    "# # !pip install azure-keyvault-secrets azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "L2XSJ3guqcRf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65be3442932a4dc590d43549a76bf1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import dspy\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dsp.utils.utils import deduplicate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, BootstrapFinetune\n",
    "\n",
    "kwargs={\"max_tokens\":1000}\n",
    "lm = dspy.HFModel(model='mistralai/Mistral-7B-Instruct-v0.1')\n",
    "dspy.settings.configure(lm=lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMH7rMycrOdQ"
   },
   "source": [
    "# Word Scrambling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkbqdYhQrVH0"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zde416GDrCep",
    "outputId": "65491076-1f8b-4369-a139-fdf2a5f85bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'answer': 'A', 'word': 'prophet', 'scrambled': 'prohept', 'question': \"Rearrange the letters in 'prohept' to form the correct word.\\nA: prophet\\nB: jessica\\nC: child\\nD: respected\"}) (input_keys={'question'})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "hf_dataset = load_dataset(\"kurtn718/scrambled_words_multiple_choice\")\n",
    "\n",
    "# Function to convert a Huggingface dataset row to DSPy format\n",
    "def convert_to_dspy_format(item):\n",
    "    return dspy.Example(\n",
    "        answer=item[\"correct_answer\"],\n",
    "        word=item[\"word\"],\n",
    "        scrambled=item[\"scrambled\"],\n",
    "        question=item[\"question\"]\n",
    "    )\n",
    "\n",
    "# Convert and combine all splits\n",
    "dspy_dataset = defaultdict(list)\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for item in hf_dataset[split]:\n",
    "        dspy_example = convert_to_dspy_format(item)\n",
    "        dspy_dataset[split].append(dspy_example)\n",
    "\n",
    "train_set = dspy_dataset[\"train\"]\n",
    "validation_set = dspy_dataset[\"validation\"]\n",
    "test_set = dspy_dataset[\"test\"]\n",
    "\n",
    "train_set = [x.with_inputs('question') for x in train_set]\n",
    "validation_set = [x.with_inputs('question') for x in validation_set]\n",
    "test_set = [x.with_inputs('question') for x in test_set]\n",
    "\n",
    "# Check the first element of the training set\n",
    "example = train_set[0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWPytOuVxnBQ",
    "outputId": "69f92d00-bd2b-4e98-c66b-0846448a879d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Rearrange the letters in 'prohept' to form the correct word.\n",
      "A: prophet\n",
      "B: jessica\n",
      "C: child\n",
      "D: respected\n",
      "Predicted Answer: Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prohept' to form the correct word. A: prophet B: jessica C: child D: respected\n",
      "Answer: B\n"
     ]
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer multiple choice questions from the given options A,B,C,D\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"1 letter from A,B,C,D\")\n",
    "\n",
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Call the predictor on a particular input.\n",
    "pred = generate_answer(question=example.question)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuKUbGJ05f9h",
    "outputId": "be80ac6b-47a9-4484-a4ec-6f7d0b38da68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prohept' to form the correct word. A: prophet B: jessica C: child D: respected\n",
      "Answer:\u001b[32mAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prohept' to form the correct word. A: prophet B: jessica C: child D: respected\n",
      "Answer: B\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HMzCJ48z8fJ3"
   },
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(BasicQA)\n",
    "    def postprocess(self, prediction):\n",
    "        # print(\"_______\")\n",
    "        # print(prediction)\n",
    "        # print(\"_______\")\n",
    "        return prediction.split(\"Answer: \")[-1][0]\n",
    "    \n",
    "    def forward(self, question):\n",
    "        prediction = self.generate_answer(question=question)\n",
    "        prediction.answer = self.postprocess(prediction.answer)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S99nssb35o9I",
    "outputId": "6d2db15a-695f-444c-9f8b-57aeba5a4dce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Rearrange the letters in 'prohept' to form the correct word.\n",
      "A: prophet\n",
      "B: jessica\n",
      "C: child\n",
      "D: respected\n",
      "Predicted Answer: B\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\n",
    "generate_answer_with_chain_of_thought = CoT()\n",
    "\n",
    "# Call the predictor on the same input.\n",
    "pred = generate_answer_with_chain_of_thought(question=example.question)\n",
    "\n",
    "# Print the input, the chain of thought, and the prediction.\n",
    "print(f\"Question: {example.question}\")\n",
    "# print(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lmiited' to form the correct word. A: physiology B: space C: wherever D: limited\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ceczh'. A: promotions B: supply C: tissues D: czech\n",
      "Answer: D: czech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hoetl'. A: cream B: hotel C: portrait D: religion\n",
      "Answer: C: portrait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'webhstos'? A: burial B: frontier C: portuguese D: webshots\n",
      "Answer: B: frontier\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aotrbion' to form the correct word. A: lightning B: number C: abortion D: pointer\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ceeland'. A: cleaned B: organizing C: commitments D: households\n",
      "Answer: B: organizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'naillvshe' represent when unscrambled? A: nashville B: wrist C: challenge D: forces\n",
      "Answer: D: forces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'croe' represent when unscrambled? A: publication B: participate C: core D: receipt\n",
      "Answer: D: receipt\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tihng'. A: situated B: concurrent C: thing D: lotus\n",
      "Answer: C: thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oavl'? A: quarterly B: john C: oval D: antivirus\n",
      "Answer: oval\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wlid' to form the correct word. A: finger B: wild C: plates D: furniture\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 0/2000 [00:11<?, ?it/s]\u001b[A\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 1/2000 [00:12<6:40:21, 12.02s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 2  (50.0):   0%|          | 1/2000 [00:12<6:40:21, 12.02s/it] \u001b[A\n",
      "Average Metric: 1 / 2  (50.0):   0%|          | 2/2000 [00:12<2:47:28,  5.03s/it]\u001b[A\n",
      "Average Metric: 1 / 3  (33.3):   0%|          | 2/2000 [00:12<2:47:28,  5.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 4  (25.0):   0%|          | 3/2000 [00:12<2:47:23,  5.03s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 5  (20.0):   0%|          | 4/2000 [00:12<2:47:18,  5.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 1 / 5  (20.0):   0%|          | 5/2000 [00:12<48:48,  1.47s/it]  \u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 6  (16.7):   0%|          | 5/2000 [00:12<48:48,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 7  (14.3):   0%|          | 6/2000 [00:12<48:47,  1.47s/it]\u001b[A\n",
      "Average Metric: 1 / 7  (14.3):   0%|          | 7/2000 [00:12<29:59,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'daigtil' to form the correct word. A: digital B: orthodox C: themselves D: determination\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 8  (25.0):   0%|          | 7/2000 [00:12<29:59,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aalts' represent when unscrambled? A: atlas B: norman C: magnetic D: const\n",
      "Answer: A: atlas\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hlpeed'? A: badge B: hotels C: helped D: tech\n",
      "Answer: D: tech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dniiclspie'. A: discipline B: better C: fault D: spain\n",
      "Answer: D: spainAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ptniaing'? A: genetic B: compressed C: properties D: painting\n",
      "Answer: D: painting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oedslt'? A: dirty B: oldest C: climate D: baking\n",
      "Answer: D: baking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'luagh'? A: keywords B: counted C: laugh D: provinces\n",
      "Answer: D: provinces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'barihan' to form the correct word. A: bahrain B: polished C: milfhunter D: interested\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vtoes'? A: votes B: download C: scotia D: rates\n",
      "Answer: A: votes\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'niiamonton'? A: feature B: filename C: nomination D: horny\n",
      "Answer: D: horny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sgavae'. A: saudi B: editorial C: savage D: dynamics\n",
      "Answer: A: saudi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'deoelpyd'. A: feet B: muscle C: deployed D: character\n",
      "Answer: D: character\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'crcoeninng' represent when unscrambled? A: supplied B: teachers C: voyeur D: concerning\n",
      "Answer: D: concerning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sihft' to form the correct word. A: continued B: streaming C: pools D: shift\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cnateirg'. A: mainly B: disputes C: hour D: catering\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'agtens'. A: prayer B: wheel C: agents D: hamburg\n",
      "Answer: D: hamburg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 8  (25.0):   0%|          | 8/2000 [00:22<29:58,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dalals' represent when unscrambled? A: dallas B: seeds C: casting D: ideas\n",
      "Answer: A: dallas\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'arnuod' to form the correct word. A: obligations B: defence C: honors D: around\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 9  (33.3):   0%|          | 8/2000 [00:23<29:58,  1.11it/s]\u001b[A\n",
      "Average Metric: 3 / 9  (33.3):   0%|          | 9/2000 [00:23<1:24:06,  2.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 3 / 10  (30.0):   0%|          | 9/2000 [00:23<1:24:06,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 3 / 10  (30.0):   0%|          | 10/2000 [00:23<1:09:12,  2.09s/it]\u001b[A\n",
      "Average Metric: 3 / 11  (27.3):   0%|          | 10/2000 [00:23<1:09:12,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sawn' represent when unscrambled? A: swan B: refurbished C: shoes D: prompt\n",
      "Answer: A: swan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 12  (25.0):   1%|          | 11/2000 [00:23<1:09:10,  2.09s/it]\u001b[A\n",
      "Average Metric: 3 / 12  (25.0):   1%|          | 12/2000 [00:23<44:57,  1.36s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 13  (30.8):   1%|          | 12/2000 [00:23<44:57,  1.36s/it]\u001b[A\n",
      "Average Metric: 4 / 13  (30.8):   1%|          | 13/2000 [00:23<36:19,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 14  (28.6):   1%|          | 13/2000 [00:23<36:19,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 15  (26.7):   1%|          | 14/2000 [00:24<36:18,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 15  (26.7):   1%|          | 15/2000 [00:24<23:31,  1.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snivag'. A: humor B: intimate C: saving D: belts\n",
      "Answer: D: belts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4 / 16  (25.0):   1%|          | 15/2000 [00:24<23:31,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 5 / 17  (29.4):   1%|          | 16/2000 [00:24<23:31,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 18  (33.3):   1%|          | 17/2000 [00:24<23:30,  1.41it/s]\u001b[A\n",
      "Average Metric: 6 / 18  (33.3):   1%|          | 18/2000 [00:24<13:34,  2.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 6 / 19  (31.6):   1%|          | 18/2000 [00:24<13:34,  2.43it/s]\u001b[A\n",
      "Average Metric: 7 / 20  (35.0):   1%|          | 19/2000 [00:24<13:34,  2.43it/s]\u001b[A\n",
      "Average Metric: 7 / 20  (35.0):   1%|          | 20/2000 [00:24<10:02,  3.29it/s]\u001b[A\n",
      "Average Metric: 7 / 21  (33.3):   1%|          | 20/2000 [00:24<10:02,  3.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 22  (36.4):   1%|          | 21/2000 [00:24<10:02,  3.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 23  (39.1):   1%|          | 22/2000 [00:24<10:01,  3.29it/s]\u001b[A\n",
      "Average Metric: 9 / 23  (39.1):   1%|          | 23/2000 [00:24<06:44,  4.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pisrah' represent when unscrambled? A: warcraft B: alphabetical C: parish D: lately\n",
      "Answer: D: lately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'shecems'. A: begun B: posters C: schemes D: motorola\n",
      "Answer: D: motorola\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'nnoe' represent when unscrambled? A: conclusion B: none C: jane D: globalization\n",
      "Answer: B: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sinetag'? A: paperback B: cylinder C: seating D: leadership\n",
      "Answer: B: cylinder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 24  (37.5):   1%|          | 23/2000 [00:29<06:44,  4.89it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 25  (36.0):   1%|          | 24/2000 [00:29<06:44,  4.89it/s]\u001b[A\n",
      "Average Metric: 9 / 25  (36.0):   1%|         | 25/2000 [00:29<29:38,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 10 / 26  (38.5):   1%|         | 25/2000 [00:30<29:38,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 27  (40.7):   1%|         | 26/2000 [00:30<29:37,  1.11it/s]\u001b[A\n",
      "Average Metric: 11 / 27  (40.7):   1%|         | 27/2000 [00:30<21:55,  1.50it/s]\u001b[A\n",
      "Average Metric: 11 / 28  (39.3):   1%|         | 27/2000 [00:30<21:55,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 11 / 29  (37.9):   1%|         | 28/2000 [00:30<21:55,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 11 / 29  (37.9):   1%|         | 29/2000 [00:30<16:55,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 12 / 30  (40.0):   1%|         | 29/2000 [00:30<16:55,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mclaaticpre' to form the correct word. A: table B: malpractice C: oscar D: grounds\n",
      "Answer: C: oscar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'xobx' to form the correct word. A: xbox B: vegetation C: families D: dependence\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sttnaig' represent when unscrambled? A: stating B: trace C: benz D: traffic\n",
      "Answer: A: stating\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'polos' to form the correct word. A: subdivision B: minimum C: subscriber D: pools\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mcexio' to form the correct word. A: hood B: consideration C: mexico D: name\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cshet' represent when unscrambled? A: dressing B: faces C: protecting D: chest\n",
      "Answer: D: chest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 31  (41.9):   2%|         | 30/2000 [00:35<16:54,  1.94it/s]\u001b[A\n",
      "Average Metric: 13 / 31  (41.9):   2%|         | 31/2000 [00:35<35:37,  1.09s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 32  (40.6):   2%|         | 31/2000 [00:35<35:37,  1.09s/it]\u001b[A\n",
      "Average Metric: 13 / 32  (40.6):   2%|         | 32/2000 [00:35<30:26,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 33  (42.4):   2%|         | 32/2000 [00:35<30:26,  1.08it/s]\u001b[A\n",
      "Average Metric: 14 / 33  (42.4):   2%|         | 33/2000 [00:35<26:03,  1.26it/s]\u001b[A\n",
      "Average Metric: 14 / 34  (41.2):   2%|         | 33/2000 [00:35<26:03,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 14 / 35  (40.0):   2%|         | 34/2000 [00:35<26:02,  1.26it/s]\u001b[A\n",
      "Average Metric: 14 / 35  (40.0):   2%|         | 35/2000 [00:35<17:48,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 36  (38.9):   2%|         | 35/2000 [00:36<17:48,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 36  (38.9):   2%|         | 36/2000 [00:36<15:08,  2.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 37  (37.8):   2%|         | 36/2000 [00:36<15:08,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 38  (36.8):   2%|         | 37/2000 [00:36<15:07,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 39  (35.9):   2%|         | 38/2000 [00:36<15:07,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 40  (35.0):   2%|         | 39/2000 [00:36<15:06,  2.16it/s]\u001b[A\n",
      "Average Metric: 14 / 40  (35.0):   2%|         | 40/2000 [00:36<07:24,  4.41it/s]\u001b[A\n",
      "Average Metric: 14 / 41  (34.1):   2%|         | 40/2000 [00:36<07:24,  4.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 42  (35.7):   2%|         | 41/2000 [00:36<07:24,  4.41it/s]\u001b[A\n",
      "Average Metric: 15 / 42  (35.7):   2%|         | 42/2000 [00:36<06:52,  4.75it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sloid'? A: adapter B: solid C: cake D: truck\n",
      "Answer: B: solid\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bapckcak'? A: corners B: satisfaction C: backpack D: certificate\n",
      "Answer: B: satisfaction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'uuinqe'. A: unique B: amounts C: offered D: observers\n",
      "Answer: A: unique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'moriblmiaea'. A: memorabilia B: proof C: eyes D: spouse\n",
      "Answer: A: memorabilia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gitnas' represent when unscrambled? A: faculty B: changes C: giants D: hardware\n",
      "Answer: D: hardware\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'book'. A: commonly B: pharmacies C: explicit D: book\n",
      "Answer: D: book\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gsals' to form the correct word. A: capacity B: ecology C: somebody D: glass\n",
      "Answer: C: somebody\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hservat'. A: harvest B: necessity C: resource D: visit\n",
      "Answer: D: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 43  (34.9):   2%|         | 42/2000 [00:41<06:52,  4.75it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 16 / 44  (36.4):   2%|         | 43/2000 [00:41<06:51,  4.75it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 16 / 44  (36.4):   2%|         | 44/2000 [00:41<27:08,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 16 / 45  (35.6):   2%|         | 44/2000 [00:41<27:08,  1.20it/s]\u001b[A\n",
      "Average Metric: 16 / 45  (35.6):   2%|         | 45/2000 [00:41<25:14,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 16 / 46  (34.8):   2%|         | 45/2000 [00:41<25:14,  1.29it/s]\u001b[A\n",
      "Average Metric: 16 / 47  (34.0):   2%|         | 46/2000 [00:41<25:14,  1.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ptasa'. A: distributors B: purposes C: vitamin D: pasta\n",
      "Answer: A: distributors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'setpirs'. A: electron B: stripes C: patrol D: economies\n",
      "Answer: A\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'relox' to form the correct word. A: reduce B: rolex C: graphics D: selection\n",
      "Answer: B: rolex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mnitue'. A: minute B: shepherd C: gaming D: balance\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'itrrnctuodoy' represent when unscrambled? A: duff B: readers C: introductory D: twain\n",
      "Answer: D: twain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'drietot'. A: detroit B: glad C: teenage D: webster\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bkroe'. A: yemen B: introductory C: robust D: broke\n",
      "Answer: D: broke\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aanl' represent when unscrambled? A: hope B: waterfront C: calvin D: anal\n",
      "Answer: A: hope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 17 / 48  (35.4):   2%|         | 47/2000 [00:47<25:13,  1.29it/s]\u001b[A\n",
      "Average Metric: 17 / 48  (35.4):   2%|         | 48/2000 [00:47<38:37,  1.19s/it]\u001b[A\n",
      "Average Metric: 18 / 49  (36.7):   2%|         | 48/2000 [00:47<38:37,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 18 / 49  (36.7):   2%|         | 49/2000 [00:47<33:30,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 18 / 50  (36.0):   2%|         | 49/2000 [00:47<33:30,  1.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'maartil'. A: disable B: martial C: pentium D: diary\n",
      "Answer: D: diary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 51  (37.3):   2%|         | 50/2000 [00:47<33:29,  1.03s/it]\u001b[A\n",
      "Average Metric: 19 / 51  (37.3):   3%|         | 51/2000 [00:47<23:59,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 52  (36.5):   3%|         | 51/2000 [00:47<23:59,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 19 / 52  (36.5):   3%|         | 52/2000 [00:47<20:32,  1.58it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 19 / 53  (35.8):   3%|         | 52/2000 [00:47<20:32,  1.58it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 20 / 54  (37.0):   3%|         | 53/2000 [00:47<20:31,  1.58it/s]\u001b[A\n",
      "Average Metric: 20 / 54  (37.0):   3%|         | 54/2000 [00:47<13:58,  2.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 55  (36.4):   3%|         | 54/2000 [00:47<13:58,  2.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 20 / 56  (35.7):   3%|         | 55/2000 [00:47<13:58,  2.32it/s]\u001b[A\n",
      "Average Metric: 20 / 56  (35.7):   3%|         | 56/2000 [00:47<09:52,  3.28it/s]\u001b[A\n",
      "Average Metric: 21 / 57  (36.8):   3%|         | 56/2000 [00:48<09:52,  3.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'beoecms' represent when unscrambled? A: telescope B: hourly C: becomes D: anaheim\n",
      "Answer: D: anaheim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sbatilatlsuny' to form the correct word. A: lamp B: substantially C: genetics D: sewer\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mseseags'? A: messages B: kinase C: life D: arrive\n",
      "Answer: messages\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cohir'. A: aware B: cordless C: choir D: idiot\n",
      "Answer: D: idiot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 22 / 58  (37.9):   3%|         | 57/2000 [00:52<09:51,  3.28it/s]\u001b[A\n",
      "Average Metric: 22 / 58  (37.9):   3%|         | 58/2000 [00:52<32:18,  1.00it/s]\u001b[A\n",
      "Average Metric: 23 / 59  (39.0):   3%|         | 58/2000 [00:52<32:18,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 24 / 60  (40.0):   3%|         | 59/2000 [00:52<32:17,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'decifenfre' represent when unscrambled? A: difference B: portuguese C: immediately D: greens\n",
      "Answer: D: greens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 61  (39.3):   3%|         | 60/2000 [00:53<32:16,  1.00it/s]\u001b[A\n",
      "Average Metric: 24 / 61  (39.3):   3%|         | 61/2000 [00:53<20:05,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 62  (38.7):   3%|         | 61/2000 [00:53<20:05,  1.61it/s]\u001b[A\n",
      "Average Metric: 24 / 63  (38.1):   3%|         | 62/2000 [00:53<20:05,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 24 / 63  (38.1):   3%|         | 63/2000 [00:53<16:07,  2.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 64  (37.5):   3%|         | 63/2000 [00:53<16:07,  2.00it/s]\u001b[A\n",
      "Average Metric: 24 / 64  (37.5):   3%|         | 64/2000 [00:53<14:36,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 25 / 65  (38.5):   3%|         | 64/2000 [00:53<14:36,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 25 / 65  (38.5):   3%|         | 65/2000 [00:53<13:12,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fukny' represent when unscrambled? A: richmond B: funky C: phillip D: cunt\n",
      "Answer: B: funky\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'suols' to form the correct word. A: souls B: shield C: type D: partnerships\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cotnercs' represent when unscrambled? A: concerts B: coding C: supervision D: mill\n",
      "Answer: A: concerts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 66  (39.4):   3%|         | 65/2000 [00:58<13:12,  2.44it/s]\u001b[A\n",
      "Average Metric: 26 / 66  (39.4):   3%|         | 66/2000 [00:58<39:11,  1.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iaintil'. A: fraction B: initial C: bonuses D: thomas\n",
      "Answer: A: fraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ganit'? A: retrieved B: malawi C: charming D: giant\n",
      "Answer: D: giant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 27 / 67  (40.3):   3%|         | 66/2000 [00:58<39:11,  1.22s/it]\u001b[A\n",
      "Average Metric: 27 / 67  (40.3):   3%|         | 67/2000 [00:58<34:03,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 68  (39.7):   3%|         | 67/2000 [00:59<34:03,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 27 / 68  (39.7):   3%|         | 68/2000 [00:59<29:31,  1.09it/s]\u001b[A\n",
      "Average Metric: 27 / 69  (39.1):   3%|         | 68/2000 [00:59<29:31,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bfualfo' to form the correct word. A: implied B: holland C: buffalo D: disability\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mnra'. A: guilty B: gardens C: talked D: mrna\n",
      "Answer: D: mrna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 28 / 70  (40.0):   3%|         | 69/2000 [00:59<29:30,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 71  (39.4):   4%|         | 70/2000 [00:59<29:29,  1.09it/s]\u001b[A\n",
      "Average Metric: 28 / 71  (39.4):   4%|         | 71/2000 [00:59<15:27,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 72  (38.9):   4%|         | 71/2000 [00:59<15:27,  2.08it/s]\u001b[A\n",
      "Average Metric: 28 / 72  (38.9):   4%|         | 72/2000 [00:59<14:01,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 73  (38.4):   4%|         | 72/2000 [00:59<14:01,  2.29it/s]\u001b[A\n",
      "Average Metric: 28 / 73  (38.4):   4%|         | 73/2000 [00:59<12:15,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hmoe'? A: home B: menus C: xerox D: mysterious\n",
      "Answer: A: home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iejknt'. A: inkjet B: montana C: patience D: highlands\n",
      "Answer: A: inkjet\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wehietgd' represent when unscrambled? A: combines B: bestsellers C: weighted D: thermal\n",
      "Answer: B: bestsellers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sisfieatd'. A: satisfied B: offers C: costume D: polyester\n",
      "Answer: A: satisfied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dsheis' to form the correct word. A: deaf B: camcorders C: dishes D: miller\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'airuqce'? A: challenge B: corruption C: heroes D: acquire\n",
      "Answer: D: acquire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 74  (37.8):   4%|         | 73/2000 [01:04<12:15,  2.62it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 74  (37.8):   4%|         | 74/2000 [01:04<42:52,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'drwaer'? A: scholarships B: cleaning C: wrap D: drawer\n",
      "Answer: D: drawer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 28 / 75  (37.3):   4%|         | 74/2000 [01:04<42:52,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 76  (38.2):   4%|         | 75/2000 [01:04<42:51,  1.34s/it]\u001b[A\n",
      "Average Metric: 29 / 76  (38.2):   4%|         | 76/2000 [01:04<26:18,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 29 / 77  (37.7):   4%|         | 76/2000 [01:04<26:18,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 78  (38.5):   4%|         | 77/2000 [01:04<26:17,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 78  (38.5):   4%|         | 78/2000 [01:04<19:29,  1.64it/s]\u001b[A\n",
      "Average Metric: 30 / 79  (38.0):   4%|         | 78/2000 [01:04<19:29,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fsluh'. A: unto B: intuitive C: chairman D: flush\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aorrw'? A: sampling B: arrow C: courage D: send\n",
      "Answer: D: send\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'firseiehs'. A: wholly B: fabric C: weblog D: fisheries\n",
      "Answer: D: fisheries\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ctaehprs' to form the correct word. A: athens B: constitutes C: victim D: chapters\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dmtoticonuaen' represent when unscrambled? A: documentation B: ruby C: generally D: marvel\n",
      "Answer: D: marvel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'deer' represent when unscrambled? A: deer B: additional C: manages D: sweden\n",
      "Answer: A: deer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gdciuane'? A: magnet B: guidance C: conversation D: kazakhstan\n",
      "Answer: B: guidance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'iepnxnvesie' represent when unscrambled? A: halo B: logical C: punk D: inexpensive\n",
      "Answer: A: halo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'studcnaork' to form the correct word. A: restrictions B: solutions C: diana D: soundtrack\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'piferx' to form the correct word. A: prefix B: capacity C: symbolic D: leaving\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 80  (37.5):   4%|         | 79/2000 [01:10<19:29,  1.64it/s]\u001b[A\n",
      "Average Metric: 30 / 80  (37.5):   4%|         | 80/2000 [01:10<43:08,  1.35s/it]\u001b[A\n",
      "Average Metric: 30 / 81  (37.0):   4%|         | 80/2000 [01:10<43:08,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 31 / 82  (37.8):   4%|         | 81/2000 [01:10<43:06,  1.35s/it]\u001b[A\n",
      "Average Metric: 31 / 83  (37.3):   4%|         | 82/2000 [01:10<43:05,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 31 / 83  (37.3):   4%|         | 83/2000 [01:10<25:27,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 84  (36.9):   4%|         | 83/2000 [01:10<25:27,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 85  (36.5):   4%|         | 84/2000 [01:10<25:26,  1.26it/s]\u001b[A\n",
      "Average Metric: 31 / 85  (36.5):   4%|         | 85/2000 [01:10<18:47,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 31 / 86  (36.0):   4%|         | 85/2000 [01:10<18:47,  1.70it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 87  (35.6):   4%|         | 86/2000 [01:10<18:47,  1.70it/s]\u001b[A\n",
      "Average Metric: 31 / 87  (35.6):   4%|         | 87/2000 [01:10<14:10,  2.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 32 / 88  (36.4):   4%|         | 87/2000 [01:10<14:10,  2.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 33 / 89  (37.1):   4%|         | 88/2000 [01:10<14:09,  2.25it/s]\u001b[A\n",
      "Average Metric: 33 / 89  (37.1):   4%|         | 89/2000 [01:10<10:56,  2.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 34 / 90  (37.8):   4%|         | 89/2000 [01:11<10:56,  2.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 35 / 91  (38.5):   4%|         | 90/2000 [01:11<10:56,  2.91it/s]\u001b[A\n",
      "Average Metric: 35 / 91  (38.5):   5%|         | 91/2000 [01:11<08:19,  3.82it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 36 / 92  (39.1):   5%|         | 91/2000 [01:11<08:19,  3.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 36 / 93  (38.7):   5%|         | 92/2000 [01:11<08:18,  3.82it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 36 / 94  (38.3):   5%|         | 93/2000 [01:11<08:18,  3.82it/s]\u001b[A\n",
      "Average Metric: 36 / 94  (38.3):   5%|         | 94/2000 [01:11<05:49,  5.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bkacing' to form the correct word. A: receipts B: studied C: chords D: backing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'esnure'. A: seals B: ensure C: indexes D: undefined\n",
      "Answer: B: ensure\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'puapa' represent when unscrambled? A: overhead B: instruction C: diaries D: papua\n",
      "Answer: D: papua\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'paatwyhs' to form the correct word. A: boot B: brutal C: verified D: pathways\n",
      "Answer: D: pathways\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hriybd' to form the correct word. A: hybrid B: pioneer C: same D: updating\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 95  (38.9):   5%|         | 94/2000 [01:15<05:49,  5.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hrrhiacey'. A: therefore B: hierarchy C: deep D: construction\n",
      "Answer: D: construction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 37 / 96  (38.5):   5%|         | 95/2000 [01:15<05:48,  5.46it/s]\u001b[A\n",
      "Average Metric: 37 / 96  (38.5):   5%|         | 96/2000 [01:15<24:09,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 97  (38.1):   5%|         | 96/2000 [01:16<24:09,  1.31it/s]\u001b[A\n",
      "Average Metric: 37 / 97  (38.1):   5%|         | 97/2000 [01:16<22:03,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 37 / 98  (37.8):   5%|         | 97/2000 [01:16<22:03,  1.44it/s]\u001b[A\n",
      "Average Metric: 38 / 99  (38.4):   5%|         | 98/2000 [01:16<22:02,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 38 / 99  (38.4):   5%|         | 99/2000 [01:16<15:56,  1.99it/s]\u001b[A\n",
      "Average Metric: 38 / 100  (38.0):   5%|         | 99/2000 [01:16<15:56,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'atnitmsdiriave'. A: equipped B: washer C: administrative D: subcommittee\n",
      "Answer: D: subcommittee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hroowdad'. A: calibration B: nano C: redhat D: hardwood\n",
      "Answer: D: hardwood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ungdaa' represent when unscrambled? A: begun B: uganda C: allergy D: demographics\n",
      "Answer: A: begun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 101  (38.6):   5%|         | 100/2000 [01:21<15:56,  1.99it/s]\u001b[A\n",
      "Average Metric: 39 / 101  (38.6):   5%|         | 101/2000 [01:21<35:23,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnmpeectoe'? A: expanded B: clicking C: quotations D: competence\n",
      "Answer: D: competence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 102  (38.2):   5%|         | 101/2000 [01:21<35:23,  1.12s/it]\u001b[A\n",
      "Average Metric: 39 / 102  (38.2):   5%|         | 102/2000 [01:21<31:13,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 103  (37.9):   5%|         | 102/2000 [01:21<31:13,  1.01it/s]\u001b[A\n",
      "Average Metric: 39 / 103  (37.9):   5%|         | 103/2000 [01:22<25:51,  1.22it/s]\u001b[A\n",
      "Average Metric: 40 / 104  (38.5):   5%|         | 103/2000 [01:22<25:51,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 105  (39.0):   5%|         | 104/2000 [01:22<25:50,  1.22it/s]\u001b[A\n",
      "Average Metric: 41 / 105  (39.0):   5%|         | 105/2000 [01:22<17:08,  1.84it/s]\u001b[A\n",
      "Average Metric: 41 / 106  (38.7):   5%|         | 105/2000 [01:22<17:08,  1.84it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 107  (38.3):   5%|         | 106/2000 [01:22<17:08,  1.84it/s]\u001b[A\n",
      "Average Metric: 41 / 107  (38.3):   5%|         | 107/2000 [01:22<11:48,  2.67it/s]\u001b[A\n",
      "Average Metric: 42 / 108  (38.9):   5%|         | 107/2000 [01:22<11:48,  2.67it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 109  (38.5):   5%|         | 108/2000 [01:22<11:47,  2.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 110  (38.2):   5%|         | 109/2000 [01:22<11:47,  2.67it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 110  (38.2):   6%|         | 110/2000 [01:22<08:00,  3.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 43 / 111  (38.7):   6%|         | 110/2000 [01:22<08:00,  3.93it/s]\u001b[A\n",
      "Average Metric: 43 / 112  (38.4):   6%|         | 111/2000 [01:22<08:00,  3.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'almnias' represent when unscrambled? A: devoted B: animals C: trades D: audio\n",
      "Answer: A: devoted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 112  (38.4):   6%|         | 112/2000 [01:22<06:12,  5.07it/s]\u001b[A\n",
      "Average Metric: 43 / 113  (38.1):   6%|         | 112/2000 [01:22<06:12,  5.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ecxittaopens' to form the correct word. A: expectations B: funny C: terminal D: flag\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pnntoiig' represent when unscrambled? A: pointing B: chromosome C: gaps D: publication\n",
      "Answer: D: publication\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bpasys'. A: further B: moore C: bypass D: citations\n",
      "Answer: D: citations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lgoo' represent when unscrambled? A: dayton B: logo C: rolled D: mainstream\n",
      "Answer: B: logo\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sviecres'. A: services B: custody C: fails D: offence\n",
      "Answer: A: services\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 114  (38.6):   6%|         | 113/2000 [01:27<06:12,  5.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'siaroencs'. A: moral B: imperial C: scenarios D: organ\n",
      "Answer: D: organ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 114  (38.6):   6%|         | 114/2000 [01:27<24:44,  1.27it/s]\u001b[A\n",
      "Average Metric: 44 / 115  (38.3):   6%|         | 114/2000 [01:27<24:44,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 44 / 115  (38.3):   6%|         | 115/2000 [01:27<22:40,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 116  (37.9):   6%|         | 115/2000 [01:27<22:40,  1.39it/s]\u001b[A\n",
      "Average Metric: 44 / 116  (37.9):   6%|         | 116/2000 [01:27<19:49,  1.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 117  (37.6):   6%|         | 116/2000 [01:27<19:49,  1.58it/s]\u001b[A\n",
      "Average Metric: 44 / 117  (37.6):   6%|         | 117/2000 [01:27<16:35,  1.89it/s]\u001b[A\n",
      "Average Metric: 44 / 118  (37.3):   6%|         | 117/2000 [01:28<16:35,  1.89it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 44 / 118  (37.3):   6%|         | 118/2000 [01:28<13:40,  2.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 45 / 119  (37.8):   6%|         | 118/2000 [01:28<13:40,  2.29it/s]\u001b[A\n",
      "Average Metric: 45 / 119  (37.8):   6%|         | 119/2000 [01:28<12:05,  2.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'akile'? A: campus B: alike C: pushed D: advertiser\n",
      "Answer: B: alikeAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sldade'. A: generic B: headed C: consequences D: saddle\n",
      "Answer: D: saddle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scomtah'? A: stomach B: lace C: reflecting D: related\n",
      "Answer: A: stomach\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'qautiiles'. A: auditorium B: qualities C: witnesses D: need\n",
      "Answer: D: need\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aearldy'. A: already B: injury C: communications D: rebuild\n",
      "Answer: A: already\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 46 / 120  (38.3):   6%|         | 119/2000 [01:32<12:05,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'paer'. A: viable B: queens C: allows D: pear\n",
      "Answer: D: pear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46 / 120  (38.3):   6%|         | 120/2000 [01:32<45:57,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ygoa' represent when unscrambled? A: reserved B: yoga C: popular D: oecd\n",
      "Answer: B: yoga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'reeslaed' to form the correct word. A: drop B: savannah C: released D: hours\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47 / 121  (38.8):   6%|         | 120/2000 [01:33<45:57,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 47 / 121  (38.8):   6%|         | 121/2000 [01:33<40:31,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 122  (38.5):   6%|         | 121/2000 [01:34<40:31,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 122  (38.5):   6%|         | 122/2000 [01:34<32:52,  1.05s/it]\u001b[A\n",
      "Average Metric: 47 / 123  (38.2):   6%|         | 122/2000 [01:34<32:52,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 47 / 124  (37.9):   6%|         | 123/2000 [01:34<32:51,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 47 / 124  (37.9):   6%|         | 124/2000 [01:34<18:59,  1.65it/s]\u001b[A\n",
      "Average Metric: 48 / 125  (38.4):   6%|         | 124/2000 [01:34<18:59,  1.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 48 / 126  (38.1):   6%|         | 125/2000 [01:34<18:59,  1.65it/s]\u001b[A\n",
      "Average Metric: 48 / 126  (38.1):   6%|         | 126/2000 [01:34<12:29,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'taitoaxn'. A: gazette B: subcommittee C: taxation D: tickets\n",
      "Answer: A: gazette\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'qutaunm'. A: powered B: headers C: quantum D: prescription\n",
      "Answer: D: prescription\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'drmaa' represent when unscrambled? A: gates B: beth C: drama D: overview\n",
      "Answer: D: overview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'piars' represent when unscrambled? A: receivers B: meditation C: pairs D: friday\n",
      "Answer: A: receivers\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ceahpl' to form the correct word. A: arnold B: feedback C: chapel D: strategies\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'snuod' to form the correct word. A: jewel B: sound C: receiving D: impacts\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'oebtsiy' to form the correct word. A: members B: smart C: scared D: obesity\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aianlba'. A: albania B: recognizes C: viable D: reimbursement\n",
      "Answer: A: albania\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ternds' to form the correct word. A: circulation B: baker C: virtual D: trends\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 49 / 127  (38.6):   6%|         | 126/2000 [01:38<12:29,  2.50it/s]\u001b[A\n",
      "Average Metric: 49 / 127  (38.6):   6%|         | 127/2000 [01:38<39:53,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 128  (38.3):   6%|         | 127/2000 [01:38<39:53,  1.28s/it]\u001b[A\n",
      "Average Metric: 49 / 128  (38.3):   6%|         | 128/2000 [01:38<31:41,  1.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hahciti' represent when unscrambled? A: hitachi B: analysis C: permits D: satisfactory\n",
      "Answer: A: hitachi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 129  (38.0):   6%|         | 128/2000 [01:39<31:41,  1.02s/it]\u001b[A\n",
      "Average Metric: 49 / 129  (38.0):   6%|         | 129/2000 [01:39<25:14,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 130  (38.5):   6%|         | 129/2000 [01:39<25:14,  1.24it/s]\u001b[A\n",
      "Average Metric: 50 / 130  (38.5):   6%|         | 130/2000 [01:39<21:26,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 131  (38.2):   6%|         | 130/2000 [01:39<21:26,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'saprk'. A: sewer B: soviet C: grant D: spark\n",
      "Answer: D: spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 132  (38.6):   7%|         | 131/2000 [01:39<21:25,  1.45it/s]\u001b[A\n",
      "Average Metric: 51 / 132  (38.6):   7%|         | 132/2000 [01:39<13:52,  2.24it/s]\u001b[A\n",
      "Average Metric: 51 / 133  (38.3):   7%|         | 132/2000 [01:39<13:52,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 51 / 133  (38.3):   7%|         | 133/2000 [01:39<11:21,  2.74it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 52 / 134  (38.8):   7%|         | 133/2000 [01:39<11:21,  2.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cpocnet' to form the correct word. A: lexmark B: work C: concept D: weekly\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cmap'. A: camp B: belgium C: shades D: improve\n",
      "Answer: D"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'coaclenhlr'? A: sectors B: opponent C: chancellor D: images\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 53 / 135  (39.3):   7%|         | 134/2000 [01:44<11:20,  2.74it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 53 / 135  (39.3):   7%|         | 135/2000 [01:44<37:10,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'nnrusig'. A: nursing B: involved C: gems D: intuitive\n",
      "Answer: D: intuitive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 136  (39.7):   7%|         | 135/2000 [01:45<37:10,  1.20s/it]\u001b[A\n",
      "Average Metric: 54 / 136  (39.7):   7%|         | 136/2000 [01:45<33:42,  1.08s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 137  (39.4):   7%|         | 136/2000 [01:45<33:42,  1.08s/it]\u001b[A\n",
      "Average Metric: 54 / 137  (39.4):   7%|         | 137/2000 [01:45<27:25,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 138  (39.9):   7%|         | 137/2000 [01:45<27:25,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eiuaelvqnt' represent when unscrambled? A: weapon B: equivalent C: acting D: ready\n",
      "Answer: D: ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'muarry' represent when unscrambled? A: reported B: murray C: written D: noaa\n",
      "Answer: B: murray\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'utnetonlfruay'. A: lyrics B: matters C: tires D: unfortunately\n",
      "Answer: D: unfortunately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gtmleuaaa' to form the correct word. A: guatemala B: roster C: tracks D: iran\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pploee'. A: sympathy B: people C: pearl D: paul\n",
      "Answer: A: sympathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rurseatnats' to form the correct word. A: restaurants B: commodity C: left D: accessible\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'btroan'. A: roots B: often C: chords D: barton\n",
      "Answer: D: barton\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fbire' to form the correct word. A: academy B: liberals C: britney D: fibre\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 139  (39.6):   7%|         | 138/2000 [01:50<27:24,  1.13it/s]\u001b[A\n",
      "Average Metric: 55 / 139  (39.6):   7%|         | 139/2000 [01:50<45:00,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 140  (39.3):   7%|         | 139/2000 [01:50<45:00,  1.45s/it]\u001b[A\n",
      "Average Metric: 55 / 140  (39.3):   7%|         | 140/2000 [01:50<35:48,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tduhner'. A: scholar B: thunder C: respiratory D: davidson\n",
      "Answer: D: davidson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 141  (39.7):   7%|         | 140/2000 [01:50<35:48,  1.16s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 141  (39.7):   7%|         | 141/2000 [01:50<31:37,  1.02s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 142  (39.4):   7%|         | 141/2000 [01:50<31:37,  1.02s/it]\u001b[A\n",
      "Average Metric: 57 / 143  (39.9):   7%|         | 142/2000 [01:50<31:36,  1.02s/it]\u001b[A\n",
      "Average Metric: 57 / 144  (39.6):   7%|         | 143/2000 [01:51<31:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 57 / 144  (39.6):   7%|         | 144/2000 [01:51<16:11,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 145  (39.3):   7%|         | 144/2000 [01:51<16:11,  1.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 146  (39.0):   7%|         | 145/2000 [01:51<16:10,  1.91it/s]\u001b[A\n",
      "Average Metric: 57 / 146  (39.0):   7%|         | 146/2000 [01:51<12:01,  2.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 147  (38.8):   7%|         | 146/2000 [01:51<12:01,  2.57it/s]\u001b[A\n",
      "Average Metric: 57 / 147  (38.8):   7%|         | 147/2000 [01:51<10:44,  2.87it/s]\u001b[A\n",
      "Average Metric: 57 / 148  (38.5):   7%|         | 147/2000 [01:51<10:44,  2.87it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 58 / 149  (38.9):   7%|         | 148/2000 [01:51<10:44,  2.87it/s]\u001b[A\n",
      "Average Metric: 59 / 150  (39.3):   7%|         | 149/2000 [01:51<10:43,  2.87it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 59 / 150  (39.3):   8%|         | 150/2000 [01:51<06:30,  4.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sitsttcias'. A: scat B: statistics C: loads D: franc\n",
      "Answer: D"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'polit' represent when unscrambled? A: imperial B: brush C: pilot D: verification\n",
      "Answer: A: imperial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 151  (39.1):   8%|         | 150/2000 [01:55<06:30,  4.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'twarod'? A: toward B: consumers C: past D: lexington\n",
      "Answer: D: lexington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 59 / 152  (38.8):   8%|         | 151/2000 [01:57<06:29,  4.74it/s]\u001b[A\n",
      "Average Metric: 59 / 152  (38.8):   8%|         | 152/2000 [01:57<29:44,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 153  (38.6):   8%|         | 152/2000 [01:57<29:44,  1.04it/s]\u001b[A\n",
      "Average Metric: 59 / 153  (38.6):   8%|         | 153/2000 [01:57<25:59,  1.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'voectily' represent when unscrambled? A: appearances B: experiences C: nominations D: velocity\n",
      "Answer: D: velocity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 154  (39.0):   8%|         | 153/2000 [01:57<25:59,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 60 / 154  (39.0):   8%|         | 154/2000 [01:57<22:40,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 60 / 155  (38.7):   8%|         | 154/2000 [01:57<22:40,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 156  (38.5):   8%|         | 155/2000 [01:57<22:39,  1.36it/s]\u001b[A\n",
      "Average Metric: 60 / 156  (38.5):   8%|         | 156/2000 [01:57<15:32,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dlaysips' to form the correct word. A: imprint B: sensing C: displays D: contributor\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'actusoiiqin' represent when unscrambled? A: operative B: ignored C: insider D: acquisition\n",
      "Answer: A: operative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'riruiqeng'. A: requiring B: ecological C: switches D: cash\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rlciecyng'? A: recycling B: elderly C: mentor D: directv\n",
      "Answer: D: directv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bokcls' represent when unscrambled? A: valued B: blocks C: quantum D: removing\n",
      "Answer: B: blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dbiet'. A: identify B: debit C: reduce D: spirit\n",
      "Answer: D: spirit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'klley'. A: length B: kelly C: incest D: finish\n",
      "Answer: A: length\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tereurass' to form the correct word. A: shoppers B: unauthorized C: treasures D: recognised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'seanncr' to form the correct word. A: advertising B: scanner C: reconstruction D: chef\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'baen'. A: come B: converted C: bean D: patents\n",
      "Answer: A: come\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 157  (38.2):   8%|         | 156/2000 [02:01<15:32,  1.98it/s]\u001b[A\n",
      "Average Metric: 60 / 157  (38.2):   8%|         | 157/2000 [02:01<38:04,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'feorsts'? A: forests B: problem C: vast D: contests\n",
      "Answer: forests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 158  (38.6):   8%|         | 157/2000 [02:02<38:04,  1.24s/it]\u001b[A\n",
      "Average Metric: 61 / 158  (38.6):   8%|         | 158/2000 [02:02<31:42,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 159  (38.4):   8%|         | 158/2000 [02:02<31:42,  1.03s/it]\u001b[A\n",
      "Average Metric: 61 / 159  (38.4):   8%|         | 159/2000 [02:02<26:02,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dtrcomieac' represent when unscrambled? A: democratic B: biographies C: participants D: wonderful\n",
      "Answer: D: wonderful\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oeatpvire'. A: suzuki B: sided C: addresses D: operative\n",
      "Answer: D: operative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 160  (38.1):   8%|         | 159/2000 [02:02<26:02,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 61 / 160  (38.1):   8%|         | 160/2000 [02:02<21:27,  1.43it/s]\u001b[A\n",
      "Average Metric: 62 / 161  (38.5):   8%|         | 160/2000 [02:02<21:27,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 162  (38.9):   8%|         | 161/2000 [02:03<21:26,  1.43it/s]\u001b[A\n",
      "Average Metric: 63 / 162  (38.9):   8%|         | 162/2000 [02:03<15:14,  2.01it/s]\u001b[A\n",
      "Average Metric: 63 / 163  (38.7):   8%|         | 162/2000 [02:03<15:14,  2.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 164  (38.4):   8%|         | 163/2000 [02:03<15:13,  2.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 164  (38.4):   8%|         | 164/2000 [02:03<10:21,  2.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 165  (38.2):   8%|         | 164/2000 [02:03<10:21,  2.96it/s]\u001b[A\n",
      "Average Metric: 63 / 165  (38.2):   8%|         | 165/2000 [02:03<08:56,  3.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'giaturs'? A: guitars B: turn C: tiles D: band\n",
      "Answer: B: turn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 63 / 166  (38.0):   8%|         | 165/2000 [02:07<08:56,  3.42it/s]\u001b[A\n",
      "Average Metric: 63 / 166  (38.0):   8%|         | 166/2000 [02:07<35:32,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'laon'. A: taste B: loan C: carbon D: eleven\n",
      "Answer: D: eleven\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'saevd'. A: tank B: interviews C: saved D: benin\n",
      "Answer: D: benin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 64 / 167  (38.3):   8%|         | 166/2000 [02:08<35:32,  1.16s/it]\u001b[A\n",
      "Average Metric: 64 / 167  (38.3):   8%|         | 167/2000 [02:08<36:29,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 65 / 168  (38.7):   8%|         | 167/2000 [02:08<36:29,  1.19s/it]\u001b[A\n",
      "Average Metric: 65 / 168  (38.7):   8%|         | 168/2000 [02:08<28:10,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 169  (38.5):   8%|         | 168/2000 [02:09<28:10,  1.08it/s]\u001b[A\n",
      "Average Metric: 65 / 170  (38.2):   8%|         | 169/2000 [02:09<28:09,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 170  (38.2):   8%|         | 170/2000 [02:09<17:18,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tchquneie'? A: insure B: inches C: technique D: dogs\n",
      "Answer: technique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 66 / 171  (38.6):   8%|         | 170/2000 [02:13<17:18,  1.76it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 66 / 171  (38.6):   9%|         | 171/2000 [02:13<42:28,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iarneld'. A: ireland B: frank C: rotten D: indonesia\n",
      "Answer: ireland\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'liad'. A: injured B: fibre C: laid D: distributions\n",
      "Answer: A: injured\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'vleuad' to form the correct word. A: valued B: speaker C: subscribe D: cycling\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 67 / 172  (39.0):   9%|         | 171/2000 [02:13<42:28,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 67 / 172  (39.0):   9%|         | 172/2000 [02:13<34:03,  1.12s/it]\u001b[A\n",
      "Average Metric: 67 / 173  (38.7):   9%|         | 172/2000 [02:13<34:03,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 67 / 173  (38.7):   9%|         | 173/2000 [02:13<27:36,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 174  (38.5):   9%|         | 173/2000 [02:13<27:36,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 175  (38.3):   9%|         | 174/2000 [02:14<27:36,  1.10it/s]\u001b[A\n",
      "Average Metric: 67 / 175  (38.3):   9%|         | 175/2000 [02:14<17:41,  1.72it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 176  (38.1):   9%|         | 175/2000 [02:14<17:41,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 67 / 177  (37.9):   9%|         | 176/2000 [02:14<17:40,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'adbitnoy' to form the correct word. A: antibody B: plasma C: sections D: barber\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 68 / 178  (38.2):   9%|         | 177/2000 [02:14<17:40,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 68 / 178  (38.2):   9%|         | 178/2000 [02:14<10:46,  2.82it/s]\u001b[A\n",
      "Average Metric: 69 / 179  (38.5):   9%|         | 178/2000 [02:14<10:46,  2.82it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 70 / 180  (38.9):   9%|         | 179/2000 [02:14<10:46,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sctopiafciien'. A: fewer B: trees C: specification D: deborah\n",
      "Answer: D: deborah\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'marrkes'? A: could B: bailey C: markers D: weddings\n",
      "Answer: B: bailey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 70 / 180  (38.9):   9%|         | 180/2000 [02:14<08:14,  3.68it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 70 / 181  (38.7):   9%|         | 180/2000 [02:14<08:14,  3.68it/s]\u001b[A\n",
      "Average Metric: 70 / 181  (38.7):   9%|         | 181/2000 [02:14<07:50,  3.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 71 / 182  (39.0):   9%|         | 181/2000 [02:15<07:50,  3.86it/s]\u001b[A\n",
      "Average Metric: 71 / 182  (39.0):   9%|         | 182/2000 [02:15<07:45,  3.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'weebr'? A: enjoyable B: weber C: natalie D: radar\n",
      "Answer: B: weber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'itranent'. A: cayman B: intranet C: talk D: privacy\n",
      "Answer: B: intranet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 71 / 183  (38.8):   9%|         | 182/2000 [02:19<07:45,  3.91it/s]\u001b[A\n",
      "Average Metric: 71 / 183  (38.8):   9%|         | 183/2000 [02:19<34:26,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 72 / 184  (39.1):   9%|         | 183/2000 [02:19<34:26,  1.14s/it]\u001b[A\n",
      "Average Metric: 72 / 184  (39.1):   9%|         | 184/2000 [02:19<26:42,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 73 / 185  (39.5):   9%|         | 184/2000 [02:20<26:42,  1.13it/s]\u001b[A\n",
      "Average Metric: 73 / 185  (39.5):   9%|         | 185/2000 [02:20<25:11,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 73 / 186  (39.2):   9%|         | 185/2000 [02:20<25:11,  1.20it/s]\u001b[A\n",
      "Average Metric: 73 / 186  (39.2):   9%|         | 186/2000 [02:20<21:56,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 74 / 187  (39.6):   9%|         | 186/2000 [02:20<21:56,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 188  (39.9):   9%|         | 187/2000 [02:20<21:55,  1.38it/s]\u001b[A\n",
      "Average Metric: 75 / 188  (39.9):   9%|         | 188/2000 [02:20<13:27,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 75 / 189  (39.7):   9%|         | 188/2000 [02:20<13:27,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snyc'. A: sync B: mexican C: lack D: tours\n",
      "Answer: A: sync\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 190  (39.5):   9%|         | 189/2000 [02:20<13:27,  2.24it/s]\u001b[A\n",
      "Average Metric: 75 / 190  (39.5):  10%|         | 190/2000 [02:20<09:37,  3.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 191  (39.3):  10%|         | 190/2000 [02:20<09:37,  3.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'asmoertih'. A: participant B: aerosmith C: hopefully D: infant\n",
      "Answer: D: infant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'adaeptd'. A: spots B: beverage C: adapted D: aircraft\n",
      "Answer: C: adapted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'fienst'? A: finest B: travel C: gibson D: phillips\n",
      "Answer: A: finest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ecficfay'. A: beliefs B: sometimes C: efficacy D: optimization\n",
      "Answer: D: optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'criictsim' represent when unscrambled? A: felt B: polynesia C: bdsm D: criticism\n",
      "Answer: D: criticism\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hrat'. A: fitting B: hart C: except D: efficiency\n",
      "Answer: D: efficiency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ciicartl'? A: final B: watson C: cargo D: critical\n",
      "Answer: D: critical\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ctcertaeiifs'. A: certificates B: revenues C: british D: identical\n",
      "Answer: C: british\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 192  (39.1):  10%|         | 191/2000 [02:24<09:37,  3.13it/s]\u001b[A\n",
      "Average Metric: 75 / 192  (39.1):  10%|         | 192/2000 [02:24<27:25,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sdneeocd' to form the correct word. A: makers B: enable C: seconded D: security\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cssiimoomn' to form the correct word. A: deutsch B: commission C: denim D: languages\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ggae'. A: blogger B: basketball C: enlargement D: gage\n",
      "Answer: D: gage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 76 / 193  (39.4):  10%|         | 192/2000 [02:25<27:25,  1.10it/s]\u001b[A\n",
      "Average Metric: 76 / 193  (39.4):  10%|         | 193/2000 [02:25<28:01,  1.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 194  (39.7):  10%|         | 193/2000 [02:26<28:01,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 77 / 194  (39.7):  10%|         | 194/2000 [02:26<23:35,  1.28it/s]\u001b[A\n",
      "Average Metric: 77 / 195  (39.5):  10%|         | 194/2000 [02:26<23:35,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 196  (39.3):  10%|         | 195/2000 [02:26<23:34,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 77 / 196  (39.3):  10%|         | 196/2000 [02:26<18:33,  1.62it/s]\u001b[A\n",
      "Average Metric: 77 / 197  (39.1):  10%|         | 196/2000 [02:26<18:33,  1.62it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 78 / 198  (39.4):  10%|         | 197/2000 [02:26<18:32,  1.62it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'noriitutn'. A: grove B: nutrition C: collapse D: warriors\n",
      "Answer: D: warriors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dealys'. A: january B: uses C: aviation D: delays\n",
      "Answer: D: delays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 79 / 199  (39.7):  10%|         | 198/2000 [02:30<18:31,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 79 / 199  (39.7):  10%|         | 199/2000 [02:30<27:16,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ctue'? A: oregon B: cute C: boat D: lacrosse\n",
      "Answer: B: cute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'linvig'. A: living B: routers C: sheriff D: triumph\n",
      "Answer: A: living\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 80 / 200  (40.0):  10%|         | 199/2000 [02:32<27:16,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sraes'? A: calendars B: sears C: swim D: manages\n",
      "Answer: B: sears\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 80 / 200  (40.0):  10%|         | 200/2000 [02:32<30:04,  1.00s/it]\u001b[A\n",
      "Average Metric: 81 / 201  (40.3):  10%|         | 200/2000 [02:32<30:04,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 81 / 201  (40.3):  10%|         | 201/2000 [02:32<24:38,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 81 / 202  (40.1):  10%|         | 201/2000 [02:32<24:38,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 81 / 202  (40.1):  10%|         | 202/2000 [02:32<19:54,  1.50it/s]\u001b[A\n",
      "Average Metric: 81 / 203  (39.9):  10%|         | 202/2000 [02:32<19:54,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aemgeenrts' to form the correct word. A: manages B: agreements C: seem D: upcoming\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 82 / 204  (40.2):  10%|         | 203/2000 [02:33<19:54,  1.50it/s]\u001b[A\n",
      "Average Metric: 82 / 204  (40.2):  10%|         | 204/2000 [02:33<16:24,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'olny' to form the correct word. A: aperture B: only C: downloading D: despite\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'daoiteiicrns' represent when unscrambled? A: craig B: sewing C: dictionaries D: furthermore\n",
      "Answer: A: craig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 82 / 205  (40.0):  10%|         | 204/2000 [02:36<16:24,  1.83it/s]\u001b[A\n",
      "Average Metric: 82 / 205  (40.0):  10%|         | 205/2000 [02:36<38:11,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lfet' to form the correct word. A: birds B: left C: odyssey D: placing\n",
      "Answer: D: placing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 83 / 206  (40.3):  10%|         | 205/2000 [02:37<38:11,  1.28s/it]\u001b[A\n",
      "Average Metric: 83 / 206  (40.3):  10%|         | 206/2000 [02:37<31:42,  1.06s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 207  (40.6):  10%|         | 206/2000 [02:37<31:42,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 84 / 207  (40.6):  10%|         | 207/2000 [02:37<27:32,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 85 / 208  (40.9):  10%|         | 207/2000 [02:37<27:32,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 85 / 209  (40.7):  10%|         | 208/2000 [02:37<27:31,  1.09it/s]\u001b[A\n",
      "Average Metric: 85 / 209  (40.7):  10%|         | 209/2000 [02:37<16:51,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'inutps' represent when unscrambled? A: tear B: inputs C: clouds D: legitimate\n",
      "Answer: A: tear\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oiignrs'? A: ninja B: origins C: plumbing D: latvia\n",
      "Answer: B: origins\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'clotran'. A: carlton B: hammer C: whole D: sluts\n",
      "Answer: C: whole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 210  (41.0):  10%|         | 209/2000 [02:38<16:51,  1.77it/s]\u001b[A\n",
      "Average Metric: 86 / 210  (41.0):  10%|         | 210/2000 [02:38<15:18,  1.95it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hguh' represent when unscrambled? A: graduated B: hugh C: baldwin D: techno\n",
      "Answer: B: hugh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'doess' to form the correct word. A: resist B: instructors C: cancel D: doses\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sewhcits' represent when unscrambled? A: detected B: atmospheric C: switches D: girlfriend\n",
      "Answer: D: girlfriend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'euongh'? A: played B: minister C: huge D: enough\n",
      "Answer: played\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 211  (40.8):  10%|         | 210/2000 [02:43<15:18,  1.95it/s]\u001b[A\n",
      "Average Metric: 86 / 211  (40.8):  11%|         | 211/2000 [02:43<46:49,  1.57s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 212  (40.6):  11%|         | 211/2000 [02:43<46:49,  1.57s/it]\u001b[A\n",
      "Average Metric: 86 / 212  (40.6):  11%|         | 212/2000 [02:43<35:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 86 / 213  (40.4):  11%|         | 212/2000 [02:43<35:35,  1.19s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 214  (40.2):  11%|         | 213/2000 [02:43<35:34,  1.19s/it]\u001b[A\n",
      "Average Metric: 86 / 214  (40.2):  11%|         | 214/2000 [02:43<21:06,  1.41it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 215  (40.0):  11%|         | 214/2000 [02:43<21:06,  1.41it/s]\u001b[A\n",
      "Average Metric: 86 / 215  (40.0):  11%|         | 215/2000 [02:43<19:05,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 86 / 216  (39.8):  11%|         | 215/2000 [02:43<19:05,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 86 / 216  (39.8):  11%|         | 216/2000 [02:43<15:06,  1.97it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 217  (40.1):  11%|         | 216/2000 [02:44<15:06,  1.97it/s]\u001b[A\n",
      "Average Metric: 87 / 217  (40.1):  11%|         | 217/2000 [02:44<13:23,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 87 / 218  (39.9):  11%|         | 217/2000 [02:44<13:23,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 219  (40.2):  11%|         | 218/2000 [02:44<13:23,  2.22it/s]\u001b[A\n",
      "Average Metric: 88 / 219  (40.2):  11%|         | 219/2000 [02:44<09:08,  3.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tirsapeht'? A: sports B: simpson C: roberts D: therapist\n",
      "Answer: therapist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'thosomn'. A: supplier B: copying C: thomson D: seriously\n",
      "Answer: D: seriously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'biarenkg'? A: outlook B: breaking C: failed D: cycle\n",
      "Answer: D: cycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'puecroerds' represent when unscrambled? A: recommend B: procedures C: given D: catholic\n",
      "Answer: A: recommend\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lbael' represent when unscrambled? A: register B: impaired C: beans D: label\n",
      "Answer: D: label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'statrs' represent when unscrambled? A: gardening B: starts C: blogthis D: psychological\n",
      "Answer: A: gardening\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ftals'. A: cutting B: flats C: bennett D: initiatives\n",
      "Answer: A: cutting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 220  (40.0):  11%|         | 219/2000 [02:48<09:08,  3.25it/s]\u001b[A\n",
      "Average Metric: 88 / 220  (40.0):  11%|         | 220/2000 [02:48<34:13,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dnayota'? A: msgstr B: pulling C: welding D: daytona\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lvoer' represent when unscrambled? A: lover B: listened C: employee D: reel\n",
      "Answer: A: lover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 221  (39.8):  11%|         | 220/2000 [02:49<34:13,  1.15s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 221  (39.8):  11%|         | 221/2000 [02:49<34:56,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 88 / 222  (39.6):  11%|         | 221/2000 [02:49<34:56,  1.18s/it]\u001b[A\n",
      "Average Metric: 89 / 223  (39.9):  11%|         | 222/2000 [02:49<34:55,  1.18s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 224  (39.7):  11%|         | 223/2000 [02:49<34:53,  1.18s/it]\u001b[A\n",
      "Average Metric: 89 / 224  (39.7):  11%|         | 224/2000 [02:49<17:41,  1.67it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 89 / 225  (39.6):  11%|         | 224/2000 [02:49<17:41,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 89 / 226  (39.4):  11%|        | 225/2000 [02:49<17:41,  1.67it/s]\u001b[A\n",
      "Average Metric: 89 / 226  (39.4):  11%|        | 226/2000 [02:49<12:55,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 227  (39.6):  11%|        | 226/2000 [02:50<12:55,  2.29it/s]\u001b[A\n",
      "Average Metric: 90 / 227  (39.6):  11%|        | 227/2000 [02:50<12:07,  2.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tpioacrl'? A: tropical B: detectors C: outlined D: facilitate\n",
      "Answer: B: detectors\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mlid'? A: cabinets B: mild C: excluded D: dragons\n",
      "Answer: D: dragons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'flreows' to form the correct word. A: answer B: flowers C: maintains D: lawsuit\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'revan'. A: raven B: simulation C: patches D: pantyhose\n",
      "Answer: A: raven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tset' represent when unscrambled? A: venues B: test C: chinese D: blowjobs\n",
      "Answer: A: venues\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nkead'? A: steering B: answered C: naked D: organizing\n",
      "Answer: B: answered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 228  (39.9):  11%|        | 227/2000 [02:55<12:07,  2.44it/s]\u001b[A\n",
      "Average Metric: 91 / 228  (39.9):  11%|        | 228/2000 [02:55<42:04,  1.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'faom' represent when unscrambled? A: jungle B: foam C: viii D: glue\n",
      "Answer: B: foam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 92 / 229  (40.2):  11%|        | 228/2000 [02:55<42:04,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 229  (40.2):  11%|        | 229/2000 [02:55<35:48,  1.21s/it]\u001b[A\n",
      "Average Metric: 92 / 230  (40.0):  11%|        | 229/2000 [02:56<35:48,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 92 / 230  (40.0):  12%|        | 230/2000 [02:56<28:14,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 231  (40.3):  12%|        | 230/2000 [02:56<28:14,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 232  (40.1):  12%|        | 231/2000 [02:56<28:13,  1.04it/s]\u001b[A\n",
      "Average Metric: 93 / 232  (40.1):  12%|        | 232/2000 [02:56<17:12,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aouts' represent when unscrambled? A: genome B: autos C: influence D: atlantic\n",
      "Answer: A: genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'grhaam'? A: bodies B: graham C: welfare D: draw\n",
      "Answer: D: draw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cebeiirtles' to form the correct word. A: evening B: celebrities C: dominated D: clicks\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 233  (40.3):  12%|        | 232/2000 [03:00<17:12,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 233  (40.3):  12%|        | 233/2000 [03:00<40:50,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'plbaayck' to form the correct word. A: playback B: equipment C: motherboard D: deaf\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 234  (40.2):  12%|        | 233/2000 [03:00<40:50,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 234  (40.2):  12%|        | 234/2000 [03:00<33:50,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fteifen' to form the correct word. A: casa B: fifteen C: lawrence D: occupational\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ecdlxue'. A: dean B: permission C: exclude D: exercise\n",
      "Answer: D: exercise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 94 / 235  (40.0):  12%|        | 234/2000 [03:01<33:50,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 235  (40.0):  12%|        | 235/2000 [03:01<27:19,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'agleeld' represent when unscrambled? A: nickname B: relates C: byron D: alleged\n",
      "Answer: D: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 94 / 236  (39.8):  12%|        | 235/2000 [03:01<27:19,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 94 / 236  (39.8):  12%|        | 236/2000 [03:01<22:18,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 237  (39.7):  12%|        | 236/2000 [03:01<22:18,  1.32it/s]\u001b[A\n",
      "Average Metric: 94 / 237  (39.7):  12%|        | 237/2000 [03:01<17:54,  1.64it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 95 / 238  (39.9):  12%|        | 237/2000 [03:01<17:54,  1.64it/s]\u001b[A\n",
      "Average Metric: 95 / 238  (39.9):  12%|        | 238/2000 [03:01<14:12,  2.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 95 / 239  (39.7):  12%|        | 238/2000 [03:01<14:12,  2.07it/s]\u001b[A\n",
      "Average Metric: 95 / 239  (39.7):  12%|        | 239/2000 [03:01<10:59,  2.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 96 / 240  (40.0):  12%|        | 239/2000 [03:01<10:59,  2.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lsaahricne'. A: incorporation B: encyclopedia C: lancashire D: independence\n",
      "Answer: D: independence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rtealy'? A: realty B: adding C: quizzes D: added\n",
      "Answer: A: realty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 96 / 241  (39.8):  12%|        | 240/2000 [03:05<10:58,  2.67it/s]\u001b[A\n",
      "Average Metric: 96 / 241  (39.8):  12%|        | 241/2000 [03:05<28:37,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ckeas'? A: cakes B: generating C: surgeons D: accessed\n",
      "Answer: cakes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sprac' to form the correct word. A: deleted B: verification C: sparc D: frost\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cstoa'. A: receiver B: hydrogen C: costa D: impressions\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 242  (39.7):  12%|        | 241/2000 [03:05<28:37,  1.02it/s]\u001b[A\n",
      "Average Metric: 96 / 242  (39.7):  12%|        | 242/2000 [03:05<26:08,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 243  (39.9):  12%|        | 242/2000 [03:06<26:08,  1.12it/s]\u001b[A\n",
      "Average Metric: 97 / 243  (39.9):  12%|        | 243/2000 [03:06<21:24,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 244  (39.8):  12%|        | 243/2000 [03:06<21:24,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 97 / 245  (39.6):  12%|        | 244/2000 [03:06<21:23,  1.37it/s]\u001b[A\n",
      "Average Metric: 97 / 245  (39.6):  12%|        | 245/2000 [03:06<13:00,  2.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 98 / 246  (39.8):  12%|        | 245/2000 [03:06<13:00,  2.25it/s]\u001b[A\n",
      "Average Metric: 98 / 246  (39.8):  12%|        | 246/2000 [03:06<11:40,  2.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 247  (40.1):  12%|        | 246/2000 [03:06<11:40,  2.50it/s]\u001b[A\n",
      "Average Metric: 99 / 247  (40.1):  12%|        | 247/2000 [03:06<10:04,  2.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 100 / 248  (40.3):  12%|        | 247/2000 [03:06<10:04,  2.90it/s]\u001b[A\n",
      "Average Metric: 100 / 248  (40.3):  12%|        | 248/2000 [03:06<08:22,  3.49it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 249  (40.6):  12%|        | 248/2000 [03:06<08:22,  3.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'barin'. A: sampling B: turks C: brian D: dietary\n",
      "Answer: D: dietary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 250  (40.4):  12%|        | 249/2000 [03:07<08:21,  3.49it/s]\u001b[A\n",
      "Average Metric: 101 / 250  (40.4):  12%|        | 250/2000 [03:07<07:47,  3.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 101 / 251  (40.2):  12%|        | 250/2000 [03:07<07:47,  3.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 101 / 251  (40.2):  13%|        | 251/2000 [03:07<07:11,  4.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'exratct'. A: irvine B: extract C: stakeholders D: button\n",
      "Answer: B: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 252  (40.1):  13%|        | 251/2000 [03:07<07:11,  4.05it/s]\u001b[A\n",
      "Average Metric: 101 / 252  (40.1):  13%|        | 252/2000 [03:07<07:18,  3.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cireatnly'. A: bears B: certainly C: maintained D: info\n",
      "Answer: D: info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t Socket operation on non-socket"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'petojecrd' to form the correct word. A: bahamas B: nokia C: projected D: copenhagen\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ctoetacnd'? A: leicester B: encourages C: wins D: contacted\n",
      "Answer: B: encourages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ierssempd' to form the correct word. A: goes B: kate C: impressed D: guards\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aactecpble'. A: poison B: acceptable C: injury D: gains\n",
      "Answer: D: gains\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'yhaama'. A: glasses B: yamaha C: companion D: week\n",
      "Answer: A: glasses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 253  (39.9):  13%|        | 252/2000 [03:11<07:18,  3.99it/s]\u001b[A\n",
      "Average Metric: 101 / 253  (39.9):  13%|        | 253/2000 [03:11<37:08,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 254  (39.8):  13%|        | 253/2000 [03:12<37:08,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 101 / 254  (39.8):  13%|        | 254/2000 [03:12<30:57,  1.06s/it]\u001b[A\n",
      "Average Metric: 101 / 255  (39.6):  13%|        | 254/2000 [03:12<30:57,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oiffecs'. A: bids B: newsletters C: sauce D: offices\n",
      "Answer: b\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vicnee' represent when unscrambled? A: disabilities B: venice C: realty D: july\n",
      "Answer: A: disabilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 102 / 256  (39.8):  13%|        | 255/2000 [03:12<30:56,  1.06s/it]\u001b[A\n",
      "Average Metric: 102 / 256  (39.8):  13%|        | 256/2000 [03:12<18:30,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 103 / 257  (40.1):  13%|        | 256/2000 [03:12<18:30,  1.57it/s]\u001b[A\n",
      "Average Metric: 103 / 257  (40.1):  13%|        | 257/2000 [03:12<16:56,  1.71it/s]\u001b[A\n",
      "Average Metric: 104 / 258  (40.3):  13%|        | 257/2000 [03:13<16:56,  1.71it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 104 / 258  (40.3):  13%|        | 258/2000 [03:13<14:32,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 259  (40.5):  13%|        | 258/2000 [03:13<14:32,  2.00it/s]\u001b[A\n",
      "Average Metric: 105 / 259  (40.5):  13%|        | 259/2000 [03:13<12:20,  2.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 260  (40.4):  13%|        | 259/2000 [03:13<12:20,  2.35it/s]\u001b[A\n",
      "Average Metric: 105 / 260  (40.4):  13%|        | 260/2000 [03:13<09:48,  2.96it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hsore'? A: turnover B: horse C: player D: sixth\n",
      "Answer: B: horse\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bsuh' to form the correct word. A: buddy B: cents C: bush D: cube\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mnoo' to form the correct word. A: exclusive B: mono C: roberts D: regulatory\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 105 / 261  (40.2):  13%|        | 260/2000 [03:16<09:48,  2.96it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 105 / 261  (40.2):  13%|        | 261/2000 [03:16<34:59,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mutnniog'? A: possession B: multi C: squad D: mounting\n",
      "Answer: D: mounting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cerbnraa'. A: canberra B: pipe C: suburban D: young\n",
      "Answer: D: young\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 106 / 262  (40.5):  13%|        | 261/2000 [03:18<34:59,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 106 / 262  (40.5):  13%|        | 262/2000 [03:18<37:23,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'atbsesos'. A: unbiased B: adolescent C: asbestos D: relax\n",
      "Answer: D: relax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 263  (40.3):  13%|        | 262/2000 [03:18<37:23,  1.29s/it]\u001b[A\n",
      "Average Metric: 106 / 263  (40.3):  13%|        | 263/2000 [03:18<28:22,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 264  (40.5):  13%|        | 263/2000 [03:18<28:22,  1.02it/s]\u001b[A\n",
      "Average Metric: 107 / 264  (40.5):  13%|        | 264/2000 [03:18<21:25,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 265  (40.4):  13%|        | 264/2000 [03:18<21:25,  1.35it/s]\u001b[A\n",
      "Average Metric: 107 / 265  (40.4):  13%|        | 265/2000 [03:18<16:02,  1.80it/s]\u001b[A\n",
      "Average Metric: 108 / 266  (40.6):  13%|        | 265/2000 [03:19<16:02,  1.80it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 108 / 266  (40.6):  13%|        | 266/2000 [03:19<12:16,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 267  (40.4):  13%|        | 266/2000 [03:19<12:16,  2.35it/s]\u001b[A\n",
      "Average Metric: 108 / 267  (40.4):  13%|        | 267/2000 [03:19<10:02,  2.88it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bnliseae' to form the correct word. A: lesbian B: asses C: baseline D: trees\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 268  (40.3):  13%|        | 267/2000 [03:19<10:02,  2.88it/s]\u001b[A\n",
      "Average Metric: 108 / 268  (40.3):  13%|        | 268/2000 [03:19<10:36,  2.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 108 / 269  (40.1):  13%|        | 268/2000 [03:19<10:36,  2.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'eoffrt' to form the correct word. A: bang B: demon C: plastic D: effort\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dteteonin'. A: bryan B: detention C: maiden D: maintains\n",
      "Answer: b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 270  (40.0):  13%|        | 269/2000 [03:23<10:36,  2.72it/s]\u001b[A\n",
      "Average Metric: 108 / 270  (40.0):  14%|        | 270/2000 [03:23<33:48,  1.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pcactire'. A: practice B: boats C: buses D: faculty\n",
      "Answer: A: practice\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ftagnrmes' represent when unscrambled? A: issuance B: fragments C: daniel D: viral\n",
      "Answer: D: viral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 271  (40.2):  14%|        | 270/2000 [03:24<33:48,  1.17s/it]\u001b[A\n",
      "Average Metric: 109 / 271  (40.2):  14%|        | 271/2000 [03:24<28:45,  1.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 272  (40.4):  14%|        | 271/2000 [03:24<28:45,  1.00it/s]\u001b[A\n",
      "Average Metric: 110 / 272  (40.4):  14%|        | 272/2000 [03:24<25:04,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 273  (40.3):  14%|        | 272/2000 [03:24<25:04,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 274  (40.1):  14%|        | 273/2000 [03:25<25:03,  1.15it/s]\u001b[A\n",
      "Average Metric: 110 / 274  (40.1):  14%|        | 274/2000 [03:25<16:10,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'nrusery' represent when unscrambled? A: reasonable B: beaches C: inventory D: nursery\n",
      "Answer: D: nursery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'prbtaline' represent when unscrambled? A: interfaces B: possibly C: printable D: humanitarian\n",
      "Answer: A: interfaces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cifosounn' to form the correct word. A: gratis B: confusion C: submitting D: bunny\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 111 / 275  (40.4):  14%|        | 274/2000 [03:28<16:10,  1.78it/s]\u001b[A\n",
      "Average Metric: 111 / 275  (40.4):  14%|        | 275/2000 [03:28<36:44,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 112 / 276  (40.6):  14%|        | 275/2000 [03:29<36:44,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 276  (40.6):  14%|        | 276/2000 [03:29<29:30,  1.03s/it]\u001b[A\n",
      "Average Metric: 112 / 277  (40.4):  14%|        | 276/2000 [03:29<29:30,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 277  (40.4):  14%|        | 277/2000 [03:29<22:31,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'adrnew'? A: eden B: companion C: sentences D: andrew\n",
      "Answer: D: andrew\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'stgnehrts'. A: strengths B: cities C: suddenly D: bound\n",
      "Answer: D: bound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 278  (40.3):  14%|        | 277/2000 [03:29<22:31,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 112 / 278  (40.3):  14%|        | 278/2000 [03:29<18:59,  1.51it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 113 / 279  (40.5):  14%|        | 278/2000 [03:29<18:59,  1.51it/s]\u001b[A\n",
      "Average Metric: 113 / 279  (40.5):  14%|        | 279/2000 [03:29<15:38,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 113 / 280  (40.4):  14%|        | 279/2000 [03:29<15:38,  1.83it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 281  (40.6):  14%|        | 280/2000 [03:29<15:38,  1.83it/s]\u001b[A\n",
      "Average Metric: 114 / 281  (40.6):  14%|        | 281/2000 [03:29<09:55,  2.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cosingsroeanl'. A: adware B: bluetooth C: childcare D: congressional\n",
      "Answer: D: congressional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 282  (40.4):  14%|        | 281/2000 [03:30<09:55,  2.89it/s]\u001b[A\n",
      "Average Metric: 114 / 282  (40.4):  14%|        | 282/2000 [03:30<08:45,  3.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 114 / 283  (40.3):  14%|        | 282/2000 [03:30<08:45,  3.27it/s]\u001b[A\n",
      "Average Metric: 114 / 283  (40.3):  14%|        | 283/2000 [03:30<08:37,  3.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 284  (40.1):  14%|        | 283/2000 [03:30<08:37,  3.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tuhs' represent when unscrambled? A: convenient B: surfaces C: thus D: fruit\n",
      "Answer: C: thus\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'yarely' represent when unscrambled? A: wise B: yearly C: classical D: palmer\n",
      "Answer: A: wise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anetttimpg'. A: attempting B: disabled C: microphone D: planner\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bolinggg'? A: formulation B: dude C: blogging D: blade\n",
      "Answer: D: blade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 285  (40.0):  14%|        | 284/2000 [03:31<08:36,  3.32it/s]\u001b[A\n",
      "Average Metric: 114 / 285  (40.0):  14%|        | 285/2000 [03:31<12:47,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'blodoy' to form the correct word. A: bloody B: curves C: racial D: warcraft\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mtah'. A: eyes B: math C: intense D: victoria\n",
      "Answer: D: victoria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'desrs'? A: freeware B: basement C: ranch D: dress\n",
      "Answer: D: dress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'magenas'. A: flooring B: computing C: malcolm D: manages\n",
      "Answer: D: manages\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'queit'. A: compare B: quiet C: topless D: confusion\n",
      "Answer: B: quiet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 286  (39.9):  14%|        | 285/2000 [03:35<12:47,  2.24it/s]\u001b[A\n",
      "Average Metric: 114 / 286  (39.9):  14%|        | 286/2000 [03:35<35:12,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 115 / 287  (40.1):  14%|        | 286/2000 [03:35<35:12,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 115 / 287  (40.1):  14%|        | 287/2000 [03:35<28:50,  1.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'puolrdy'. A: stanley B: louisiana C: proudly D: contracts\n",
      "Answer: D: contracts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 116 / 288  (40.3):  14%|        | 287/2000 [03:36<28:50,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 116 / 288  (40.3):  14%|        | 288/2000 [03:36<22:46,  1.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 116 / 289  (40.1):  14%|        | 288/2000 [03:36<22:46,  1.25it/s]\u001b[A\n",
      "Average Metric: 116 / 289  (40.1):  14%|        | 289/2000 [03:36<17:45,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 290  (40.3):  14%|        | 289/2000 [03:36<17:45,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 291  (40.2):  14%|        | 290/2000 [03:36<17:44,  1.61it/s]\u001b[A\n",
      "Average Metric: 117 / 291  (40.2):  15%|        | 291/2000 [03:36<11:39,  2.44it/s]\u001b[A\n",
      "Average Metric: 117 / 292  (40.1):  15%|        | 291/2000 [03:36<11:39,  2.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 117 / 292  (40.1):  15%|        | 292/2000 [03:36<09:42,  2.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 293  (39.9):  15%|        | 292/2000 [03:36<09:42,  2.93it/s]\u001b[A\n",
      "Average Metric: 117 / 293  (39.9):  15%|        | 293/2000 [03:36<08:53,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'qauilty' represent when unscrambled? A: wind B: quality C: efficacy D: conducting\n",
      "Answer: B: quality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ccahne'. A: chance B: banking C: besides D: pgsql\n",
      "Answer: B: banking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rdnenireg' represent when unscrambled? A: traditionally B: nottingham C: conditional D: rendering\n",
      "Answer: D: rendering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 294  (39.8):  15%|        | 293/2000 [03:40<08:53,  3.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oucnrircg'. A: occurring B: easter C: software D: renewed\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'etxdnenig'? A: amino B: enquiries C: extending D: artistic\n",
      "Answer: D: artistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 117 / 294  (39.8):  15%|        | 294/2000 [03:40<37:06,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 295  (40.0):  15%|        | 294/2000 [03:41<37:06,  1.31s/it]\u001b[A\n",
      "Average Metric: 118 / 295  (40.0):  15%|        | 295/2000 [03:41<30:47,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 118 / 296  (39.9):  15%|        | 295/2000 [03:41<30:47,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 118 / 296  (39.9):  15%|        | 296/2000 [03:41<23:57,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ldeas'. A: camel B: relations C: heard D: leads\n",
      "Answer: D: leads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 297  (39.7):  15%|        | 296/2000 [03:41<23:57,  1.19it/s]\u001b[A\n",
      "Average Metric: 118 / 297  (39.7):  15%|        | 297/2000 [03:41<18:54,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 298  (39.6):  15%|        | 297/2000 [03:42<18:54,  1.50it/s]\u001b[A\n",
      "Average Metric: 118 / 298  (39.6):  15%|        | 298/2000 [03:42<15:36,  1.82it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 119 / 299  (39.8):  15%|        | 298/2000 [03:42<15:36,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 119 / 299  (39.8):  15%|        | 299/2000 [03:42<13:13,  2.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 300  (39.7):  15%|        | 299/2000 [03:42<13:13,  2.14it/s]\u001b[A\n",
      "Average Metric: 119 / 300  (39.7):  15%|        | 300/2000 [03:42<11:58,  2.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'piatrck' represent when unscrambled? A: celtic B: body C: clothing D: patrick\n",
      "Answer: A: celtic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 301  (39.9):  15%|        | 300/2000 [03:46<11:58,  2.37it/s]\u001b[A\n",
      "Average Metric: 120 / 301  (39.9):  15%|        | 301/2000 [03:46<39:55,  1.41s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 121 / 302  (40.1):  15%|        | 301/2000 [03:46<39:55,  1.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tnruk' represent when unscrambled? A: trunk B: phase C: programmers D: beings\n",
      "Answer: B: phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'deinefs'. A: attendance B: defines C: financial D: force\n",
      "Answer: D: force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 122 / 303  (40.3):  15%|        | 302/2000 [03:47<39:53,  1.41s/it]\u001b[A\n",
      "Average Metric: 122 / 303  (40.3):  15%|        | 303/2000 [03:47<29:21,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sohp' to form the correct word. A: reporting B: welfare C: shop D: wonders\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 123 / 304  (40.5):  15%|        | 303/2000 [03:47<29:21,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 124 / 305  (40.7):  15%|        | 304/2000 [03:47<29:20,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 124 / 305  (40.7):  15%|        | 305/2000 [03:47<18:59,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'srue'? A: belgium B: wonders C: mysql D: sure\n",
      "Answer: D: sure\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'smlal'. A: small B: claimed C: paraguay D: stated\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pvratie'. A: klein B: owner C: private D: terminal\n",
      "Answer: D: terminal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'oetsvobiran' represent when unscrambled? A: literally B: sectors C: observation D: incorrect\n",
      "Answer: B: sectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 306  (40.8):  15%|        | 305/2000 [03:52<18:59,  1.49it/s]\u001b[A\n",
      "Average Metric: 125 / 306  (40.8):  15%|        | 306/2000 [03:52<43:14,  1.53s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 307  (41.0):  15%|        | 306/2000 [03:52<43:14,  1.53s/it]\u001b[A\n",
      "Average Metric: 126 / 307  (41.0):  15%|        | 307/2000 [03:52<36:01,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 308  (40.9):  15%|        | 307/2000 [03:52<36:01,  1.28s/it]\u001b[A\n",
      "Average Metric: 127 / 309  (41.1):  15%|        | 308/2000 [03:52<36:00,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aera' represent when unscrambled? A: conservation B: orgasm C: area D: smoke\n",
      "Answer: C: area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 310  (41.3):  15%|        | 309/2000 [03:53<35:58,  1.28s/it]\u001b[A\n",
      "Average Metric: 128 / 310  (41.3):  16%|        | 310/2000 [03:53<19:48,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 311  (41.2):  16%|        | 310/2000 [03:53<19:48,  1.42it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 311  (41.2):  16%|        | 311/2000 [03:53<18:20,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'crop' represent when unscrambled? A: funeral B: corp C: ideal D: maiden\n",
      "Answer: C: ideal\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'intvmeetsns' represent when unscrambled? A: discussed B: investments C: consortium D: tall\n",
      "Answer: A: discussed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 312  (41.0):  16%|        | 311/2000 [03:54<18:20,  1.54it/s]\u001b[A\n",
      "Average Metric: 128 / 312  (41.0):  16%|        | 312/2000 [03:54<17:41,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dliraeicmss' represent when unscrambled? A: span B: disclaimers C: monitors D: request\n",
      "Answer: D: request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 313  (40.9):  16%|        | 312/2000 [03:55<17:41,  1.59it/s]\u001b[A\n",
      "Average Metric: 128 / 313  (40.9):  16%|        | 313/2000 [03:55<18:12,  1.54it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'slae' represent when unscrambled? A: drops B: plains C: sale D: christ\n",
      "Answer: C: sale\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iensertd'. A: inserted B: idea C: yards D: lacrosse\n",
      "Answer: A: inserted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'seeuccd'. A: sussex B: ongoing C: webster D: succeed\n",
      "Answer: D: succeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'codroirr'. A: corridor B: acknowledged C: headquarters D: adventures\n",
      "Answer: D: adventures\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wrad'. A: chairs B: ward C: purchasing D: death\n",
      "Answer: C: purchasing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 128 / 314  (40.8):  16%|        | 313/2000 [03:58<18:12,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 128 / 314  (40.8):  16%|        | 314/2000 [03:58<37:22,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 315  (40.6):  16%|        | 314/2000 [03:58<37:22,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 316  (40.5):  16%|        | 315/2000 [03:58<37:21,  1.33s/it]\u001b[A\n",
      "Average Metric: 128 / 316  (40.5):  16%|        | 316/2000 [03:58<23:57,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 128 / 317  (40.4):  16%|        | 316/2000 [03:58<23:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 128 / 318  (40.3):  16%|        | 317/2000 [03:58<23:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 319  (40.1):  16%|        | 318/2000 [03:59<23:56,  1.17it/s]\u001b[A\n",
      "Average Metric: 128 / 319  (40.1):  16%|        | 319/2000 [03:59<14:38,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 128 / 320  (40.0):  16%|        | 319/2000 [03:59<14:38,  1.91it/s]\u001b[A\n",
      "Average Metric: 128 / 320  (40.0):  16%|        | 320/2000 [03:59<13:15,  2.11it/s]\u001b[A\n",
      "Average Metric: 129 / 321  (40.2):  16%|        | 320/2000 [03:59<13:15,  2.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 129 / 321  (40.2):  16%|        | 321/2000 [03:59<12:44,  2.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 129 / 322  (40.1):  16%|        | 321/2000 [04:00<12:44,  2.20it/s]\u001b[A\n",
      "Average Metric: 129 / 322  (40.1):  16%|        | 322/2000 [04:00<10:50,  2.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 129 / 323  (39.9):  16%|        | 322/2000 [04:00<10:50,  2.58it/s]\u001b[A\n",
      "Average Metric: 129 / 323  (39.9):  16%|        | 323/2000 [04:00<09:38,  2.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wwilodrde'? A: worldwide B: powers C: controllers D: even\n",
      "Answer: D: even\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tmep'. A: spoken B: temp C: combined D: salem\n",
      "Answer: A: spoken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mgiac'. A: channels B: magic C: guided D: bhutan\n",
      "Answer: D: bhutan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 324  (40.1):  16%|        | 323/2000 [04:04<09:38,  2.90it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'jsut'? A: earrings B: hang C: attacks D: just\n",
      "Answer: D: just\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 130 / 324  (40.1):  16%|        | 324/2000 [04:04<40:12,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 325  (40.0):  16%|        | 324/2000 [04:04<40:12,  1.44s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 326  (39.9):  16%|        | 325/2000 [04:04<40:11,  1.44s/it]\u001b[A\n",
      "Average Metric: 130 / 326  (39.9):  16%|        | 326/2000 [04:04<23:41,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 327  (39.8):  16%|        | 326/2000 [04:05<23:41,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 130 / 327  (39.8):  16%|        | 327/2000 [04:05<21:24,  1.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'piuovers'. A: cast B: importantly C: previous D: harrison\n",
      "Answer: D: harrison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 131 / 328  (39.9):  16%|        | 327/2000 [04:05<21:24,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 131 / 329  (39.8):  16%|        | 328/2000 [04:06<21:23,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 131 / 329  (39.8):  16%|        | 329/2000 [04:06<18:44,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'uilztie' to form the correct word. A: briefly B: everybody C: utilize D: urgent\n",
      "Answer: Briefly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'grlnealey'. A: capri B: generally C: saves D: renewed\n",
      "Answer: D: renewed\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'crtous'. A: courts B: monica C: jeff D: registration\n",
      "Answer: D: registration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 330  (39.7):  16%|        | 329/2000 [04:10<18:44,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 131 / 330  (39.7):  16%|        | 330/2000 [04:10<36:54,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 331  (39.9):  16%|        | 330/2000 [04:10<36:54,  1.33s/it]\u001b[A\n",
      "Average Metric: 132 / 332  (39.8):  17%|        | 331/2000 [04:10<36:53,  1.33s/it]\u001b[A\n",
      "Average Metric: 132 / 333  (39.6):  17%|        | 332/2000 [04:10<36:51,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 132 / 333  (39.6):  17%|        | 333/2000 [04:10<19:40,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mainehcs'. A: finished B: machines C: fashion D: supplements\n",
      "Answer: D: supplements\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iaktne'? A: bath B: which C: intake D: requirements\n",
      "Answer: D: requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 132 / 334  (39.5):  17%|        | 333/2000 [04:10<19:40,  1.41it/s]\u001b[A\n",
      "Average Metric: 132 / 334  (39.5):  17%|        | 334/2000 [04:10<19:27,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 133 / 335  (39.7):  17%|        | 334/2000 [04:10<19:27,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 133 / 336  (39.6):  17%|        | 335/2000 [04:11<19:26,  1.43it/s]\u001b[A\n",
      "Average Metric: 134 / 337  (39.8):  17%|        | 336/2000 [04:11<19:25,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 134 / 337  (39.8):  17%|        | 337/2000 [04:11<11:24,  2.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 338  (39.6):  17%|        | 337/2000 [04:11<11:24,  2.43it/s]\u001b[A\n",
      "Average Metric: 134 / 338  (39.6):  17%|        | 338/2000 [04:11<10:49,  2.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 135 / 339  (39.8):  17%|        | 338/2000 [04:11<10:49,  2.56it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 135 / 339  (39.8):  17%|        | 339/2000 [04:11<09:26,  2.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snoerposd'. A: sponsored B: boys C: dawn D: petroleum\n",
      "Answer: A: sponsored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rtsipelsobniiy' represent when unscrambled? A: loans B: skating C: inline D: responsibility\n",
      "Answer: D: responsibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 135 / 340  (39.7):  17%|        | 339/2000 [04:16<09:26,  2.93it/s]\u001b[A\n",
      "Average Metric: 135 / 340  (39.7):  17%|        | 340/2000 [04:16<36:57,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'essncee'. A: hungarian B: essence C: twice D: american\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sult'. A: kenny B: slut C: skate D: files\n",
      "Answer: kenny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hyduialrc'. A: intranet B: integrate C: hydraulic D: into\n",
      "Answer: D: into\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'angles'? A: relaxation B: coordinates C: monte D: angels\n",
      "Answer: D: angels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 135 / 341  (39.6):  17%|        | 340/2000 [04:17<36:57,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 135 / 341  (39.6):  17%|        | 341/2000 [04:17<35:10,  1.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 136 / 342  (39.8):  17%|        | 341/2000 [04:17<35:10,  1.27s/it]\u001b[A\n",
      "Average Metric: 136 / 342  (39.8):  17%|        | 342/2000 [04:17<27:48,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'peiotnd' represent when unscrambled? A: pointed B: sanders C: calendar D: folks\n",
      "Answer: A: pointed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rkciy'. A: muze B: ricky C: radar D: establishments\n",
      "Answer: D: establishments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uoinns'? A: unions B: viewpicture C: goal D: amazon\n",
      "Answer: B: viewpicture\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'vwrupicitee'. A: viewpicture B: attendance C: elastic D: seeking\n",
      "Answer: D: seeking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 136 / 343  (39.7):  17%|        | 342/2000 [04:21<27:48,  1.01s/it]\u001b[A\n",
      "Average Metric: 136 / 343  (39.7):  17%|        | 343/2000 [04:21<47:13,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'jepsanae'. A: elementary B: japanese C: guild D: calendar\n",
      "Answer: A: elementary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'turly' to form the correct word. A: truly B: adopted C: titans D: underground\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 137 / 344  (39.8):  17%|        | 343/2000 [04:22<47:13,  1.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 344  (39.8):  17%|        | 344/2000 [04:22<40:40,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'svered'? A: recognised B: served C: discretion D: terrain\n",
      "Answer: B: served\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 137 / 345  (39.7):  17%|        | 344/2000 [04:22<40:40,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 345  (39.7):  17%|        | 345/2000 [04:22<31:12,  1.13s/it]\u001b[A\n",
      "Average Metric: 137 / 346  (39.6):  17%|        | 345/2000 [04:22<31:12,  1.13s/it]\u001b[A\n",
      "Average Metric: 138 / 347  (39.8):  17%|        | 346/2000 [04:22<31:11,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 138 / 347  (39.8):  17%|        | 347/2000 [04:22<19:23,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aotm'? A: save B: quantity C: atom D: thee\n",
      "Answer: D: thee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 139 / 348  (39.9):  17%|        | 347/2000 [04:24<19:23,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 139 / 348  (39.9):  17%|        | 348/2000 [04:24<26:36,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'looaictn'. A: suits B: democracy C: location D: beth\n",
      "Answer: D: beth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'beidse' represent when unscrambled? A: lasting B: sperm C: midwest D: beside\n",
      "Answer: D: beside\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cliam' represent when unscrambled? A: claim B: commitments C: bacon D: unauthorized\n",
      "Answer: A: claim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'srpueb' represent when unscrambled? A: ridge B: superb C: murder D: hist\n",
      "Answer: B: superb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 139 / 349  (39.8):  17%|        | 348/2000 [04:27<26:36,  1.03it/s]\u001b[A\n",
      "Average Metric: 139 / 349  (39.8):  17%|        | 349/2000 [04:27<42:53,  1.56s/it]\u001b[A\n",
      "Average Metric: 139 / 350  (39.7):  17%|        | 349/2000 [04:28<42:53,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 139 / 350  (39.7):  18%|        | 350/2000 [04:28<33:32,  1.22s/it]\u001b[A\n",
      "Average Metric: 139 / 351  (39.6):  18%|        | 350/2000 [04:28<33:32,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 139 / 351  (39.6):  18%|        | 351/2000 [04:28<25:00,  1.10it/s]\u001b[A\n",
      "Average Metric: 140 / 352  (39.8):  18%|        | 351/2000 [04:28<25:00,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 140 / 352  (39.8):  18%|        | 352/2000 [04:28<18:48,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rpiceiotaln'. A: replication B: begin C: copper D: interviews\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mainnainitg' represent when unscrambled? A: after B: genuine C: prepared D: maintaining\n",
      "Answer: D: maintaining\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'intienolnrlatay'. A: internationally B: population C: awarded D: museums\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 353  (39.9):  18%|        | 352/2000 [04:29<18:48,  1.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aoelwld'. A: whitney B: annotation C: allowed D: provinces\n",
      "Answer: D: provinces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 353  (39.9):  18%|        | 353/2000 [04:29<26:22,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'biesdes' to form the correct word. A: trembl B: participating C: prof D: besides\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 142 / 354  (40.1):  18%|        | 353/2000 [04:33<26:22,  1.04it/s]\u001b[A\n",
      "Average Metric: 142 / 354  (40.1):  18%|        | 354/2000 [04:33<44:41,  1.63s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 355  (40.3):  18%|        | 354/2000 [04:33<44:41,  1.63s/it]\u001b[A\n",
      "Average Metric: 143 / 355  (40.3):  18%|        | 355/2000 [04:33<32:50,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sxtih'? A: viruses B: battlefield C: calm D: sixth\n",
      "Answer: D: sixth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 144 / 356  (40.4):  18%|        | 355/2000 [04:33<32:50,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 144 / 356  (40.4):  18%|        | 356/2000 [04:33<27:50,  1.02s/it]\u001b[A\n",
      "Average Metric: 144 / 357  (40.3):  18%|        | 356/2000 [04:34<27:50,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 144 / 357  (40.3):  18%|        | 357/2000 [04:34<21:12,  1.29it/s]\u001b[A\n",
      "Average Metric: 145 / 358  (40.5):  18%|        | 357/2000 [04:34<21:12,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 145 / 359  (40.4):  18%|        | 358/2000 [04:34<21:11,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 145 / 359  (40.4):  18%|        | 359/2000 [04:34<12:25,  2.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'setnceens' represent when unscrambled? A: manuscript B: sentences C: introduce D: chemicals\n",
      "Answer: B: sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 145 / 360  (40.3):  18%|        | 359/2000 [04:34<12:25,  2.20it/s]\u001b[A\n",
      "Average Metric: 145 / 360  (40.3):  18%|        | 360/2000 [04:34<11:30,  2.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 145 / 361  (40.2):  18%|        | 360/2000 [04:34<11:30,  2.37it/s]\u001b[A\n",
      "Average Metric: 145 / 361  (40.2):  18%|        | 361/2000 [04:34<09:45,  2.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scuaellrinve'? A: auction B: heath C: surveillance D: cases\n",
      "Answer: A: auction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 145 / 362  (40.1):  18%|        | 361/2000 [04:34<09:45,  2.80it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 145 / 362  (40.1):  18%|        | 362/2000 [04:34<08:15,  3.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 146 / 363  (40.2):  18%|        | 362/2000 [04:35<08:15,  3.31it/s]\u001b[A\n",
      "Average Metric: 147 / 364  (40.4):  18%|        | 363/2000 [04:35<08:15,  3.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 147 / 364  (40.4):  18%|        | 364/2000 [04:35<07:35,  3.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vieiwng'? A: interested B: states C: viewing D: legislature\n",
      "Answer: D: legislature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cednlas' to form the correct word. A: reference B: understanding C: candles D: please\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'kllis'. A: kills B: areas C: commented D: owned\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 365  (40.3):  18%|        | 364/2000 [04:39<07:35,  3.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 147 / 365  (40.3):  18%|        | 365/2000 [04:39<32:40,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 147 / 366  (40.2):  18%|        | 365/2000 [04:39<32:40,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 367  (40.3):  18%|        | 366/2000 [04:39<32:39,  1.20s/it]\u001b[A\n",
      "Average Metric: 148 / 367  (40.3):  18%|        | 367/2000 [04:39<20:12,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 149 / 368  (40.5):  18%|        | 367/2000 [04:40<20:12,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wievs'. A: nipples B: prostores C: broader D: wives\n",
      "Answer: D: wives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 149 / 368  (40.5):  18%|        | 368/2000 [04:40<18:54,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 150 / 369  (40.7):  18%|        | 368/2000 [04:40<18:54,  1.44it/s]\u001b[A\n",
      "Average Metric: 150 / 369  (40.7):  18%|        | 369/2000 [04:40<15:07,  1.80it/s]\u001b[A\n",
      "Average Metric: 150 / 370  (40.5):  18%|        | 369/2000 [04:40<15:07,  1.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 150 / 370  (40.5):  18%|        | 370/2000 [04:40<12:57,  2.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 371  (40.7):  18%|        | 370/2000 [04:40<12:57,  2.10it/s]\u001b[A\n",
      "Average Metric: 151 / 371  (40.7):  19%|        | 371/2000 [04:41<11:52,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hmeoamde' represent when unscrambled? A: router B: mark C: fellow D: homemade\n",
      "Answer: D: homemade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'chrias'? A: germany B: chairs C: wave D: royalty\n",
      "Answer: C: wave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'saolr'. A: solar B: genre C: remark D: introduction\n",
      "Answer: D: introduction\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aountccs'. A: accounts B: freebsd C: verizon D: dawn\n",
      "Answer: D: dawn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 151 / 372  (40.6):  19%|        | 371/2000 [04:44<11:52,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 151 / 372  (40.6):  19%|        | 372/2000 [04:44<38:06,  1.40s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 373  (40.8):  19%|        | 372/2000 [04:45<38:06,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 152 / 373  (40.8):  19%|        | 373/2000 [04:45<28:52,  1.06s/it]\u001b[A\n",
      "Average Metric: 152 / 374  (40.6):  19%|        | 373/2000 [04:45<28:52,  1.06s/it]\u001b[A\n",
      "Average Metric: 152 / 375  (40.5):  19%|        | 374/2000 [04:45<28:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 152 / 375  (40.5):  19%|        | 375/2000 [04:45<18:30,  1.46it/s]\u001b[A\n",
      "Average Metric: 153 / 376  (40.7):  19%|        | 375/2000 [04:45<18:30,  1.46it/s]\u001b[A\n",
      "Average Metric: 153 / 377  (40.6):  19%|        | 376/2000 [04:45<18:29,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fnitocun' represent when unscrambled? A: signup B: horny C: aspect D: function\n",
      "Answer: D: function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 378  (40.5):  19%|        | 377/2000 [04:46<18:29,  1.46it/s]\u001b[A\n",
      "Average Metric: 153 / 378  (40.5):  19%|        | 378/2000 [04:46<11:37,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'atecvitiis'. A: activities B: spin C: messaging D: worldsex\n",
      "Answer: D: worldsex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 379  (40.4):  19%|        | 378/2000 [04:46<11:37,  2.33it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 379  (40.4):  19%|        | 379/2000 [04:46<11:38,  2.32it/s]\u001b[A\n",
      "Average Metric: 153 / 380  (40.3):  19%|        | 379/2000 [04:46<11:38,  2.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'itliaan'? A: marathon B: jobs C: zoom D: italian\n",
      "Answer: D: italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 381  (40.2):  19%|        | 380/2000 [04:47<11:37,  2.32it/s]\u001b[A\n",
      "Average Metric: 153 / 381  (40.2):  19%|        | 381/2000 [04:47<13:31,  1.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tbaelts'. A: loading B: delivery C: tablets D: webster\n",
      "Answer: D: webster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'teaxs'. A: trained B: towels C: texas D: surprisingly\n",
      "Answer: D: surprisingly\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'boristl'. A: bristol B: beginning C: marie D: fully\n",
      "Answer: D: fully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 382  (40.1):  19%|        | 381/2000 [04:50<13:31,  1.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 153 / 382  (40.1):  19%|        | 382/2000 [04:50<24:38,  1.09it/s]\u001b[A\n",
      "Average Metric: 153 / 383  (39.9):  19%|        | 382/2000 [04:50<24:38,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lses'? A: less B: local C: catholic D: attempt\n",
      "Answer: less\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 153 / 384  (39.8):  19%|        | 383/2000 [04:51<24:37,  1.09it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 384  (39.8):  19%|        | 384/2000 [04:51<20:46,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 385  (39.7):  19%|        | 384/2000 [04:51<20:46,  1.30it/s]\u001b[A\n",
      "Average Metric: 153 / 385  (39.7):  19%|        | 385/2000 [04:51<17:40,  1.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ulnkie'? A: local B: enforcement C: usgs D: unlike\n",
      "Answer: D: unlike\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'apnetnimopt'. A: donation B: appointment C: language D: brunswick\n",
      "Answer: D: brunswick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 386  (39.6):  19%|        | 385/2000 [04:52<17:40,  1.52it/s]\u001b[A\n",
      "Average Metric: 153 / 386  (39.6):  19%|        | 386/2000 [04:52<16:25,  1.64it/s]\u001b[A\n",
      "Average Metric: 153 / 387  (39.5):  19%|        | 386/2000 [04:52<16:25,  1.64it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 153 / 387  (39.5):  19%|        | 387/2000 [04:52<13:31,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'crsuoe' represent when unscrambled? A: affiliation B: course C: ideas D: congo\n",
      "Answer: C: ideas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 154 / 388  (39.7):  19%|        | 387/2000 [04:53<13:31,  1.99it/s]\u001b[A\n",
      "Average Metric: 154 / 388  (39.7):  19%|        | 388/2000 [04:53<15:42,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 154 / 389  (39.6):  19%|        | 388/2000 [04:53<15:42,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'uifonrm' represent when unscrambled? A: flies B: stimulation C: uniform D: traditionally\n",
      "Answer: D: traditionally\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cmoamnd'. A: extras B: command C: temperature D: sanders\n",
      "Answer: C: temperature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 154 / 390  (39.5):  19%|        | 389/2000 [04:56<15:41,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pgirrmmnaog'. A: whitney B: judith C: sahara D: programming\n",
      "Answer: D: programming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 154 / 390  (39.5):  20%|        | 390/2000 [04:57<31:52,  1.19s/it]\u001b[A\n",
      "Average Metric: 155 / 391  (39.6):  20%|        | 390/2000 [04:57<31:52,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'folw'? A: bargains B: flow C: fear D: limitations\n",
      "Answer: B: flow\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'crboa'. A: promote B: myth C: faqs D: cobra\n",
      "Answer: D: cobra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 392  (39.8):  20%|        | 391/2000 [04:58<31:51,  1.19s/it]\u001b[A\n",
      "Average Metric: 156 / 392  (39.8):  20%|        | 392/2000 [04:58<25:47,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 393  (39.7):  20%|        | 392/2000 [04:58<25:47,  1.04it/s]\u001b[A\n",
      "Average Metric: 156 / 394  (39.6):  20%|        | 393/2000 [04:58<25:46,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 156 / 394  (39.6):  20%|        | 394/2000 [04:58<18:47,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'enidf' to form the correct word. A: withdrawn B: accomplished C: endif D: prot\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'henadd'. A: handed B: shooting C: topics D: rendered\n",
      "Answer: D: rendered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'qenstious'? A: shipping B: postcard C: institutions D: questions\n",
      "Answer: D: questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 157 / 395  (39.7):  20%|        | 394/2000 [05:02<18:47,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 157 / 395  (39.7):  20%|        | 395/2000 [05:02<36:01,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 396  (39.6):  20%|        | 395/2000 [05:02<36:01,  1.35s/it]\u001b[A\n",
      "Average Metric: 157 / 396  (39.6):  20%|        | 396/2000 [05:02<30:00,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 157 / 397  (39.5):  20%|        | 396/2000 [05:02<30:00,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 398  (39.7):  20%|        | 397/2000 [05:03<29:59,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'root' to form the correct word. A: patterns B: scheduled C: quoted D: root\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'fcrtaos'? A: marina B: alzheimer C: lasting D: factors\n",
      "Answer: D: factors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 398  (39.7):  20%|        | 398/2000 [05:03<19:37,  1.36it/s]\u001b[A\n",
      "Average Metric: 158 / 399  (39.6):  20%|        | 398/2000 [05:03<19:37,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 158 / 399  (39.6):  20%|        | 399/2000 [05:03<18:17,  1.46it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 400  (39.8):  20%|        | 399/2000 [05:04<18:17,  1.46it/s]\u001b[A\n",
      "Average Metric: 159 / 400  (39.8):  20%|        | 400/2000 [05:04<16:34,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 159 / 401  (39.7):  20%|        | 400/2000 [05:04<16:34,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 401  (39.7):  20%|        | 401/2000 [05:04<13:20,  2.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'horus' to form the correct word. A: jimmy B: hours C: hockey D: indians\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 402  (39.6):  20%|        | 401/2000 [05:04<13:20,  2.00it/s]\u001b[A\n",
      "Average Metric: 159 / 402  (39.6):  20%|        | 402/2000 [05:04<12:03,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 159 / 403  (39.5):  20%|        | 402/2000 [05:04<12:03,  2.21it/s]\u001b[A\n",
      "Average Metric: 159 / 403  (39.5):  20%|        | 403/2000 [05:04<10:32,  2.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'crciaiioettfn'. A: sections B: certification C: orange D: violence\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ceiomuintms' represent when unscrambled? A: weird B: subsidiaries C: exact D: communities\n",
      "Answer: C: exact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'inplaoinidas'. A: indianapolis B: time C: annie D: handbook\n",
      "Answer: A: indianapolis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'svruvoris' represent when unscrambled? A: learn B: jackson C: survivors D: either\n",
      "Answer: D: either\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rncietirug'. A: symposium B: towels C: recruiting D: leak\n",
      "Answer: D: leak\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 404  (39.6):  20%|        | 403/2000 [05:08<10:32,  2.52it/s]\u001b[A\n",
      "Average Metric: 160 / 404  (39.6):  20%|        | 404/2000 [05:08<33:29,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 405  (39.8):  20%|        | 404/2000 [05:08<33:29,  1.26s/it]\u001b[A\n",
      "Average Metric: 161 / 405  (39.8):  20%|        | 405/2000 [05:08<28:45,  1.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'traes'. A: church B: tears C: acting D: incredible\n",
      "Answer: D: incredible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 406  (39.9):  20%|        | 405/2000 [05:08<28:45,  1.08s/it]\u001b[A\n",
      "Average Metric: 162 / 406  (39.9):  20%|        | 406/2000 [05:09<21:13,  1.25it/s]\u001b[A\n",
      "Average Metric: 162 / 407  (39.8):  20%|        | 406/2000 [05:09<21:13,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 407  (39.8):  20%|        | 407/2000 [05:09<16:14,  1.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gbmh' represent when unscrambled? A: reporters B: gmbh C: somewhere D: surprisingly\n",
      "Answer: B: gmbh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tgboao' to form the correct word. A: tobago B: song C: reel D: mighty\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 163 / 408  (40.0):  20%|        | 407/2000 [05:10<16:14,  1.63it/s]\u001b[A\n",
      "Average Metric: 163 / 408  (40.0):  20%|        | 408/2000 [05:10<23:52,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ilnmemept'. A: bankruptcy B: implement C: elite D: relatives\n",
      "Answer: A: bankruptcy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'verteiais'? A: empty B: vernon C: varieties D: semantics\n",
      "Answer: C: varieties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'itaitnie' represent when unscrambled? A: fails B: advantage C: initiate D: urged\n",
      "Answer: D: urged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 164 / 409  (40.1):  20%|        | 408/2000 [05:13<23:52,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 164 / 409  (40.1):  20%|        | 409/2000 [05:13<39:45,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 164 / 410  (40.0):  20%|        | 409/2000 [05:13<39:45,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 411  (40.1):  20%|        | 410/2000 [05:14<39:43,  1.50s/it]\u001b[A\n",
      "Average Metric: 165 / 411  (40.1):  21%|        | 411/2000 [05:14<24:32,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 412  (40.0):  21%|        | 411/2000 [05:14<24:32,  1.08it/s]\u001b[A\n",
      "Average Metric: 165 / 412  (40.0):  21%|        | 412/2000 [05:14<20:38,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'teils' to form the correct word. A: spell B: agreements C: tiles D: strengths\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aairdn'. A: grams B: analysts C: pour D: adrian\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 413  (40.0):  21%|        | 412/2000 [05:14<20:38,  1.28it/s]\u001b[A\n",
      "Average Metric: 165 / 413  (40.0):  21%|        | 413/2000 [05:14<18:22,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'caihamrn'. A: detroit B: hearts C: specific D: chairman\n",
      "Answer: D: chairman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 165 / 414  (39.9):  21%|        | 413/2000 [05:15<18:22,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 165 / 414  (39.9):  21%|        | 414/2000 [05:15<15:39,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 415  (39.8):  21%|        | 414/2000 [05:15<15:39,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 416  (39.7):  21%|        | 415/2000 [05:15<15:39,  1.69it/s]\u001b[A\n",
      "Average Metric: 165 / 416  (39.7):  21%|        | 416/2000 [05:15<10:32,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'barigans'. A: contained B: bargains C: pizza D: satisfied\n",
      "Answer: B: bargains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 417  (39.6):  21%|        | 416/2000 [05:16<10:32,  2.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 165 / 417  (39.6):  21%|        | 417/2000 [05:16<10:49,  2.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 418  (39.5):  21%|        | 417/2000 [05:16<10:49,  2.44it/s]\u001b[A\n",
      "Average Metric: 165 / 418  (39.5):  21%|        | 418/2000 [05:16<09:57,  2.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bool'. A: plants B: bool C: injury D: particular\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 419  (39.4):  21%|        | 418/2000 [05:19<09:57,  2.65it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hwak'. A: outside B: audience C: hawk D: reed\n",
      "Answer: C: hawk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 165 / 419  (39.4):  21%|        | 419/2000 [05:19<27:51,  1.06s/it]\u001b[A\n",
      "Average Metric: 166 / 420  (39.5):  21%|        | 419/2000 [05:19<27:51,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 166 / 420  (39.5):  21%|        | 420/2000 [05:19<23:56,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 166 / 421  (39.4):  21%|        | 420/2000 [05:20<23:56,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 166 / 421  (39.4):  21%|        | 421/2000 [05:20<21:31,  1.22it/s]\u001b[A\n",
      "Average Metric: 167 / 422  (39.6):  21%|        | 421/2000 [05:20<21:31,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 423  (39.5):  21%|        | 422/2000 [05:20<21:30,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 167 / 423  (39.5):  21%|        | 423/2000 [05:20<15:17,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aetcotiidracn'. A: patent B: accreditation C: house D: roughly\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iorn'. A: textile B: constructed C: veterinary D: iron\n",
      "Answer: C: constructed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'feibr' to form the correct word. A: fiber B: stats C: invision D: hardcover\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eprimiacl'. A: moments B: empirical C: clients D: collections\n",
      "Answer: D: collections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'enltisesas' represent when unscrambled? A: restructuring B: lawrence C: essentials D: executives\n",
      "Answer: B: lawrence\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hnkus'? A: maine B: adelaide C: hunks D: motherboards\n",
      "Answer: B: adelaide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 424  (39.4):  21%|        | 423/2000 [05:25<15:17,  1.72it/s]\u001b[A\n",
      "Average Metric: 167 / 424  (39.4):  21%|        | 424/2000 [05:25<43:34,  1.66s/it]\u001b[A\n",
      "Average Metric: 167 / 425  (39.3):  21%|        | 424/2000 [05:26<43:34,  1.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 167 / 425  (39.3):  21%|       | 425/2000 [05:26<33:13,  1.27s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 426  (39.2):  21%|       | 425/2000 [05:26<33:13,  1.27s/it]\u001b[A\n",
      "Average Metric: 167 / 426  (39.2):  21%|       | 426/2000 [05:26<29:02,  1.11s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 427  (39.1):  21%|       | 426/2000 [05:27<29:02,  1.11s/it]\u001b[A\n",
      "Average Metric: 167 / 427  (39.1):  21%|       | 427/2000 [05:27<25:54,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mitoeennd'. A: diego B: mentioned C: excluding D: noticed\n",
      "Answer: D: noticed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 168 / 428  (39.3):  21%|       | 427/2000 [05:28<25:54,  1.01it/s]\u001b[A\n",
      "Average Metric: 168 / 428  (39.3):  21%|       | 428/2000 [05:28<26:29,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'airttoatcn' to form the correct word. A: transmitted B: attraction C: decisions D: incorrect\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'insdeir'. A: advertising B: ranging C: expo D: insider\n",
      "Answer: D: insider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'oibtan'? A: gzip B: pull C: obtain D: generations\n",
      "Answer: C: obtain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 168 / 429  (39.2):  21%|       | 428/2000 [05:31<26:29,  1.01s/it]\u001b[A\n",
      "Average Metric: 168 / 429  (39.2):  21%|       | 429/2000 [05:31<39:20,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ecteeld'. A: travels B: elected C: crossword D: insect\n",
      "Answer: D: insect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 169 / 430  (39.3):  21%|       | 429/2000 [05:31<39:20,  1.50s/it]\u001b[A\n",
      "Average Metric: 169 / 430  (39.3):  22%|       | 430/2000 [05:31<30:08,  1.15s/it]\u001b[A\n",
      "Average Metric: 169 / 431  (39.2):  22%|       | 430/2000 [05:31<30:08,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 169 / 431  (39.2):  22%|       | 431/2000 [05:31<24:33,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eanrcta'. A: italia B: peripherals C: encarta D: compensation\n",
      "Answer: D: compensation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bidedr'. A: bidder B: continental C: distributor D: hampshire\n",
      "Answer: D: hampshire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 169 / 432  (39.1):  22%|       | 431/2000 [05:32<24:33,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 169 / 432  (39.1):  22%|       | 432/2000 [05:32<24:57,  1.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 433  (39.3):  22%|       | 432/2000 [05:33<24:57,  1.05it/s]\u001b[A\n",
      "Average Metric: 170 / 433  (39.3):  22%|       | 433/2000 [05:33<18:30,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 434  (39.2):  22%|       | 433/2000 [05:33<18:30,  1.41it/s]\u001b[A\n",
      "Average Metric: 170 / 434  (39.2):  22%|       | 434/2000 [05:33<14:40,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gernrsobeo' represent when unscrambled? A: ambient B: conviction C: blues D: greensboro\n",
      "Answer: D: greensboro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 435  (39.1):  22%|       | 434/2000 [05:34<14:40,  1.78it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 435  (39.1):  22%|       | 435/2000 [05:34<17:57,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 436  (39.2):  22%|       | 435/2000 [05:36<17:57,  1.45it/s]\u001b[A\n",
      "Average Metric: 171 / 436  (39.2):  22%|       | 436/2000 [05:36<29:46,  1.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jtsarliunos' represent when unscrambled? A: cleaned B: recipient C: journalists D: horror\n",
      "Answer: A: cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'deadctiion'? A: expression B: balancing C: msgid D: dedication\n",
      "Answer: D: dedication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 437  (39.1):  22%|       | 436/2000 [05:37<29:46,  1.14s/it]\u001b[A\n",
      "Average Metric: 171 / 437  (39.1):  22%|       | 437/2000 [05:37<26:40,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'regeufe' to form the correct word. A: cold B: colored C: refugee D: scripture\n",
      "Answer: D: scripture\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'piant' to form the correct word. A: spots B: paint C: professors D: assist\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 171 / 438  (39.0):  22%|       | 437/2000 [05:37<26:40,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 171 / 438  (39.0):  22%|       | 438/2000 [05:37<21:59,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 439  (39.0):  22%|       | 438/2000 [05:37<21:59,  1.18it/s]\u001b[A\n",
      "Average Metric: 171 / 439  (39.0):  22%|       | 439/2000 [05:37<17:10,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nwhrsoett'? A: payable B: layout C: northwest D: invasion\n",
      "Answer: D: invasion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 440  (38.9):  22%|       | 439/2000 [05:37<17:10,  1.51it/s]\u001b[A\n",
      "Average Metric: 171 / 440  (38.9):  22%|       | 440/2000 [05:38<13:01,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 441  (38.8):  22%|       | 440/2000 [05:38<13:01,  2.00it/s]\u001b[A\n",
      "Average Metric: 171 / 441  (38.8):  22%|       | 441/2000 [05:38<10:53,  2.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mntael' represent when unscrambled? A: mental B: inserted C: kazaa D: dutch\n",
      "Answer: A: mental\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'plloiw'. A: pillow B: cave C: attributes D: latvia\n",
      "Answer: A: pillow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 172 / 442  (38.9):  22%|       | 441/2000 [05:38<10:53,  2.39it/s]\u001b[A\n",
      "Average Metric: 172 / 442  (38.9):  22%|       | 442/2000 [05:38<09:46,  2.66it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 173 / 443  (39.1):  22%|       | 442/2000 [05:38<09:46,  2.66it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 444  (39.0):  22%|       | 443/2000 [05:38<09:45,  2.66it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 173 / 444  (39.0):  22%|       | 444/2000 [05:38<07:01,  3.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cutretcnosd'. A: performers B: constructed C: estimation D: assessed\n",
      "Answer: C: estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 174 / 445  (39.1):  22%|       | 444/2000 [05:39<07:01,  3.69it/s]\u001b[A\n",
      "Average Metric: 174 / 445  (39.1):  22%|       | 445/2000 [05:39<10:13,  2.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 175 / 446  (39.2):  22%|       | 445/2000 [05:39<10:13,  2.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 175 / 446  (39.2):  22%|       | 446/2000 [05:39<09:00,  2.88it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pron'. A: wednesday B: transmitted C: porn D: healthy\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tnmseaoitlis' to form the correct word. A: virginia B: drops C: absolutely D: testimonials\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 176 / 447  (39.4):  22%|       | 446/2000 [05:42<09:00,  2.88it/s]\u001b[A\n",
      "Average Metric: 176 / 447  (39.4):  22%|       | 447/2000 [05:42<24:24,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'gallieers'. A: galleries B: sphere C: neglect D: heart\n",
      "Answer: D: heart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 176 / 448  (39.3):  22%|       | 447/2000 [05:42<24:24,  1.06it/s]\u001b[A\n",
      "Average Metric: 176 / 448  (39.3):  22%|       | 448/2000 [05:42<20:55,  1.24it/s]\u001b[A\n",
      "Average Metric: 176 / 449  (39.2):  22%|       | 448/2000 [05:43<20:55,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 176 / 449  (39.2):  22%|       | 449/2000 [05:43<21:13,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 450  (39.3):  22%|       | 449/2000 [05:43<21:13,  1.22it/s]\u001b[A\n",
      "Average Metric: 177 / 450  (39.3):  22%|       | 450/2000 [05:43<16:35,  1.56it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 451  (39.2):  22%|       | 450/2000 [05:43<16:35,  1.56it/s]\u001b[A\n",
      "Average Metric: 177 / 451  (39.2):  23%|       | 451/2000 [05:44<12:57,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 452  (39.2):  23%|       | 451/2000 [05:44<12:57,  1.99it/s]\u001b[A\n",
      "Average Metric: 177 / 452  (39.2):  23%|       | 452/2000 [05:44<11:25,  2.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sonw' represent when unscrambled? A: someone B: snow C: factory D: riley\n",
      "Answer: B: snow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 177 / 453  (39.1):  23%|       | 452/2000 [05:44<11:25,  2.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 454  (39.0):  23%|       | 453/2000 [05:44<11:25,  2.26it/s]\u001b[A\n",
      "Average Metric: 177 / 454  (39.0):  23%|       | 454/2000 [05:44<08:43,  2.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'awrdas'. A: dana B: presenting C: awards D: toddler\n",
      "Answer: D: toddler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ptiols'. A: proposed B: issuance C: pilots D: pens\n",
      "Answer: C: pilots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gruoemt' represent when unscrambled? A: demo B: sofa C: disney D: gourmet\n",
      "Answer: D: gourmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 455  (39.1):  23%|       | 454/2000 [05:46<08:43,  2.95it/s]\u001b[A\n",
      "Average Metric: 178 / 455  (39.1):  23%|       | 455/2000 [05:46<16:26,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 456  (39.0):  23%|       | 455/2000 [05:46<16:26,  1.57it/s]\u001b[A\n",
      "Average Metric: 178 / 456  (39.0):  23%|       | 456/2000 [05:46<15:12,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'isnutnmrtael'? A: attended B: instrumental C: phillips D: investigator\n",
      "Answer: B: instrumental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 179 / 457  (39.2):  23%|       | 456/2000 [05:48<15:12,  1.69it/s]\u001b[A\n",
      "Average Metric: 179 / 457  (39.2):  23%|       | 457/2000 [05:48<25:27,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'byus'. A: informed B: regulations C: buys D: various\n",
      "Answer: D: various\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 179 / 458  (39.1):  23%|       | 457/2000 [05:48<25:27,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 179 / 458  (39.1):  23%|       | 458/2000 [05:48<19:20,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 180 / 459  (39.2):  23%|       | 458/2000 [05:49<19:20,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 180 / 459  (39.2):  23%|       | 459/2000 [05:49<20:18,  1.27it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 181 / 460  (39.3):  23%|       | 459/2000 [05:49<20:18,  1.27it/s]\u001b[A\n",
      "Average Metric: 181 / 460  (39.3):  23%|       | 460/2000 [05:50<15:43,  1.63it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 182 / 461  (39.5):  23%|       | 460/2000 [05:50<15:43,  1.63it/s]\u001b[A\n",
      "Average Metric: 182 / 461  (39.5):  23%|       | 461/2000 [05:50<13:06,  1.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 462  (39.6):  23%|       | 461/2000 [05:50<13:06,  1.96it/s]\u001b[A\n",
      "Average Metric: 183 / 462  (39.6):  23%|       | 462/2000 [05:50<10:36,  2.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tarp'. A: trap B: outlined C: procurement D: electronic\n",
      "Answer: A: trap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'corsrswod' to form the correct word. A: phase B: relate C: crossword D: francisco\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 183 / 463  (39.5):  23%|       | 462/2000 [05:51<10:36,  2.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 183 / 463  (39.5):  23%|       | 463/2000 [05:51<15:41,  1.63it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bucnoe'. A: technology B: milwaukee C: hottest D: bounce\n",
      "Answer: D: bounce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 464  (39.4):  23%|       | 463/2000 [05:53<15:41,  1.63it/s]\u001b[A\n",
      "Average Metric: 183 / 464  (39.4):  23%|       | 464/2000 [05:53<28:09,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bnirg' represent when unscrambled? A: kodak B: clean C: bring D: andy\n",
      "Answer: C: bring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 465  (39.4):  23%|       | 464/2000 [05:54<28:09,  1.10s/it]\u001b[A\n",
      "Average Metric: 183 / 465  (39.4):  23%|       | 465/2000 [05:54<26:30,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 466  (39.3):  23%|       | 465/2000 [05:54<26:30,  1.04s/it]\u001b[A\n",
      "Average Metric: 183 / 466  (39.3):  23%|       | 466/2000 [05:54<20:13,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 467  (39.4):  23%|       | 466/2000 [05:55<20:13,  1.26it/s]\u001b[A\n",
      "Average Metric: 184 / 467  (39.4):  23%|       | 467/2000 [05:55<17:50,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 468  (39.3):  23%|       | 467/2000 [05:55<17:50,  1.43it/s]\u001b[A\n",
      "Average Metric: 184 / 468  (39.3):  23%|       | 468/2000 [05:55<13:51,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 469  (39.2):  23%|       | 468/2000 [05:55<13:51,  1.84it/s]\u001b[A\n",
      "Average Metric: 184 / 469  (39.2):  23%|       | 469/2000 [05:55<11:50,  2.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 185 / 470  (39.4):  23%|       | 469/2000 [05:56<11:50,  2.16it/s]\u001b[A\n",
      "Average Metric: 185 / 470  (39.4):  24%|       | 470/2000 [05:56<13:24,  1.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uionn'? A: stopping B: casio C: humanitarian D: union\n",
      "Answer: D: union\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tucrk' to form the correct word. A: welfare B: together C: truck D: navy\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 185 / 471  (39.3):  24%|       | 470/2000 [05:58<13:24,  1.90it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 185 / 471  (39.3):  24%|       | 471/2000 [05:58<26:52,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 185 / 472  (39.2):  24%|       | 471/2000 [05:59<26:52,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 185 / 472  (39.2):  24%|       | 472/2000 [05:59<23:03,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cibmrdgae'? A: bookmark B: statutes C: cambridge D: sensor\n",
      "Answer: B: statutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 473  (39.3):  24%|       | 472/2000 [06:00<23:03,  1.10it/s]\u001b[A\n",
      "Average Metric: 186 / 473  (39.3):  24%|       | 473/2000 [06:00<22:00,  1.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oaitmpl'. A: chat B: buys C: optimal D: within\n",
      "Answer: D: within\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 474  (39.5):  24%|       | 473/2000 [06:00<22:00,  1.16it/s]\u001b[A\n",
      "Average Metric: 187 / 474  (39.5):  24%|       | 474/2000 [06:00<19:22,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 475  (39.4):  24%|       | 474/2000 [06:00<19:22,  1.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tnhak' represent when unscrambled? A: pregnancy B: golden C: frankfurt D: thank\n",
      "Answer: D: thank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 188 / 476  (39.5):  24%|       | 475/2000 [06:00<19:21,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 188 / 476  (39.5):  24%|       | 476/2000 [06:00<11:25,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dknirs'? A: perhaps B: drinks C: enthusiasm D: telescope\n",
      "Answer: D: telescope\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scile'? A: products B: irvine C: intense D: slice\n",
      "Answer: D: slice\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'faounitncl' represent when unscrambled? A: conventional B: ministry C: functional D: dildos\n",
      "Answer: A: conventional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aiudo' to form the correct word. A: baths B: slice C: buck D: audio\n",
      "Answer: D: audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 188 / 477  (39.4):  24%|       | 476/2000 [06:01<11:25,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 188 / 477  (39.4):  24%|       | 477/2000 [06:01<13:27,  1.89it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 478  (39.5):  24%|       | 477/2000 [06:01<13:27,  1.89it/s]\u001b[A\n",
      "Average Metric: 189 / 478  (39.5):  24%|       | 478/2000 [06:01<10:58,  2.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 479  (39.5):  24%|       | 478/2000 [06:02<10:58,  2.31it/s]\u001b[A\n",
      "Average Metric: 189 / 479  (39.5):  24%|       | 479/2000 [06:02<09:55,  2.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'kron'. A: google B: hearings C: korn D: enough\n",
      "Answer: A: google\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 189 / 480  (39.4):  24%|       | 479/2000 [06:02<09:55,  2.55it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 480  (39.4):  24%|       | 480/2000 [06:02<11:33,  2.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 481  (39.3):  24%|       | 480/2000 [06:05<11:33,  2.19it/s]\u001b[A\n",
      "Average Metric: 189 / 481  (39.3):  24%|       | 481/2000 [06:05<27:33,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 482  (39.4):  24%|       | 481/2000 [06:06<27:33,  1.09s/it]\u001b[A\n",
      "Average Metric: 190 / 482  (39.4):  24%|       | 482/2000 [06:06<26:57,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'etinibxihos'? A: begins B: cheney C: tion D: exhibitions\n",
      "Answer: B: cheney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 190 / 483  (39.3):  24%|       | 482/2000 [06:06<26:57,  1.07s/it]\u001b[A\n",
      "Average Metric: 190 / 483  (39.3):  24%|       | 483/2000 [06:06<21:07,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dnimoatoin'? A: auditorium B: governor C: verse D: domination\n",
      "Answer: A: auditorium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 190 / 484  (39.3):  24%|       | 483/2000 [06:07<21:07,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 190 / 484  (39.3):  24%|       | 484/2000 [06:07<23:06,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'metrhos'? A: amplifier B: mountains C: plains D: mothers\n",
      "Answer: A: amplifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 485  (39.4):  24%|       | 484/2000 [06:09<23:06,  1.09it/s]\u001b[A\n",
      "Average Metric: 191 / 485  (39.4):  24%|       | 485/2000 [06:09<29:03,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mrroirs'. A: bennett B: releases C: mirrors D: adapted\n",
      "Answer: D: adapted\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'muidem'? A: medium B: dealer C: enlarge D: auburn\n",
      "Answer: medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 486  (39.3):  24%|       | 485/2000 [06:11<29:03,  1.15s/it]\u001b[A\n",
      "Average Metric: 191 / 486  (39.3):  24%|       | 486/2000 [06:11<34:11,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 487  (39.2):  24%|       | 486/2000 [06:11<34:11,  1.36s/it]\u001b[A\n",
      "Average Metric: 191 / 487  (39.2):  24%|       | 487/2000 [06:11<25:59,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 192 / 488  (39.3):  24%|       | 487/2000 [06:11<25:59,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'firnugshnis'. A: consumption B: poetry C: furnishings D: preceding\n",
      "Answer: D: preceding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aeswnerd'? A: answered B: caribbean C: senior D: sunglasses\n",
      "Answer: D: sunglasses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 489  (39.3):  24%|       | 488/2000 [06:12<25:58,  1.03s/it]\u001b[A\n",
      "Average Metric: 192 / 489  (39.3):  24%|       | 489/2000 [06:12<20:34,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 193 / 490  (39.4):  24%|       | 489/2000 [06:12<20:34,  1.22it/s]\u001b[A\n",
      "Average Metric: 193 / 490  (39.4):  24%|       | 490/2000 [06:12<17:01,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 491  (39.3):  24%|       | 490/2000 [06:13<17:01,  1.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'baet'. A: climbing B: opinions C: beat D: relates\n",
      "Answer: D: relates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 193 / 491  (39.3):  25%|       | 491/2000 [06:13<15:49,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 492  (39.2):  25%|       | 491/2000 [06:13<15:49,  1.59it/s]\u001b[A\n",
      "Average Metric: 193 / 492  (39.2):  25%|       | 492/2000 [06:13<13:18,  1.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rahecl'. A: lily B: insured C: paste D: rachel\n",
      "Answer: D: rachel\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'acdrae'. A: inventory B: choose C: arcade D: compliance\n",
      "Answer: C: arcade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 194 / 493  (39.4):  25%|       | 492/2000 [06:13<13:18,  1.89it/s]\u001b[A\n",
      "Average Metric: 194 / 493  (39.4):  25%|       | 493/2000 [06:13<10:53,  2.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dmeos'. A: cologne B: demos C: subset D: correctly\n",
      "Answer: D: correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 195 / 494  (39.5):  25%|       | 493/2000 [06:14<10:53,  2.31it/s]\u001b[A\n",
      "Average Metric: 195 / 494  (39.5):  25%|       | 494/2000 [06:14<13:29,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'drkiinng'? A: shaw B: understand C: items D: drinking\n",
      "Answer: D: drinking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 495  (39.4):  25%|       | 494/2000 [06:16<13:29,  1.86it/s]\u001b[A\n",
      "Average Metric: 195 / 495  (39.4):  25%|       | 495/2000 [06:16<20:27,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rrpieas' represent when unscrambled? A: topical B: blast C: finances D: repairs\n",
      "Answer: A: topical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 496  (39.5):  25%|       | 495/2000 [06:17<20:27,  1.23it/s]\u001b[A\n",
      "Average Metric: 196 / 496  (39.5):  25%|       | 496/2000 [06:17<26:31,  1.06s/it]\u001b[A\n",
      "Average Metric: 197 / 497  (39.6):  25%|       | 496/2000 [06:18<26:31,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 197 / 497  (39.6):  25%|       | 497/2000 [06:18<22:14,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 198 / 498  (39.8):  25%|       | 497/2000 [06:19<22:14,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 198 / 498  (39.8):  25%|       | 498/2000 [06:19<21:15,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 499  (39.9):  25%|       | 498/2000 [06:19<21:15,  1.18it/s]\u001b[A\n",
      "Average Metric: 199 / 499  (39.9):  25%|       | 499/2000 [06:19<16:31,  1.51it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 200 / 500  (40.0):  25%|       | 499/2000 [06:19<16:31,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 200 / 500  (40.0):  25%|       | 500/2000 [06:19<12:58,  1.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anaitctotrs'. A: methods B: specialist C: hotels D: attractions\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'coorls' represent when unscrambled? A: distinct B: bigger C: colors D: paid\n",
      "Answer: D: paid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ltmioitian' to form the correct word. A: marking B: amps C: alicia D: limitation\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gredas' represent when unscrambled? A: grades B: exclusion C: fell D: cutter\n",
      "Answer: D: cutter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 201 / 501  (40.1):  25%|       | 500/2000 [06:22<12:58,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 201 / 501  (40.1):  25%|       | 501/2000 [06:22<33:19,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'etchail'. A: ethical B: dentists C: strong D: accordingly\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rlol'. A: roll B: newsletter C: heavily D: parameter\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'shiglt'. A: geneva B: slight C: scheduled D: fleet\n",
      "Answer: D: fleet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iechns'. A: knowledgestorm B: inches C: writings D: jill\n",
      "Answer: D: jill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 201 / 502  (40.0):  25%|       | 501/2000 [06:24<33:19,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 502  (40.0):  25%|       | 502/2000 [06:24<35:49,  1.43s/it]\u001b[A\n",
      "Average Metric: 201 / 503  (40.0):  25%|       | 502/2000 [06:24<35:49,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'colepud'? A: promote B: doors C: mission D: coupled\n",
      "Answer: B: doors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 201 / 504  (39.9):  25%|       | 503/2000 [06:24<35:47,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 201 / 504  (39.9):  25%|       | 504/2000 [06:24<19:55,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peslyoina'? A: exports B: cited C: polynesia D: defining\n",
      "Answer: D: defining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 202 / 505  (40.0):  25%|       | 504/2000 [06:25<19:55,  1.25it/s]\u001b[A\n",
      "Average Metric: 202 / 505  (40.0):  25%|       | 505/2000 [06:25<18:28,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 202 / 506  (39.9):  25%|       | 505/2000 [06:25<18:28,  1.35it/s]\u001b[A\n",
      "Average Metric: 202 / 506  (39.9):  25%|       | 506/2000 [06:25<15:02,  1.66it/s]\u001b[A\n",
      "Average Metric: 203 / 507  (40.0):  25%|       | 506/2000 [06:25<15:02,  1.66it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 203 / 508  (40.0):  25%|       | 507/2000 [06:25<15:01,  1.66it/s]\u001b[A\n",
      "Average Metric: 203 / 508  (40.0):  25%|       | 508/2000 [06:25<10:25,  2.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 509  (40.1):  25%|       | 508/2000 [06:25<10:25,  2.38it/s]\u001b[A\n",
      "Average Metric: 204 / 510  (40.0):  25%|       | 509/2000 [06:25<10:25,  2.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 204 / 510  (40.0):  26%|       | 510/2000 [06:25<06:57,  3.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 511  (40.1):  26%|       | 510/2000 [06:26<06:57,  3.57it/s]\u001b[A\n",
      "Average Metric: 205 / 511  (40.1):  26%|       | 511/2000 [06:26<07:18,  3.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'btuetr' to form the correct word. A: bodies B: violin C: smith D: butter\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ilusinn'? A: accommodations B: propaganda C: insulin D: keeps\n",
      "Answer: D: keeps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'stmoopauthn' represent when unscrambled? A: southampton B: specialists C: preference D: harvard\n",
      "Answer: A: southampton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 512  (40.0):  26%|       | 511/2000 [06:28<07:18,  3.40it/s]\u001b[A\n",
      "Average Metric: 205 / 512  (40.0):  26%|       | 512/2000 [06:28<22:12,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mtruae' to form the correct word. A: mature B: live C: nevertheless D: tariff\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pcik'. A: future B: pick C: expressly D: cumshot\n",
      "Answer: A: future\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 513  (40.0):  26%|       | 512/2000 [06:29<22:12,  1.12it/s]\u001b[A\n",
      "Average Metric: 205 / 513  (40.0):  26%|       | 513/2000 [06:29<22:52,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 514  (39.9):  26%|       | 513/2000 [06:30<22:52,  1.08it/s]\u001b[A\n",
      "Average Metric: 205 / 514  (39.9):  26%|       | 514/2000 [06:30<17:59,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 515  (39.8):  26%|       | 514/2000 [06:30<17:59,  1.38it/s]\u001b[A\n",
      "Average Metric: 205 / 515  (39.8):  26%|       | 515/2000 [06:30<16:32,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'iastnnllig' represent when unscrambled? A: installing B: availability C: audience D: biotechnology\n",
      "Answer: A: installing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 516  (39.7):  26%|       | 515/2000 [06:31<16:32,  1.50it/s]\u001b[A\n",
      "Average Metric: 205 / 516  (39.7):  26%|       | 516/2000 [06:31<17:50,  1.39it/s]\u001b[A\n",
      "Average Metric: 205 / 517  (39.7):  26%|       | 516/2000 [06:31<17:50,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 205 / 517  (39.7):  26%|       | 517/2000 [06:31<14:20,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dicss'? A: venue B: renowned C: discs D: moderators\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bogrhut'. A: farmer B: brought C: racism D: acts\n",
      "Answer: D: acts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 206 / 518  (39.8):  26%|       | 517/2000 [06:35<14:20,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 206 / 518  (39.8):  26%|       | 518/2000 [06:35<34:13,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dtboiutiisrn'. A: exceed B: mono C: capture D: distribution\n",
      "Answer: D: distribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 519  (39.7):  26%|       | 518/2000 [06:35<34:13,  1.39s/it]\u001b[A\n",
      "Average Metric: 206 / 519  (39.7):  26%|       | 519/2000 [06:35<30:51,  1.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cfrieited'. A: urls B: watershed C: certified D: pharmacology\n",
      "Answer: D: pharmacology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tankhs' represent when unscrambled? A: stainless B: finger C: thanks D: prayer\n",
      "Answer: C: thanks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 520  (39.6):  26%|       | 519/2000 [06:37<30:51,  1.25s/it]\u001b[A\n",
      "Average Metric: 206 / 520  (39.6):  26%|       | 520/2000 [06:37<30:55,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 207 / 521  (39.7):  26%|       | 520/2000 [06:37<30:55,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 522  (39.8):  26%|       | 521/2000 [06:37<30:54,  1.25s/it]\u001b[A\n",
      "Average Metric: 208 / 522  (39.8):  26%|       | 522/2000 [06:37<17:44,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'exprssely'. A: changed B: detected C: expressly D: startup\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 208 / 523  (39.8):  26%|       | 522/2000 [06:38<17:44,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 208 / 523  (39.8):  26%|       | 523/2000 [06:38<19:13,  1.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 524  (39.7):  26%|       | 523/2000 [06:38<19:13,  1.28it/s]\u001b[A\n",
      "Average Metric: 208 / 524  (39.7):  26%|       | 524/2000 [06:38<15:49,  1.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'iitamtne'. A: hannah B: wayne C: intimate D: organization\n",
      "Answer: D: organization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 525  (39.6):  26%|       | 524/2000 [06:39<15:49,  1.55it/s]\u001b[A\n",
      "Average Metric: 208 / 525  (39.6):  26%|       | 525/2000 [06:39<20:07,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 526  (39.7):  26%|       | 525/2000 [06:40<20:07,  1.22it/s]\u001b[A\n",
      "Average Metric: 209 / 526  (39.7):  26%|       | 526/2000 [06:40<16:26,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 209 / 527  (39.7):  26%|       | 526/2000 [06:41<16:26,  1.49it/s]\u001b[A\n",
      "Average Metric: 209 / 527  (39.7):  26%|       | 527/2000 [06:41<21:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 210 / 528  (39.8):  26%|       | 527/2000 [06:41<21:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 210 / 528  (39.8):  26%|       | 528/2000 [06:41<18:04,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ciolears' to form the correct word. A: rapidly B: kurt C: correctly D: calories\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 529  (39.9):  26%|       | 528/2000 [06:42<18:04,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 529  (39.9):  26%|       | 529/2000 [06:42<18:03,  1.36it/s]\u001b[A\n",
      "Average Metric: 211 / 530  (39.8):  26%|       | 529/2000 [06:42<18:03,  1.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tkcurs'. A: condo B: trucks C: establishments D: advertisers\n",
      "Answer: C: establishments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aoinnto'. A: physician B: interval C: antonio D: unable\n",
      "Answer: D: unable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stonloius'. A: italicized B: problem C: solutions D: dairy\n",
      "Answer: C: solutions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'yuong' to form the correct word. A: peters B: different C: human D: young\n",
      "Answer: yuong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bstaowna' to form the correct word. A: botswana B: files C: fifth D: oncology\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tnraxasesul'? A: judy B: accent C: shipments D: transsexual\n",
      "Answer: B: accent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 531  (39.7):  26%|       | 530/2000 [06:46<18:02,  1.36it/s]\u001b[A\n",
      "Average Metric: 211 / 531  (39.7):  27%|       | 531/2000 [06:46<31:16,  1.28s/it]\u001b[A\n",
      "Average Metric: 211 / 532  (39.7):  27%|       | 531/2000 [06:47<31:16,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 211 / 532  (39.7):  27%|       | 532/2000 [06:47<27:54,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 533  (39.8):  27%|       | 532/2000 [06:47<27:54,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 533  (39.8):  27%|       | 533/2000 [06:47<22:16,  1.10it/s]\u001b[A\n",
      "Average Metric: 212 / 534  (39.7):  27%|       | 533/2000 [06:47<22:16,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'irtno' to form the correct word. A: comfort B: oxide C: manufacturing D: intro\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pgae'. A: ignored B: page C: attach D: conservative\n",
      "Answer: C: attach\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'celtuurs' represent when unscrambled? A: ringtones B: cultures C: pics D: lender\n",
      "Answer: C: pics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 213 / 535  (39.8):  27%|       | 534/2000 [06:48<22:15,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 213 / 535  (39.8):  27%|       | 535/2000 [06:48<17:27,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 214 / 536  (39.9):  27%|       | 535/2000 [06:48<17:27,  1.40it/s]\u001b[A\n",
      "Average Metric: 214 / 536  (39.9):  27%|       | 536/2000 [06:48<14:25,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dsisopal' to form the correct word. A: tucker B: suspension C: disposal D: ebooks\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ieirethnd'. A: predictions B: inherited C: decreased D: acdbentity\n",
      "Answer: D: acdbentity\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'paaleinrmt'? A: competence B: parliament C: analyze D: signature\n",
      "Answer: C: analyze\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rageloutr'. A: regulator B: console C: nursing D: croatia\n",
      "Answer: A: regulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bciabill'. A: piece B: real C: biblical D: switch\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 214 / 537  (39.9):  27%|       | 536/2000 [06:51<14:25,  1.69it/s]\u001b[A\n",
      "Average Metric: 214 / 537  (39.9):  27%|       | 537/2000 [06:51<27:04,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 538  (40.0):  27%|       | 537/2000 [06:51<27:04,  1.11s/it]\u001b[A\n",
      "Average Metric: 215 / 538  (40.0):  27%|       | 538/2000 [06:51<24:20,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stituaions'. A: situations B: xerox C: fossil D: harm\n",
      "Answer: A: situations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hgih'? A: atomic B: high C: screen D: scottish\n",
      "Answer: A: atomic\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'invetneics' represent when unscrambled? A: fans B: incentives C: wyoming D: haiti\n",
      "Answer: B: incentives\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'frarems' represent when unscrambled? A: diaries B: seeds C: farmers D: exempt\n",
      "Answer: D: exempt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 216 / 539  (40.1):  27%|       | 538/2000 [06:52<24:20,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 216 / 539  (40.1):  27%|       | 539/2000 [06:52<24:22,  1.00s/it]\u001b[A\n",
      "Average Metric: 217 / 540  (40.2):  27%|       | 539/2000 [06:53<24:22,  1.00s/it]\u001b[A\n",
      "Average Metric: 218 / 541  (40.3):  27%|       | 540/2000 [06:53<24:21,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 218 / 541  (40.3):  27%|       | 541/2000 [06:53<16:35,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'upicnmog' to form the correct word. A: looks B: existing C: wool D: upcoming\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'psotage'? A: tactics B: postage C: smoking D: concrete\n",
      "Answer: B: postage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eelticitrcy' represent when unscrambled? A: electricity B: posted C: trivia D: article\n",
      "Answer: A: electricity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 218 / 542  (40.2):  27%|       | 541/2000 [06:58<16:35,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 218 / 542  (40.2):  27%|       | 542/2000 [06:58<39:00,  1.60s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 218 / 543  (40.1):  27%|       | 542/2000 [06:58<39:00,  1.60s/it]\u001b[A\n",
      "Average Metric: 218 / 543  (40.1):  27%|       | 543/2000 [06:58<30:55,  1.27s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 219 / 544  (40.3):  27%|       | 543/2000 [06:58<30:55,  1.27s/it]\u001b[A\n",
      "Average Metric: 219 / 544  (40.3):  27%|       | 544/2000 [06:58<24:33,  1.01s/it]\u001b[A\n",
      "Average Metric: 219 / 545  (40.2):  27%|       | 544/2000 [06:58<24:33,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pyelad' to form the correct word. A: played B: warrant C: perfume D: worldwide\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 546  (40.3):  27%|       | 545/2000 [07:00<24:32,  1.01s/it]\u001b[A\n",
      "Average Metric: 220 / 546  (40.3):  27%|       | 546/2000 [07:00<21:11,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 547  (40.2):  27%|       | 546/2000 [07:00<21:11,  1.14it/s]\u001b[A\n",
      "Average Metric: 220 / 547  (40.2):  27%|       | 547/2000 [07:00<17:20,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 221 / 548  (40.3):  27%|       | 547/2000 [07:00<17:20,  1.40it/s]\u001b[A\n",
      "Average Metric: 221 / 548  (40.3):  27%|       | 548/2000 [07:00<14:32,  1.66it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 221 / 549  (40.3):  27%|       | 548/2000 [07:00<14:32,  1.66it/s]\u001b[A\n",
      "Average Metric: 221 / 549  (40.3):  27%|       | 549/2000 [07:00<13:34,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ltitle'. A: little B: tobacco C: martha D: investigate\n",
      "Answer: A: little\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 550  (40.4):  27%|       | 549/2000 [07:02<13:34,  1.78it/s]\u001b[A\n",
      "Average Metric: 222 / 550  (40.4):  28%|       | 550/2000 [07:02<19:35,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pcaks' represent when unscrambled? A: ordinance B: packs C: come D: sleep\n",
      "Answer: A: ordinance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 551  (40.3):  28%|       | 550/2000 [07:04<19:35,  1.23it/s]\u001b[A\n",
      "Average Metric: 222 / 551  (40.3):  28%|       | 551/2000 [07:04<27:33,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 223 / 552  (40.4):  28%|       | 551/2000 [07:04<27:33,  1.14s/it]\u001b[A\n",
      "Average Metric: 223 / 552  (40.4):  28%|       | 552/2000 [07:04<21:14,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 553  (40.5):  28%|       | 552/2000 [07:05<21:14,  1.14it/s]\u001b[A\n",
      "Average Metric: 224 / 553  (40.5):  28%|       | 553/2000 [07:05<20:19,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ktnneeh' represent when unscrambled? A: downs B: connection C: kenneth D: pages\n",
      "Answer: D: pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 224 / 554  (40.4):  28%|       | 553/2000 [07:05<20:19,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 224 / 554  (40.4):  28%|       | 554/2000 [07:05<17:36,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 225 / 555  (40.5):  28%|       | 554/2000 [07:06<17:36,  1.37it/s]\u001b[A\n",
      "Average Metric: 225 / 555  (40.5):  28%|       | 555/2000 [07:06<18:59,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gorw'? A: grow B: press C: understanding D: renaissance\n",
      "Answer: A: grow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 226 / 556  (40.6):  28%|       | 555/2000 [07:08<18:59,  1.27it/s]\u001b[A\n",
      "Average Metric: 226 / 556  (40.6):  28%|       | 556/2000 [07:08<25:21,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wlak' represent when unscrambled? A: camera B: walk C: hart D: scanning\n",
      "Answer: A: camera\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'idneed' to form the correct word. A: consumption B: indeed C: admission D: hard\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 227 / 557  (40.8):  28%|       | 556/2000 [07:09<25:21,  1.05s/it]\u001b[A\n",
      "Average Metric: 227 / 557  (40.8):  28%|       | 557/2000 [07:09<22:20,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 558  (40.9):  28%|       | 557/2000 [07:10<22:20,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 558  (40.9):  28%|       | 558/2000 [07:10<25:22,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'renoindpsg' represent when unscrambled? A: gang B: torque C: responding D: clark\n",
      "Answer: D: clark\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seem'. A: plates B: suse C: viagra D: seem\n",
      "Answer: D: seem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'baem' to form the correct word. A: beam B: seeds C: webmasters D: easily\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 559  (41.0):  28%|       | 558/2000 [07:11<25:22,  1.06s/it]\u001b[A\n",
      "Average Metric: 229 / 559  (41.0):  28%|       | 559/2000 [07:11<26:19,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'jfef'? A: jeff B: mystery C: houses D: member\n",
      "Answer: B: mystery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 229 / 560  (40.9):  28%|       | 559/2000 [07:11<26:19,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 560  (40.9):  28%|       | 560/2000 [07:11<19:25,  1.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cionuyrsdte'. A: countryside B: derek C: weapons D: choice\n",
      "Answer: D: choice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 561  (41.0):  28%|       | 560/2000 [07:13<19:25,  1.24it/s]\u001b[A\n",
      "Average Metric: 230 / 561  (41.0):  28%|       | 561/2000 [07:13<28:40,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 231 / 562  (41.1):  28%|       | 561/2000 [07:14<28:40,  1.20s/it]\u001b[A\n",
      "Average Metric: 231 / 562  (41.1):  28%|       | 562/2000 [07:14<25:27,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rnfirreeg' represent when unscrambled? A: talked B: elections C: referring D: consolidation\n",
      "Answer: D: consolidation\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'igtirmmioan' to form the correct word. A: immigration B: translator C: parts D: searching\n",
      "Answer: D: searching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vurses'? A: chances B: versus C: writing D: sonic\n",
      "Answer: B: versus\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'recejt'? A: extremely B: smile C: reject D: know\n",
      "Answer: D: know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 232 / 563  (41.2):  28%|       | 562/2000 [07:15<25:27,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 232 / 563  (41.2):  28%|       | 563/2000 [07:15<25:09,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 233 / 564  (41.3):  28%|       | 563/2000 [07:15<25:09,  1.05s/it]\u001b[A\n",
      "Average Metric: 233 / 564  (41.3):  28%|       | 564/2000 [07:15<19:15,  1.24it/s]\u001b[A\n",
      "Average Metric: 233 / 565  (41.2):  28%|       | 564/2000 [07:15<19:15,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 566  (41.3):  28%|       | 565/2000 [07:16<19:14,  1.24it/s]\u001b[A\n",
      "Average Metric: 234 / 566  (41.3):  28%|       | 566/2000 [07:16<12:24,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 234 / 567  (41.3):  28%|       | 566/2000 [07:16<12:24,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 234 / 567  (41.3):  28%|       | 567/2000 [07:16<12:15,  1.95it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 235 / 568  (41.4):  28%|       | 567/2000 [07:17<12:15,  1.95it/s]\u001b[A\n",
      "Average Metric: 235 / 568  (41.4):  28%|       | 568/2000 [07:17<11:35,  2.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 569  (41.5):  28%|       | 568/2000 [07:17<11:35,  2.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 236 / 569  (41.5):  28%|       | 569/2000 [07:17<10:05,  2.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'utileizd'. A: utilized B: poetry C: preserved D: timber\n",
      "Answer: D: timber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'thuhen' represent when unscrambled? A: barton B: thehun C: teddy D: trend\n",
      "Answer: B: thehun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'poirfts'? A: existing B: portal C: samoa D: profits\n",
      "Answer: D: profits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'clirhae'. A: applying B: earliest C: natural D: charlie\n",
      "Answer: D: charlie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ataeoumtd'. A: automated B: improves C: major D: gregory\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 236 / 570  (41.4):  28%|       | 569/2000 [07:20<10:05,  2.36it/s]\u001b[A\n",
      "Average Metric: 236 / 570  (41.4):  28%|       | 570/2000 [07:20<25:03,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fdees'. A: will B: clouds C: organic D: feeds\n",
      "Answer: D: feeds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 237 / 571  (41.5):  28%|       | 570/2000 [07:21<25:03,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 237 / 571  (41.5):  29%|       | 571/2000 [07:21<26:47,  1.13s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 572  (41.4):  29%|       | 571/2000 [07:21<26:47,  1.13s/it]\u001b[A\n",
      "Average Metric: 237 / 572  (41.4):  29%|       | 572/2000 [07:21<21:02,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 573  (41.5):  29%|       | 572/2000 [07:21<21:02,  1.13it/s]\u001b[A\n",
      "Average Metric: 238 / 573  (41.5):  29%|       | 573/2000 [07:21<16:45,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 574  (41.5):  29%|       | 573/2000 [07:23<16:45,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mredchisnae' to form the correct word. A: warehouse B: baseball C: treating D: merchandise\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 238 / 574  (41.5):  29%|       | 574/2000 [07:23<20:12,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 239 / 575  (41.6):  29%|       | 574/2000 [07:23<20:12,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 239 / 575  (41.6):  29%|       | 575/2000 [07:23<15:33,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uiiotliztan'? A: utilization B: engineer C: bundle D: investigating\n",
      "Answer: D: investigating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t Socket operation on non-socket"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 239 / 576  (41.5):  29%|       | 575/2000 [07:25<15:33,  1.53it/s]\u001b[A\n",
      "Average Metric: 239 / 576  (41.5):  29%|       | 576/2000 [07:25<25:47,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 577  (41.6):  29%|       | 576/2000 [07:26<25:47,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mcoadanld' to form the correct word. A: administrator B: macdonald C: chan D: arising\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 240 / 577  (41.6):  29%|       | 577/2000 [07:26<24:52,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 578  (41.5):  29%|       | 577/2000 [07:27<24:52,  1.05s/it]\u001b[A\n",
      "Average Metric: 240 / 578  (41.5):  29%|       | 578/2000 [07:27<22:32,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 579  (41.5):  29%|       | 578/2000 [07:27<22:32,  1.05it/s]\u001b[A\n",
      "Average Metric: 240 / 579  (41.5):  29%|       | 579/2000 [07:27<17:52,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'whrieen'. A: worldwide B: joined C: wherein D: honeymoon\n",
      "Answer: D: honeymoon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 241 / 580  (41.6):  29%|       | 579/2000 [07:28<17:52,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 241 / 580  (41.6):  29%|       | 580/2000 [07:28<19:38,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'stnkaig'? A: skating B: treating C: trauma D: lambda\n",
      "Answer: skating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 242 / 581  (41.7):  29%|       | 580/2000 [07:28<19:38,  1.20it/s]\u001b[A\n",
      "Average Metric: 242 / 581  (41.7):  29%|       | 581/2000 [07:28<17:17,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 242 / 582  (41.6):  29%|       | 581/2000 [07:30<17:17,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 242 / 582  (41.6):  29%|       | 582/2000 [07:30<19:42,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cazry'. A: oncology B: crazy C: identity D: bounce\n",
      "Answer: D: bounce\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'uoeypnmlnmet' to form the correct word. A: response B: grounds C: pounds D: unemployment\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'orrpetaos'. A: authentication B: operators C: monaco D: seychelles\n",
      "Answer: D: seychelles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 242 / 583  (41.5):  29%|       | 582/2000 [07:31<19:42,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 242 / 583  (41.5):  29%|       | 583/2000 [07:31<25:13,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cchuk' represent when unscrambled? A: consequences B: chuck C: bnet D: leeds\n",
      "Answer: B: chuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 242 / 584  (41.4):  29%|       | 583/2000 [07:32<25:13,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 242 / 584  (41.4):  29%|       | 584/2000 [07:32<20:28,  1.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'naitoton'? A: embrace B: appeared C: notation D: minority\n",
      "Answer: D: minority\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'beaclrets'? A: auction B: bracelets C: bailey D: macedonia\n",
      "Answer: B: bracelets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'iidnan' represent when unscrambled? A: sale B: indian C: darkness D: stakeholders\n",
      "Answer: A: sale\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cemina'. A: cinema B: proceedings C: jewellery D: seattle\n",
      "Answer: A: cinema\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cemabhr'. A: medicaid B: cylinder C: chamber D: massage\n",
      "Answer: C: chamber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cehm'? A: chem B: steven C: checkout D: player\n",
      "Answer: B: steven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 243 / 585  (41.5):  29%|       | 584/2000 [07:35<20:28,  1.15it/s]\u001b[A\n",
      "Average Metric: 243 / 585  (41.5):  29%|       | 585/2000 [07:35<37:33,  1.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pllos'? A: distributed B: minds C: sealed D: polls\n",
      "Answer: D: polls\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Earth B: Mars C: Jupiter D: Venus\n",
      "Answer: C: Jupiter\n",
      "\n",
      "Question: What is the smallest country in the world? A: China B: Japan C: Monaco D: Vatican City\n",
      "Answer: D: Vatican City\n",
      "\n",
      "Question: What is the highest mountain in the world? A: Mount Everest B: Kangchenjunga C: K2 D: Lhotse\n",
      "Answer: A:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 244 / 586  (41.6):  29%|       | 585/2000 [07:35<37:33,  1.59s/it]\u001b[A\n",
      "Average Metric: 244 / 586  (41.6):  29%|       | 586/2000 [07:35<30:36,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 587  (41.7):  29%|       | 586/2000 [07:36<30:36,  1.30s/it]\u001b[A\n",
      "Average Metric: 245 / 587  (41.7):  29%|       | 587/2000 [07:36<27:11,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mzada'. A: aids B: literally C: mazda D: planets\n",
      "Answer: aids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'siwm' represent when unscrambled? A: ports B: swim C: traveller D: bargains\n",
      "Answer: B: swim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 588  (41.8):  29%|       | 587/2000 [07:38<27:11,  1.15s/it]\u001b[A\n",
      "Average Metric: 246 / 588  (41.8):  29%|       | 588/2000 [07:38<31:09,  1.32s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 589  (41.8):  29%|       | 588/2000 [07:38<31:09,  1.32s/it]\u001b[A\n",
      "Average Metric: 246 / 589  (41.8):  29%|       | 589/2000 [07:38<24:09,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cllosey' represent when unscrambled? A: closely B: prospective C: requiring D: coastal\n",
      "Answer: A: closely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 247 / 590  (41.9):  29%|       | 589/2000 [07:39<24:09,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 247 / 590  (41.9):  30%|       | 590/2000 [07:39<22:46,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'riceiootgnn' to form the correct word. A: creek B: recognition C: employers D: systems\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 591  (42.0):  30%|       | 590/2000 [07:39<22:46,  1.03it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 591  (42.0):  30%|       | 591/2000 [07:39<16:45,  1.40it/s]\u001b[A\n",
      "Average Metric: 248 / 592  (41.9):  30%|       | 591/2000 [07:39<16:45,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cmonuopd'. A: pregnancy B: pointed C: compound D: punch\n",
      "Answer: D: punch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 249 / 593  (42.0):  30%|       | 592/2000 [07:40<16:44,  1.40it/s]\u001b[A\n",
      "Average Metric: 249 / 593  (42.0):  30%|       | 593/2000 [07:40<11:05,  2.11it/s]\u001b[A\n",
      "Average Metric: 250 / 594  (42.1):  30%|       | 593/2000 [07:40<11:05,  2.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 595  (42.2):  30%|       | 594/2000 [07:40<11:05,  2.11it/s]\u001b[A\n",
      "Average Metric: 251 / 595  (42.2):  30%|       | 595/2000 [07:40<07:25,  3.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 251 / 596  (42.1):  30%|       | 595/2000 [07:41<07:25,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 251 / 596  (42.1):  30%|       | 596/2000 [07:41<12:14,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'riillateiby'. A: jean B: foto C: reliability D: people\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 597  (42.0):  30%|       | 596/2000 [07:42<12:14,  1.91it/s]\u001b[A\n",
      "Average Metric: 251 / 597  (42.0):  30%|       | 597/2000 [07:42<15:40,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gilud'? A: guild B: utilizing C: behaviour D: frame\n",
      "Answer: D: frame\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iuecnldd'? A: included B: failed C: tribe D: attempted\n",
      "Answer: D: attempted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 252 / 598  (42.1):  30%|       | 597/2000 [07:43<15:40,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 252 / 598  (42.1):  30%|       | 598/2000 [07:43<19:16,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sinprtog'. A: family B: queue C: operator D: sporting\n",
      "Answer: D: sporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 252 / 599  (42.1):  30%|       | 598/2000 [07:44<19:16,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 252 / 599  (42.1):  30%|       | 599/2000 [07:44<16:29,  1.42it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 252 / 600  (42.0):  30%|       | 599/2000 [07:44<16:29,  1.42it/s]\u001b[A\n",
      "Average Metric: 252 / 600  (42.0):  30%|       | 600/2000 [07:44<15:28,  1.51it/s]\u001b[A\n",
      "Average Metric: 252 / 601  (41.9):  30%|       | 600/2000 [07:44<15:28,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 252 / 602  (41.9):  30%|       | 601/2000 [07:45<15:27,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 252 / 602  (41.9):  30%|       | 602/2000 [07:45<09:57,  2.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cltobliooaarn'. A: collaboration B: hits C: photography D: idol\n",
      "Answer: C: photography\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 252 / 603  (41.8):  30%|       | 602/2000 [07:46<09:57,  2.34it/s]\u001b[A\n",
      "Average Metric: 252 / 603  (41.8):  30%|       | 603/2000 [07:46<14:40,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 253 / 604  (41.9):  30%|       | 603/2000 [07:46<14:40,  1.59it/s]\u001b[A\n",
      "Average Metric: 253 / 604  (41.9):  30%|       | 604/2000 [07:46<11:48,  1.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ltgiehr'. A: lighter B: fighters C: plus D: monkey\n",
      "Answer: C: plus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'caelrncae'. A: scattered B: trout C: clearance D: switched\n",
      "Answer: C: clearance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 253 / 605  (41.8):  30%|       | 604/2000 [07:48<11:48,  1.97it/s]\u001b[A\n",
      "Average Metric: 253 / 605  (41.8):  30%|       | 605/2000 [07:48<20:53,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'variga' to form the correct word. A: washer B: viagra C: anywhere D: wearing\n",
      "Answer: D: wearing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 253 / 606  (41.7):  30%|       | 605/2000 [07:49<20:53,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 253 / 606  (41.7):  30%|       | 606/2000 [07:49<23:27,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sopke'. A: spoke B: addressed C: sans D: monitored\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 254 / 607  (41.8):  30%|       | 606/2000 [07:50<23:27,  1.01s/it]\u001b[A\n",
      "Average Metric: 254 / 607  (41.8):  30%|       | 607/2000 [07:50<22:33,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dseaiclmir' to form the correct word. A: crazy B: disclaimer C: helping D: sharp\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 608  (41.9):  30%|       | 607/2000 [07:51<22:33,  1.03it/s]\u001b[A\n",
      "Average Metric: 255 / 608  (41.9):  30%|       | 608/2000 [07:51<21:27,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 609  (41.9):  30%|       | 608/2000 [07:51<21:27,  1.08it/s]\u001b[A\n",
      "Average Metric: 255 / 609  (41.9):  30%|       | 609/2000 [07:51<16:46,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 610  (42.0):  30%|       | 609/2000 [07:51<16:46,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 611  (42.1):  30%|       | 610/2000 [07:52<16:45,  1.38it/s]\u001b[A\n",
      "Average Metric: 257 / 611  (42.1):  31%|       | 611/2000 [07:52<13:52,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mnes'. A: functional B: subject C: mens D: dioxide\n",
      "Answer: A: functional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'vsita' to form the correct word. A: americans B: supervisor C: theorem D: vista\n",
      "Answer: D: vista\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 612  (42.0):  31%|       | 611/2000 [07:55<13:52,  1.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aeeatnrmnrgs'. A: electricity B: gravity C: wonderful D: arrangements\n",
      "Answer: D: arrangements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 257 / 612  (42.0):  31%|       | 612/2000 [07:55<27:35,  1.19s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 613  (41.9):  31%|       | 612/2000 [07:55<27:35,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eiqbuliurim' represent when unscrambled? A: passed B: finances C: month D: equilibrium\n",
      "Answer: D: equilibrium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 614  (41.9):  31%|       | 613/2000 [07:56<27:34,  1.19s/it]\u001b[A\n",
      "Average Metric: 257 / 614  (41.9):  31%|       | 614/2000 [07:56<18:20,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oanrngozaatiil'. A: deposit B: meyer C: organizational D: intervention\n",
      "Answer: D: intervention\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'nrom'. A: podcasts B: fears C: holder D: norm\n",
      "Answer: D: norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'reenottin' represent when unscrambled? A: frontpage B: incentive C: memorandum D: retention\n",
      "Answer: A: frontpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ance'. A: jacob B: acne C: units D: encourage\n",
      "Answer: D: encourage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lokoing'. A: determines B: looking C: concepts D: guided\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'saald' represent when unscrambled? A: salad B: myanmar C: helicopter D: charming\n",
      "Answer: A: salad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'raaoitidn'? A: albuquerque B: road C: actual D: radiation\n",
      "Answer: D: radiation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 615  (41.8):  31%|       | 614/2000 [08:01<18:20,  1.26it/s]\u001b[A\n",
      "Average Metric: 257 / 615  (41.8):  31%|       | 615/2000 [08:01<39:59,  1.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 616  (41.7):  31%|       | 615/2000 [08:02<39:59,  1.73s/it]\u001b[A\n",
      "Average Metric: 257 / 616  (41.7):  31%|       | 616/2000 [08:02<35:56,  1.56s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 617  (41.8):  31%|       | 616/2000 [08:02<35:56,  1.56s/it]\u001b[A\n",
      "Average Metric: 258 / 617  (41.8):  31%|       | 617/2000 [08:02<27:33,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 618  (41.7):  31%|       | 617/2000 [08:02<27:33,  1.20s/it]\u001b[A\n",
      "Average Metric: 258 / 618  (41.7):  31%|       | 618/2000 [08:02<21:17,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lruael'. A: laurel B: wonderful C: theorem D: promotion\n",
      "Answer: D: promotion\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'notgaetie'. A: graphs B: introduces C: negotiate D: lost\n",
      "Answer: D: lost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 619  (41.7):  31%|       | 618/2000 [08:03<21:17,  1.08it/s]\u001b[A\n",
      "Average Metric: 258 / 619  (41.7):  31%|       | 619/2000 [08:03<19:42,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 620  (41.6):  31%|       | 619/2000 [08:03<19:42,  1.17it/s]\u001b[A\n",
      "Average Metric: 258 / 620  (41.6):  31%|       | 620/2000 [08:03<15:27,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 621  (41.5):  31%|       | 620/2000 [08:03<15:27,  1.49it/s]\u001b[A\n",
      "Average Metric: 258 / 621  (41.5):  31%|       | 621/2000 [08:03<13:23,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 622  (41.5):  31%|       | 621/2000 [08:04<13:23,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 622  (41.5):  31%|       | 622/2000 [08:04<13:12,  1.74it/s]\u001b[A\n",
      "Average Metric: 259 / 623  (41.6):  31%|       | 622/2000 [08:04<13:12,  1.74it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 624  (41.7):  31%|       | 623/2000 [08:04<13:11,  1.74it/s]\u001b[A\n",
      "Average Metric: 260 / 624  (41.7):  31%|       | 624/2000 [08:04<10:26,  2.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 625  (41.6):  31%|       | 624/2000 [08:05<10:26,  2.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 260 / 625  (41.6):  31%|      | 625/2000 [08:05<11:29,  1.99it/s]\u001b[A\n",
      "Average Metric: 260 / 626  (41.5):  31%|      | 625/2000 [08:05<11:29,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 260 / 626  (41.5):  31%|      | 626/2000 [08:05<09:13,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lvnoig' to form the correct word. A: loving B: clients C: tape D: backyard\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'smhopnyy'? A: symphony B: mistake C: helped D: periods\n",
      "Answer: B: mistake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'turhogh'? A: applying B: becomes C: concentrate D: through\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fvie' represent when unscrambled? A: robertson B: springer C: individually D: five\n",
      "Answer: D: five\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 260 / 627  (41.5):  31%|      | 626/2000 [08:07<09:13,  2.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 260 / 627  (41.5):  31%|      | 627/2000 [08:07<17:20,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 628  (41.6):  31%|      | 627/2000 [08:07<17:20,  1.32it/s]\u001b[A\n",
      "Average Metric: 261 / 628  (41.6):  31%|      | 628/2000 [08:07<13:55,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 261 / 629  (41.5):  31%|      | 628/2000 [08:08<13:55,  1.64it/s]\u001b[A\n",
      "Average Metric: 261 / 629  (41.5):  31%|      | 629/2000 [08:08<14:47,  1.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 630  (41.4):  31%|      | 629/2000 [08:08<14:47,  1.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'jonhs'. A: tone B: johns C: observer D: rent\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 261 / 630  (41.4):  32%|      | 630/2000 [08:08<12:57,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 631  (41.4):  32%|      | 630/2000 [08:09<12:57,  1.76it/s]\u001b[A\n",
      "Average Metric: 261 / 631  (41.4):  32%|      | 631/2000 [08:09<16:25,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 632  (41.5):  32%|      | 631/2000 [08:11<16:25,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 262 / 632  (41.5):  32%|      | 632/2000 [08:11<24:20,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'somesert'. A: foster B: hung C: somerset D: blonde\n",
      "Answer: C: somerset\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ltian'. A: hardy B: cheaper C: latin D: asylum\n",
      "Answer: A: hardy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'psuae'. A: pause B: files C: justin D: this\n",
      "Answer: A: pause\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fitlncaoituny'. A: wrestling B: gourmet C: bother D: functionality\n",
      "Answer: D: functionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 633  (41.5):  32%|      | 632/2000 [08:13<24:20,  1.07s/it]\u001b[A\n",
      "Average Metric: 263 / 633  (41.5):  32%|      | 633/2000 [08:13<28:41,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 634  (41.5):  32%|      | 633/2000 [08:13<28:41,  1.26s/it]\u001b[A\n",
      "Average Metric: 263 / 634  (41.5):  32%|      | 634/2000 [08:13<21:04,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 635  (41.4):  32%|      | 634/2000 [08:13<21:04,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 636  (41.4):  32%|      | 635/2000 [08:13<21:03,  1.08it/s]\u001b[A\n",
      "Average Metric: 263 / 636  (41.4):  32%|      | 636/2000 [08:13<12:48,  1.78it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 637  (41.4):  32%|      | 636/2000 [08:13<12:48,  1.78it/s]\u001b[A\n",
      "Average Metric: 264 / 637  (41.4):  32%|      | 637/2000 [08:13<10:26,  2.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 265 / 638  (41.5):  32%|      | 637/2000 [08:14<10:26,  2.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 265 / 638  (41.5):  32%|      | 638/2000 [08:14<12:25,  1.83it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 265 / 639  (41.5):  32%|      | 638/2000 [08:14<12:25,  1.83it/s]\u001b[A\n",
      "Average Metric: 265 / 639  (41.5):  32%|      | 639/2000 [08:15<10:36,  2.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'essricon'. A: governing B: ericsson C: pokemon D: wonders\n",
      "Answer: D: wonders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 266 / 640  (41.6):  32%|      | 639/2000 [08:15<10:36,  2.14it/s]\u001b[A\n",
      "Average Metric: 266 / 640  (41.6):  32%|      | 640/2000 [08:15<10:49,  2.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anocmpianycg'. A: grades B: cost C: absolutely D: accompanying\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 641  (41.5):  32%|      | 640/2000 [08:18<10:49,  2.09it/s]\u001b[A\n",
      "Average Metric: 266 / 641  (41.5):  32%|      | 641/2000 [08:18<26:24,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 642  (41.6):  32%|      | 641/2000 [08:19<26:24,  1.17s/it]\u001b[A\n",
      "Average Metric: 267 / 642  (41.6):  32%|      | 642/2000 [08:19<24:15,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'daefet'. A: frances B: barriers C: defeat D: stereo\n",
      "Answer: D: stereo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'msikate'. A: partly B: mistake C: king D: fundamental\n",
      "Answer: B: mistake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 643  (41.5):  32%|      | 642/2000 [08:20<24:15,  1.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wfie'. A: develops B: wife C: nevis D: addresses\n",
      "Answer: D: addresses\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pdcinruog' to form the correct word. A: private B: producing C: christmas D: postcard\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 267 / 643  (41.5):  32%|      | 643/2000 [08:20<24:22,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'drceibse' represent when unscrambled? A: describe B: beauty C: travel D: expressions\n",
      "Answer: D: expressions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 267 / 644  (41.5):  32%|      | 643/2000 [08:21<24:22,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 267 / 644  (41.5):  32%|      | 644/2000 [08:21<23:34,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'isnriatgotves'. A: expertise B: investigators C: bacteria D: suzuki\n",
      "Answer: D: suzuki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lokos'? A: looks B: ongoing C: suggesting D: nearest\n",
      "Answer: D: nearest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'gleeilrnve'. A: greenville B: investigating C: staying D: magazines\n",
      "Answer: D: magazines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 645  (41.4):  32%|      | 644/2000 [08:23<23:34,  1.04s/it]\u001b[A\n",
      "Average Metric: 267 / 645  (41.4):  32%|      | 645/2000 [08:23<29:40,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 268 / 646  (41.5):  32%|      | 645/2000 [08:24<29:40,  1.31s/it]\u001b[A\n",
      "Average Metric: 268 / 646  (41.5):  32%|      | 646/2000 [08:24<26:09,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eslxcivue' represent when unscrambled? A: thin B: exclusive C: examples D: baseball\n",
      "Answer: B: exclusive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'haytt'. A: hyatt B: sides C: narrow D: tobago\n",
      "Answer: D: tobago\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sitnegts'. A: continent B: shawn C: settings D: cracks\n",
      "Answer: D: cracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 269 / 647  (41.6):  32%|      | 646/2000 [08:24<26:09,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 269 / 647  (41.6):  32%|      | 647/2000 [08:24<23:34,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 270 / 648  (41.7):  32%|      | 647/2000 [08:25<23:34,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 270 / 648  (41.7):  32%|      | 648/2000 [08:25<20:09,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 649  (41.6):  32%|      | 648/2000 [08:25<20:09,  1.12it/s]\u001b[A\n",
      "Average Metric: 270 / 649  (41.6):  32%|      | 649/2000 [08:25<16:20,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fornute'. A: every B: email C: intake D: fortune\n",
      "Answer: D: fortune\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 650  (41.7):  32%|      | 649/2000 [08:26<16:20,  1.38it/s]\u001b[A\n",
      "Average Metric: 271 / 650  (41.7):  32%|      | 650/2000 [08:26<19:53,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 651  (41.6):  32%|      | 650/2000 [08:28<19:53,  1.13it/s]\u001b[A\n",
      "Average Metric: 271 / 651  (41.6):  33%|      | 651/2000 [08:28<22:20,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 272 / 652  (41.7):  33%|      | 651/2000 [08:28<22:20,  1.01it/s]\u001b[A\n",
      "Average Metric: 272 / 652  (41.7):  33%|      | 652/2000 [08:28<17:52,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'osioppte'. A: controlled B: retro C: costumes D: opposite\n",
      "Answer: D: opposite\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'adreawd'. A: progress B: florist C: awarded D: branch\n",
      "Answer: D: branch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 653  (41.8):  33%|      | 652/2000 [08:30<17:52,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 653  (41.8):  33%|      | 653/2000 [08:30<24:37,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 654  (41.7):  33%|      | 653/2000 [08:30<24:37,  1.10s/it]\u001b[A\n",
      "Average Metric: 273 / 654  (41.7):  33%|      | 654/2000 [08:30<18:20,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 655  (41.7):  33%|      | 654/2000 [08:30<18:20,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 273 / 655  (41.7):  33%|      | 655/2000 [08:30<15:26,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'noon'. A: prisoners B: noon C: existed D: organizer\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 274 / 656  (41.8):  33%|      | 655/2000 [08:31<15:26,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 656  (41.8):  33%|      | 656/2000 [08:31<13:57,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 657  (41.7):  33%|      | 656/2000 [08:31<13:57,  1.61it/s]\u001b[A\n",
      "Average Metric: 274 / 657  (41.7):  33%|      | 657/2000 [08:31<11:40,  1.92it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'curz'. A: reseller B: nominations C: cruz D: goals\n",
      "Answer: C: cruz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 658  (41.6):  33%|      | 657/2000 [08:32<11:40,  1.92it/s]\u001b[A\n",
      "Average Metric: 274 / 658  (41.6):  33%|      | 658/2000 [08:32<12:45,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 659  (41.6):  33%|      | 658/2000 [08:32<12:45,  1.75it/s]\u001b[A\n",
      "Average Metric: 274 / 659  (41.6):  33%|      | 659/2000 [08:33<13:35,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stcritly'. A: divorce B: page C: strictly D: proceedings\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'faocl' to form the correct word. A: zero B: focal C: chelsea D: overcome\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 660  (41.7):  33%|      | 659/2000 [08:33<13:35,  1.64it/s]\u001b[A\n",
      "Average Metric: 275 / 660  (41.7):  33%|      | 660/2000 [08:33<13:30,  1.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fuard'. A: fraud B: regime C: burst D: formatting\n",
      "Answer: D: formatting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 661  (41.6):  33%|      | 660/2000 [08:35<13:30,  1.65it/s]\u001b[A\n",
      "Average Metric: 275 / 661  (41.6):  33%|      | 661/2000 [08:35<21:39,  1.03it/s]\u001b[A\n",
      "Average Metric: 275 / 662  (41.5):  33%|      | 661/2000 [08:35<21:39,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 275 / 662  (41.5):  33%|      | 662/2000 [08:35<15:55,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'seotrd' represent when unscrambled? A: representation B: duties C: barbados D: stored\n",
      "Answer: B: duties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ctesisnont' to form the correct word. A: headache B: catholic C: consistent D: memo\n",
      "Answer: D: memo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 275 / 663  (41.5):  33%|      | 662/2000 [08:36<15:55,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 275 / 663  (41.5):  33%|      | 663/2000 [08:36<19:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 276 / 664  (41.6):  33%|      | 663/2000 [08:36<19:19,  1.15it/s]\u001b[A\n",
      "Average Metric: 276 / 665  (41.5):  33%|      | 664/2000 [08:36<19:18,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 665  (41.5):  33%|      | 665/2000 [08:36<11:10,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 666  (41.4):  33%|      | 665/2000 [08:38<11:10,  1.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 276 / 666  (41.4):  33%|      | 666/2000 [08:38<15:59,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wras'? A: wars B: loading C: yorkshire D: cards\n",
      "Answer: B: loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 667  (41.4):  33%|      | 666/2000 [08:39<15:59,  1.39it/s]\u001b[A\n",
      "Average Metric: 276 / 667  (41.4):  33%|      | 667/2000 [08:39<16:36,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 277 / 668  (41.5):  33%|      | 667/2000 [08:40<16:36,  1.34it/s]\u001b[A\n",
      "Average Metric: 277 / 668  (41.5):  33%|      | 668/2000 [08:40<19:30,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'clkcis'? A: clicks B: praise C: excess D: your\n",
      "Answer: D: your\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the capital of Spain? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'riavl' represent when unscrambled? A: painful B: deadline C: rival D: developmental\n",
      "Answer: D: developmental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'knog'. A: solve B: abraham C: kong D: representing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 669  (41.4):  33%|      | 668/2000 [08:42<19:30,  1.14it/s]\u001b[A\n",
      "Average Metric: 277 / 669  (41.4):  33%|      | 669/2000 [08:42<29:38,  1.34s/it]\u001b[A\n",
      "Average Metric: 277 / 670  (41.3):  33%|      | 669/2000 [08:43<29:38,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 277 / 670  (41.3):  34%|      | 670/2000 [08:43<23:11,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wcihh'? A: workout B: gamers C: fertility D: which\n",
      "Answer: D: which\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peoprr'. A: strengthen B: considering C: investing D: proper\n",
      "Answer: D: proper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 277 / 671  (41.3):  34%|      | 670/2000 [08:43<23:11,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 671  (41.3):  34%|      | 671/2000 [08:43<19:37,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ptale'. A: plate B: visions C: bounce D: cuts\n",
      "Answer: A: plate\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aomrr' to form the correct word. A: better B: armor C: written D: tragedy\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 672  (41.4):  34%|      | 671/2000 [08:44<19:37,  1.13it/s]\u001b[A\n",
      "Average Metric: 278 / 672  (41.4):  34%|      | 672/2000 [08:44<19:12,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 673  (41.3):  34%|      | 672/2000 [08:44<19:12,  1.15it/s]\u001b[A\n",
      "Average Metric: 278 / 673  (41.3):  34%|      | 673/2000 [08:44<15:55,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'smaimrues' represent when unscrambled? A: packs B: wired C: organizer D: summaries\n",
      "Answer: A: packs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'otpuoiptrny' to form the correct word. A: duration B: opportunity C: forced D: physics\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vitacan' represent when unscrambled? A: copying B: golden C: sender D: vatican\n",
      "Answer: D: vatican\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hstos'. A: complete B: hosts C: extends D: travelling\n",
      "Answer: D: travelling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 279 / 674  (41.4):  34%|      | 673/2000 [08:48<15:55,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 279 / 674  (41.4):  34%|      | 674/2000 [08:48<34:45,  1.57s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 675  (41.5):  34%|      | 674/2000 [08:48<34:45,  1.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 280 / 675  (41.5):  34%|      | 675/2000 [08:48<26:48,  1.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sewedn'. A: accidents B: victim C: mobiles D: sweden\n",
      "Answer: D: sweden\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iearnsce'. A: blogger B: allegations C: disclaimers D: increase\n",
      "Answer: D: increase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 676  (41.4):  34%|      | 675/2000 [08:49<26:48,  1.21s/it]\u001b[A\n",
      "Average Metric: 280 / 676  (41.4):  34%|      | 676/2000 [08:49<22:25,  1.02s/it]\u001b[A\n",
      "Average Metric: 280 / 677  (41.4):  34%|      | 676/2000 [08:49<22:25,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 280 / 677  (41.4):  34%|      | 677/2000 [08:49<16:26,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lokcs'? A: clock B: forth C: paid D: locks\n",
      "Answer: D: locks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 281 / 678  (41.4):  34%|      | 677/2000 [08:49<16:26,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 281 / 678  (41.4):  34%|      | 678/2000 [08:49<13:50,  1.59it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 282 / 679  (41.5):  34%|      | 678/2000 [08:50<13:50,  1.59it/s]\u001b[A\n",
      "Average Metric: 282 / 679  (41.5):  34%|      | 679/2000 [08:50<13:44,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 283 / 680  (41.6):  34%|      | 679/2000 [08:53<13:44,  1.60it/s]\u001b[A\n",
      "Average Metric: 283 / 680  (41.6):  34%|      | 680/2000 [08:53<28:07,  1.28s/it]\u001b[A\n",
      "Average Metric: 284 / 681  (41.7):  34%|      | 680/2000 [08:53<28:07,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 284 / 681  (41.7):  34%|      | 681/2000 [08:53<20:50,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 682  (41.6):  34%|      | 681/2000 [08:53<20:50,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'daen' to form the correct word. A: accommodate B: target C: movie D: dean\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'fniundg'? A: annual B: conducting C: funding D: core\n",
      "Answer: D: core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'meairrd'. A: safely B: carrier C: married D: something\n",
      "Answer: D: something\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'asess'. A: bookstore B: apparatus C: tech D: asses\n",
      "Answer: A: bookstore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 683  (41.6):  34%|      | 682/2000 [08:54<20:49,  1.06it/s]\u001b[A\n",
      "Average Metric: 284 / 683  (41.6):  34%|      | 683/2000 [08:54<15:54,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 684  (41.7):  34%|      | 683/2000 [08:54<15:54,  1.38it/s]\u001b[A\n",
      "Average Metric: 285 / 684  (41.7):  34%|      | 684/2000 [08:54<13:47,  1.59it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 286 / 685  (41.8):  34%|      | 684/2000 [08:54<13:47,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 287 / 686  (41.8):  34%|      | 685/2000 [08:56<13:46,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 287 / 686  (41.8):  34%|      | 686/2000 [08:56<14:30,  1.51it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 687  (41.8):  34%|      | 686/2000 [08:56<14:30,  1.51it/s]\u001b[A\n",
      "Average Metric: 287 / 687  (41.8):  34%|      | 687/2000 [08:56<13:00,  1.68it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pylhslciay'. A: plaintiff B: physically C: symbolic D: scattered\n",
      "Answer: D: scattered\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'anonencud' represent when unscrambled? A: simulated B: meaning C: civil D: announced\n",
      "Answer: D: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 688  (41.7):  34%|      | 687/2000 [08:57<13:00,  1.68it/s]\u001b[A\n",
      "Average Metric: 287 / 688  (41.7):  34%|      | 688/2000 [08:57<15:22,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 288 / 689  (41.8):  34%|      | 688/2000 [08:57<15:22,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 288 / 689  (41.8):  34%|      | 689/2000 [08:57<12:01,  1.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wtineesss'? A: witnesses B: scotland C: voted D: patients\n",
      "Answer: B: scotland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 288 / 690  (41.7):  34%|      | 689/2000 [08:58<12:01,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 288 / 690  (41.7):  34%|      | 690/2000 [08:58<11:13,  1.95it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ganrtaeue'? A: filled B: promoted C: guarantee D: push\n",
      "Answer: D: push\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aatcth' represent when unscrambled? A: tire B: mercury C: owns D: attach\n",
      "Answer: D: attach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 288 / 691  (41.7):  34%|      | 690/2000 [09:00<11:13,  1.95it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 288 / 691  (41.7):  35%|      | 691/2000 [09:00<19:50,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 289 / 692  (41.8):  35%|      | 691/2000 [09:00<19:50,  1.10it/s]\u001b[A\n",
      "Average Metric: 289 / 692  (41.8):  35%|      | 692/2000 [09:00<16:05,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 290 / 693  (41.8):  35%|      | 692/2000 [09:00<16:05,  1.35it/s]\u001b[A\n",
      "Average Metric: 290 / 693  (41.8):  35%|      | 693/2000 [09:00<12:30,  1.74it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 694  (41.9):  35%|      | 693/2000 [09:00<12:30,  1.74it/s]\u001b[A\n",
      "Average Metric: 291 / 694  (41.9):  35%|      | 694/2000 [09:00<10:50,  2.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 695  (41.9):  35%|      | 694/2000 [09:01<10:50,  2.01it/s]\u001b[A\n",
      "Average Metric: 291 / 695  (41.9):  35%|      | 695/2000 [09:01<14:29,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 292 / 696  (42.0):  35%|      | 695/2000 [09:02<14:29,  1.50it/s]\u001b[A\n",
      "Average Metric: 292 / 696  (42.0):  35%|      | 696/2000 [09:02<11:14,  1.93it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 293 / 697  (42.0):  35%|      | 696/2000 [09:03<11:14,  1.93it/s]\u001b[A\n",
      "Average Metric: 293 / 697  (42.0):  35%|      | 697/2000 [09:03<14:15,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 294 / 698  (42.1):  35%|      | 697/2000 [09:04<14:15,  1.52it/s]\u001b[A\n",
      "Average Metric: 294 / 698  (42.1):  35%|      | 698/2000 [09:04<17:58,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rereatt'. A: entertainment B: mcgraw C: centuries D: retreat\n",
      "Answer: D: retreat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'daef'. A: typing B: deaf C: chicken D: besides\n",
      "Answer: D: besides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'silinag' to form the correct word. A: sailing B: banking C: rice D: improving\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 295 / 699  (42.2):  35%|      | 698/2000 [09:05<17:58,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 295 / 699  (42.2):  35%|      | 699/2000 [09:06<23:56,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wdie' to form the correct word. A: giant B: ford C: system D: wide\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 700  (42.1):  35%|      | 699/2000 [09:06<23:56,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mroevs'. A: lease B: movers C: finnish D: router\n",
      "Answer: D: router\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 701  (42.1):  35%|      | 700/2000 [09:07<23:55,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 701  (42.1):  35%|      | 701/2000 [09:07<18:30,  1.17it/s]\u001b[A\n",
      "Average Metric: 295 / 702  (42.0):  35%|      | 701/2000 [09:07<18:30,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'vitnisig'. A: gordon B: eagles C: interests D: visiting\n",
      "Answer: D: visiting\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eixalpns' represent when unscrambled? A: privileges B: distributor C: explains D: preferences\n",
      "Answer: A: privileges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 703  (42.1):  35%|      | 702/2000 [09:08<18:30,  1.17it/s]\u001b[A\n",
      "Average Metric: 296 / 703  (42.1):  35%|      | 703/2000 [09:08<15:01,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mslcue' to form the correct word. A: finds B: forecasts C: muscle D: spacious\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'adtteuits'. A: attitudes B: anthony C: generate D: examine\n",
      "Answer: D: examine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'deicrt'? A: vanity B: satellite C: honor D: direct\n",
      "Answer: D: direct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sapek'? A: amsterdam B: speak C: amanda D: harvey\n",
      "Answer: B: speak\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'veorinss' represent when unscrambled? A: gardens B: expense C: fleet D: versions\n",
      "Answer: D: versions\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sneoor'? A: ranks B: sooner C: burns D: chances\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 704  (42.0):  35%|      | 703/2000 [09:11<15:01,  1.44it/s]\u001b[A\n",
      "Average Metric: 296 / 704  (42.0):  35%|      | 704/2000 [09:11<29:05,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 705  (42.0):  35%|      | 704/2000 [09:12<29:05,  1.35s/it]\u001b[A\n",
      "Average Metric: 296 / 705  (42.0):  35%|      | 705/2000 [09:12<26:15,  1.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 297 / 706  (42.1):  35%|      | 705/2000 [09:12<26:15,  1.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pierton' represent when unscrambled? A: lisa B: protein C: fuels D: torture\n",
      "Answer: A: lisa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aenswr'. A: electrical B: keno C: answer D: violin\n",
      "Answer: C: answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 297 / 707  (42.0):  35%|      | 706/2000 [09:13<26:14,  1.22s/it]\u001b[A\n",
      "Average Metric: 297 / 707  (42.0):  35%|      | 707/2000 [09:13<20:48,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 298 / 708  (42.1):  35%|      | 707/2000 [09:16<20:48,  1.04it/s]\u001b[A\n",
      "Average Metric: 298 / 708  (42.1):  35%|      | 708/2000 [09:16<29:04,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 298 / 709  (42.0):  35%|      | 708/2000 [09:16<29:04,  1.35s/it]\u001b[A\n",
      "Average Metric: 298 / 709  (42.0):  35%|      | 709/2000 [09:16<24:23,  1.13s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 710  (42.1):  35%|      | 709/2000 [09:16<24:23,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 711  (42.1):  36%|      | 710/2000 [09:17<24:21,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 711  (42.1):  36%|      | 711/2000 [09:17<18:54,  1.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'itcesns'. A: tutor B: panic C: insects D: ladyboy\n",
      "Answer: C: insects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 712  (42.0):  36%|      | 711/2000 [09:18<18:54,  1.14it/s]\u001b[A\n",
      "Average Metric: 299 / 712  (42.0):  36%|      | 712/2000 [09:18<16:09,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnsirooutm'? A: jumping B: creation C: common D: consortium\n",
      "Answer: D: consortium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 300 / 713  (42.1):  36%|      | 712/2000 [09:19<16:09,  1.33it/s]\u001b[A\n",
      "Average Metric: 300 / 713  (42.1):  36%|      | 713/2000 [09:19<19:53,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 301 / 714  (42.2):  36%|      | 713/2000 [09:20<19:53,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 301 / 714  (42.2):  36%|      | 714/2000 [09:20<17:28,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oeboctr'. A: october B: walsh C: gang D: discovered\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'stesyms'? A: convention B: feature C: systems D: relax\n",
      "Answer: D: relax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 301 / 715  (42.1):  36%|      | 714/2000 [09:20<17:28,  1.23it/s]\u001b[A\n",
      "Average Metric: 301 / 715  (42.1):  36%|      | 715/2000 [09:20<16:33,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 302 / 716  (42.2):  36%|      | 715/2000 [09:21<16:33,  1.29it/s]\u001b[A\n",
      "Average Metric: 302 / 716  (42.2):  36%|      | 716/2000 [09:21<17:58,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pceturis' to form the correct word. A: webmasters B: pictures C: replication D: race\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 303 / 717  (42.3):  36%|      | 716/2000 [09:23<17:58,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 303 / 717  (42.3):  36%|      | 717/2000 [09:23<24:09,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 304 / 718  (42.3):  36%|      | 717/2000 [09:23<24:09,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ltvirea' represent when unscrambled? A: levitra B: buzz C: trap D: submitted\n",
      "Answer: A: levitra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 719  (42.4):  36%|      | 718/2000 [09:24<24:08,  1.13s/it]\u001b[A\n",
      "Average Metric: 305 / 719  (42.4):  36%|      | 719/2000 [09:24<15:15,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 720  (42.4):  36%|      | 719/2000 [09:24<15:15,  1.40it/s]\u001b[A\n",
      "Average Metric: 305 / 720  (42.4):  36%|      | 720/2000 [09:24<12:16,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'jneesn' to form the correct word. A: hero B: jensen C: waist D: socket\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 721  (42.3):  36%|      | 720/2000 [09:24<12:16,  1.74it/s]\u001b[A\n",
      "Average Metric: 305 / 721  (42.3):  36%|      | 721/2000 [09:24<12:23,  1.72it/s]\u001b[A\n",
      "Average Metric: 305 / 722  (42.2):  36%|      | 721/2000 [09:25<12:23,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 305 / 722  (42.2):  36%|      | 722/2000 [09:25<14:22,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dsrictit' represent when unscrambled? A: sentences B: envelope C: district D: fuels\n",
      "Answer: D: fuels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 305 / 723  (42.2):  36%|      | 722/2000 [09:27<14:22,  1.48it/s]\u001b[A\n",
      "Average Metric: 305 / 723  (42.2):  36%|      | 723/2000 [09:27<20:26,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 306 / 724  (42.3):  36%|      | 723/2000 [09:27<20:26,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 306 / 724  (42.3):  36%|      | 724/2000 [09:27<17:03,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cnebrutary'. A: postscript B: corp C: kitchen D: canterbury\n",
      "Answer: D: canterbury\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'moroe'. A: warnings B: moore C: cares D: tigers\n",
      "Answer: A: warnings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 725  (42.3):  36%|      | 724/2000 [09:28<17:03,  1.25it/s]\u001b[A\n",
      "Average Metric: 307 / 725  (42.3):  36%|      | 725/2000 [09:28<15:31,  1.37it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 726  (42.3):  36%|      | 725/2000 [09:28<15:31,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'qtuiimkce'. A: involves B: fails C: quicktime D: gamecube\n",
      "Answer: D: gamecube\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'afpilmeir'. A: amplifier B: mississippi C: yamaha D: train\n",
      "Answer: A: amplifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 727  (42.2):  36%|      | 726/2000 [09:29<15:30,  1.37it/s]\u001b[A\n",
      "Average Metric: 307 / 727  (42.2):  36%|      | 727/2000 [09:29<12:15,  1.73it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dutecshe'. A: speaking B: deutsche C: helped D: leap\n",
      "Answer: D: leap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 308 / 728  (42.3):  36%|      | 727/2000 [09:29<12:15,  1.73it/s]\u001b[A\n",
      "Average Metric: 308 / 728  (42.3):  36%|      | 728/2000 [09:29<10:58,  1.93it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 729  (42.4):  36%|      | 728/2000 [09:29<10:58,  1.93it/s]\u001b[A\n",
      "Average Metric: 309 / 729  (42.4):  36%|      | 729/2000 [09:29<09:52,  2.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'htsenoly'. A: britain B: exercises C: honestly D: passes\n",
      "Answer: D: passes\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cnoe'. A: cone B: guatemala C: colorful D: cock\n",
      "Answer: D: cock\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peacagks'? A: simplicity B: forum C: packages D: garnet\n",
      "Answer: B: forum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 730  (42.5):  36%|      | 729/2000 [09:30<09:52,  2.14it/s]\u001b[A\n",
      "Average Metric: 310 / 730  (42.5):  36%|      | 730/2000 [09:30<11:32,  1.83it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 731  (42.5):  36%|      | 730/2000 [09:30<11:32,  1.83it/s]\u001b[A\n",
      "Average Metric: 311 / 731  (42.5):  37%|      | 731/2000 [09:30<10:09,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 732  (42.5):  37%|      | 731/2000 [09:31<10:09,  2.08it/s]\u001b[A\n",
      "Average Metric: 311 / 732  (42.5):  37%|      | 732/2000 [09:31<08:16,  2.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 733  (42.6):  37%|      | 732/2000 [09:31<08:16,  2.56it/s]\u001b[A\n",
      "Average Metric: 312 / 733  (42.6):  37%|      | 733/2000 [09:31<08:52,  2.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hrloeds'. A: geographical B: emily C: orthodox D: holders\n",
      "Answer: D: holders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ulits' represent when unscrambled? A: eclipse B: utils C: copy D: lotion\n",
      "Answer: A: eclipse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 734  (42.5):  37%|      | 733/2000 [09:35<08:52,  2.38it/s]\u001b[A\n",
      "Average Metric: 312 / 734  (42.5):  37%|      | 734/2000 [09:35<28:17,  1.34s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 735  (42.6):  37%|      | 734/2000 [09:35<28:17,  1.34s/it]\u001b[A\n",
      "Average Metric: 313 / 735  (42.6):  37%|      | 735/2000 [09:35<21:12,  1.01s/it]\u001b[A\n",
      "Average Metric: 313 / 736  (42.5):  37%|      | 735/2000 [09:35<21:12,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 313 / 736  (42.5):  37%|      | 736/2000 [09:35<15:56,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 737  (42.6):  37%|      | 736/2000 [09:36<15:56,  1.32it/s]\u001b[A\n",
      "Average Metric: 314 / 737  (42.6):  37%|      | 737/2000 [09:36<17:20,  1.21it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 738  (42.7):  37%|      | 737/2000 [09:36<17:20,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bcrhmenak' represent when unscrambled? A: hurricane B: simultaneously C: benchmark D: political\n",
      "Answer: A: hurricane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 739  (42.6):  37%|      | 738/2000 [09:39<17:20,  1.21it/s]\u001b[A\n",
      "Average Metric: 315 / 739  (42.6):  37%|      | 739/2000 [09:39<22:52,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vualim' represent when unscrambled? A: petite B: diving C: valium D: directive\n",
      "Answer: C: valium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'liqiud'. A: sudan B: claiming C: liquid D: cash\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 740  (42.6):  37%|      | 739/2000 [09:40<22:52,  1.09s/it]\u001b[A\n",
      "Average Metric: 315 / 740  (42.6):  37%|      | 740/2000 [09:40<23:35,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 315 / 741  (42.5):  37%|      | 740/2000 [09:40<23:35,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 742  (42.6):  37%|      | 741/2000 [09:40<23:34,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 743  (42.5):  37%|      | 742/2000 [09:40<23:33,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 744  (42.5):  37%|      | 743/2000 [09:41<23:32,  1.12s/it]\u001b[A\n",
      "Average Metric: 316 / 744  (42.5):  37%|      | 744/2000 [09:41<11:18,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cdnlcoue' represent when unscrambled? A: conclude B: nose C: carrying D: moses\n",
      "Answer: B: nose\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'geirf'? A: grief B: examine C: exceptions D: excluded\n",
      "Answer: grief\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 745  (42.4):  37%|      | 744/2000 [09:42<11:18,  1.85it/s]\u001b[A\n",
      "Average Metric: 316 / 745  (42.4):  37%|      | 745/2000 [09:42<16:08,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bwol'? A: bowl B: channels C: graham D: amplifier\n",
      "Answer: B: channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pruivleosy'? A: movements B: kyoto C: unlike D: previously\n",
      "Answer: B: kyoto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'prloicean'? A: believe B: omissions C: porcelain D: tripadvisor\n",
      "Answer: D: tripadvisor\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sbyomls'. A: scene B: belize C: symbols D: chemicals\n",
      "Answer: D: chemicals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 746  (42.4):  37%|      | 745/2000 [09:46<16:08,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 316 / 746  (42.4):  37%|      | 746/2000 [09:46<27:04,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 747  (42.3):  37%|      | 746/2000 [09:46<27:04,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 747  (42.3):  37%|      | 747/2000 [09:46<21:45,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sacveneserr'. A: nightmare B: lived C: bull D: screensaver\n",
      "Answer: D: screensaver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wesmenttsir'. A: milk B: westminster C: kurt D: positions\n",
      "Answer: D: positions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 748  (42.4):  37%|      | 747/2000 [09:47<21:45,  1.04s/it]\u001b[A\n",
      "Average Metric: 317 / 748  (42.4):  37%|      | 748/2000 [09:47<23:32,  1.13s/it]\u001b[A\n",
      "Average Metric: 317 / 749  (42.3):  37%|      | 748/2000 [09:48<23:32,  1.13s/it]\u001b[A\n",
      "Average Metric: 317 / 749  (42.3):  37%|      | 749/2000 [09:48<18:30,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 317 / 750  (42.3):  37%|      | 749/2000 [09:48<18:30,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 751  (42.2):  38%|      | 750/2000 [09:48<18:29,  1.13it/s]\u001b[A\n",
      "Average Metric: 317 / 751  (42.2):  38%|      | 751/2000 [09:48<13:06,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 752  (42.2):  38%|      | 751/2000 [09:49<13:06,  1.59it/s]\u001b[A\n",
      "Average Metric: 317 / 752  (42.2):  38%|      | 752/2000 [09:49<13:26,  1.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mniwhleae'. A: meanwhile B: pills C: curtain D: myspace\n",
      "Answer: D: myspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mtpliule'? A: arrive B: whereas C: allowance D: multiple\n",
      "Answer: D: multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 753  (42.1):  38%|      | 752/2000 [09:50<13:26,  1.55it/s]\u001b[A\n",
      "Average Metric: 317 / 753  (42.1):  38%|      | 753/2000 [09:50<16:31,  1.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 754  (42.2):  38%|      | 753/2000 [09:50<16:31,  1.26it/s]\u001b[A\n",
      "Average Metric: 318 / 754  (42.2):  38%|      | 754/2000 [09:50<13:38,  1.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 755  (42.1):  38%|      | 754/2000 [09:51<13:38,  1.52it/s]\u001b[A\n",
      "Average Metric: 318 / 755  (42.1):  38%|      | 755/2000 [09:51<14:23,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 756  (42.1):  38%|      | 755/2000 [09:51<14:23,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'psrnitaleoy' to form the correct word. A: lavender B: upgrade C: personality D: tide\n",
      "Answer: D: tide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 318 / 757  (42.0):  38%|      | 756/2000 [09:52<14:22,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 318 / 757  (42.0):  38%|      | 757/2000 [09:52<10:42,  1.93it/s]\u001b[A\n",
      "Average Metric: 318 / 758  (42.0):  38%|      | 757/2000 [09:52<10:42,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 759  (42.0):  38%|      | 758/2000 [09:52<10:42,  1.93it/s]\u001b[A\n",
      "Average Metric: 319 / 759  (42.0):  38%|      | 759/2000 [09:52<08:03,  2.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 760  (42.0):  38%|      | 759/2000 [09:52<08:03,  2.57it/s]\u001b[A\n",
      "Average Metric: 319 / 760  (42.0):  38%|      | 760/2000 [09:52<06:53,  3.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'msetar' to form the correct word. A: useless B: meal C: polar D: master\n",
      "Answer: D: master\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'crraees'. A: retailer B: largest C: careers D: namibia\n",
      "Answer: A: retailer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'levid' to form the correct word. A: cube B: lived C: staying D: tracker\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest prime number?  A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 761  (41.9):  38%|      | 760/2000 [09:53<06:53,  3.00it/s]\u001b[A\n",
      "Average Metric: 319 / 761  (41.9):  38%|      | 761/2000 [09:53<10:33,  1.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 762  (41.9):  38%|      | 761/2000 [09:54<10:33,  1.96it/s]\u001b[A\n",
      "Average Metric: 319 / 762  (41.9):  38%|      | 762/2000 [09:54<10:03,  2.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'jeep'. A: jeep B: words C: clubs D: dressed\n",
      "Answer: A: jeep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ianrian' to form the correct word. A: behaviour B: requirements C: instructor D: iranian\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'clopemid' represent when unscrambled? A: compiled B: canon C: hyundai D: jobs\n",
      "Answer: A: compiled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ksis' to form the correct word. A: occurred B: seychelles C: kiss D: sympathy\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fsahrles'. A: flashers B: textbook C: ultram D: tuesday\n",
      "Answer: A: flashers\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wlhie' to form the correct word. A: while B: concurrent C: smooth D: intranet\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 763  (41.8):  38%|      | 762/2000 [09:58<10:03,  2.05it/s]\u001b[A\n",
      "Average Metric: 319 / 763  (41.8):  38%|      | 763/2000 [09:58<31:01,  1.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 319 / 764  (41.8):  38%|      | 763/2000 [09:58<31:01,  1.51s/it]\u001b[A\n",
      "Average Metric: 319 / 764  (41.8):  38%|      | 764/2000 [09:58<24:35,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peetrflcy'. A: strengthen B: perfectly C: catherine D: specialized\n",
      "Answer: C: catherine\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'flshewoilp'. A: married B: fellowship C: wildlife D: ford\n",
      "Answer: D: ford\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 319 / 765  (41.7):  38%|      | 764/2000 [09:59<24:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 319 / 765  (41.7):  38%|      | 765/2000 [09:59<21:37,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rbebur' to form the correct word. A: priced B: remarkable C: recruiting D: rubber\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pzlaa' to form the correct word. A: hall B: error C: category D: plaza\n",
      "Answer: D: plaza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seccneis'. A: algorithms B: fair C: starring D: sciences\n",
      "Answer: D: sciences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'leis'? A: lies B: earlier C: chairs D: plaza\n",
      "Answer: B: earlier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 766  (41.6):  38%|      | 765/2000 [10:03<21:37,  1.05s/it]\u001b[A\n",
      "Average Metric: 319 / 766  (41.6):  38%|      | 766/2000 [10:03<35:58,  1.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 319 / 767  (41.6):  38%|      | 766/2000 [10:03<35:58,  1.75s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 767  (41.6):  38%|      | 767/2000 [10:03<28:50,  1.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 319 / 768  (41.5):  38%|      | 767/2000 [10:03<28:50,  1.40s/it]\u001b[A\n",
      "Average Metric: 319 / 768  (41.5):  38%|      | 768/2000 [10:03<21:58,  1.07s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 769  (41.5):  38%|      | 768/2000 [10:04<21:58,  1.07s/it]\u001b[A\n",
      "Average Metric: 319 / 769  (41.5):  38%|      | 769/2000 [10:04<18:31,  1.11it/s]\u001b[A\n",
      "Average Metric: 319 / 770  (41.4):  38%|      | 769/2000 [10:04<18:31,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'repnteeavisetrs'. A: virtue B: representatives C: uniform D: luxury\n",
      "Answer: A: virtue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 771  (41.4):  38%|      | 770/2000 [10:05<18:30,  1.11it/s]\u001b[A\n",
      "Average Metric: 319 / 771  (41.4):  39%|      | 771/2000 [10:05<13:01,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gtes'. A: affected B: gets C: variables D: bookmarks\n",
      "Answer: C: variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'frae'? A: fare B: plays C: brazilian D: pages\n",
      "Answer: A: fare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 320 / 772  (41.5):  39%|      | 771/2000 [10:07<13:01,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 772  (41.5):  39%|      | 772/2000 [10:07<22:08,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eeyd' represent when unscrambled? A: beads B: reform C: eyed D: darwin\n",
      "Answer: D: darwin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'anegls' to form the correct word. A: enom B: angles C: keys D: distributor\n",
      "Answer: Distributor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 321 / 773  (41.5):  39%|      | 772/2000 [10:08<22:08,  1.08s/it]\u001b[A\n",
      "Average Metric: 321 / 773  (41.5):  39%|      | 773/2000 [10:09<24:25,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'indsie'. A: attributes B: linear C: inside D: vector\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'daasaetbs' represent when unscrambled? A: walking B: exactly C: charming D: databases\n",
      "Answer: D: databases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 322 / 774  (41.6):  39%|      | 773/2000 [10:10<24:25,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 322 / 774  (41.6):  39%|      | 774/2000 [10:10<25:09,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'drleopvees' to form the correct word. A: cool B: sophisticated C: toolkit D: developers\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 775  (41.7):  39%|      | 774/2000 [10:10<25:09,  1.23s/it]\u001b[A\n",
      "Average Metric: 323 / 775  (41.7):  39%|      | 775/2000 [10:10<20:32,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 776  (41.6):  39%|      | 775/2000 [10:11<20:32,  1.01s/it]\u001b[A\n",
      "Average Metric: 323 / 776  (41.6):  39%|      | 776/2000 [10:11<19:47,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 777  (41.7):  39%|      | 776/2000 [10:11<19:47,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 324 / 777  (41.7):  39%|      | 777/2000 [10:11<14:44,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'prmie'. A: restore B: prime C: ashley D: plenty\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cnurotnligoatas'. A: investigating B: irvine C: chords D: congratulations\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 324 / 778  (41.6):  39%|      | 777/2000 [10:13<14:44,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 324 / 778  (41.6):  39%|      | 778/2000 [10:13<22:21,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 779  (41.6):  39%|      | 778/2000 [10:14<22:21,  1.10s/it]\u001b[A\n",
      "Average Metric: 324 / 779  (41.6):  39%|      | 779/2000 [10:14<20:57,  1.03s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 780  (41.5):  39%|      | 779/2000 [10:14<20:57,  1.03s/it]\u001b[A\n",
      "Average Metric: 324 / 780  (41.5):  39%|      | 780/2000 [10:14<15:29,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 781  (41.6):  39%|      | 780/2000 [10:14<15:29,  1.31it/s]\u001b[A\n",
      "Average Metric: 325 / 781  (41.6):  39%|      | 781/2000 [10:14<11:46,  1.73it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 782  (41.6):  39%|      | 781/2000 [10:15<11:46,  1.73it/s]\u001b[A\n",
      "Average Metric: 325 / 782  (41.6):  39%|      | 782/2000 [10:15<09:56,  2.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 783  (41.5):  39%|      | 782/2000 [10:15<09:56,  2.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 783  (41.5):  39%|      | 783/2000 [10:15<07:49,  2.59it/s]\u001b[A\n",
      "Average Metric: 326 / 784  (41.6):  39%|      | 783/2000 [10:15<07:49,  2.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 327 / 785  (41.7):  39%|      | 784/2000 [10:15<07:49,  2.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'etnioids'. A: overcome B: editions C: accordingly D: fighting\n",
      "Answer: D: fighting\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'resslibpnoe'. A: thrown B: legends C: responsible D: opera\n",
      "Answer: D: opera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rcak'. A: select B: going C: enemies D: rack\n",
      "Answer: D: rack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 327 / 786  (41.6):  39%|      | 785/2000 [10:17<07:48,  2.59it/s]\u001b[A\n",
      "Average Metric: 327 / 786  (41.6):  39%|      | 786/2000 [10:17<11:38,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'chraegrs' represent when unscrambled? A: potter B: turnover C: chargers D: desk\n",
      "Answer: A: potter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hndoa' to form the correct word. A: distinct B: draws C: honda D: hash\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 328 / 787  (41.7):  39%|      | 786/2000 [10:19<11:38,  1.74it/s]\u001b[A\n",
      "Average Metric: 328 / 787  (41.7):  39%|      | 787/2000 [10:19<17:46,  1.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rmeoevd'. A: reload B: geological C: removed D: emotion\n",
      "Answer: D: emotion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fieliams'. A: bonus B: crow C: copyright D: families\n",
      "Answer: D: families\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crok'? A: folders B: weapon C: swing D: cork\n",
      "Answer: D: cork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sryia'? A: songs B: library C: syria D: bool\n",
      "Answer: B: library\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dmeo' to form the correct word. A: penalties B: another C: remaining D: demo\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ritaen'. A: location B: infrared C: minneapolis D: retain\n",
      "Answer: D: retain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 329 / 788  (41.8):  39%|      | 787/2000 [10:21<17:46,  1.14it/s]\u001b[A\n",
      "Average Metric: 329 / 788  (41.8):  39%|      | 788/2000 [10:21<22:58,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 789  (41.8):  39%|      | 788/2000 [10:21<22:58,  1.14s/it]\u001b[A\n",
      "Average Metric: 330 / 789  (41.8):  39%|      | 789/2000 [10:21<18:13,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'arednas'. A: orleans B: andreas C: cotton D: examples\n",
      "Answer: D: examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 330 / 790  (41.8):  39%|      | 789/2000 [10:22<18:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 330 / 790  (41.8):  40%|      | 790/2000 [10:22<15:09,  1.33it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 791  (41.8):  40%|      | 790/2000 [10:22<15:09,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pkemoon' to form the correct word. A: pokemon B: blood C: recorders D: disclosed\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 792  (41.8):  40%|      | 791/2000 [10:25<15:09,  1.33it/s]\u001b[A\n",
      "Average Metric: 331 / 792  (41.8):  40%|      | 792/2000 [10:25<22:58,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 793  (41.7):  40%|      | 792/2000 [10:25<22:58,  1.14s/it]\u001b[A\n",
      "Average Metric: 331 / 793  (41.7):  40%|      | 793/2000 [10:25<20:03,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ctus'. A: israeli B: initiatives C: banks D: cuts\n",
      "Answer: D: cuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 331 / 794  (41.7):  40%|      | 793/2000 [10:26<20:03,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 331 / 794  (41.7):  40%|      | 794/2000 [10:26<19:53,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 331 / 795  (41.6):  40%|      | 794/2000 [10:27<19:53,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 331 / 795  (41.6):  40%|      | 795/2000 [10:27<19:01,  1.06it/s]\u001b[A\n",
      "Average Metric: 331 / 796  (41.6):  40%|      | 795/2000 [10:27<19:01,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 332 / 797  (41.7):  40%|      | 796/2000 [10:28<19:00,  1.06it/s]\u001b[A\n",
      "Average Metric: 332 / 797  (41.7):  40%|      | 797/2000 [10:28<13:03,  1.54it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'qnsueaenld'? A: readers B: clara C: queensland D: packs\n",
      "Answer: B: clara\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 798  (41.7):  40%|      | 797/2000 [10:28<13:03,  1.54it/s]\u001b[A\n",
      "Average Metric: 333 / 798  (41.7):  40%|      | 798/2000 [10:28<13:07,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'trvias'. A: travis B: signs C: fits D: outputs\n",
      "Answer: D: outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 334 / 799  (41.8):  40%|      | 798/2000 [10:31<13:07,  1.53it/s]\u001b[A\n",
      "Average Metric: 334 / 799  (41.8):  40%|      | 799/2000 [10:31<20:47,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sfcraue' represent when unscrambled? A: iceland B: precious C: surface D: outreach\n",
      "Answer: C: surface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cntneots' represent when unscrambled? A: suggestion B: refresh C: contents D: weather\n",
      "Answer: C: contents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 800  (41.8):  40%|      | 799/2000 [10:32<20:47,  1.04s/it]\u001b[A\n",
      "Average Metric: 334 / 800  (41.8):  40%|      | 800/2000 [10:32<22:07,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ctseher' to form the correct word. A: lexington B: blame C: chester D: folders\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 334 / 801  (41.7):  40%|      | 800/2000 [10:33<22:07,  1.11s/it]\u001b[A\n",
      "Average Metric: 334 / 801  (41.7):  40%|      | 801/2000 [10:33<21:59,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sepll' to form the correct word. A: username B: spell C: fabric D: barcelona\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 802  (41.6):  40%|      | 801/2000 [10:33<21:59,  1.10s/it]\u001b[A\n",
      "Average Metric: 334 / 802  (41.6):  40%|      | 802/2000 [10:34<19:06,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 803  (41.6):  40%|      | 802/2000 [10:35<19:06,  1.04it/s]\u001b[A\n",
      "Average Metric: 334 / 803  (41.6):  40%|      | 803/2000 [10:35<20:10,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 804  (41.5):  40%|      | 803/2000 [10:36<20:10,  1.01s/it]\u001b[A\n",
      "Average Metric: 334 / 804  (41.5):  40%|      | 804/2000 [10:36<21:57,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'viod' represent when unscrambled? A: outsourcing B: void C: bloglines D: phoenix\n",
      "Answer: A: outsourcing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 805  (41.5):  40%|      | 804/2000 [10:37<21:57,  1.10s/it]\u001b[A\n",
      "Average Metric: 334 / 805  (41.5):  40%|      | 805/2000 [10:37<23:15,  1.17s/it]\u001b[A\n",
      "Average Metric: 335 / 806  (41.6):  40%|      | 805/2000 [10:38<23:15,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 806  (41.6):  40%|      | 806/2000 [10:38<18:52,  1.05it/s]\u001b[A\n",
      "Average Metric: 335 / 807  (41.5):  40%|      | 806/2000 [10:38<18:52,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 808  (41.5):  40%|      | 807/2000 [10:38<18:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 335 / 808  (41.5):  40%|      | 808/2000 [10:38<10:41,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 336 / 809  (41.5):  40%|      | 808/2000 [10:38<10:41,  1.86it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 336 / 809  (41.5):  40%|      | 809/2000 [10:38<09:07,  2.18it/s]\u001b[A\n",
      "Average Metric: 337 / 810  (41.6):  40%|      | 809/2000 [10:38<09:07,  2.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'setm'. A: stem B: pathway C: pants D: interval\n",
      "Answer: D: interval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'htpts'? A: sbjct B: shop C: https D: targeting\n",
      "Answer: C: https\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'kcntueky'. A: kentucky B: sunrise C: thereafter D: paragraphs\n",
      "Answer: A: kentucky\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ctneoempt' represent when unscrambled? A: arise B: competent C: corrected D: brunswick\n",
      "Answer: B: competent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 337 / 811  (41.6):  40%|      | 810/2000 [10:39<09:06,  2.18it/s]\u001b[A\n",
      "Average Metric: 337 / 811  (41.6):  41%|      | 811/2000 [10:39<10:00,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'qetous' to form the correct word. A: meeting B: quotes C: spoken D: while\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 337 / 812  (41.5):  41%|      | 811/2000 [10:40<10:00,  1.98it/s]\u001b[A\n",
      "Average Metric: 337 / 812  (41.5):  41%|      | 812/2000 [10:40<13:16,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stetres'. A: this B: create C: nightmare D: streets\n",
      "Answer: D: streets\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'feird'. A: finishes B: expensive C: wills D: fired\n",
      "Answer: D: fired\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'anietxy' to form the correct word. A: anxiety B: breathing C: cumulative D: calls\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ajecandt'? A: hebrew B: adjacent C: mississippi D: sucking\n",
      "Answer: D: sucking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'catoed'. A: coated B: amounts C: wastewater D: logged\n",
      "Answer: C: wastewater\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'piootisn'? A: position B: protection C: benz D: customs\n",
      "Answer: B: protection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 338 / 813  (41.6):  41%|      | 812/2000 [10:43<13:16,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 338 / 813  (41.6):  41%|      | 813/2000 [10:43<24:43,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 339 / 814  (41.6):  41%|      | 813/2000 [10:44<24:43,  1.25s/it]\u001b[A\n",
      "Average Metric: 339 / 814  (41.6):  41%|      | 814/2000 [10:44<19:46,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 339 / 815  (41.6):  41%|      | 814/2000 [10:44<19:46,  1.00s/it]\u001b[A\n",
      "Average Metric: 339 / 815  (41.6):  41%|      | 815/2000 [10:44<16:33,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 339 / 816  (41.5):  41%|      | 815/2000 [10:44<16:33,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'niel'? A: bargaining B: dominican C: accessible D: neil\n",
      "Answer: D: neil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 339 / 816  (41.5):  41%|      | 816/2000 [10:44<13:43,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 817  (41.6):  41%|      | 816/2000 [10:45<13:43,  1.44it/s]\u001b[A\n",
      "Average Metric: 340 / 817  (41.6):  41%|      | 817/2000 [10:45<12:47,  1.54it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 818  (41.6):  41%|      | 817/2000 [10:47<12:47,  1.54it/s]\u001b[A\n",
      "Average Metric: 340 / 818  (41.6):  41%|      | 818/2000 [10:47<18:38,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 819  (41.5):  41%|      | 818/2000 [10:49<18:38,  1.06it/s]\u001b[A\n",
      "Average Metric: 340 / 819  (41.5):  41%|      | 819/2000 [10:49<24:35,  1.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ctntcraoor'. A: optic B: unit C: contractor D: humidity\n",
      "Answer: D: humidity\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lgare'? A: deficiency B: desk C: large D: moses\n",
      "Answer: D: moses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 340 / 820  (41.5):  41%|      | 819/2000 [10:49<24:35,  1.25s/it]\u001b[A\n",
      "Average Metric: 340 / 820  (41.5):  41%|      | 820/2000 [10:49<19:36,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'boderr'. A: anybody B: petite C: oceania D: border\n",
      "Answer: B: petite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 821  (41.4):  41%|      | 820/2000 [10:50<19:36,  1.00it/s]\u001b[A\n",
      "Average Metric: 340 / 821  (41.4):  41%|      | 821/2000 [10:50<18:35,  1.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mnylarad' represent when unscrambled? A: maryland B: achieve C: structured D: semester\n",
      "Answer: D: semester\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 340 / 822  (41.4):  41%|      | 821/2000 [10:50<18:35,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 340 / 822  (41.4):  41%|      | 822/2000 [10:50<15:04,  1.30it/s]\u001b[A\n",
      "Average Metric: 341 / 823  (41.4):  41%|      | 822/2000 [10:51<15:04,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 341 / 823  (41.4):  41%|      | 823/2000 [10:51<12:47,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 824  (41.4):  41%|      | 823/2000 [10:51<12:47,  1.53it/s]\u001b[A\n",
      "Average Metric: 341 / 824  (41.4):  41%|      | 824/2000 [10:51<09:39,  2.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tntiseg' to form the correct word. A: generates B: reservoir C: testing D: advised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 825  (41.3):  41%|      | 824/2000 [10:52<09:39,  2.03it/s]\u001b[A\n",
      "Average Metric: 341 / 825  (41.3):  41%|     | 825/2000 [10:52<13:04,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 826  (41.4):  41%|     | 825/2000 [10:54<13:04,  1.50it/s]\u001b[A\n",
      "Average Metric: 342 / 826  (41.4):  41%|     | 826/2000 [10:54<21:38,  1.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aacletlod' to form the correct word. A: allocated B: display C: lace D: subscribe\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aoevidd'. A: risk B: respect C: deployed D: avoided\n",
      "Answer: D: avoided\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'thiaanld'. A: glasses B: thailand C: kiss D: patriot\n",
      "Answer: D: patriot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cllnaeevd'. A: grown B: experiments C: cleveland D: offshore\n",
      "Answer: C: cleveland\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'noevl' represent when unscrambled? A: erik B: novel C: float D: terminology\n",
      "Answer: B: novel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 342 / 827  (41.4):  41%|     | 826/2000 [10:55<21:38,  1.11s/it]\u001b[A\n",
      "Average Metric: 342 / 827  (41.4):  41%|     | 827/2000 [10:55<22:51,  1.17s/it]\u001b[A\n",
      "Average Metric: 342 / 828  (41.3):  41%|     | 827/2000 [10:55<22:51,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 343 / 829  (41.4):  41%|     | 828/2000 [10:56<22:50,  1.17s/it]\u001b[A\n",
      "Average Metric: 343 / 829  (41.4):  41%|     | 829/2000 [10:56<14:46,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 343 / 830  (41.3):  41%|     | 829/2000 [10:56<14:46,  1.32it/s]\u001b[A\n",
      "Average Metric: 343 / 830  (41.3):  42%|     | 830/2000 [10:56<13:40,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'smnkiog'. A: hilary B: cincinnati C: drive D: smoking\n",
      "Answer: D: smoking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 344 / 831  (41.4):  42%|     | 830/2000 [10:57<13:40,  1.43it/s]\u001b[A\n",
      "Average Metric: 344 / 831  (41.4):  42%|     | 831/2000 [10:57<11:32,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 832  (41.3):  42%|     | 831/2000 [10:58<11:32,  1.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 344 / 832  (41.3):  42%|     | 832/2000 [10:58<16:11,  1.20it/s]\u001b[A\n",
      "Average Metric: 344 / 833  (41.3):  42%|     | 832/2000 [10:58<16:11,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 834  (41.2):  42%|     | 833/2000 [10:59<16:10,  1.20it/s]\u001b[A\n",
      "Average Metric: 344 / 834  (41.2):  42%|     | 834/2000 [10:59<12:51,  1.51it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 835  (41.2):  42%|     | 834/2000 [10:59<12:51,  1.51it/s]\u001b[A\n",
      "Average Metric: 344 / 835  (41.2):  42%|     | 835/2000 [10:59<10:57,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hsbunad'? A: uganda B: cuba C: inspired D: husband\n",
      "Answer: D: husband\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 836  (41.1):  42%|     | 835/2000 [11:00<10:57,  1.77it/s]\u001b[A\n",
      "Average Metric: 344 / 836  (41.1):  42%|     | 836/2000 [11:00<14:16,  1.36it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'suiydtng'? A: arizona B: files C: integer D: studying\n",
      "Answer: D: studying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 837  (41.1):  42%|     | 836/2000 [11:01<14:16,  1.36it/s]\u001b[A\n",
      "Average Metric: 344 / 837  (41.1):  42%|     | 837/2000 [11:01<14:29,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 344 / 838  (41.1):  42%|     | 837/2000 [11:02<14:29,  1.34it/s]\u001b[A\n",
      "Average Metric: 344 / 838  (41.1):  42%|     | 838/2000 [11:02<12:41,  1.53it/s]\u001b[A\n",
      "Average Metric: 344 / 839  (41.0):  42%|     | 838/2000 [11:02<12:41,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 344 / 839  (41.0):  42%|     | 839/2000 [11:02<09:48,  1.97it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnoiojuntcn'? A: differential B: conjunction C: kenya D: corpus\n",
      "Answer: B: conjunction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lisence' to form the correct word. A: race B: wage C: python D: license\n",
      "Answer: D: license\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'motbiana'. A: section B: carter C: defines D: manitoba\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'acepct'. A: thrown B: accept C: hiring D: humanities\n",
      "Answer: C: hiring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 840  (41.0):  42%|     | 839/2000 [11:03<09:48,  1.97it/s]\u001b[A\n",
      "Average Metric: 344 / 840  (41.0):  42%|     | 840/2000 [11:03<13:35,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'stwhcied' represent when unscrambled? A: lansing B: fitted C: skype D: switched\n",
      "Answer: D: switched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 345 / 841  (41.0):  42%|     | 840/2000 [11:04<13:35,  1.42it/s]\u001b[A\n",
      "Average Metric: 345 / 841  (41.0):  42%|     | 841/2000 [11:04<13:14,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tomsrehee'. A: adult B: threesome C: shelves D: pass\n",
      "Answer: D: pass\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'seeht' represent when unscrambled? A: waist B: jeff C: reliability D: sheet\n",
      "Answer: A: waist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 346 / 842  (41.1):  42%|     | 841/2000 [11:05<13:14,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 346 / 842  (41.1):  42%|     | 842/2000 [11:05<19:10,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'doonr' to form the correct word. A: humanity B: envelope C: founding D: donor\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 346 / 843  (41.0):  42%|     | 842/2000 [11:06<19:10,  1.01it/s]\u001b[A\n",
      "Average Metric: 346 / 843  (41.0):  42%|     | 843/2000 [11:06<19:45,  1.02s/it]\u001b[A\n",
      "Average Metric: 347 / 844  (41.1):  42%|     | 843/2000 [11:07<19:45,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 347 / 844  (41.1):  42%|     | 844/2000 [11:07<15:43,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pcorieisn'. A: direction B: things C: precision D: indeed\n",
      "Answer: D: indeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'edide'? A: matches B: sussex C: procedure D: eddie\n",
      "Answer: D: eddie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 845  (41.1):  42%|     | 844/2000 [11:08<15:43,  1.22it/s]\u001b[A\n",
      "Average Metric: 347 / 845  (41.1):  42%|     | 845/2000 [11:08<19:35,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 846  (41.0):  42%|     | 845/2000 [11:09<19:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 347 / 846  (41.0):  42%|     | 846/2000 [11:09<19:45,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ceftrad'. A: image B: pear C: porn D: crafted\n",
      "Answer: D: crafted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'webtesr'? A: scam B: webster C: blowjobs D: savage\n",
      "Answer: B: webster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 348 / 847  (41.1):  42%|     | 846/2000 [11:11<19:45,  1.03s/it]\u001b[A\n",
      "Average Metric: 348 / 847  (41.1):  42%|     | 847/2000 [11:11<21:18,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'vuarios'. A: roll B: situations C: various D: routing\n",
      "Answer: C: various\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 349 / 848  (41.2):  42%|     | 847/2000 [11:12<21:18,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 349 / 848  (41.2):  42%|     | 848/2000 [11:12<23:22,  1.22s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 849  (41.1):  42%|     | 848/2000 [11:13<23:22,  1.22s/it]\u001b[A\n",
      "Average Metric: 349 / 849  (41.1):  42%|     | 849/2000 [11:13<20:02,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 350 / 850  (41.2):  42%|     | 849/2000 [11:14<20:02,  1.05s/it]\u001b[A\n",
      "Average Metric: 350 / 850  (41.2):  42%|     | 850/2000 [11:14<18:45,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'beard' to form the correct word. A: bread B: sorry C: sand D: reagan\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 351 / 851  (41.2):  42%|     | 850/2000 [11:14<18:45,  1.02it/s]\u001b[A\n",
      "Average Metric: 351 / 851  (41.2):  43%|     | 851/2000 [11:14<15:17,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 852  (41.2):  43%|     | 851/2000 [11:17<15:17,  1.25it/s]\u001b[A\n",
      "Average Metric: 351 / 852  (41.2):  43%|     | 852/2000 [11:17<28:59,  1.52s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 853  (41.1):  43%|     | 852/2000 [11:17<28:59,  1.52s/it]\u001b[A\n",
      "Average Metric: 351 / 853  (41.1):  43%|     | 853/2000 [11:17<21:10,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'figetrhs'. A: fighters B: mercy C: preston D: portions\n",
      "Answer: A: fighters\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cupoe' to form the correct word. A: duties B: strongly C: opportunities D: coupe\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'clhid'. A: revolution B: quarter C: child D: gzip\n",
      "Answer: D: gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wicth'? A: timely B: known C: uganda D: witch\n",
      "Answer: D: witch\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bicneomg'? A: guard B: becoming C: infantry D: camden\n",
      "Answer: D: camden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 351 / 854  (41.1):  43%|     | 853/2000 [11:18<21:10,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 351 / 854  (41.1):  43%|     | 854/2000 [11:18<20:20,  1.06s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 352 / 855  (41.2):  43%|     | 854/2000 [11:18<20:20,  1.06s/it]\u001b[A\n",
      "Average Metric: 352 / 855  (41.2):  43%|     | 855/2000 [11:18<15:14,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 353 / 856  (41.2):  43%|     | 855/2000 [11:19<15:14,  1.25it/s]\u001b[A\n",
      "Average Metric: 353 / 856  (41.2):  43%|     | 856/2000 [11:19<14:54,  1.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 857  (41.3):  43%|     | 856/2000 [11:19<14:54,  1.28it/s]\u001b[A\n",
      "Average Metric: 354 / 857  (41.3):  43%|     | 857/2000 [11:19<11:13,  1.70it/s]\u001b[A\n",
      "Average Metric: 354 / 858  (41.3):  43%|     | 857/2000 [11:20<11:13,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 858  (41.3):  43%|     | 858/2000 [11:20<09:13,  2.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'danelig'. A: tones B: championships C: labor D: dealing\n",
      "Answer: D: dealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 354 / 859  (41.2):  43%|     | 858/2000 [11:21<09:13,  2.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 859  (41.2):  43%|     | 859/2000 [11:21<14:40,  1.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 860  (41.2):  43%|     | 859/2000 [11:21<14:40,  1.30it/s]\u001b[A\n",
      "Average Metric: 354 / 860  (41.2):  43%|     | 860/2000 [11:21<12:14,  1.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 861  (41.1):  43%|     | 860/2000 [11:22<12:14,  1.55it/s]\u001b[A\n",
      "Average Metric: 354 / 861  (41.1):  43%|     | 861/2000 [11:22<12:39,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rntuioe' represent when unscrambled? A: future B: routine C: traveler D: harassment\n",
      "Answer: A: future\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'twon' to form the correct word. A: obligations B: changelog C: gulf D: town\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'risacm'. A: specialized B: reduced C: racism D: automation\n",
      "Answer: D: automation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rggeae' to form the correct word. A: heating B: queens C: cadillac D: reggae\n",
      "Answer: D: reggae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 354 / 862  (41.1):  43%|     | 861/2000 [11:24<12:39,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 354 / 862  (41.1):  43%|     | 862/2000 [11:24<18:33,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dbuet'. A: berlin B: legend C: reserved D: debut\n",
      "Answer: D: debut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 863  (41.1):  43%|     | 862/2000 [11:24<18:33,  1.02it/s]\u001b[A\n",
      "Average Metric: 355 / 863  (41.1):  43%|     | 863/2000 [11:24<14:58,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 356 / 864  (41.2):  43%|     | 863/2000 [11:25<14:58,  1.27it/s]\u001b[A\n",
      "Average Metric: 356 / 864  (41.2):  43%|     | 864/2000 [11:25<13:30,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 865  (41.2):  43%|     | 864/2000 [11:25<13:30,  1.40it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 865  (41.2):  43%|     | 865/2000 [11:25<10:32,  1.79it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 866  (41.2):  43%|     | 865/2000 [11:25<10:32,  1.79it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'prcoituodn'? A: spring B: production C: compiled D: areas\n",
      "Answer: B: production\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 358 / 867  (41.3):  43%|     | 866/2000 [11:26<10:32,  1.79it/s]\u001b[A\n",
      "Average Metric: 358 / 867  (41.3):  43%|     | 867/2000 [11:26<09:53,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'diostisoipn'. A: eligible B: michel C: disposition D: weeks\n",
      "Answer: D: weeks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 358 / 868  (41.2):  43%|     | 867/2000 [11:26<09:53,  1.91it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 358 / 868  (41.2):  43%|     | 868/2000 [11:26<09:37,  1.96it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cieraommcl'. A: fixtures B: radius C: affecting D: commercial\n",
      "Answer: D: commercial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'flarmuos' represent when unscrambled? A: voting B: elsewhere C: software D: formulas\n",
      "Answer: A: voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 359 / 869  (41.3):  43%|     | 868/2000 [11:29<09:37,  1.96it/s]\u001b[A\n",
      "Average Metric: 359 / 869  (41.3):  43%|     | 869/2000 [11:29<20:51,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'asdl' to form the correct word. A: toll B: sensitive C: adsl D: deviation\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cmom'? A: comm B: handbags C: leap D: preserve\n",
      "Answer: B: handbags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 870  (41.3):  43%|     | 869/2000 [11:30<20:51,  1.11s/it]\u001b[A\n",
      "Average Metric: 359 / 870  (41.3):  44%|     | 870/2000 [11:30<18:44,  1.00it/s]\u001b[A\n",
      "Average Metric: 359 / 871  (41.2):  44%|     | 870/2000 [11:30<18:44,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'otuput'. A: anywhere B: fans C: output D: reviewed\n",
      "Answer: C: output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 872  (41.3):  44%|     | 871/2000 [11:31<18:43,  1.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 872  (41.3):  44%|     | 872/2000 [11:31<15:58,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aceiamrn' to form the correct word. A: struggling B: american C: critics D: beth\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'coledsrs'? A: cordless B: pupils C: lawyer D: emacs\n",
      "Answer: D: emacs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tdnes' represent when unscrambled? A: delivered B: wichita C: tends D: hardwood\n",
      "Answer: D: hardwood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dcunan'. A: terminated B: duncan C: rock D: dildo\n",
      "Answer: C: rock\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eimtanile'. A: certificates B: athens C: zoloft D: eliminate\n",
      "Answer: D: eliminate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 873  (41.2):  44%|     | 872/2000 [11:34<15:58,  1.18it/s]\u001b[A\n",
      "Average Metric: 360 / 873  (41.2):  44%|     | 873/2000 [11:34<23:23,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 874  (41.2):  44%|     | 873/2000 [11:36<23:23,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 360 / 874  (41.2):  44%|     | 874/2000 [11:36<27:41,  1.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 875  (41.1):  44%|     | 874/2000 [11:36<27:41,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bdes'. A: ipod B: infringement C: intention D: beds\n",
      "Answer: D: beds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 360 / 875  (41.1):  44%|     | 875/2000 [11:36<23:11,  1.24s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 876  (41.1):  44%|     | 875/2000 [11:37<23:11,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 876  (41.1):  44%|     | 876/2000 [11:37<17:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 361 / 877  (41.2):  44%|     | 876/2000 [11:37<17:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 362 / 878  (41.2):  44%|     | 877/2000 [11:37<17:50,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 362 / 878  (41.2):  44%|     | 878/2000 [11:37<12:39,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'suivrvor' to form the correct word. A: backyard B: trails C: survivor D: friendly\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 879  (41.2):  44%|     | 878/2000 [11:40<12:39,  1.48it/s]\u001b[A\n",
      "Average Metric: 362 / 879  (41.2):  44%|     | 879/2000 [11:40<21:45,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tnalet'. A: pull B: talent C: polyphonic D: communication\n",
      "Answer: D: communication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 880  (41.1):  44%|     | 879/2000 [11:41<21:45,  1.16s/it]\u001b[A\n",
      "Average Metric: 362 / 880  (41.1):  44%|     | 880/2000 [11:41<19:22,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pessoss' to form the correct word. A: java B: hugh C: possess D: save\n",
      "Answer: D: save\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'caasul' to form the correct word. A: fisting B: umbrella C: sender D: casual\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'smhrip'. A: chairs B: jessica C: computed D: shrimp\n",
      "Answer: D: shrimp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 362 / 881  (41.1):  44%|     | 880/2000 [11:42<19:22,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 362 / 881  (41.1):  44%|     | 881/2000 [11:42<22:12,  1.19s/it]\u001b[A\n",
      "Average Metric: 363 / 882  (41.2):  44%|     | 881/2000 [11:42<22:12,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cuenrrt'? A: current B: partnership C: mike D: contacted\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 363 / 883  (41.1):  44%|     | 882/2000 [11:44<22:11,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'briazl' to form the correct word. A: packing B: brazil C: deferred D: individuals\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 363 / 883  (41.1):  44%|     | 883/2000 [11:44<20:08,  1.08s/it]\u001b[A\n",
      "Average Metric: 363 / 884  (41.1):  44%|     | 883/2000 [11:44<20:08,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 364 / 885  (41.1):  44%|     | 884/2000 [11:45<20:07,  1.08s/it]\u001b[A\n",
      "Average Metric: 364 / 885  (41.1):  44%|     | 885/2000 [11:45<15:25,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'smidhct'. A: informal B: schmidt C: knives D: ourselves\n",
      "Answer: D: ourselves\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lttaiude'. A: radio B: latitude C: absorption D: listen\n",
      "Answer: D: listen\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'scotk'. A: limiting B: detected C: stock D: lives\n",
      "Answer: D: lives\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'riblatotehiian'. A: outer B: bottle C: rehabilitation D: voyuer\n",
      "Answer: D: voyuer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jtes' represent when unscrambled? A: rewards B: mighty C: honeymoon D: jets\n",
      "Answer: B: mighty\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sekes'. A: seeks B: marco C: chromosome D: valve\n",
      "Answer: A: seeks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 365 / 886  (41.2):  44%|     | 885/2000 [11:47<15:25,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 365 / 886  (41.2):  44%|     | 886/2000 [11:47<19:47,  1.07s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 887  (41.1):  44%|     | 886/2000 [11:47<19:47,  1.07s/it]\u001b[A\n",
      "Average Metric: 365 / 887  (41.1):  44%|     | 887/2000 [11:47<16:27,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 888  (41.2):  44%|     | 887/2000 [11:47<16:27,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 889  (41.2):  44%|     | 888/2000 [11:47<16:26,  1.13it/s]\u001b[A\n",
      "Average Metric: 366 / 889  (41.2):  44%|     | 889/2000 [11:47<10:39,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'selhl' represent when unscrambled? A: forthcoming B: bullet C: parental D: shell\n",
      "Answer: D: shell\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pseverre'. A: wikimedia B: preserve C: marry D: cabin\n",
      "Answer: D: cabin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'veuens'? A: venues B: tiffany C: himself D: totals\n",
      "Answer: venues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 890  (41.1):  44%|     | 889/2000 [11:49<10:39,  1.74it/s]\u001b[A\n",
      "Average Metric: 366 / 890  (41.1):  44%|     | 890/2000 [11:49<15:45,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 891  (41.1):  44%|     | 890/2000 [11:51<15:45,  1.17it/s]\u001b[A\n",
      "Average Metric: 366 / 891  (41.1):  45%|     | 891/2000 [11:51<22:15,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 366 / 892  (41.0):  45%|     | 891/2000 [11:52<22:15,  1.20s/it]\u001b[A\n",
      "Average Metric: 366 / 892  (41.0):  45%|     | 892/2000 [11:52<18:30,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'scpeeh'? A: transexuales B: speech C: numbers D: bitter\n",
      "Answer: B: speech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ihsigtns'. A: reached B: hamilton C: holdings D: insights\n",
      "Answer: D: insights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 367 / 893  (41.1):  45%|     | 892/2000 [11:53<18:30,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 367 / 893  (41.1):  45%|     | 893/2000 [11:53<17:52,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'snnpideg'. A: brent B: spending C: wicked D: took\n",
      "Answer: b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 894  (41.1):  45%|     | 893/2000 [11:54<17:52,  1.03it/s]\u001b[A\n",
      "Average Metric: 367 / 894  (41.1):  45%|     | 894/2000 [11:54<18:20,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mlratoity' represent when unscrambled? A: girl B: aberdeen C: mortality D: meaning\n",
      "Answer: D: meaning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 367 / 895  (41.0):  45%|     | 894/2000 [11:56<18:20,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 367 / 895  (41.0):  45%|     | 895/2000 [11:56<25:08,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'blnoaols'. A: balloons B: processors C: yeast D: clients\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'coprrotae' to form the correct word. A: corporate B: decent C: fuzzy D: exciting\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'suepr' represent when unscrambled? A: hamilton B: users C: super D: boating\n",
      "Answer: A: hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 896  (41.0):  45%|     | 895/2000 [11:58<25:08,  1.36s/it]\u001b[A\n",
      "Average Metric: 367 / 896  (41.0):  45%|     | 896/2000 [11:58<29:58,  1.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wacsbet' to form the correct word. A: blades B: webcast C: fridge D: analyses\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 367 / 897  (40.9):  45%|     | 896/2000 [11:58<29:58,  1.63s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 898  (40.9):  45%|     | 897/2000 [11:59<29:56,  1.63s/it]\u001b[A\n",
      "Average Metric: 367 / 898  (40.9):  45%|     | 898/2000 [11:59<16:54,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lsaer'? A: laser B: fabrics C: figure D: setup\n",
      "Answer: A: laser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 368 / 899  (40.9):  45%|     | 898/2000 [12:00<16:54,  1.09it/s]\u001b[A\n",
      "Average Metric: 368 / 899  (40.9):  45%|     | 899/2000 [12:00<18:17,  1.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 900  (40.9):  45%|     | 899/2000 [12:00<18:17,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 901  (41.0):  45%|     | 900/2000 [12:00<18:16,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 369 / 901  (41.0):  45%|     | 901/2000 [12:00<11:29,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'haobnodk'. A: hitting B: handbook C: mailbox D: suites\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'orgsaiend' represent when unscrambled? A: organised B: viewers C: tobacco D: hockey\n",
      "Answer: A: organised\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eisgnlh'. A: grid B: english C: cialis D: wilson\n",
      "Answer: D: wilson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'veertan' represent when unscrambled? A: adequately B: veteran C: reasonably D: combining\n",
      "Answer: D: combining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'silnet'. A: silent B: insulation C: attempt D: happened\n",
      "Answer: D: happened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 902  (41.0):  45%|     | 901/2000 [12:04<11:29,  1.59it/s]\u001b[A\n",
      "Average Metric: 370 / 902  (41.0):  45%|     | 902/2000 [12:04<25:58,  1.42s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 903  (41.0):  45%|     | 902/2000 [12:05<25:58,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 370 / 903  (41.0):  45%|     | 903/2000 [12:05<24:19,  1.33s/it]\u001b[A\n",
      "Average Metric: 370 / 904  (40.9):  45%|     | 903/2000 [12:05<24:19,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 371 / 905  (41.0):  45%|     | 904/2000 [12:06<24:18,  1.33s/it]\u001b[A\n",
      "Average Metric: 371 / 905  (41.0):  45%|     | 905/2000 [12:06<15:47,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 906  (41.1):  45%|     | 905/2000 [12:07<15:47,  1.16it/s]\u001b[A\n",
      "Average Metric: 372 / 906  (41.1):  45%|     | 906/2000 [12:07<17:22,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'erous'. A: baseline B: back C: southeast D: euros\n",
      "Answer: C: southeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 372 / 907  (41.0):  45%|     | 906/2000 [12:08<17:22,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 372 / 907  (41.0):  45%|     | 907/2000 [12:08<18:01,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'soon' represent when unscrambled? A: birmingham B: soon C: favors D: achieve\n",
      "Answer: B: soon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 908  (41.0):  45%|     | 907/2000 [12:09<18:01,  1.01it/s]\u001b[A\n",
      "Average Metric: 372 / 908  (41.0):  45%|     | 908/2000 [12:09<16:30,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bleow' to form the correct word. A: price B: below C: determined D: temporal\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bellut'. A: stocks B: attachments C: bullet D: supportive\n",
      "Answer: D: supportive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cinnatos' represent when unscrambled? A: roster B: breasts C: relay D: contains\n",
      "Answer: D: contains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'seurm'. A: diploma B: breasts C: fitting D: serum\n",
      "Answer: D: serum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 909  (40.9):  45%|     | 908/2000 [12:10<16:30,  1.10it/s]\u001b[A\n",
      "Average Metric: 372 / 909  (40.9):  45%|     | 909/2000 [12:10<18:57,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 372 / 910  (40.9):  45%|     | 909/2000 [12:10<18:57,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 372 / 911  (40.8):  46%|     | 910/2000 [12:10<18:56,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 912  (40.9):  46%|     | 911/2000 [12:10<18:55,  1.04s/it]\u001b[A\n",
      "Average Metric: 373 / 912  (40.9):  46%|     | 912/2000 [12:10<09:45,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wreroks'. A: happiness B: workers C: publication D: beastality\n",
      "Answer: D: beastality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'pliulng' to form the correct word. A: pulling B: buyers C: news D: episodes\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tanurneomt'? A: tournament B: assisting C: sims D: yale\n",
      "Answer: B: assisting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 913  (40.9):  46%|     | 912/2000 [12:13<09:45,  1.86it/s]\u001b[A\n",
      "Average Metric: 373 / 913  (40.9):  46%|     | 913/2000 [12:13<19:07,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 914  (40.8):  46%|     | 913/2000 [12:14<19:07,  1.06s/it]\u001b[A\n",
      "Average Metric: 373 / 914  (40.8):  46%|     | 914/2000 [12:14<17:54,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 915  (40.9):  46%|     | 914/2000 [12:15<17:54,  1.01it/s]\u001b[A\n",
      "Average Metric: 374 / 915  (40.9):  46%|     | 915/2000 [12:15<15:32,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'shopsnat'? A: miles B: snapshot C: elder D: focal\n",
      "Answer: miles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 375 / 916  (40.9):  46%|     | 915/2000 [12:15<15:32,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 375 / 916  (40.9):  46%|     | 916/2000 [12:15<15:08,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bvoeeld'? A: sheriff B: beloved C: completing D: stack\n",
      "Answer: D: stack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 917  (41.0):  46%|     | 916/2000 [12:16<15:08,  1.19it/s]\u001b[A\n",
      "Average Metric: 376 / 917  (41.0):  46%|     | 917/2000 [12:16<12:37,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 918  (41.0):  46%|     | 917/2000 [12:17<12:37,  1.43it/s]\u001b[A\n",
      "Average Metric: 376 / 918  (41.0):  46%|     | 918/2000 [12:17<13:24,  1.34it/s]\u001b[A\n",
      "Average Metric: 377 / 919  (41.0):  46%|     | 918/2000 [12:17<13:24,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 377 / 919  (41.0):  46%|     | 919/2000 [12:17<10:11,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'door' represent when unscrambled? A: titanium B: door C: gone D: ball\n",
      "Answer: B: door\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 920  (41.0):  46%|     | 919/2000 [12:17<10:11,  1.77it/s]\u001b[A\n",
      "Average Metric: 377 / 920  (41.0):  46%|     | 920/2000 [12:17<09:59,  1.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 921  (40.9):  46%|     | 920/2000 [12:18<09:59,  1.80it/s]\u001b[A\n",
      "Average Metric: 377 / 921  (40.9):  46%|     | 921/2000 [12:18<12:34,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cviic' to form the correct word. A: ride B: clear C: civic D: represents\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fumlroa' represent when unscrambled? A: aware B: examined C: slideshow D: formula\n",
      "Answer: D: formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ternaid'? A: properly B: trained C: nipple D: toolbar\n",
      "Answer: A: properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 922  (40.9):  46%|     | 921/2000 [12:20<12:34,  1.43it/s]\u001b[A\n",
      "Average Metric: 377 / 922  (40.9):  46%|     | 922/2000 [12:20<18:47,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'inenetdd'. A: generators B: riley C: intended D: negative\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ctitnoiounbrs' represent when unscrambled? A: handmade B: freeman C: contributions D: completed\n",
      "Answer: D: completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 378 / 923  (41.0):  46%|     | 922/2000 [12:22<18:47,  1.05s/it]\u001b[A\n",
      "Average Metric: 378 / 923  (41.0):  46%|     | 923/2000 [12:22<20:42,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'vovlo'. A: volvo B: contents C: published D: wagner\n",
      "Answer: D: wagner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dndmaes'? A: meditation B: tanzania C: tennessee D: demands\n",
      "Answer: B: tanzania\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mtreats'? A: essays B: books C: matters D: copenhagen\n",
      "Answer: B: books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 924  (41.0):  46%|     | 923/2000 [12:23<20:42,  1.15s/it]\u001b[A\n",
      "Average Metric: 379 / 924  (41.0):  46%|     | 924/2000 [12:23<21:09,  1.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rsepcet'? A: corresponds B: pogo C: respect D: guardian\n",
      "Answer: D: guardian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 925  (41.0):  46%|     | 924/2000 [12:23<21:09,  1.18s/it]\u001b[A\n",
      "Average Metric: 379 / 925  (41.0):  46%|     | 925/2000 [12:23<16:21,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dualpicte' to form the correct word. A: erotik B: exclusively C: duplicate D: refill\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pkbraapecs'. A: paperbacks B: tamil C: actress D: prague\n",
      "Answer: C: actress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 926  (40.9):  46%|     | 925/2000 [12:25<16:21,  1.10it/s]\u001b[A\n",
      "Average Metric: 379 / 926  (40.9):  46%|     | 926/2000 [12:25<24:14,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sripct' represent when unscrambled? A: ebony B: browsers C: threats D: script\n",
      "Answer: D: script\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 927  (40.9):  46%|     | 926/2000 [12:27<24:14,  1.35s/it]\u001b[A\n",
      "Average Metric: 379 / 927  (40.9):  46%|     | 927/2000 [12:27<25:52,  1.45s/it]\u001b[A\n",
      "Average Metric: 379 / 928  (40.8):  46%|     | 927/2000 [12:27<25:52,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 929  (40.9):  46%|     | 928/2000 [12:28<25:50,  1.45s/it]\u001b[A\n",
      "Average Metric: 380 / 929  (40.9):  46%|     | 929/2000 [12:28<18:44,  1.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tkwins'. A: theory B: mailed C: import D: twinks\n",
      "Answer: D: twinks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'brainbse'. A: entertainment B: provision C: button D: brisbane\n",
      "Answer: D: brisbane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 381 / 930  (41.0):  46%|     | 929/2000 [12:29<18:44,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 381 / 930  (41.0):  46%|     | 930/2000 [12:29<17:39,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cnoan'. A: lauderdale B: canon C: hybrid D: graduated\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gule' represent when unscrambled? A: villa B: cheats C: glue D: broad\n",
      "Answer: D: broad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'szeid' represent when unscrambled? A: sized B: stating C: initiative D: compact\n",
      "Answer: D: compact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iotcuniefs'? A: hierarchy B: tsunami C: infectious D: carl\n",
      "Answer: hierarchy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nwohere'. A: nets B: rest C: nowhere D: bomb\n",
      "Answer: D: bomb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 381 / 931  (40.9):  46%|     | 930/2000 [12:33<17:39,  1.01it/s]\u001b[A\n",
      "Average Metric: 381 / 931  (40.9):  47%|     | 931/2000 [12:33<30:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nniforpot'. A: nonprofit B: atoms C: scream D: slideshow\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 381 / 932  (40.9):  47%|     | 931/2000 [12:33<30:18,  1.70s/it]\u001b[A\n",
      "Average Metric: 381 / 932  (40.9):  47%|     | 932/2000 [12:33<23:48,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 381 / 933  (40.8):  47%|     | 932/2000 [12:33<23:48,  1.34s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 382 / 934  (40.9):  47%|     | 933/2000 [12:33<23:47,  1.34s/it]\u001b[A\n",
      "Average Metric: 382 / 934  (40.9):  47%|     | 934/2000 [12:33<13:48,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 382 / 935  (40.9):  47%|     | 934/2000 [12:34<13:48,  1.29it/s]\u001b[A\n",
      "Average Metric: 382 / 935  (40.9):  47%|     | 935/2000 [12:34<12:10,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'chciamel'. A: relay B: jump C: chemical D: personal\n",
      "Answer: A: relay\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'gard'. A: grad B: films C: different D: appearing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iatoonaimfnrl'? A: smilies B: informational C: away D: determines\n",
      "Answer: D: determines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 936  (40.9):  47%|     | 935/2000 [12:36<12:10,  1.46it/s]\u001b[A\n",
      "Average Metric: 383 / 936  (40.9):  47%|     | 936/2000 [12:36<19:30,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 937  (40.9):  47%|     | 936/2000 [12:37<19:30,  1.10s/it]\u001b[A\n",
      "Average Metric: 383 / 937  (40.9):  47%|     | 937/2000 [12:37<17:46,  1.00s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 938  (40.8):  47%|     | 937/2000 [12:37<17:46,  1.00s/it]\u001b[A\n",
      "Average Metric: 383 / 938  (40.8):  47%|     | 938/2000 [12:37<13:38,  1.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 939  (40.8):  47%|     | 938/2000 [12:37<13:38,  1.30it/s]\u001b[A\n",
      "Average Metric: 383 / 939  (40.8):  47%|     | 939/2000 [12:37<11:52,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'droos'. A: doors B: senegal C: hate D: developments\n",
      "Answer: D: developments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 383 / 940  (40.7):  47%|     | 939/2000 [12:38<11:52,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 383 / 940  (40.7):  47%|     | 940/2000 [12:38<11:50,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ridpas'? A: rapids B: israel C: flavor D: united\n",
      "Answer: D: united\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'uinv'. A: univ B: scales C: productions D: podcasts\n",
      "Answer: A: univ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bteotls' to form the correct word. A: lone B: bottles C: what D: ocean\n",
      "Answer: B\n",
      "\n",
      "Question: Which of the following is the smallest value?  (a) 0.1  (b) 1/3  (c) 1/2  (d) 0.01\n",
      "Answer: d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 383 / 941  (40.7):  47%|     | 940/2000 [12:39<11:50,  1.49it/s]\u001b[A\n",
      "Average Metric: 383 / 941  (40.7):  47%|     | 941/2000 [12:39<13:16,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 942  (40.8):  47%|     | 941/2000 [12:39<13:16,  1.33it/s]\u001b[A\n",
      "Average Metric: 384 / 942  (40.8):  47%|     | 942/2000 [12:39<11:19,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'msuoe' represent when unscrambled? A: analyst B: that C: mouse D: interracial\n",
      "Answer: A: analyst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 384 / 943  (40.7):  47%|     | 942/2000 [12:40<11:19,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 384 / 943  (40.7):  47%|     | 943/2000 [12:40<13:50,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'csehs'. A: manufacturer B: chess C: apply D: nuke\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 944  (40.7):  47%|     | 943/2000 [12:42<13:50,  1.27it/s]\u001b[A\n",
      "Average Metric: 384 / 944  (40.7):  47%|     | 944/2000 [12:42<17:49,  1.01s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 945  (40.6):  47%|     | 944/2000 [12:42<17:49,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ieetrnitvnon' represent when unscrambled? A: thick B: intervention C: overall D: picked\n",
      "Answer: D: picked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mgnaaer' to form the correct word. A: roland B: larger C: cordless D: manager\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 946  (40.7):  47%|     | 945/2000 [12:44<17:48,  1.01s/it]\u001b[A\n",
      "Average Metric: 385 / 946  (40.7):  47%|     | 946/2000 [12:44<19:10,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peessrd'? A: classics B: pressed C: manitoba D: wait\n",
      "Answer: B: pressed\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ftaerhs'. A: finishing B: uniforms C: fathers D: bonds\n",
      "Answer: D: bonds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'lgnodtiue' to form the correct word. A: longitude B: journals C: quote D: competition\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cceanl' to form the correct word. A: sold B: newsletter C: segment D: cancel\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 947  (40.8):  47%|     | 946/2000 [12:46<19:10,  1.09s/it]\u001b[A\n",
      "Average Metric: 386 / 947  (40.8):  47%|     | 947/2000 [12:46<20:32,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 387 / 948  (40.8):  47%|     | 947/2000 [12:46<20:32,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 387 / 948  (40.8):  47%|     | 948/2000 [12:46<16:07,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'frobes' represent when unscrambled? A: trains B: suggestions C: forbes D: vocals\n",
      "Answer: A: trains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 387 / 949  (40.8):  47%|     | 948/2000 [12:47<16:07,  1.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 387 / 949  (40.8):  47%|     | 949/2000 [12:47<18:28,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tisohba' represent when unscrambled? A: lunch B: lamp C: toshiba D: toronto\n",
      "Answer: A: lunch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 387 / 950  (40.7):  47%|     | 949/2000 [12:48<18:28,  1.05s/it]\u001b[A\n",
      "Average Metric: 387 / 950  (40.7):  48%|     | 950/2000 [12:48<17:28,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'qenirnoituase'? A: manner B: tries C: sage D: questionnaire\n",
      "Answer: D: questionnaire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'svriuve'. A: slovak B: arabia C: versus D: survive\n",
      "Answer: D: survive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 388 / 951  (40.8):  48%|     | 950/2000 [12:50<17:28,  1.00it/s]\u001b[A\n",
      "Average Metric: 388 / 951  (40.8):  48%|     | 951/2000 [12:50<22:31,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cnmmacuiote' to form the correct word. A: interface B: communicate C: human D: crossing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 389 / 952  (40.9):  48%|     | 951/2000 [12:51<22:31,  1.29s/it]\u001b[A\n",
      "Average Metric: 389 / 952  (40.9):  48%|     | 952/2000 [12:51<19:02,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 390 / 953  (40.9):  48%|     | 952/2000 [12:51<19:02,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 390 / 953  (40.9):  48%|     | 953/2000 [12:51<14:20,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'poduns'. A: looksmart B: introduction C: pounds D: dies\n",
      "Answer: D: dies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 391 / 954  (41.0):  48%|     | 953/2000 [12:54<14:20,  1.22it/s]\u001b[A\n",
      "Average Metric: 391 / 954  (41.0):  48%|     | 954/2000 [12:54<23:27,  1.35s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 391 / 955  (40.9):  48%|     | 954/2000 [12:54<23:27,  1.35s/it]\u001b[A\n",
      "Average Metric: 391 / 955  (40.9):  48%|     | 955/2000 [12:54<17:36,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 956  (41.0):  48%|     | 955/2000 [12:55<17:36,  1.01s/it]\u001b[A\n",
      "Average Metric: 392 / 956  (41.0):  48%|     | 956/2000 [12:55<17:09,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'giong'. A: transcripts B: accordance C: lodges D: going\n",
      "Answer: D: going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hgneyie'? A: swing B: references C: hygiene D: obtaining\n",
      "Answer: D: obtaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 392 / 957  (41.0):  48%|     | 956/2000 [12:56<17:09,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 392 / 957  (41.0):  48%|     | 957/2000 [12:56<20:27,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 392 / 958  (40.9):  48%|     | 957/2000 [12:56<20:27,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 959  (40.9):  48%|     | 958/2000 [12:57<20:25,  1.18s/it]\u001b[A\n",
      "Average Metric: 392 / 959  (40.9):  48%|     | 959/2000 [12:57<12:01,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'trrnoastiptoan'? A: transportation B: assumptions C: inquiry D: expanding\n",
      "Answer: transportation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 392 / 960  (40.8):  48%|     | 959/2000 [12:57<12:01,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 392 / 960  (40.8):  48%|     | 960/2000 [12:57<09:38,  1.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'psnneeorl'. A: personnel B: referring C: gallon D: hyatt\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 392 / 961  (40.8):  48%|     | 960/2000 [12:58<09:38,  1.80it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 392 / 961  (40.8):  48%|     | 961/2000 [12:58<11:30,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 962  (40.9):  48%|     | 961/2000 [12:58<11:30,  1.50it/s]\u001b[A\n",
      "Average Metric: 393 / 962  (40.9):  48%|     | 962/2000 [12:58<09:27,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fmarol' to form the correct word. A: vice B: formal C: obtained D: photography\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 393 / 963  (40.8):  48%|     | 962/2000 [12:59<09:27,  1.83it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 393 / 963  (40.8):  48%|     | 963/2000 [12:59<12:24,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ttrhneeead' represent when unscrambled? A: museum B: oceania C: threatened D: slut\n",
      "Answer: D: slut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 964  (40.9):  48%|     | 963/2000 [13:00<12:24,  1.39it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 394 / 964  (40.9):  48%|     | 964/2000 [13:00<14:33,  1.19it/s]\u001b[A\n",
      "Average Metric: 394 / 965  (40.8):  48%|     | 964/2000 [13:00<14:33,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tcacital' to form the correct word. A: securely B: tactical C: schemes D: customized\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ceemnt'. A: vacation B: diseases C: cement D: merry\n",
      "Answer: C: cement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lniux'? A: vegetation B: allowance C: linux D: incentive\n",
      "Answer: C: linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'atrs' to form the correct word. A: months B: supplier C: mayor D: arts\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest prime number?  A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hmour' represent when unscrambled? A: viral B: bizarre C: eighth D: humor\n",
      "Answer: D: humor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 394 / 966  (40.8):  48%|     | 965/2000 [13:02<14:33,  1.19it/s]\u001b[A\n",
      "Average Metric: 394 / 966  (40.8):  48%|     | 966/2000 [13:02<16:16,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 395 / 967  (40.8):  48%|     | 966/2000 [13:02<16:16,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 968  (40.9):  48%|     | 967/2000 [13:03<16:15,  1.06it/s]\u001b[A\n",
      "Average Metric: 396 / 968  (40.9):  48%|     | 968/2000 [13:03<10:34,  1.63it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 397 / 969  (41.0):  48%|     | 968/2000 [13:03<10:34,  1.63it/s]\u001b[A\n",
      "Average Metric: 397 / 969  (41.0):  48%|     | 969/2000 [13:03<09:05,  1.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vkolgwesan' represent when unscrambled? A: volkswagen B: cdna C: preview D: glenn\n",
      "Answer: A: volkswagen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gnmoe'. A: gnome B: mirrors C: compact D: tribunal\n",
      "Answer: A: gnome\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'arvired' represent when unscrambled? A: cabin B: counters C: arrived D: proceed\n",
      "Answer: D: proceed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'criale' represent when unscrambled? A: claire B: illustrate C: furthermore D: damages\n",
      "Answer: A: claire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 398 / 970  (41.0):  48%|     | 969/2000 [13:05<09:05,  1.89it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 970  (41.0):  48%|     | 970/2000 [13:05<17:02,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'maeanitrsm'. A: mainstream B: belts C: binding D: proportion\n",
      "Answer: D: proportion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 399 / 971  (41.1):  48%|     | 970/2000 [13:06<17:02,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 399 / 971  (41.1):  49%|     | 971/2000 [13:06<16:27,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bsuty'? A: install B: busty C: diving D: salvador\n",
      "Answer: D: salvador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'fuotrh'. A: cleveland B: searches C: theories D: fourth\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rownened' to form the correct word. A: compute B: gothic C: renowned D: introduces\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 399 / 972  (41.0):  49%|     | 971/2000 [13:09<16:27,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 972  (41.0):  49%|     | 972/2000 [13:09<24:49,  1.45s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 973  (41.0):  49%|     | 972/2000 [13:09<24:49,  1.45s/it]\u001b[A\n",
      "Average Metric: 399 / 973  (41.0):  49%|     | 973/2000 [13:09<19:17,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mmreoy' to form the correct word. A: memory B: norway C: milk D: pressure\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 974  (41.0):  49%|     | 973/2000 [13:12<19:17,  1.13s/it]\u001b[A\n",
      "Average Metric: 399 / 974  (41.0):  49%|     | 974/2000 [13:12<25:14,  1.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 975  (40.9):  49%|     | 974/2000 [13:12<25:14,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 399 / 975  (40.9):  49%|     | 975/2000 [13:12<20:33,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'auldt' to form the correct word. A: remedy B: checking C: kernel D: adult\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'derise'. A: barely B: parents C: bits D: desire\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 976  (40.9):  49%|     | 975/2000 [13:13<20:33,  1.20s/it]\u001b[A\n",
      "Average Metric: 399 / 976  (40.9):  49%|     | 976/2000 [13:13<19:06,  1.12s/it]\u001b[A\n",
      "Average Metric: 399 / 977  (40.8):  49%|     | 976/2000 [13:13<19:06,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 977  (40.8):  49%|     | 977/2000 [13:13<14:53,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'moiauntn' represent when unscrambled? A: yard B: isle C: mountain D: navy\n",
      "Answer: C: mountain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'elemrpoys'. A: optics B: employers C: spotlight D: seat\n",
      "Answer: C: spotlight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cooln'. A: meta B: worked C: beatles D: colon\n",
      "Answer: D: colon\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'elnroscue' represent when unscrambled? A: enclosure B: neat C: uniprotkb D: refinance\n",
      "Answer: A: enclosure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mepg' to form the correct word. A: evaluations B: aged C: mpeg D: oakland\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 399 / 978  (40.8):  49%|     | 977/2000 [13:17<14:53,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 978  (40.8):  49%|     | 978/2000 [13:17<27:51,  1.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 979  (40.8):  49%|     | 978/2000 [13:17<27:51,  1.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 400 / 980  (40.8):  49%|     | 979/2000 [13:18<27:49,  1.64s/it]\u001b[A\n",
      "Average Metric: 400 / 980  (40.8):  49%|     | 980/2000 [13:18<18:59,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 981  (40.9):  49%|     | 980/2000 [13:18<18:59,  1.12s/it]\u001b[A\n",
      "Average Metric: 401 / 981  (40.9):  49%|     | 981/2000 [13:18<16:04,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 982  (40.8):  49%|     | 981/2000 [13:20<16:04,  1.06it/s]\u001b[A\n",
      "Average Metric: 401 / 982  (40.8):  49%|     | 982/2000 [13:20<17:33,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bevieeld' to form the correct word. A: gave B: seeks C: placement D: believed\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 401 / 983  (40.8):  49%|     | 982/2000 [13:20<17:33,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 401 / 983  (40.8):  49%|     | 983/2000 [13:20<14:16,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'onngoig' represent when unscrambled? A: thomas B: inclusion C: cartridge D: ongoing\n",
      "Answer: D: ongoing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 984  (40.8):  49%|     | 983/2000 [13:21<14:16,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 984  (40.8):  49%|     | 984/2000 [13:21<14:51,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 402 / 985  (40.8):  49%|     | 984/2000 [13:21<14:51,  1.14it/s]\u001b[A\n",
      "Average Metric: 402 / 985  (40.8):  49%|     | 985/2000 [13:21<11:25,  1.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sapm'. A: prospects B: spam C: usgs D: tracks\n",
      "Answer: D: tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'terhw' to form the correct word. A: brazilian B: threw C: carlo D: ecommerce\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bratzie'. A: hardcore B: bizrate C: couples D: forwarded\n",
      "Answer: B: bizrate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 402 / 986  (40.8):  49%|     | 985/2000 [13:24<11:25,  1.48it/s]\u001b[A\n",
      "Average Metric: 402 / 986  (40.8):  49%|     | 986/2000 [13:24<20:22,  1.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fcitunnos'. A: proxy B: insure C: browsers D: functions\n",
      "Answer: C: browsers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'aovn' represent when unscrambled? A: sign B: attitudes C: avon D: judgment\n",
      "Answer: D: judgment\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tteints'? A: milf B: tittens C: headsets D: biological\n",
      "Answer: B: tittens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 402 / 987  (40.7):  49%|     | 986/2000 [13:25<20:22,  1.21s/it]\u001b[A\n",
      "Average Metric: 402 / 987  (40.7):  49%|     | 987/2000 [13:25<22:13,  1.32s/it]\u001b[A\n",
      "Average Metric: 403 / 988  (40.8):  49%|     | 987/2000 [13:25<22:13,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 404 / 989  (40.8):  49%|     | 988/2000 [13:26<22:12,  1.32s/it]\u001b[A\n",
      "Average Metric: 404 / 989  (40.8):  49%|     | 989/2000 [13:26<13:47,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 405 / 990  (40.9):  49%|     | 989/2000 [13:26<13:47,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 991  (40.9):  50%|     | 990/2000 [13:26<13:46,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 992  (40.8):  50%|     | 991/2000 [13:26<13:45,  1.22it/s]\u001b[A\n",
      "Average Metric: 405 / 992  (40.8):  50%|     | 992/2000 [13:26<07:15,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 993  (40.9):  50%|     | 992/2000 [13:26<07:15,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 994  (40.8):  50%|     | 993/2000 [13:28<07:15,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 994  (40.8):  50%|     | 994/2000 [13:28<12:23,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 406 / 995  (40.8):  50%|     | 994/2000 [13:29<12:23,  1.35it/s]\u001b[A\n",
      "Average Metric: 406 / 995  (40.8):  50%|     | 995/2000 [13:29<12:31,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 407 / 996  (40.9):  50%|     | 995/2000 [13:29<12:31,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 407 / 996  (40.9):  50%|     | 996/2000 [13:29<10:30,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sahw'. A: tennis B: efficiency C: shaw D: brake\n",
      "Answer: A: tennis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'brigaan' represent when unscrambled? A: bargain B: employee C: sites D: tragedy\n",
      "Answer: A: bargain\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lnad' represent when unscrambled? A: wallace B: singapore C: honest D: land\n",
      "Answer: D: land\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'perlhirepas' represent when unscrambled? A: peripherals B: specialty C: defendant D: adaptation\n",
      "Answer: A: peripherals\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pnnelras' represent when unscrambled? A: rest B: valium C: respiratory D: planners\n",
      "Answer: A: rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 997  (40.9):  50%|     | 996/2000 [13:32<10:30,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 408 / 997  (40.9):  50%|     | 997/2000 [13:32<19:07,  1.14s/it]\u001b[A\n",
      "Average Metric: 408 / 998  (40.9):  50%|     | 997/2000 [13:32<19:07,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 409 / 999  (40.9):  50%|     | 998/2000 [13:33<19:05,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 409 / 999  (40.9):  50%|     | 999/2000 [13:33<12:44,  1.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ecepntixg'? A: expecting B: cracks C: draws D: finals\n",
      "Answer: D: finals\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vrenods'? A: towards B: vendors C: heavy D: disasters\n",
      "Answer: D: disasters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 410 / 1000  (41.0):  50%|     | 999/2000 [13:34<12:44,  1.31it/s]\u001b[A\n",
      "Average Metric: 410 / 1000  (41.0):  50%|     | 1000/2000 [13:34<14:46,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lragset'. A: phpbb B: assessed C: fleece D: largest\n",
      "Answer: D: largest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1001  (41.1):  50%|     | 1000/2000 [13:36<14:46,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 411 / 1001  (41.1):  50%|     | 1001/2000 [13:36<18:16,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'msaks'. A: flats B: masks C: face D: ministry\n",
      "Answer: C: face\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1002  (41.0):  50%|     | 1001/2000 [13:36<18:16,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 411 / 1002  (41.0):  50%|     | 1002/2000 [13:36<15:13,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ciisrs' to form the correct word. A: drive B: depth C: freeman D: crisis\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eentr' represent when unscrambled? A: moves B: enter C: eventually D: barton\n",
      "Answer: B: enter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cnsot'? A: panic B: const C: factory D: trend\n",
      "Answer: B: const\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 411 / 1003  (41.0):  50%|     | 1002/2000 [13:40<15:13,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 411 / 1003  (41.0):  50%|     | 1003/2000 [13:40<27:29,  1.65s/it]\u001b[A\n",
      "Average Metric: 412 / 1004  (41.0):  50%|     | 1003/2000 [13:40<27:29,  1.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 413 / 1005  (41.1):  50%|     | 1004/2000 [13:40<27:27,  1.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 413 / 1005  (41.1):  50%|     | 1005/2000 [13:40<16:53,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pplrue'? A: give B: similar C: purple D: antibody\n",
      "Answer: D: antibody\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 414 / 1006  (41.2):  50%|     | 1005/2000 [13:42<16:53,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 414 / 1006  (41.2):  50%|     | 1006/2000 [13:42<21:42,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 415 / 1007  (41.2):  50%|     | 1006/2000 [13:44<21:42,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 415 / 1007  (41.2):  50%|     | 1007/2000 [13:44<21:57,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'restors' to form the correct word. A: configuring B: ocean C: resorts D: cutting\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pahts'. A: desperate B: paths C: pound D: compatibility\n",
      "Answer: D: compatibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1008  (41.3):  50%|     | 1007/2000 [13:45<21:57,  1.33s/it]\u001b[A\n",
      "Average Metric: 416 / 1008  (41.3):  50%|     | 1008/2000 [13:45<23:01,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'deis' represent when unscrambled? A: traveling B: accredited C: dies D: valuation\n",
      "Answer: A: traveling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1009  (41.2):  50%|     | 1008/2000 [13:47<23:01,  1.39s/it]\u001b[A\n",
      "Average Metric: 416 / 1009  (41.2):  50%|     | 1009/2000 [13:47<21:58,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1010  (41.2):  50%|     | 1009/2000 [13:47<21:58,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 416 / 1010  (41.2):  50%|     | 1010/2000 [13:47<20:01,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ceoimttmes'. A: committees B: nutten C: inspector D: skill\n",
      "Answer: D: skill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 416 / 1011  (41.1):  50%|     | 1010/2000 [13:48<20:01,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 416 / 1011  (41.1):  51%|     | 1011/2000 [13:48<17:30,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cgpaamnhe' represent when unscrambled? A: champagne B: running C: interviewed D: rubber\n",
      "Answer: A: champagne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1012  (41.1):  51%|     | 1011/2000 [13:48<17:30,  1.06s/it]\u001b[A\n",
      "Average Metric: 416 / 1012  (41.1):  51%|     | 1012/2000 [13:48<13:05,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 417 / 1013  (41.2):  51%|     | 1012/2000 [13:48<13:05,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 417 / 1013  (41.2):  51%|     | 1013/2000 [13:49<10:23,  1.58it/s]\u001b[A\n",
      "Average Metric: 418 / 1014  (41.2):  51%|     | 1013/2000 [13:49<10:23,  1.58it/s]\u001b[A\n",
      "Average Metric: 419 / 1015  (41.3):  51%|     | 1014/2000 [13:49<10:22,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1015  (41.3):  51%|     | 1015/2000 [13:49<06:01,  2.73it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 419 / 1016  (41.2):  51%|     | 1015/2000 [13:49<06:01,  2.73it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'eiquienrs'. A: meant B: copper C: enquiries D: berry\n",
      "Answer: C: enquiries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rurnets'. A: returns B: mauritania C: soldiers D: spanish\n",
      "Answer: D: spanish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'slilnpeg' to form the correct word. A: settlement B: spelling C: costume D: graphical\n",
      "Answer: D: graphical\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pimarry'. A: insure B: trials C: conducted D: primary\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gewnaodrutr'? A: critical B: salt C: groundwater D: processor\n",
      "Answer: D: processor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'epxo' represent when unscrambled? A: lady B: expo C: quizzes D: formulas\n",
      "Answer: A: lady\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 1017  (41.2):  51%|     | 1016/2000 [13:54<06:00,  2.73it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1017  (41.2):  51%|     | 1017/2000 [13:54<20:15,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tspeecole' represent when unscrambled? A: sean B: telescope C: retrieval D: qualify\n",
      "Answer: B: telescope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 419 / 1018  (41.2):  51%|     | 1017/2000 [13:55<20:15,  1.24s/it]\u001b[A\n",
      "Average Metric: 419 / 1018  (41.2):  51%|     | 1018/2000 [13:55<20:12,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ppaadnogra' to form the correct word. A: withdrawn B: amino C: cure D: propaganda\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 1019  (41.1):  51%|     | 1018/2000 [13:58<20:12,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1019  (41.1):  51%|     | 1019/2000 [13:58<25:26,  1.56s/it]\u001b[A\n",
      "Average Metric: 419 / 1020  (41.1):  51%|     | 1019/2000 [13:58<25:26,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1020  (41.1):  51%|     | 1020/2000 [13:58<20:04,  1.23s/it]\u001b[A\n",
      "Average Metric: 419 / 1021  (41.0):  51%|     | 1020/2000 [13:58<20:04,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1022  (41.0):  51%|     | 1021/2000 [13:58<20:03,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 419 / 1022  (41.0):  51%|     | 1022/2000 [13:58<12:45,  1.28it/s]\u001b[A\n",
      "Average Metric: 419 / 1023  (41.0):  51%|     | 1022/2000 [13:58<12:45,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'haomnry'. A: findlaw B: vancouver C: physicians D: harmony\n",
      "Answer: D: harmony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sehlf' to form the correct word. A: minds B: shelf C: arctic D: aquarium\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hlelo' to form the correct word. A: politics B: light C: paraguay D: hello\n",
      "Answer: D: hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dteslahcund'? A: commits B: render C: elementary D: deutschland\n",
      "Answer: D: deutschland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 420 / 1024  (41.0):  51%|     | 1023/2000 [14:00<12:44,  1.28it/s]\u001b[A\n",
      "Average Metric: 420 / 1024  (41.0):  51%|     | 1024/2000 [14:00<14:48,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 420 / 1025  (41.0):  51%|     | 1024/2000 [14:01<14:48,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 420 / 1025  (41.0):  51%|    | 1025/2000 [14:01<12:11,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'souuedrrnd'. A: surrounded B: religions C: highlight D: matt\n",
      "Answer: D: matt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 421 / 1026  (41.0):  51%|    | 1025/2000 [14:02<12:11,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 421 / 1026  (41.0):  51%|    | 1026/2000 [14:02<13:15,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crapet'? A: carpet B: attributed C: builders D: gaming\n",
      "Answer: carpet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 421 / 1027  (41.0):  51%|    | 1026/2000 [14:03<13:15,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 421 / 1027  (41.0):  51%|    | 1027/2000 [14:03<13:59,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 1028  (41.1):  51%|    | 1027/2000 [14:03<13:59,  1.16it/s]\u001b[A\n",
      "Average Metric: 422 / 1028  (41.1):  51%|    | 1028/2000 [14:03<11:24,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pnioautblcis' represent when unscrambled? A: publications B: devices C: loved D: pubs\n",
      "Answer: D: pubs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 422 / 1029  (41.0):  51%|    | 1028/2000 [14:04<11:24,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 422 / 1029  (41.0):  51%|    | 1029/2000 [14:05<15:31,  1.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'sitaemnrg'? A: postcards B: blair C: compensation D: streaming\n",
      "Answer: B: blair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wyas'. A: ways B: porn C: painting D: ultra\n",
      "Answer: D: ultra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 1030  (41.0):  51%|    | 1029/2000 [14:06<15:31,  1.04it/s]\u001b[A\n",
      "Average Metric: 422 / 1030  (41.0):  52%|    | 1030/2000 [14:06<19:55,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 423 / 1031  (41.0):  52%|    | 1030/2000 [14:06<19:55,  1.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jmimy' represent when unscrambled? A: colleges B: knows C: jimmy D: maintaining\n",
      "Answer: B: knows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 423 / 1032  (41.0):  52%|    | 1031/2000 [14:08<19:54,  1.23s/it]\u001b[A\n",
      "Average Metric: 423 / 1032  (41.0):  52%|    | 1032/2000 [14:08<17:07,  1.06s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1033  (41.0):  52%|    | 1032/2000 [14:09<17:07,  1.06s/it]\u001b[A\n",
      "Average Metric: 424 / 1033  (41.0):  52%|    | 1033/2000 [14:09<14:57,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1034  (41.0):  52%|    | 1033/2000 [14:09<14:57,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1034  (41.0):  52%|    | 1034/2000 [14:09<12:52,  1.25it/s]\u001b[A\n",
      "Average Metric: 424 / 1035  (41.0):  52%|    | 1034/2000 [14:09<12:52,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mnoore' to form the correct word. A: monroe B: vocal C: anthropology D: commons\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1036  (40.9):  52%|    | 1035/2000 [14:10<12:52,  1.25it/s]\u001b[A\n",
      "Average Metric: 424 / 1036  (40.9):  52%|    | 1036/2000 [14:10<11:00,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bitetr'. A: purely B: casio C: bitter D: profession\n",
      "Answer: D: profession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1037  (40.9):  52%|    | 1036/2000 [14:11<11:00,  1.46it/s]\u001b[A\n",
      "Average Metric: 424 / 1037  (40.9):  52%|    | 1037/2000 [14:11<10:48,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1038  (40.8):  52%|    | 1037/2000 [14:11<10:48,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 424 / 1038  (40.8):  52%|    | 1038/2000 [14:11<09:42,  1.65it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1039  (40.8):  52%|    | 1038/2000 [14:11<09:42,  1.65it/s]\u001b[A\n",
      "Average Metric: 424 / 1039  (40.8):  52%|    | 1039/2000 [14:11<08:16,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1040  (40.8):  52%|    | 1039/2000 [14:11<08:16,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bunrs'. A: mileage B: burns C: addressing D: paragraph\n",
      "Answer: D: paragraph\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'seodomby' to form the correct word. A: gage B: sail C: somebody D: searching\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'acidve'. A: zoning B: nodes C: levy D: advice\n",
      "Answer: D: advice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1041  (40.7):  52%|    | 1040/2000 [14:13<08:16,  1.94it/s]\u001b[A\n",
      "Average Metric: 424 / 1041  (40.7):  52%|    | 1041/2000 [14:13<10:18,  1.55it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 425 / 1042  (40.8):  52%|    | 1041/2000 [14:14<10:18,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 425 / 1042  (40.8):  52%|    | 1042/2000 [14:14<10:07,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'psusy' to form the correct word. A: sandra B: clothes C: pussy D: band\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'oaiinbtng'. A: individually B: motels C: obtaining D: wonder\n",
      "Answer: D: wonder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'isuess'. A: issues B: portions C: fires D: fujitsu\n",
      "Answer: A: issues\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dsik' represent when unscrambled? A: risk B: japanese C: disk D: alito\n",
      "Answer: D: alito\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 425 / 1043  (40.7):  52%|    | 1042/2000 [14:16<10:07,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 425 / 1043  (40.7):  52%|    | 1043/2000 [14:16<16:11,  1.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'enegagd' represent when unscrambled? A: sends B: engaged C: starsmerchant D: spoke\n",
      "Answer: B: engaged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 425 / 1044  (40.7):  52%|    | 1043/2000 [14:17<16:11,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 425 / 1044  (40.7):  52%|    | 1044/2000 [14:17<15:03,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bonld'. A: blond B: businesses C: designer D: streams\n",
      "Answer: D: streams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 426 / 1045  (40.8):  52%|    | 1044/2000 [14:17<15:03,  1.06it/s]\u001b[A\n",
      "Average Metric: 426 / 1045  (40.8):  52%|    | 1045/2000 [14:17<13:26,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lftniig' represent when unscrambled? A: lifting B: talking C: major D: surely\n",
      "Answer: B: talking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 426 / 1046  (40.7):  52%|    | 1045/2000 [14:21<13:26,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "Average Metric: 426 / 1046  (40.7):  52%|    | 1046/2000 [14:21<24:45,  1.56s/it]  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1047  (40.8):  52%|    | 1046/2000 [14:21<24:45,  1.56s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1047  (40.8):  52%|    | 1047/2000 [14:21<20:24,  1.29s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1048  (40.7):  52%|    | 1047/2000 [14:21<20:24,  1.29s/it]\u001b[A\n",
      "Average Metric: 427 / 1048  (40.7):  52%|    | 1048/2000 [14:21<16:00,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 427 / 1049  (40.7):  52%|    | 1048/2000 [14:23<16:00,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 427 / 1049  (40.7):  52%|    | 1049/2000 [14:23<17:07,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1050  (40.8):  52%|    | 1049/2000 [14:24<17:07,  1.08s/it]\u001b[A\n",
      "Average Metric: 428 / 1050  (40.8):  52%|    | 1050/2000 [14:24<17:11,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'byiung'. A: magazines B: raid C: byron D: buying\n",
      "Answer: D: buying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 428 / 1051  (40.7):  52%|    | 1050/2000 [14:25<17:11,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 428 / 1051  (40.7):  53%|    | 1051/2000 [14:25<16:17,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'felemas'? A: corpus B: pour C: math D: females\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'choen' to form the correct word. A: church B: portfolios C: cohen D: networks\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 428 / 1052  (40.7):  53%|    | 1051/2000 [14:26<16:17,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 428 / 1052  (40.7):  53%|    | 1052/2000 [14:26<16:16,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cihps'? A: plymouth B: chips C: nearest D: robot\n",
      "Answer: B: chips\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'miad'. A: maid B: title C: surrounded D: lincoln\n",
      "Answer: D: lincoln\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eruqniy'. A: refinance B: enquiry C: clinical D: sizes\n",
      "Answer: D: sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1053  (40.6):  53%|    | 1052/2000 [14:29<16:16,  1.03s/it]\u001b[A\n",
      "Average Metric: 428 / 1053  (40.6):  53%|    | 1053/2000 [14:29<24:37,  1.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gievs' to form the correct word. A: cigarettes B: ebooks C: tied D: gives\n",
      "Answer: D: gives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1054  (40.6):  53%|    | 1053/2000 [14:29<24:37,  1.56s/it]\u001b[A\n",
      "Average Metric: 428 / 1054  (40.6):  53%|    | 1054/2000 [14:29<21:13,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 428 / 1055  (40.6):  53%|    | 1054/2000 [14:29<21:13,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lctaoe' represent when unscrambled? A: digg B: antenna C: blair D: locate\n",
      "Answer: D: locate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 429 / 1056  (40.6):  53%|    | 1055/2000 [14:32<21:12,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 429 / 1056  (40.6):  53%|    | 1056/2000 [14:32<21:25,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1057  (40.6):  53%|    | 1056/2000 [14:32<21:25,  1.36s/it]\u001b[A\n",
      "Average Metric: 429 / 1057  (40.6):  53%|    | 1057/2000 [14:32<16:44,  1.07s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1058  (40.5):  53%|    | 1057/2000 [14:33<16:44,  1.07s/it]\u001b[A\n",
      "Average Metric: 429 / 1058  (40.5):  53%|    | 1058/2000 [14:33<13:18,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1059  (40.5):  53%|    | 1058/2000 [14:33<13:18,  1.18it/s]\u001b[A\n",
      "Average Metric: 429 / 1059  (40.5):  53%|    | 1059/2000 [14:33<13:06,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tdioiarsvpr'? A: reprint B: break C: feet D: tripadvisor\n",
      "Answer: D: tripadvisor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 429 / 1060  (40.5):  53%|    | 1059/2000 [14:34<13:06,  1.20it/s]\u001b[A\n",
      "Average Metric: 429 / 1060  (40.5):  53%|    | 1060/2000 [14:34<13:21,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 1061  (40.5):  53%|    | 1060/2000 [14:34<13:21,  1.17it/s]\u001b[A\n",
      "Average Metric: 430 / 1061  (40.5):  53%|    | 1061/2000 [14:34<10:13,  1.53it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 1062  (40.5):  53%|    | 1061/2000 [14:35<10:13,  1.53it/s]\u001b[A\n",
      "Average Metric: 430 / 1062  (40.5):  53%|    | 1062/2000 [14:35<08:25,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1063  (40.5):  53%|    | 1062/2000 [14:35<08:25,  1.86it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tkecit'. A: ticket B: axis C: allowing D: devil\n",
      "Answer: A: ticket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 430 / 1063  (40.5):  53%|    | 1063/2000 [14:35<06:56,  2.25it/s]\u001b[A\n",
      "Average Metric: 430 / 1064  (40.4):  53%|    | 1063/2000 [14:35<06:56,  2.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 430 / 1064  (40.4):  53%|    | 1064/2000 [14:35<06:03,  2.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'detoariacln' to form the correct word. A: gently B: declaration C: credit D: york\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'nxet'. A: environment B: jade C: pricing D: next\n",
      "Answer: D: next\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'neods' represent when unscrambled? A: myanmar B: nodes C: adjusted D: gifts\n",
      "Answer: D: gifts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1065  (40.4):  53%|    | 1064/2000 [14:37<06:03,  2.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 1065  (40.4):  53%|    | 1065/2000 [14:37<12:37,  1.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1066  (40.4):  53%|    | 1065/2000 [14:37<12:37,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 431 / 1066  (40.4):  53%|    | 1066/2000 [14:37<10:39,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 431 / 1067  (40.4):  53%|    | 1066/2000 [14:37<10:39,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 431 / 1067  (40.4):  53%|    | 1067/2000 [14:37<08:12,  1.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dmeoinsin'. A: outer B: bound C: found D: dimension\n",
      "Answer: D: dimension\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'carrries'? A: error B: carriers C: east D: yankees\n",
      "Answer: C: east\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 432 / 1068  (40.4):  53%|    | 1067/2000 [14:39<08:12,  1.90it/s]\u001b[A\n",
      "Average Metric: 432 / 1068  (40.4):  53%|    | 1068/2000 [14:39<11:34,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ansbet'. A: ventilation B: apartment C: absent D: obtaining\n",
      "Answer: D: obtaining\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rruteend'. A: housewives B: returned C: scholar D: postal\n",
      "Answer: D: postal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1069  (40.4):  53%|    | 1068/2000 [14:40<11:34,  1.34it/s]\u001b[A\n",
      "Average Metric: 432 / 1069  (40.4):  53%|    | 1069/2000 [14:40<11:41,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dugrs'. A: hearts B: case C: rates D: drugs\n",
      "Answer: D: drugs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 432 / 1070  (40.4):  53%|    | 1069/2000 [14:40<11:41,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 432 / 1070  (40.4):  54%|    | 1070/2000 [14:40<09:37,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 433 / 1071  (40.4):  54%|    | 1070/2000 [14:40<09:37,  1.61it/s]\u001b[A\n",
      "Average Metric: 433 / 1071  (40.4):  54%|    | 1071/2000 [14:40<09:08,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 434 / 1072  (40.5):  54%|    | 1071/2000 [14:41<09:08,  1.69it/s]\u001b[A\n",
      "Average Metric: 434 / 1072  (40.5):  54%|    | 1072/2000 [14:41<08:22,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'plplihis'. A: dramatic B: compliant C: gadgets D: phillips\n",
      "Answer: A: dramatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1073  (40.5):  54%|    | 1072/2000 [14:42<08:22,  1.85it/s]\u001b[A\n",
      "Average Metric: 435 / 1073  (40.5):  54%|    | 1073/2000 [14:42<13:36,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 436 / 1074  (40.6):  54%|    | 1073/2000 [14:44<13:36,  1.14it/s]\u001b[A\n",
      "Average Metric: 436 / 1074  (40.6):  54%|    | 1074/2000 [14:44<14:50,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'whnacitg'. A: watching B: placement C: saddam D: emotion\n",
      "Answer: C: saddam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 436 / 1075  (40.6):  54%|    | 1074/2000 [14:46<14:50,  1.04it/s]\u001b[A\n",
      "Average Metric: 436 / 1075  (40.6):  54%|    | 1075/2000 [14:46<22:03,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'toiraismsnsn' to form the correct word. A: spirituality B: rats C: transmission D: refund\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'signels' to form the correct word. A: margins B: twice C: singles D: allows\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cosonle'? A: console B: broader C: danger D: handed\n",
      "Answer: console\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1076  (40.6):  54%|    | 1075/2000 [14:48<22:03,  1.43s/it]\u001b[A\n",
      "Average Metric: 437 / 1076  (40.6):  54%|    | 1076/2000 [14:48<24:21,  1.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'aeegrs'. A: slower B: subtle C: desirable D: agrees\n",
      "Answer: D: agrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cveor'? A: upgraded B: computers C: cover D: holdings\n",
      "Answer: C: cover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seetl'. A: rentals B: fulfill C: sound D: steel\n",
      "Answer: D: steel\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which is the smallest planet in our solar system? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: Which is the most abundant greenhouse gas in the atmosphere? A: Carbon dioxide B: Methane C: Nitrous oxide D: Water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1077  (40.6):  54%|    | 1076/2000 [14:50<24:21,  1.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1077  (40.6):  54%|    | 1077/2000 [14:50<26:05,  1.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aalrm'? A: bali B: scenes C: climate D: alarm\n",
      "Answer: D: alarm\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ettiny'? A: regulator B: hepatitis C: entity D: were\n",
      "Answer: D: were\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dloube'? A: double B: calculation C: accessible D: entity\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1078  (40.5):  54%|    | 1077/2000 [14:52<26:05,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 437 / 1078  (40.5):  54%|    | 1078/2000 [14:52<29:31,  1.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1079  (40.5):  54%|    | 1078/2000 [14:55<29:31,  1.92s/it]\u001b[A\n",
      "Average Metric: 437 / 1079  (40.5):  54%|    | 1079/2000 [14:55<32:32,  2.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1080  (40.5):  54%|    | 1079/2000 [14:55<32:32,  2.12s/it]\u001b[A\n",
      "Average Metric: 437 / 1080  (40.5):  54%|    | 1080/2000 [14:55<23:29,  1.53s/it]\u001b[A\n",
      "Average Metric: 438 / 1081  (40.5):  54%|    | 1080/2000 [14:56<23:29,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 438 / 1081  (40.5):  54%|    | 1081/2000 [14:56<20:08,  1.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'firnmag'. A: framing B: frontier C: traveling D: carriers\n",
      "Answer: D: carriers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1082  (40.6):  54%|    | 1081/2000 [14:57<20:08,  1.31s/it]\u001b[A\n",
      "Average Metric: 439 / 1082  (40.6):  54%|    | 1082/2000 [14:57<19:57,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1083  (40.5):  54%|    | 1082/2000 [14:57<19:57,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1083  (40.5):  54%|    | 1083/2000 [14:57<14:43,  1.04it/s]\u001b[A\n",
      "Average Metric: 439 / 1084  (40.5):  54%|    | 1083/2000 [14:58<14:43,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'srahaa'. A: discontinued B: pointer C: sahara D: salvador\n",
      "Answer: D: salvador\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'iitencnds'? A: incidents B: physically C: tolerance D: arena\n",
      "Answer: B: physically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1085  (40.5):  54%|    | 1084/2000 [14:58<14:42,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1085  (40.5):  54%|    | 1085/2000 [14:58<11:02,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cnet' to form the correct word. A: jurisdiction B: cent C: organizing D: humanitarian\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cook'. A: cook B: worldcat C: simulated D: boring\n",
      "Answer: C: simulated\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sitiralimy' to form the correct word. A: imagination B: similarity C: decade D: replacing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1086  (40.4):  54%|    | 1085/2000 [15:00<11:02,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1086  (40.4):  54%|    | 1086/2000 [15:00<14:05,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'snniping' to form the correct word. A: showers B: spinning C: scat D: gary\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hvaen' represent when unscrambled? A: criminal B: haven C: coordinated D: finished\n",
      "Answer: A: criminal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'euneepdtrxis' represent when unscrambled? A: accompanying B: lipitor C: expenditures D: brokers\n",
      "Answer: A: accompanying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fgnmaert' to form the correct word. A: putting B: vocabulary C: except D: fragment\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'invenstie'. A: accordingly B: intensive C: given D: arrivals\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1087  (40.4):  54%|    | 1086/2000 [15:02<14:05,  1.08it/s]\u001b[A\n",
      "Average Metric: 439 / 1087  (40.4):  54%|    | 1087/2000 [15:02<18:15,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rcoevered'. A: investigate B: recovered C: queens D: cleveland\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bigegr'? A: exciting B: away C: bigger D: suggest\n",
      "Answer: D: suggest\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'weavs'. A: arabic B: championship C: waves D: investing\n",
      "Answer: D: investing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1088  (40.4):  54%|    | 1087/2000 [15:03<18:15,  1.20s/it]\u001b[A\n",
      "Average Metric: 440 / 1088  (40.4):  54%|    | 1088/2000 [15:03<16:29,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'laantis'? A: latinas B: fiction C: irish D: univ\n",
      "Answer: D: univ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1089  (40.4):  54%|    | 1088/2000 [15:03<16:29,  1.08s/it]\u001b[A\n",
      "Average Metric: 440 / 1089  (40.4):  54%|    | 1089/2000 [15:03<14:03,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 440 / 1090  (40.4):  54%|    | 1089/2000 [15:03<14:03,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 440 / 1091  (40.3):  55%|    | 1090/2000 [15:04<14:02,  1.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1091  (40.3):  55%|    | 1091/2000 [15:04<09:32,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 441 / 1092  (40.4):  55%|    | 1091/2000 [15:06<09:32,  1.59it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 441 / 1092  (40.4):  55%|    | 1092/2000 [15:06<16:34,  1.10s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 442 / 1093  (40.4):  55%|    | 1092/2000 [15:07<16:34,  1.10s/it]\u001b[A\n",
      "Average Metric: 442 / 1093  (40.4):  55%|    | 1093/2000 [15:07<13:31,  1.12it/s]\u001b[A\n",
      "Average Metric: 442 / 1094  (40.4):  55%|    | 1093/2000 [15:07<13:31,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 442 / 1094  (40.4):  55%|    | 1094/2000 [15:07<11:20,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 1095  (40.5):  55%|    | 1094/2000 [15:07<11:20,  1.33it/s]\u001b[A\n",
      "Average Metric: 443 / 1095  (40.5):  55%|    | 1095/2000 [15:07<10:03,  1.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1096  (40.5):  55%|    | 1095/2000 [15:08<10:03,  1.50it/s]\u001b[A\n",
      "Average Metric: 444 / 1096  (40.5):  55%|    | 1096/2000 [15:08<08:23,  1.79it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1097  (40.5):  55%|    | 1096/2000 [15:10<08:23,  1.79it/s]\u001b[A\n",
      "Average Metric: 444 / 1097  (40.5):  55%|    | 1097/2000 [15:10<14:35,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iupnt'. A: because B: input C: triangle D: highly\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tnak' represent when unscrambled? A: hired B: tank C: planting D: chick\n",
      "Answer: A: hired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'siltlhgy'. A: slightly B: because C: eventually D: motorcycles\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'itnenlcgeile'. A: enable B: operate C: intelligence D: roger\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ciyclng'. A: cookie B: crying C: cycling D: discount\n",
      "Answer: C: cycling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1098  (40.5):  55%|    | 1097/2000 [15:12<14:35,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 445 / 1098  (40.5):  55%|    | 1098/2000 [15:12<18:42,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'simga' to form the correct word. A: handjob B: retreat C: sigma D: opinions\n",
      "Answer: D: opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'inceefulnd'. A: benz B: integral C: influenced D: brother\n",
      "Answer: D: brother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'potls' to form the correct word. A: plots B: injuries C: nation D: sized\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wllas' to form the correct word. A: cornwall B: accredited C: walls D: insufficient\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1099  (40.5):  55%|    | 1098/2000 [15:14<18:42,  1.24s/it]\u001b[A\n",
      "Average Metric: 445 / 1099  (40.5):  55%|    | 1099/2000 [15:14<22:02,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'inheernt'? A: inherent B: database C: possible D: changed\n",
      "Answer: A: inherent\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'riogen'. A: hear B: region C: severe D: academy\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1100  (40.5):  55%|    | 1099/2000 [15:16<22:02,  1.47s/it]\u001b[A\n",
      "Average Metric: 445 / 1100  (40.5):  55%|    | 1100/2000 [15:16<25:09,  1.68s/it]\u001b[A\n",
      "Average Metric: 445 / 1101  (40.4):  55%|    | 1100/2000 [15:16<25:09,  1.68s/it]\u001b[A\n",
      "Average Metric: 445 / 1101  (40.4):  55%|    | 1101/2000 [15:16<19:46,  1.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'comoomshre'? A: indexed B: hebrew C: chromosome D: offence\n",
      "Answer: indexed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 445 / 1102  (40.4):  55%|    | 1101/2000 [15:18<19:46,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 445 / 1102  (40.4):  55%|    | 1102/2000 [15:18<20:30,  1.37s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1103  (40.3):  55%|    | 1102/2000 [15:18<20:30,  1.37s/it]\u001b[A\n",
      "Average Metric: 445 / 1103  (40.3):  55%|    | 1103/2000 [15:18<14:57,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Average Metric: 446 / 1104  (40.4):  55%|    | 1103/2000 [15:19<14:57,  1.00s/it]Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "\u001b[A\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Average Metric: 446 / 1104  (40.4):  55%|    | 1104/2000 [15:19<14:27,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 447 / 1105  (40.5):  55%|    | 1104/2000 [15:19<14:27,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 447 / 1105  (40.5):  55%|    | 1105/2000 [15:19<11:34,  1.29it/s]\u001b[A\n",
      "Average Metric: 447 / 1106  (40.4):  55%|    | 1105/2000 [15:20<11:34,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 447 / 1106  (40.4):  55%|    | 1106/2000 [15:20<12:08,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 448 / 1107  (40.5):  55%|    | 1106/2000 [15:20<12:08,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 448 / 1108  (40.4):  55%|    | 1107/2000 [15:21<12:07,  1.23it/s]\u001b[A\n",
      "Average Metric: 448 / 1108  (40.4):  55%|    | 1108/2000 [15:21<09:05,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pvscipotree'. A: pond B: allergy C: prospective D: affiliates\n",
      "Answer: pond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 448 / 1109  (40.4):  55%|    | 1108/2000 [15:21<09:05,  1.64it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 448 / 1109  (40.4):  55%|    | 1109/2000 [15:21<08:22,  1.77it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 449 / 1110  (40.5):  55%|    | 1109/2000 [15:21<08:22,  1.77it/s]\u001b[A\n",
      "Average Metric: 449 / 1110  (40.5):  56%|    | 1110/2000 [15:21<06:41,  2.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1111  (40.5):  56%|    | 1110/2000 [15:22<06:41,  2.22it/s]\u001b[A\n",
      "Average Metric: 450 / 1111  (40.5):  56%|    | 1111/2000 [15:22<06:16,  2.36it/s]\u001b[A\n",
      "Average Metric: 450 / 1112  (40.5):  56%|    | 1111/2000 [15:22<06:16,  2.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 450 / 1112  (40.5):  56%|    | 1112/2000 [15:22<05:46,  2.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'seakpres'? A: juvenile B: speakers C: saturn D: pamela\n",
      "Answer: B: speakers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1113  (40.4):  56%|    | 1112/2000 [15:25<05:46,  2.57it/s]\u001b[A\n",
      "Average Metric: 450 / 1113  (40.4):  56%|    | 1113/2000 [15:25<16:23,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'reeval' represent when unscrambled? A: muze B: reveal C: intensity D: recommends\n",
      "Answer: B: reveal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'srndaes'. A: sanders B: homes C: statutes D: comfortable\n",
      "Answer: D: comfortable\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'caorton' represent when unscrambled? A: donald B: reimbursement C: glance D: cartoon\n",
      "Answer: C: glance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cnonfiecde' to form the correct word. A: rebecca B: parameters C: harmony D: confidence\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'kosntgin'. A: kingston B: kenny C: bryant D: duncan\n",
      "Answer: D: duncan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 1114  (40.5):  56%|    | 1113/2000 [15:27<16:23,  1.11s/it]\u001b[A\n",
      "Average Metric: 451 / 1114  (40.5):  56%|    | 1114/2000 [15:27<22:07,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1115  (40.5):  56%|    | 1114/2000 [15:27<22:07,  1.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 452 / 1116  (40.5):  56%|    | 1115/2000 [15:27<22:06,  1.50s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1116  (40.5):  56%|    | 1116/2000 [15:27<12:38,  1.16it/s]\u001b[A\n",
      "Average Metric: 452 / 1117  (40.5):  56%|    | 1116/2000 [15:27<12:38,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'denatl'. A: player B: barriers C: montgomery D: dental\n",
      "Answer: C: montgomery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1118  (40.4):  56%|    | 1117/2000 [15:29<12:38,  1.16it/s]\u001b[A\n",
      "Average Metric: 452 / 1118  (40.4):  56%|    | 1118/2000 [15:29<13:35,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1119  (40.4):  56%|    | 1118/2000 [15:31<13:35,  1.08it/s]\u001b[A\n",
      "Average Metric: 452 / 1119  (40.4):  56%|    | 1119/2000 [15:31<15:44,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1120  (40.4):  56%|    | 1119/2000 [15:32<15:44,  1.07s/it]\u001b[A\n",
      "Average Metric: 452 / 1120  (40.4):  56%|    | 1120/2000 [15:32<14:02,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 453 / 1121  (40.4):  56%|    | 1120/2000 [15:33<14:02,  1.04it/s]\u001b[A\n",
      "Average Metric: 453 / 1121  (40.4):  56%|    | 1121/2000 [15:33<16:26,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'prael'. A: pearl B: monitored C: organizing D: hung\n",
      "Answer: D: hung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 453 / 1122  (40.4):  56%|    | 1121/2000 [15:34<16:26,  1.12s/it]\u001b[A\n",
      "Average Metric: 453 / 1122  (40.4):  56%|    | 1122/2000 [15:34<14:33,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lkae'. A: precisely B: fusion C: cancellation D: lake\n",
      "Answer: D: lake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'prdie'. A: anymore B: ought C: pride D: winchester\n",
      "Answer: C: pride\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 453 / 1123  (40.3):  56%|    | 1122/2000 [15:35<14:33,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 453 / 1123  (40.3):  56%|    | 1123/2000 [15:35<16:36,  1.14s/it]\u001b[A\n",
      "Average Metric: 454 / 1124  (40.4):  56%|    | 1123/2000 [15:36<16:36,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 454 / 1124  (40.4):  56%|    | 1124/2000 [15:36<13:03,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rlaond'. A: ronald B: lecturer C: failure D: ensure\n",
      "Answer: A: ronald\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'htdimuiy' to form the correct word. A: appear B: humidity C: vancouver D: debugging\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gsealss'. A: surge B: thorough C: cash D: glasses\n",
      "Answer: D: glasses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'bsais'. A: basis B: religious C: ladies D: tries\n",
      "Answer: A: basis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'puond' to form the correct word. A: sarah B: pound C: brett D: stood\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pihl'? A: survival B: phil C: memorandum D: restore\n",
      "Answer: A: survival\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 454 / 1125  (40.4):  56%|    | 1124/2000 [15:38<13:03,  1.12it/s]\u001b[A\n",
      "Average Metric: 454 / 1125  (40.4):  56%|    | 1125/2000 [15:38<17:09,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fuor' represent when unscrambled? A: four B: stayed C: assistant D: derivative\n",
      "Answer: D: derivative\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'trhu' to form the correct word. A: avalon B: thru C: thompson D: institute\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bsas'? A: campaigns B: fits C: matters D: bass\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 454 / 1126  (40.3):  56%|    | 1125/2000 [15:39<17:09,  1.18s/it]\u001b[A\n",
      "Average Metric: 454 / 1126  (40.3):  56%|    | 1126/2000 [15:39<18:45,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 454 / 1127  (40.3):  56%|    | 1126/2000 [15:40<18:45,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 454 / 1127  (40.3):  56%|    | 1127/2000 [15:40<15:29,  1.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cdotoniaiersn'. A: forbidden B: consideration C: katrina D: chess\n",
      "Answer: D: chess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'reicpenit'. A: aaron B: cheaper C: chile D: recipient\n",
      "Answer: D: recipient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'chmhaopisipns'? A: detectors B: championships C: outer D: competitions\n",
      "Answer: D: competitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'prok' to form the correct word. A: emotion B: byte C: ranked D: pork\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 454 / 1128  (40.2):  56%|    | 1127/2000 [15:42<15:29,  1.07s/it]\u001b[A\n",
      "Average Metric: 454 / 1128  (40.2):  56%|    | 1128/2000 [15:42<22:12,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1129  (40.3):  56%|    | 1128/2000 [15:43<22:12,  1.53s/it]\u001b[A\n",
      "Average Metric: 455 / 1129  (40.3):  56%|    | 1129/2000 [15:43<17:22,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 456 / 1130  (40.4):  56%|    | 1129/2000 [15:44<17:22,  1.20s/it]\u001b[A\n",
      "Average Metric: 456 / 1130  (40.4):  56%|    | 1130/2000 [15:44<16:09,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 457 / 1131  (40.4):  56%|    | 1130/2000 [15:44<16:09,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 457 / 1131  (40.4):  57%|    | 1131/2000 [15:44<12:51,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1132  (40.5):  57%|    | 1131/2000 [15:45<12:51,  1.13it/s]\u001b[A\n",
      "Average Metric: 458 / 1132  (40.5):  57%|    | 1132/2000 [15:45<13:07,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 458 / 1133  (40.4):  57%|    | 1132/2000 [15:46<13:07,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 458 / 1133  (40.4):  57%|    | 1133/2000 [15:46<12:18,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1134  (40.4):  57%|    | 1133/2000 [15:46<12:18,  1.17it/s]\u001b[A\n",
      "Average Metric: 458 / 1134  (40.4):  57%|    | 1134/2000 [15:46<09:10,  1.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'geilbrt' to form the correct word. A: gilbert B: anatomy C: petersburg D: dollars\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1135  (40.4):  57%|    | 1134/2000 [15:46<09:10,  1.57it/s]\u001b[A\n",
      "Average Metric: 459 / 1136  (40.4):  57%|    | 1135/2000 [15:46<09:10,  1.57it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 459 / 1136  (40.4):  57%|    | 1136/2000 [15:46<05:51,  2.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 459 / 1137  (40.4):  57%|    | 1136/2000 [15:48<05:51,  2.46it/s]\u001b[A\n",
      "Average Metric: 459 / 1137  (40.4):  57%|    | 1137/2000 [15:48<10:07,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'iioertnr' to form the correct word. A: compute B: journalists C: used D: interior\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'iiandns' to form the correct word. A: indians B: dolls C: battery D: presidents\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1138  (40.4):  57%|    | 1137/2000 [15:49<10:07,  1.42it/s]\u001b[A\n",
      "Average Metric: 460 / 1138  (40.4):  57%|    | 1138/2000 [15:49<11:49,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nsdaaq'? A: shakira B: nasdaq C: mechanical D: newsletters\n",
      "Answer: nasdaq\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'datone'? A: hats B: airports C: prepare D: donate\n",
      "Answer: D: donate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'teihr'. A: wagner B: their C: constitute D: sciences\n",
      "Answer: w\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'shtos'? A: biol B: confidence C: shots D: democratic\n",
      "Answer: D: democratic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1139  (40.4):  57%|    | 1138/2000 [15:51<11:49,  1.21it/s]\u001b[A\n",
      "Average Metric: 460 / 1139  (40.4):  57%|    | 1139/2000 [15:51<17:22,  1.21s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1140  (40.4):  57%|    | 1139/2000 [15:51<17:22,  1.21s/it]\u001b[A\n",
      "Average Metric: 460 / 1140  (40.4):  57%|    | 1140/2000 [15:51<13:57,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1141  (40.3):  57%|    | 1140/2000 [15:53<13:57,  1.03it/s]\u001b[A\n",
      "Average Metric: 460 / 1141  (40.3):  57%|    | 1141/2000 [15:53<16:27,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1142  (40.3):  57%|    | 1141/2000 [15:54<16:27,  1.15s/it]\u001b[A\n",
      "Average Metric: 460 / 1142  (40.3):  57%|    | 1142/2000 [15:54<15:06,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 461 / 1143  (40.3):  57%|    | 1142/2000 [15:55<15:06,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 461 / 1143  (40.3):  57%|    | 1143/2000 [15:55<13:29,  1.06it/s]\u001b[A\n",
      "Average Metric: 462 / 1144  (40.4):  57%|    | 1143/2000 [15:57<13:29,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 462 / 1144  (40.4):  57%|    | 1144/2000 [15:57<18:46,  1.32s/it]\u001b[A\n",
      "Average Metric: 462 / 1145  (40.3):  57%|    | 1144/2000 [15:57<18:46,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 462 / 1145  (40.3):  57%|    | 1145/2000 [15:57<15:55,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 462 / 1146  (40.3):  57%|    | 1145/2000 [16:00<15:55,  1.12s/it]\u001b[A\n",
      "Average Metric: 462 / 1146  (40.3):  57%|    | 1146/2000 [16:00<22:55,  1.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 463 / 1147  (40.4):  57%|    | 1146/2000 [16:01<22:55,  1.61s/it]\u001b[A\n",
      "Average Metric: 463 / 1147  (40.4):  57%|    | 1147/2000 [16:01<17:48,  1.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jstiiefud' represent when unscrambled? A: detection B: holmes C: compete D: justified\n",
      "Answer: D: justified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 464 / 1148  (40.4):  57%|    | 1147/2000 [16:01<17:48,  1.25s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1148  (40.4):  57%|    | 1148/2000 [16:01<15:14,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'inimvoprg'? A: kathy B: algeria C: improving D: html\n",
      "Answer: D: html\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dplaisy' to form the correct word. A: establish B: certificate C: formulation D: display\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'flolew'? A: libya B: featured C: fellow D: automated\n",
      "Answer: D: automated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rpae'. A: bicycle B: fans C: halloween D: rape\n",
      "Answer: D: rape\n",
      "\n",
      "Question: What is the capital of France? A: Berlin B: Paris C: Rome D: Madrid\n",
      "Answer: B: Paris\n",
      "\n",
      "Question: What is the smallest planet in our solar system? A: Jupiter B: Venus C: Mars D: Mercury\n",
      "Answer: D: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: What is the smallest country in the world? A: Vatican City B: Monaco C: San Marino D: Nauru\n",
      "Answer: D:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1149  (40.5):  57%|    | 1148/2000 [16:02<15:14,  1.07s/it]\u001b[A\n",
      "Average Metric: 465 / 1149  (40.5):  57%|    | 1149/2000 [16:02<14:52,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1150  (40.4):  57%|    | 1149/2000 [16:03<14:52,  1.05s/it]\u001b[A\n",
      "Average Metric: 465 / 1150  (40.4):  57%|    | 1150/2000 [16:03<14:06,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'afcira'. A: refugee B: entertainment C: worm D: africa\n",
      "Answer: D: africa\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pduerroce'. A: procedure B: herbert C: blanket D: consultant\n",
      "Answer: D: consultant\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'caopmnhis'. A: discussing B: champions C: neglect D: kills\n",
      "Answer: D: kills\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 466 / 1151  (40.5):  57%|    | 1150/2000 [16:05<14:06,  1.00it/s]\u001b[A\n",
      "Average Metric: 466 / 1151  (40.5):  58%|    | 1151/2000 [16:05<16:04,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cwrnaoll' represent when unscrambled? A: cornwall B: ranging C: involves D: jets\n",
      "Answer: A: cornwall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'edslnes'. A: testing B: endless C: beer D: wires\n",
      "Answer: D: wires\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 467 / 1152  (40.5):  58%|    | 1151/2000 [16:08<16:04,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 467 / 1152  (40.5):  58%|    | 1152/2000 [16:08<27:06,  1.92s/it]\u001b[A\n",
      "Average Metric: 467 / 1153  (40.5):  58%|    | 1152/2000 [16:08<27:06,  1.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pnrmosiesis'. A: guru B: sanders C: permissions D: purchasing\n",
      "Answer: guru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 467 / 1153  (40.5):  58%|    | 1153/2000 [16:08<19:41,  1.39s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 1154  (40.5):  58%|    | 1153/2000 [16:09<19:41,  1.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 467 / 1155  (40.4):  58%|    | 1154/2000 [16:09<19:39,  1.39s/it]\u001b[A\n",
      "Average Metric: 467 / 1155  (40.4):  58%|    | 1155/2000 [16:09<10:58,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 1156  (40.4):  58%|    | 1155/2000 [16:09<10:58,  1.28it/s]\u001b[A\n",
      "Average Metric: 467 / 1156  (40.4):  58%|    | 1156/2000 [16:09<10:29,  1.34it/s]\u001b[A\n",
      "Average Metric: 467 / 1157  (40.4):  58%|    | 1156/2000 [16:09<10:29,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rtia'. A: rita B: plug C: trackbacks D: patience\n",
      "Answer: A: rita\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stealte'. A: madison B: rocket C: claimed D: seattle\n",
      "Answer: A: madison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 1158  (40.3):  58%|    | 1157/2000 [16:10<10:28,  1.34it/s]\u001b[A\n",
      "Average Metric: 467 / 1158  (40.3):  58%|    | 1158/2000 [16:10<09:12,  1.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tirvia'. A: azerbaijan B: outsourcing C: bride D: trivia\n",
      "Answer: D: trivia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 467 / 1159  (40.3):  58%|    | 1158/2000 [16:11<09:12,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 467 / 1159  (40.3):  58%|    | 1159/2000 [16:11<08:59,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 468 / 1160  (40.3):  58%|    | 1159/2000 [16:12<08:59,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 468 / 1160  (40.3):  58%|    | 1160/2000 [16:12<11:53,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1161  (40.3):  58%|    | 1160/2000 [16:13<11:53,  1.18it/s]\u001b[A\n",
      "Average Metric: 468 / 1161  (40.3):  58%|    | 1161/2000 [16:13<10:24,  1.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'renoigal' to form the correct word. A: elvis B: wichita C: look D: regional\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1162  (40.3):  58%|    | 1161/2000 [16:13<10:24,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 468 / 1162  (40.3):  58%|    | 1162/2000 [16:13<08:21,  1.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'hreats'. A: frequently B: from C: sources D: hearts\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cpmetuor'. A: george B: prayer C: coin D: computer\n",
      "Answer: D: computer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'muacrs' to form the correct word. A: arrivals B: experimental C: carl D: marcus\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 469 / 1163  (40.3):  58%|    | 1162/2000 [16:14<08:21,  1.67it/s]\u001b[A\n",
      "Average Metric: 469 / 1163  (40.3):  58%|    | 1163/2000 [16:14<10:05,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'reeitlar'? A: average B: retailer C: parks D: instances\n",
      "Answer: B: retailer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 469 / 1164  (40.3):  58%|    | 1163/2000 [16:17<10:05,  1.38it/s]\u001b[A\n",
      "Average Metric: 469 / 1164  (40.3):  58%|    | 1164/2000 [16:17<20:31,  1.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'folor'. A: empire B: poem C: floor D: cruz\n",
      "Answer: D: cruz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'magasacdar' represent when unscrambled? A: displayed B: madagascar C: cultures D: equipped\n",
      "Answer: B: madagascar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1165  (40.3):  58%|    | 1164/2000 [16:20<20:31,  1.47s/it]\u001b[A\n",
      "Average Metric: 470 / 1165  (40.3):  58%|    | 1165/2000 [16:20<23:35,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'varetiy'. A: staffing B: falling C: variety D: india\n",
      "Answer: D: india\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1166  (40.4):  58%|    | 1165/2000 [16:20<23:35,  1.70s/it]\u001b[A\n",
      "Average Metric: 471 / 1166  (40.4):  58%|    | 1166/2000 [16:20<18:02,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 472 / 1167  (40.4):  58%|    | 1166/2000 [16:21<18:02,  1.30s/it]\u001b[A\n",
      "Average Metric: 472 / 1167  (40.4):  58%|    | 1167/2000 [16:21<15:02,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 473 / 1168  (40.5):  58%|    | 1167/2000 [16:21<15:02,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 473 / 1168  (40.5):  58%|    | 1168/2000 [16:21<12:14,  1.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'eivl'. A: nationwide B: lack C: jewel D: evil\n",
      "Answer: D: evil\n",
      "\n",
      "Question: Which is the smallest value?  A: 0.1  B: 0.01  C: 0.001  D: 0.0001\n",
      "Answer: D: 0.0001\n",
      "\n",
      "Question: Which is the third biggest value?  A: 0.1  B: 0.01  C: 0.001  D: 0.0001\n",
      "Answer: C: 0.001\n",
      "\n",
      "Question: Which is the biggest value?  A: 0.1  B: 0.01  C: 0.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1169  (40.5):  58%|    | 1168/2000 [16:22<12:14,  1.13it/s]\u001b[A\n",
      "Average Metric: 473 / 1169  (40.5):  58%|    | 1169/2000 [16:22<12:57,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'arighltom'. A: algorithm B: fight C: refugees D: richardson\n",
      "Answer: D: richardson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 473 / 1170  (40.4):  58%|    | 1169/2000 [16:23<12:57,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 473 / 1170  (40.4):  58%|    | 1170/2000 [16:23<13:19,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'prriodevs'. A: providers B: trains C: markets D: surname\n",
      "Answer: C: markets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1171  (40.4):  58%|    | 1170/2000 [16:25<13:19,  1.04it/s]\u001b[A\n",
      "Average Metric: 473 / 1171  (40.4):  59%|    | 1171/2000 [16:25<17:26,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pmrriliay'. A: ideal B: primarily C: stylish D: lesson\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1172  (40.4):  59%|    | 1171/2000 [16:26<17:26,  1.26s/it]\u001b[A\n",
      "Average Metric: 473 / 1172  (40.4):  59%|    | 1172/2000 [16:26<15:15,  1.11s/it]\u001b[A\n",
      "Average Metric: 473 / 1173  (40.3):  59%|    | 1172/2000 [16:27<15:15,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1173  (40.3):  59%|    | 1173/2000 [16:27<15:30,  1.12s/it]\u001b[A\n",
      "Average Metric: 473 / 1174  (40.3):  59%|    | 1173/2000 [16:27<15:30,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pfromrenig'. A: ipod B: clerk C: performing D: suspected\n",
      "Answer: D: suspected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1175  (40.3):  59%|    | 1174/2000 [16:29<15:29,  1.12s/it]\u001b[A\n",
      "Average Metric: 473 / 1175  (40.3):  59%|    | 1175/2000 [16:29<15:40,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bbaes'. A: scandal B: babes C: store D: police\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sults' represent when unscrambled? A: rays B: sluts C: scandal D: ripe\n",
      "Answer: D: ripe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lnhugiag'. A: proceed B: provider C: cutting D: laughing\n",
      "Answer: D: laughing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'vtores' to form the correct word. A: tracks B: atom C: voters D: idea\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 473 / 1176  (40.2):  59%|    | 1175/2000 [16:31<15:40,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 473 / 1176  (40.2):  59%|    | 1176/2000 [16:31<18:41,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'avreirs'? A: traditional B: considerably C: unofficial D: arrives\n",
      "Answer: D: arrives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 474 / 1177  (40.3):  59%|    | 1176/2000 [16:32<18:41,  1.36s/it]\u001b[A\n",
      "Average Metric: 474 / 1177  (40.3):  59%|    | 1177/2000 [16:32<15:18,  1.12s/it]\u001b[A\n",
      "Average Metric: 475 / 1178  (40.3):  59%|    | 1177/2000 [16:32<15:18,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 475 / 1178  (40.3):  59%|    | 1178/2000 [16:32<11:48,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'snata'. A: genes B: housewares C: bubble D: santa\n",
      "Answer: D: santa\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tebus'? A: tubes B: manga C: condition D: linux\n",
      "Answer: B: manga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 475 / 1179  (40.3):  59%|    | 1178/2000 [16:32<11:48,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 475 / 1179  (40.3):  59%|    | 1179/2000 [16:32<10:10,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 476 / 1180  (40.3):  59%|    | 1179/2000 [16:33<10:10,  1.35it/s]\u001b[A\n",
      "Average Metric: 476 / 1180  (40.3):  59%|    | 1180/2000 [16:33<08:35,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 476 / 1181  (40.3):  59%|    | 1180/2000 [16:33<08:35,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 476 / 1181  (40.3):  59%|    | 1181/2000 [16:33<08:01,  1.70it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'conseufd'. A: josh B: confused C: groundwater D: smart\n",
      "Answer: D: smart\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cicuotrotnsn' represent when unscrambled? A: yukon B: construction C: from D: organic\n",
      "Answer: C: from\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lveles' represent when unscrambled? A: addresses B: stylus C: jewish D: levels\n",
      "Answer: D: levels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 476 / 1182  (40.3):  59%|    | 1181/2000 [16:35<08:01,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 476 / 1182  (40.3):  59%|    | 1182/2000 [16:35<13:56,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1183  (40.3):  59%|    | 1182/2000 [16:36<13:56,  1.02s/it]\u001b[A\n",
      "Average Metric: 477 / 1183  (40.3):  59%|    | 1183/2000 [16:36<12:14,  1.11it/s]\u001b[A\n",
      "Average Metric: 478 / 1184  (40.4):  59%|    | 1183/2000 [16:36<12:14,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 478 / 1185  (40.3):  59%|    | 1184/2000 [16:36<12:13,  1.11it/s]\u001b[A\n",
      "Average Metric: 478 / 1185  (40.3):  59%|    | 1185/2000 [16:36<07:25,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'coallr' to form the correct word. A: occupancy B: holmes C: yemen D: collar\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'spudneesd' represent when unscrambled? A: professional B: readily C: milfhunter D: suspended\n",
      "Answer: A: professional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 479 / 1186  (40.4):  59%|    | 1185/2000 [16:37<07:25,  1.83it/s]\u001b[A\n",
      "Average Metric: 479 / 1186  (40.4):  59%|    | 1186/2000 [16:37<10:00,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1187  (40.4):  59%|    | 1186/2000 [16:38<10:00,  1.36it/s]\u001b[A\n",
      "Average Metric: 480 / 1187  (40.4):  59%|    | 1187/2000 [16:38<07:54,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seed'. A: binding B: seed C: column D: alphabetical\n",
      "Answer: A: binding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gmmaa' represent when unscrambled? A: daytona B: gamma C: mastercard D: exchange\n",
      "Answer: A: daytona\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rsulets' to form the correct word. A: results B: variations C: potential D: tuner\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'maeixcn' to form the correct word. A: mexican B: dock C: scream D: missed\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 480 / 1188  (40.4):  59%|    | 1187/2000 [16:41<07:54,  1.71it/s]\u001b[A\n",
      "Average Metric: 480 / 1188  (40.4):  59%|    | 1188/2000 [16:41<17:31,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1189  (40.4):  59%|    | 1188/2000 [16:42<17:31,  1.30s/it]\u001b[A\n",
      "Average Metric: 480 / 1189  (40.4):  59%|    | 1189/2000 [16:42<17:17,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 1190  (40.4):  59%|    | 1189/2000 [16:43<17:17,  1.28s/it]\u001b[A\n",
      "Average Metric: 481 / 1190  (40.4):  60%|    | 1190/2000 [16:43<15:14,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tbue'. A: arrives B: tube C: expenditures D: italy\n",
      "Answer: A: arrives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 481 / 1191  (40.4):  60%|    | 1190/2000 [16:43<15:14,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 481 / 1191  (40.4):  60%|    | 1191/2000 [16:43<13:01,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 1192  (40.4):  60%|    | 1191/2000 [16:45<13:01,  1.03it/s]\u001b[A\n",
      "Average Metric: 481 / 1192  (40.4):  60%|    | 1192/2000 [16:45<14:05,  1.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tpoic' to form the correct word. A: detection B: topic C: participation D: brazil\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 482 / 1193  (40.4):  60%|    | 1192/2000 [16:45<14:05,  1.05s/it]\u001b[A\n",
      "Average Metric: 482 / 1193  (40.4):  60%|    | 1193/2000 [16:45<11:55,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 482 / 1194  (40.4):  60%|    | 1193/2000 [16:46<11:55,  1.13it/s]\u001b[A\n",
      "Average Metric: 482 / 1194  (40.4):  60%|    | 1194/2000 [16:46<11:01,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'connairtes'? A: inspiration B: joke C: vector D: containers\n",
      "Answer: D: containers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pors' represent when unscrambled? A: victorian B: pros C: monte D: filtering\n",
      "Answer: A: victorian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ogcnoloy' to form the correct word. A: sunglasses B: sands C: quotations D: oncology\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 482 / 1195  (40.3):  60%|    | 1194/2000 [16:48<11:01,  1.22it/s]\u001b[A\n",
      "Average Metric: 482 / 1195  (40.3):  60%|    | 1195/2000 [16:48<16:45,  1.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 483 / 1196  (40.4):  60%|    | 1195/2000 [16:49<16:45,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 483 / 1196  (40.4):  60%|    | 1196/2000 [16:49<14:20,  1.07s/it]\u001b[A\n",
      "Average Metric: 484 / 1197  (40.4):  60%|    | 1196/2000 [16:49<14:20,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 484 / 1197  (40.4):  60%|    | 1197/2000 [16:49<13:03,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bwrose' represent when unscrambled? A: bell B: transcription C: browse D: gene\n",
      "Answer: C: browse"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 484 / 1198  (40.4):  60%|    | 1197/2000 [16:52<13:03,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 484 / 1198  (40.4):  60%|    | 1198/2000 [16:52<19:22,  1.45s/it]\u001b[A\n",
      "Average Metric: 484 / 1199  (40.4):  60%|    | 1198/2000 [16:52<19:22,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bwilong' represent when unscrambled? A: mime B: dead C: bowling D: satisfied\n",
      "Answer: B: dead\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wseieldrns'. A: vietnamese B: wilderness C: salary D: commissioners\n",
      "Answer: A: vietnamese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fmile'. A: continental B: full C: soup D: filme\n",
      "Answer: A: continental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1200  (40.4):  60%|    | 1199/2000 [16:54<19:21,  1.45s/it]\u001b[A\n",
      "Average Metric: 485 / 1200  (40.4):  60%|    | 1200/2000 [16:54<17:56,  1.35s/it]\u001b[A\n",
      "Average Metric: 486 / 1201  (40.5):  60%|    | 1200/2000 [16:55<17:56,  1.35s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 486 / 1201  (40.5):  60%|    | 1201/2000 [16:55<14:44,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 486 / 1202  (40.4):  60%|    | 1201/2000 [16:55<14:44,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 486 / 1202  (40.4):  60%|    | 1202/2000 [16:55<11:38,  1.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hdiing'? A: croatia B: caps C: macdonald D: hiding\n",
      "Answer: D: hiding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pakecd' represent when unscrambled? A: root B: pass C: integer D: packed\n",
      "Answer: D: packed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 486 / 1203  (40.4):  60%|    | 1202/2000 [16:55<11:38,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 486 / 1203  (40.4):  60%|    | 1203/2000 [16:55<10:05,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 486 / 1204  (40.4):  60%|    | 1203/2000 [16:56<10:05,  1.32it/s]\u001b[A\n",
      "Average Metric: 486 / 1204  (40.4):  60%|    | 1204/2000 [16:56<09:07,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 487 / 1205  (40.4):  60%|    | 1204/2000 [16:57<09:07,  1.45it/s]\u001b[A\n",
      "Average Metric: 487 / 1205  (40.4):  60%|    | 1205/2000 [16:57<08:39,  1.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pweorhsot' represent when unscrambled? A: faster B: powershot C: address D: sciences\n",
      "Answer: A: faster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1206  (40.5):  60%|    | 1205/2000 [16:58<08:39,  1.53it/s]\u001b[A\n",
      "Average Metric: 488 / 1206  (40.5):  60%|    | 1206/2000 [16:58<11:57,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 489 / 1207  (40.5):  60%|    | 1206/2000 [16:58<11:57,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 489 / 1207  (40.5):  60%|    | 1207/2000 [16:58<09:05,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bnoirg'. A: needed B: boring C: coat D: procedure\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1208  (40.6):  60%|    | 1207/2000 [16:59<09:05,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 490 / 1208  (40.6):  60%|    | 1208/2000 [16:59<07:46,  1.70it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vkniig' represent when unscrambled? A: consent B: viking C: ownership D: allan\n",
      "Answer: B: viking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sacpeil' represent when unscrambled? A: faqs B: special C: worried D: deviantart\n",
      "Answer: A: faqs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 491 / 1209  (40.6):  60%|    | 1208/2000 [17:00<07:46,  1.70it/s]\u001b[A\n",
      "Average Metric: 491 / 1209  (40.6):  60%|    | 1209/2000 [17:00<09:11,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fnud'. A: experiencing B: girls C: fund D: italian\n",
      "Answer: D: italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 492 / 1210  (40.7):  60%|    | 1209/2000 [17:00<09:11,  1.43it/s]\u001b[A\n",
      "Average Metric: 492 / 1210  (40.7):  60%|    | 1210/2000 [17:00<09:50,  1.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 492 / 1211  (40.6):  60%|    | 1210/2000 [17:01<09:50,  1.34it/s]\u001b[A\n",
      "Average Metric: 492 / 1211  (40.6):  61%|    | 1211/2000 [17:01<08:50,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gnelty' represent when unscrambled? A: gently B: boolean C: cherokee D: scottish\n",
      "Answer: A: gently\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dwionlnadog'. A: dialogue B: downloading C: thehun D: connectivity\n",
      "Answer: D: connectivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'kuergr' represent when unscrambled? A: gaining B: kruger C: consortium D: trek\n",
      "Answer: A: gaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'dteabes' to form the correct word. A: gage B: extending C: debates D: highest\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'kaasakhztn'? A: saddam B: kazakhstan C: faqs D: ware\n",
      "Answer: C: faqs\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'eyepelmos'? A: meanwhile B: lesbian C: employees D: sending\n",
      "Answer: D: sending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 493 / 1212  (40.7):  61%|    | 1211/2000 [17:06<08:50,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 493 / 1212  (40.7):  61%|    | 1212/2000 [17:06<26:28,  2.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fimorng' to form the correct word. A: forming B: voted C: lower D: haven\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'oeutr' to form the correct word. A: review B: interactive C: reply D: outer\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 494 / 1213  (40.7):  61%|    | 1212/2000 [17:07<26:28,  2.02s/it]\u001b[A\n",
      "Average Metric: 494 / 1213  (40.7):  61%|    | 1213/2000 [17:07<23:05,  1.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 494 / 1214  (40.7):  61%|    | 1213/2000 [17:08<23:05,  1.76s/it]\u001b[A\n",
      "Average Metric: 494 / 1214  (40.7):  61%|    | 1214/2000 [17:08<17:27,  1.33s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 494 / 1215  (40.7):  61%|    | 1214/2000 [17:08<17:27,  1.33s/it]\u001b[A\n",
      "Average Metric: 494 / 1215  (40.7):  61%|    | 1215/2000 [17:08<12:55,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ietidenfid' to form the correct word. A: selected B: catering C: dans D: identified\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mdlaevis'? A: nextel B: maldives C: established D: impaired\n",
      "Answer: D: impaired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1216  (40.7):  61%|    | 1215/2000 [17:10<12:55,  1.01it/s]\u001b[A\n",
      "Average Metric: 495 / 1216  (40.7):  61%|    | 1216/2000 [17:10<18:45,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'uesd'. A: waters B: basic C: wishlist D: used\n",
      "Answer: D: used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bduides' to form the correct word. A: wiley B: vegetables C: buddies D: mileage\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'inentd' represent when unscrambled? A: jury B: reply C: intend D: shoe\n",
      "Answer: D: shoe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 495 / 1217  (40.7):  61%|    | 1216/2000 [17:11<18:45,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 495 / 1217  (40.7):  61%|    | 1217/2000 [17:11<16:33,  1.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ubeinsad'. A: formulation B: recorded C: articles D: unbiased\n",
      "Answer: D: unbiased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1218  (40.7):  61%|    | 1217/2000 [17:12<16:33,  1.27s/it]\u001b[A\n",
      "Average Metric: 496 / 1218  (40.7):  61%|    | 1218/2000 [17:12<16:12,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cieocontnn'. A: peripheral B: connection C: efficiently D: priority\n",
      "Answer: C: efficiently"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1219  (40.7):  61%|    | 1218/2000 [17:15<16:12,  1.24s/it]\u001b[A\n",
      "Average Metric: 496 / 1219  (40.7):  61%|    | 1219/2000 [17:15<20:10,  1.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 496 / 1220  (40.7):  61%|    | 1219/2000 [17:15<20:10,  1.55s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1220  (40.7):  61%|    | 1220/2000 [17:15<15:29,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'etaing'. A: recommendations B: performing C: pins D: eating\n",
      "Answer: D: eating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 497 / 1221  (40.7):  61%|    | 1220/2000 [17:17<15:29,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'moiidfed'? A: modified B: disaster C: notices D: useful\n",
      "Answer: D: useful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 497 / 1221  (40.7):  61%|    | 1221/2000 [17:17<17:58,  1.38s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1222  (40.7):  61%|    | 1221/2000 [17:17<17:58,  1.38s/it]\u001b[A\n",
      "Average Metric: 497 / 1223  (40.6):  61%|    | 1222/2000 [17:17<17:57,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 497 / 1223  (40.6):  61%|    | 1223/2000 [17:17<11:26,  1.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 498 / 1224  (40.7):  61%|    | 1223/2000 [17:17<11:26,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 498 / 1225  (40.7):  61%|    | 1224/2000 [17:18<11:25,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 498 / 1225  (40.7):  61%|   | 1225/2000 [17:18<08:41,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'boiecth'. A: anchorage B: arbitrary C: biotech D: widely\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 499 / 1226  (40.7):  61%|   | 1225/2000 [17:18<08:41,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 499 / 1227  (40.7):  61%|   | 1226/2000 [17:18<08:40,  1.49it/s]\u001b[A\n",
      "Average Metric: 499 / 1227  (40.7):  61%|   | 1227/2000 [17:18<06:27,  2.00it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 499 / 1228  (40.6):  61%|   | 1227/2000 [17:19<06:27,  2.00it/s]\u001b[A\n",
      "Average Metric: 499 / 1228  (40.6):  61%|   | 1228/2000 [17:19<05:29,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ddlio'. A: timber B: suits C: telecom D: dildo\n",
      "Answer: D: dildo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 499 / 1229  (40.6):  61%|   | 1228/2000 [17:20<05:29,  2.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 499 / 1229  (40.6):  61%|   | 1229/2000 [17:20<09:40,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'terorr' represent when unscrambled? A: environmental B: terror C: odds D: senior\n",
      "Answer: B: terror\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'omzietpid'. A: optimized B: communication C: ceramic D: revised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'feflairid'. A: fairfield B: links C: discs D: brush\n",
      "Answer: D: brush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'anbydoy' to form the correct word. A: limitations B: energy C: opportunities D: anybody\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 499 / 1230  (40.6):  61%|   | 1229/2000 [17:26<09:40,  1.33it/s]\u001b[A\n",
      "Average Metric: 499 / 1230  (40.6):  62%|   | 1230/2000 [17:26<25:34,  1.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bblie' represent when unscrambled? A: engine B: bible C: mauritania D: possibly\n",
      "Answer: D: possibly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 500 / 1231  (40.6):  62%|   | 1230/2000 [17:27<25:34,  1.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1231  (40.6):  62%|   | 1231/2000 [17:27<21:53,  1.71s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1232  (40.6):  62%|   | 1231/2000 [17:27<21:53,  1.71s/it]\u001b[A\n",
      "Average Metric: 500 / 1232  (40.6):  62%|   | 1232/2000 [17:27<16:27,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eelln'. A: fourth B: ellen C: porter D: worthy\n",
      "Answer: B: ellen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'hrroor'. A: horror B: promotion C: newsgroups D: serum\n",
      "Answer: A: horror\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1233  (40.6):  62%|   | 1232/2000 [17:30<16:27,  1.29s/it]\u001b[A\n",
      "Average Metric: 500 / 1233  (40.6):  62%|   | 1233/2000 [17:30<20:01,  1.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1234  (40.5):  62%|   | 1233/2000 [17:30<20:01,  1.57s/it]\u001b[A\n",
      "Average Metric: 500 / 1234  (40.5):  62%|   | 1234/2000 [17:30<15:33,  1.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1235  (40.5):  62%|   | 1234/2000 [17:30<15:33,  1.22s/it]\u001b[A\n",
      "Average Metric: 500 / 1235  (40.5):  62%|   | 1235/2000 [17:30<11:53,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'amiebn'? A: strings B: oxford C: imports D: ambien\n",
      "Answer: D: ambien\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1236  (40.5):  62%|   | 1235/2000 [17:31<11:53,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 500 / 1236  (40.5):  62%|   | 1236/2000 [17:31<12:07,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'daoeisttnins'. A: destinations B: tray C: excerpt D: equations\n",
      "Answer: D: equations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'figindns'. A: ultimate B: ashley C: timber D: findings\n",
      "Answer: D: findings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 500 / 1237  (40.4):  62%|   | 1236/2000 [17:33<12:07,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 500 / 1237  (40.4):  62%|   | 1237/2000 [17:33<14:44,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 500 / 1238  (40.4):  62%|   | 1237/2000 [17:33<14:44,  1.16s/it]\u001b[A\n",
      "Average Metric: 500 / 1238  (40.4):  62%|   | 1238/2000 [17:33<12:09,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cucirit' represent when unscrambled? A: attended B: commit C: circuit D: carbon\n",
      "Answer: C: circuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1239  (40.4):  62%|   | 1238/2000 [17:34<12:09,  1.05it/s]\u001b[A\n",
      "Average Metric: 500 / 1239  (40.4):  62%|   | 1239/2000 [17:34<11:03,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cearmn'. A: carmen B: beaten C: hunter D: relation\n",
      "Answer: A: carmen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 501 / 1240  (40.4):  62%|   | 1239/2000 [17:35<11:03,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 501 / 1240  (40.4):  62%|   | 1240/2000 [17:35<10:17,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'tlevelarr'. A: volt B: attempts C: northwestern D: traveller\n",
      "Answer: D: traveller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'podnirivg'. A: diseases B: providing C: invasion D: controversial\n",
      "Answer: D: controversial"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 501 / 1241  (40.4):  62%|   | 1240/2000 [17:36<10:17,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 501 / 1241  (40.4):  62%|   | 1241/2000 [17:36<12:39,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pianckg'? A: packing B: additionally C: upgraded D: taylor\n",
      "Answer: D: taylor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 502 / 1242  (40.4):  62%|   | 1241/2000 [17:37<12:39,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 502 / 1242  (40.4):  62%|   | 1242/2000 [17:38<14:15,  1.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'divres' to form the correct word. A: nominations B: attachments C: jackie D: drives\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'athltee'. A: encryption B: athlete C: earned D: orchestra\n",
      "Answer: A: encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 502 / 1243  (40.4):  62%|   | 1242/2000 [17:40<14:15,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 502 / 1243  (40.4):  62%|   | 1243/2000 [17:40<18:26,  1.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sasoen' represent when unscrambled? A: stars B: miscellaneous C: season D: credit\n",
      "Answer: C: season\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rtenlaig'? A: usps B: relating C: phentermine D: pastor\n",
      "Answer: usps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1244  (40.4):  62%|   | 1243/2000 [17:41<18:26,  1.46s/it]\u001b[A\n",
      "Average Metric: 503 / 1244  (40.4):  62%|   | 1244/2000 [17:41<16:21,  1.30s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1245  (40.4):  62%|   | 1244/2000 [17:41<16:21,  1.30s/it]\u001b[A\n",
      "Average Metric: 503 / 1245  (40.4):  62%|   | 1245/2000 [17:41<13:50,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'amablaa'. A: survey B: alabama C: shakespeare D: articles\n",
      "Answer: D: articles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1246  (40.4):  62%|   | 1245/2000 [17:42<13:50,  1.10s/it]\u001b[A\n",
      "Average Metric: 503 / 1246  (40.4):  62%|   | 1246/2000 [17:42<13:46,  1.10s/it]\u001b[A\n",
      "Average Metric: 504 / 1247  (40.4):  62%|   | 1246/2000 [17:44<13:46,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 504 / 1247  (40.4):  62%|   | 1247/2000 [17:44<14:54,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'slteys' represent when unscrambled? A: throwing B: styles C: penguin D: projected\n",
      "Answer: B: styles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 504 / 1248  (40.4):  62%|   | 1247/2000 [17:45<14:54,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1248  (40.4):  62%|   | 1248/2000 [17:45<14:02,  1.12s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1249  (40.4):  62%|   | 1248/2000 [17:45<14:02,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 504 / 1249  (40.4):  62%|   | 1249/2000 [17:45<12:18,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 1250  (40.4):  62%|   | 1249/2000 [17:46<12:18,  1.02it/s]\u001b[A\n",
      "Average Metric: 505 / 1250  (40.4):  62%|   | 1250/2000 [17:46<09:35,  1.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mlik'. A: indonesian B: milk C: souls D: sided\n",
      "Answer: A: indonesian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ppoaosrl' to form the correct word. A: proposal B: allow C: taxi D: licking\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 505 / 1251  (40.4):  62%|   | 1250/2000 [17:46<09:35,  1.30it/s]\u001b[A\n",
      "Average Metric: 505 / 1251  (40.4):  63%|   | 1251/2000 [17:46<09:12,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 1252  (40.3):  63%|   | 1251/2000 [17:47<09:12,  1.36it/s]\u001b[A\n",
      "Average Metric: 505 / 1252  (40.3):  63%|   | 1252/2000 [17:47<07:59,  1.56it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1253  (40.4):  63%|   | 1252/2000 [17:47<07:59,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ulcne'? A: hurricane B: uncle C: grew D: pleasant\n",
      "Answer: B: uncle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'detfces'? A: defects B: headers C: riding D: harold\n",
      "Answer: D: harold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1254  (40.4):  63%|   | 1253/2000 [17:47<07:58,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 506 / 1254  (40.4):  63%|   | 1254/2000 [17:47<06:05,  2.04it/s]\u001b[A\n",
      "Average Metric: 507 / 1255  (40.4):  63%|   | 1254/2000 [17:47<06:05,  2.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 508 / 1256  (40.4):  63%|   | 1255/2000 [17:48<06:05,  2.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 508 / 1256  (40.4):  63%|   | 1256/2000 [17:48<04:24,  2.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mrteysy' to form the correct word. A: enforcement B: mystery C: humanities D: bounce\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 509 / 1257  (40.5):  63%|   | 1256/2000 [17:50<04:24,  2.81it/s]\u001b[A\n",
      "Average Metric: 509 / 1257  (40.5):  63%|   | 1257/2000 [17:50<08:36,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 509 / 1258  (40.5):  63%|   | 1257/2000 [17:51<08:36,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 509 / 1258  (40.5):  63%|   | 1258/2000 [17:51<11:06,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'siehld' represent when unscrambled? A: shield B: legs C: respondents D: with\n",
      "Answer: A: shield\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'losnig' to form the correct word. A: arrest B: biotech C: diving D: losing\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'srhaochsilp'? A: dell B: jpeg C: scholarship D: snowboard\n",
      "Answer: D: snowboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'atnyhing'. A: pollution B: holocaust C: bookmark D: anything\n",
      "Answer: D: anything\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 509 / 1259  (40.4):  63%|   | 1258/2000 [17:53<11:06,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 509 / 1259  (40.4):  63%|   | 1259/2000 [17:53<15:36,  1.26s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 509 / 1260  (40.4):  63%|   | 1259/2000 [17:54<15:36,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'males'? A: emission B: drops C: meals D: duck\n",
      "Answer: A: emission\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hsottet' represent when unscrambled? A: hygiene B: hottest C: suggested D: warm\n",
      "Answer: D: warm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 510 / 1261  (40.4):  63%|   | 1260/2000 [17:55<15:35,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 510 / 1261  (40.4):  63%|   | 1261/2000 [17:55<12:44,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'smunraie'? A: caption B: accessories C: suriname D: javascript\n",
      "Answer: caption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 510 / 1262  (40.4):  63%|   | 1261/2000 [17:57<12:44,  1.03s/it]\u001b[A\n",
      "Average Metric: 510 / 1262  (40.4):  63%|   | 1262/2000 [17:57<14:35,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 510 / 1263  (40.4):  63%|   | 1262/2000 [17:57<14:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 510 / 1263  (40.4):  63%|   | 1263/2000 [17:57<11:19,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'oenfsfe' to form the correct word. A: indicated B: ottawa C: households D: offense\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Madrid  B: Berlin  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest prime number?  A\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cntuoy'. A: jump B: county C: twinks D: spiritual\n",
      "Answer: A: jump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 510 / 1264  (40.3):  63%|   | 1263/2000 [17:57<11:19,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 510 / 1264  (40.3):  63%|   | 1264/2000 [17:57<10:50,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 511 / 1265  (40.4):  63%|   | 1264/2000 [17:59<10:50,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eetmxre'. A: trackback B: extreme C: advance D: location\n",
      "Answer: D: location\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crwod'? A: margaret B: crowd C: party D: annually\n",
      "Answer: B: crowd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 511 / 1265  (40.4):  63%|   | 1265/2000 [17:59<12:03,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 512 / 1266  (40.4):  63%|   | 1265/2000 [17:59<12:03,  1.02it/s]\u001b[A\n",
      "Average Metric: 512 / 1266  (40.4):  63%|   | 1266/2000 [17:59<10:09,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 512 / 1267  (40.4):  63%|   | 1266/2000 [17:59<10:09,  1.20it/s]\u001b[A\n",
      "Average Metric: 512 / 1267  (40.4):  63%|   | 1267/2000 [17:59<07:38,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'coeecnattnrd'. A: stolen B: exterior C: zealand D: concentrated\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 513 / 1268  (40.5):  63%|   | 1267/2000 [17:59<07:38,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 513 / 1268  (40.5):  63%|   | 1268/2000 [17:59<06:05,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tjtiaasikn'. A: horny B: tajikistan C: drawings D: auditing\n",
      "Answer: D: auditing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ragne' to form the correct word. A: yemen B: range C: snacks D: released\n",
      "Answer: B: range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 513 / 1269  (40.4):  63%|   | 1268/2000 [18:04<06:05,  2.00it/s]\u001b[A\n",
      "Average Metric: 513 / 1269  (40.4):  63%|   | 1269/2000 [18:04<20:59,  1.72s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 513 / 1270  (40.4):  63%|   | 1269/2000 [18:05<20:59,  1.72s/it]\u001b[A\n",
      "Average Metric: 513 / 1270  (40.4):  64%|   | 1270/2000 [18:05<16:16,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'lsoictgis'. A: logistics B: verbal C: korean D: selected\n",
      "Answer: D: selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1271  (40.4):  64%|   | 1270/2000 [18:06<16:16,  1.34s/it]\u001b[A\n",
      "Average Metric: 514 / 1271  (40.4):  64%|   | 1271/2000 [18:06<15:33,  1.28s/it]\u001b[A\n",
      "Average Metric: 514 / 1272  (40.4):  64%|   | 1271/2000 [18:06<15:33,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1272  (40.4):  64%|   | 1272/2000 [18:06<13:18,  1.10s/it]\u001b[A\n",
      "Average Metric: 514 / 1273  (40.4):  64%|   | 1272/2000 [18:07<13:18,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1273  (40.4):  64%|   | 1273/2000 [18:07<10:04,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 514 / 1274  (40.3):  64%|   | 1273/2000 [18:07<10:04,  1.20it/s]\u001b[A\n",
      "Average Metric: 514 / 1274  (40.3):  64%|   | 1274/2000 [18:07<08:23,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'aplipcant'. A: atomic B: emerging C: applicant D: distinguish\n",
      "Answer: D: distinguish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 514 / 1275  (40.3):  64%|   | 1274/2000 [18:09<08:23,  1.44it/s]\u001b[A\n",
      "Average Metric: 514 / 1275  (40.3):  64%|   | 1275/2000 [18:09<11:59,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 515 / 1276  (40.4):  64%|   | 1275/2000 [18:09<11:59,  1.01it/s]\u001b[A\n",
      "Average Metric: 515 / 1276  (40.4):  64%|   | 1276/2000 [18:09<08:49,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 516 / 1277  (40.4):  64%|   | 1276/2000 [18:09<08:49,  1.37it/s]\u001b[A\n",
      "Average Metric: 516 / 1277  (40.4):  64%|   | 1277/2000 [18:09<07:00,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 517 / 1278  (40.5):  64%|   | 1277/2000 [18:09<07:00,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fere' to form the correct word. A: appointment B: prevent C: administration D: free\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'maimi'. A: miami B: initiative C: hugh D: occurs\n",
      "Answer: miami\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 517 / 1278  (40.5):  64%|   | 1278/2000 [18:09<05:17,  2.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 518 / 1279  (40.5):  64%|   | 1278/2000 [18:09<05:17,  2.27it/s]\u001b[A\n",
      "Average Metric: 518 / 1279  (40.5):  64%|   | 1279/2000 [18:10<05:08,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'nwreak'? A: tire B: question C: newark D: intersection\n",
      "Answer: D: intersection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 518 / 1280  (40.5):  64%|   | 1279/2000 [18:10<05:08,  2.33it/s]\u001b[A\n",
      "Average Metric: 518 / 1280  (40.5):  64%|   | 1280/2000 [18:10<05:19,  2.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'smbiut'. A: blacks B: submit C: financial D: consult\n",
      "Answer: D: consult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'golw' to form the correct word. A: sought B: glow C: commitments D: pubmed\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rlaediy'? A: readily B: tell C: sexuality D: bikes\n",
      "Answer: B: tell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 518 / 1281  (40.4):  64%|   | 1280/2000 [18:10<05:19,  2.25it/s]\u001b[A\n",
      "Average Metric: 518 / 1281  (40.4):  64%|   | 1281/2000 [18:11<05:36,  2.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'beign'? A: begin B: weakness C: coordinator D: montgomery\n",
      "Answer: begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dladey'. A: postgraduate B: plugin C: shoe D: deadly\n",
      "Answer: D: deadly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 519 / 1282  (40.5):  64%|   | 1281/2000 [18:14<05:36,  2.13it/s]\u001b[A\n",
      "Average Metric: 519 / 1282  (40.5):  64%|   | 1282/2000 [18:14<16:54,  1.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mtala'. A: technicians B: forces C: vintage D: malta\n",
      "Answer: D: malta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 519 / 1283  (40.5):  64%|   | 1282/2000 [18:15<16:54,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 519 / 1283  (40.5):  64%|   | 1283/2000 [18:15<16:30,  1.38s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 519 / 1284  (40.4):  64%|   | 1283/2000 [18:17<16:30,  1.38s/it]\u001b[A\n",
      "Average Metric: 519 / 1284  (40.4):  64%|   | 1284/2000 [18:17<16:11,  1.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ltaest'. A: valid B: establishment C: enterprise D: latest\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'digeensrs'. A: happen B: designers C: disorders D: basics\n",
      "Answer: C: disorders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 520 / 1285  (40.5):  64%|   | 1284/2000 [18:20<16:11,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 520 / 1285  (40.5):  64%|   | 1285/2000 [18:20<21:47,  1.83s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 521 / 1286  (40.5):  64%|   | 1285/2000 [18:20<21:47,  1.83s/it]\u001b[A\n",
      "Average Metric: 521 / 1286  (40.5):  64%|   | 1286/2000 [18:20<16:06,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'pool' represent when unscrambled? A: surfing B: pool C: dealtime D: currently\n",
      "Answer: A: surfing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wveon'. A: elevation B: woven C: prices D: brian\n",
      "Answer: A: elevation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bairrer' to form the correct word. A: barrier B: start C: humidity D: secondary\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'nmaes' to form the correct word. A: newbie B: manual C: multimedia D: names\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 522 / 1287  (40.6):  64%|   | 1286/2000 [18:22<16:06,  1.35s/it]\u001b[A\n",
      "Average Metric: 522 / 1287  (40.6):  64%|   | 1287/2000 [18:22<17:11,  1.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 523 / 1288  (40.6):  64%|   | 1287/2000 [18:22<17:11,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "\u001b[A\n",
      "Average Metric: 523 / 1288  (40.6):  64%|   | 1288/2000 [18:22<14:06,  1.19s/it]  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'coiunntg' represent when unscrambled? A: reporters B: carnegie C: plain D: counting\n",
      "Answer: D: counting"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'sosonpr' represent when unscrambled? A: lesser B: lincoln C: sponsor D: filling\n",
      "Answer: C: sponsor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mnius' represent when unscrambled? A: governmental B: cape C: minus D: broadway\n",
      "Answer: B: cape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 523 / 1289  (40.6):  64%|   | 1288/2000 [18:25<14:06,  1.19s/it]\u001b[A\n",
      "Average Metric: 523 / 1289  (40.6):  64%|   | 1289/2000 [18:25<18:12,  1.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'daiomn' represent when unscrambled? A: become B: domain C: bunch D: experimental\n",
      "Answer: D: experimental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'rreecveis' represent when unscrambled? A: analysis B: receivers C: conflicts D: channel\n",
      "Answer: D: channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 523 / 1290  (40.5):  64%|   | 1289/2000 [18:27<18:12,  1.54s/it]\u001b[A\n",
      "Average Metric: 523 / 1290  (40.5):  64%|   | 1290/2000 [18:27<21:14,  1.79s/it]\u001b[A\n",
      "Average Metric: 523 / 1291  (40.5):  64%|   | 1290/2000 [18:27<21:14,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 523 / 1291  (40.5):  65%|   | 1291/2000 [18:28<17:00,  1.44s/it]\u001b[A\n",
      "Average Metric: 524 / 1292  (40.6):  65%|   | 1291/2000 [18:28<17:00,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 524 / 1292  (40.6):  65%|   | 1292/2000 [18:28<13:55,  1.18s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 525 / 1293  (40.6):  65%|   | 1292/2000 [18:28<13:55,  1.18s/it]\u001b[A\n",
      "Average Metric: 525 / 1293  (40.6):  65%|   | 1293/2000 [18:29<11:08,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 525 / 1294  (40.6):  65%|   | 1293/2000 [18:29<11:08,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 525 / 1295  (40.5):  65%|   | 1294/2000 [18:29<11:07,  1.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 525 / 1296  (40.5):  65%|   | 1295/2000 [18:29<11:06,  1.06it/s]\u001b[A\n",
      "Average Metric: 525 / 1296  (40.5):  65%|   | 1296/2000 [18:29<05:10,  2.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bilnk'? A: instructional B: blink C: raise D: champion\n",
      "Answer: B: blink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 526 / 1297  (40.6):  65%|   | 1296/2000 [18:29<05:10,  2.27it/s]\u001b[A\n",
      "Average Metric: 526 / 1297  (40.6):  65%|   | 1297/2000 [18:29<05:16,  2.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 527 / 1298  (40.6):  65%|   | 1297/2000 [18:30<05:16,  2.22it/s]\u001b[A\n",
      "Average Metric: 527 / 1298  (40.6):  65%|   | 1298/2000 [18:30<05:14,  2.23it/s]\u001b[A\n",
      "Average Metric: 528 / 1299  (40.6):  65%|   | 1298/2000 [18:30<05:14,  2.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 528 / 1299  (40.6):  65%|   | 1299/2000 [18:30<05:18,  2.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 528 / 1300  (40.6):  65%|   | 1299/2000 [18:31<05:18,  2.20it/s]\u001b[A\n",
      "Average Metric: 528 / 1300  (40.6):  65%|   | 1300/2000 [18:31<06:52,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'ssloaciit' to form the correct word. A: nickname B: cartridge C: socialist D: betting\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'sulppy'. A: supply B: acceptance C: philosophy D: rfid\n",
      "Answer: D: rfid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 529 / 1301  (40.7):  65%|   | 1300/2000 [18:33<06:52,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 529 / 1301  (40.7):  65%|   | 1301/2000 [18:33<11:56,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'kocnk'. A: dramatic B: knock C: exhaust D: swan\n",
      "Answer: A: dramatic\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cnueonsss' represent when unscrambled? A: free B: okay C: consensus D: cant\n",
      "Answer: D: cant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'smoe'. A: scripting B: ballot C: grief D: some\n",
      "Answer: D: some\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cepathr' to form the correct word. A: chapter B: oxford C: ranger D: operates\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'mmos' represent when unscrambled? A: hunger B: moms C: jane D: resolution\n",
      "Answer: A: hunger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 529 / 1302  (40.6):  65%|   | 1301/2000 [18:38<11:56,  1.03s/it]\u001b[A\n",
      "Average Metric: 529 / 1302  (40.6):  65%|   | 1302/2000 [18:38<22:50,  1.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 529 / 1303  (40.6):  65%|   | 1302/2000 [18:38<22:50,  1.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 529 / 1303  (40.6):  65%|   | 1303/2000 [18:38<17:06,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'raosnlebae' represent when unscrambled? A: observed B: reasonable C: scenario D: hearts\n",
      "Answer: D: hearts\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ejnoy'? A: enjoy B: vessel C: tries D: alberta\n",
      "Answer: enjoy\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pset'. A: pest B: modular C: stars D: liberal\n",
      "Answer: pest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1304  (40.6):  65%|   | 1303/2000 [18:38<17:06,  1.47s/it]\u001b[A\n",
      "Average Metric: 529 / 1304  (40.6):  65%|   | 1304/2000 [18:38<13:56,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1305  (40.5):  65%|   | 1304/2000 [18:38<13:56,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'brun'. A: memorabilia B: burn C: steady D: sears\n",
      "Answer: D: sears\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'baanmese' represent when unscrambled? A: straps B: morrison C: webmasters D: basename\n",
      "Answer: A: straps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1306  (40.5):  65%|   | 1305/2000 [18:40<13:55,  1.20s/it]\u001b[A\n",
      "Average Metric: 529 / 1306  (40.5):  65%|   | 1306/2000 [18:40<12:23,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 529 / 1307  (40.5):  65%|   | 1306/2000 [18:42<12:23,  1.07s/it]\u001b[A\n",
      "Average Metric: 529 / 1307  (40.5):  65%|   | 1307/2000 [18:42<15:17,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'clut'? A: inclusive B: surfaces C: wall D: cult\n",
      "Answer: D: cult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 530 / 1308  (40.5):  65%|   | 1307/2000 [18:42<15:17,  1.32s/it]\u001b[A\n",
      "Average Metric: 530 / 1308  (40.5):  65%|   | 1308/2000 [18:42<11:51,  1.03s/it]\u001b[A\n",
      "Average Metric: 531 / 1309  (40.6):  65%|   | 1308/2000 [18:43<11:51,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 531 / 1309  (40.6):  65%|   | 1309/2000 [18:43<10:20,  1.11it/s]\u001b[A\n",
      "Average Metric: 531 / 1310  (40.5):  65%|   | 1309/2000 [18:43<10:20,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 532 / 1311  (40.6):  66%|   | 1310/2000 [18:44<10:19,  1.11it/s]\u001b[A\n",
      "Average Metric: 532 / 1311  (40.6):  66%|   | 1311/2000 [18:44<07:45,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'skocs'. A: native B: antigua C: socks D: zoophilia\n",
      "Answer: A: native\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'wnehever' to form the correct word. A: shades B: attractive C: whenever D: dakota\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 533 / 1312  (40.6):  66%|   | 1311/2000 [18:45<07:45,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 533 / 1312  (40.6):  66%|   | 1312/2000 [18:45<10:10,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nitoce'. A: notice B: slut C: adrian D: include\n",
      "Answer: D: include\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'plezzus' to form the correct word. A: puzzles B: properties C: describes D: compare\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'bdinidg'? A: pregnancy B: ordinary C: bidding D: ministries\n",
      "Answer: B: ordinary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 534 / 1313  (40.7):  66%|   | 1312/2000 [18:47<10:10,  1.13it/s]\u001b[A\n",
      "Average Metric: 534 / 1313  (40.7):  66%|   | 1313/2000 [18:47<12:49,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'manrthecs'? A: ieee B: beam C: separation D: merchants\n",
      "Answer: B: beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wdisnor' represent when unscrambled? A: utilization B: businesses C: retain D: windsor\n",
      "Answer: D: windsor\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rgeuefes'? A: refugees B: cant C: music D: avenue\n",
      "Answer: refugees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'chanoegpen'. A: raise B: copenhagen C: offender D: makers\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'birtsih'. A: british B: collision C: analyses D: threshold\n",
      "Answer: A: british\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 535 / 1314  (40.7):  66%|   | 1313/2000 [18:50<12:49,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 535 / 1314  (40.7):  66%|   | 1314/2000 [18:50<17:33,  1.54s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 536 / 1315  (40.8):  66%|   | 1314/2000 [18:50<17:33,  1.54s/it]\u001b[A\n",
      "Average Metric: 536 / 1315  (40.8):  66%|   | 1315/2000 [18:50<13:20,  1.17s/it]\u001b[A\n",
      "Average Metric: 537 / 1316  (40.8):  66%|   | 1315/2000 [18:50<13:20,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 538 / 1317  (40.9):  66%|   | 1316/2000 [18:51<13:19,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 538 / 1317  (40.9):  66%|   | 1317/2000 [18:51<10:14,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 538 / 1318  (40.8):  66%|   | 1317/2000 [18:51<10:14,  1.11it/s]\u001b[A\n",
      "Average Metric: 538 / 1318  (40.8):  66%|   | 1318/2000 [18:51<08:39,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 538 / 1319  (40.8):  66%|   | 1318/2000 [18:52<08:39,  1.31it/s]\u001b[A\n",
      "Average Metric: 538 / 1319  (40.8):  66%|   | 1319/2000 [18:52<06:44,  1.68it/s]\u001b[A\n",
      "Average Metric: 539 / 1320  (40.8):  66%|   | 1319/2000 [18:52<06:44,  1.68it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 539 / 1320  (40.8):  66%|   | 1320/2000 [18:52<05:15,  2.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 539 / 1321  (40.8):  66%|   | 1320/2000 [18:53<05:15,  2.16it/s]\u001b[A\n",
      "Average Metric: 539 / 1321  (40.8):  66%|   | 1321/2000 [18:53<06:46,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rbuy'. A: translators B: member C: ruby D: installing\n",
      "Answer: B: member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 540 / 1322  (40.8):  66%|   | 1321/2000 [18:54<06:46,  1.67it/s]\u001b[A\n",
      "Average Metric: 540 / 1322  (40.8):  66%|   | 1322/2000 [18:54<09:14,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 540 / 1323  (40.8):  66%|   | 1322/2000 [18:56<09:14,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 540 / 1323  (40.8):  66%|   | 1323/2000 [18:56<13:45,  1.22s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 541 / 1324  (40.9):  66%|   | 1323/2000 [18:57<13:45,  1.22s/it]\u001b[A\n",
      "Average Metric: 541 / 1324  (40.9):  66%|   | 1324/2000 [18:57<10:41,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'benyrfiod'. A: boyfriend B: geographical C: cameroon D: sample\n",
      "Answer: D: sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 542 / 1325  (40.9):  66%|   | 1324/2000 [18:57<10:41,  1.05it/s]\u001b[A\n",
      "Average Metric: 542 / 1325  (40.9):  66%|   | 1325/2000 [18:57<10:01,  1.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mmaethctais'. A: mathematics B: publicly C: structural D: profiles\n",
      "Answer: D: profiles"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cricteasyh'. A: citysearch B: customers C: cisco D: subscriptions\n",
      "Answer: C: cisco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 543 / 1326  (41.0):  66%|   | 1325/2000 [18:58<10:01,  1.12it/s]\u001b[A\n",
      "Average Metric: 543 / 1326  (41.0):  66%|   | 1326/2000 [18:58<09:26,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'celcys' to form the correct word. A: cycles B: bits C: delay D: controller\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mouldes'. A: modules B: happening C: enquiry D: traditionally\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rnitneg'. A: coaching B: renting C: bibliographic D: contrast\n",
      "Answer: D: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 544 / 1327  (41.0):  66%|   | 1326/2000 [19:01<09:26,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 544 / 1327  (41.0):  66%|   | 1327/2000 [19:01<15:24,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'myaor'. A: grid B: mayor C: chill D: hilton\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wlels'. A: burton B: cheque C: moore D: wells\n",
      "Answer: D: wells\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'liimt'. A: steroids B: electro C: limit D: focusing\n",
      "Answer: C: limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 544 / 1328  (41.0):  66%|   | 1327/2000 [19:01<15:24,  1.37s/it]\u001b[A\n",
      "Average Metric: 544 / 1328  (41.0):  66%|   | 1328/2000 [19:01<13:19,  1.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'srapy' to form the correct word. A: spray B: house C: coordination D: appliance\n",
      "Answer: A: spray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 545 / 1329  (41.0):  66%|   | 1328/2000 [19:05<13:19,  1.19s/it]\u001b[A\n",
      "Average Metric: 545 / 1329  (41.0):  66%|   | 1329/2000 [19:05<22:39,  2.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'heplfluoy' represent when unscrambled? A: rica B: ambient C: senate D: hopefully\n",
      "Answer: A: rica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 545 / 1330  (41.0):  66%|   | 1329/2000 [19:05<22:39,  2.03s/it]\u001b[A\n",
      "Average Metric: 546 / 1331  (41.0):  66%|   | 1330/2000 [19:05<22:37,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 546 / 1332  (41.0):  67%|   | 1331/2000 [19:06<22:35,  2.03s/it]\u001b[A\n",
      "Average Metric: 546 / 1332  (41.0):  67%|   | 1332/2000 [19:06<11:20,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 546 / 1333  (41.0):  67%|   | 1332/2000 [19:07<11:20,  1.02s/it]\u001b[A\n",
      "Average Metric: 546 / 1333  (41.0):  67%|   | 1333/2000 [19:07<10:46,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'diestny'? A: only B: hazards C: density D: everything\n",
      "Answer: D: everything\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'pigtianns'. A: paintings B: bookmark C: minority D: rico\n",
      "Answer: D: rico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'jisewh'. A: identifying B: bind C: jewish D: fold\n",
      "Answer: D: fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 547 / 1334  (41.0):  67%|   | 1333/2000 [19:08<10:46,  1.03it/s]\u001b[A\n",
      "Average Metric: 547 / 1334  (41.0):  67%|   | 1334/2000 [19:08<10:50,  1.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'crlaa'? A: clara B: floppy C: plates D: wrapped\n",
      "Answer: D: wrapped\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aragnre'? A: ruled B: witch C: arrange D: sexual\n",
      "Answer: C: arrange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 547 / 1335  (41.0):  67%|   | 1334/2000 [19:10<10:50,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 547 / 1335  (41.0):  67%|   | 1335/2000 [19:10<12:57,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'roobt' to form the correct word. A: transcription B: clouds C: investigated D: robot\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 547 / 1336  (40.9):  67%|   | 1335/2000 [19:11<12:57,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 547 / 1336  (40.9):  67%|   | 1336/2000 [19:11<12:18,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 548 / 1337  (41.0):  67%|   | 1336/2000 [19:12<12:18,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 548 / 1337  (41.0):  67%|   | 1337/2000 [19:12<12:01,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fngeir' to form the correct word. A: shot B: finger C: transparent D: lighting\n",
      "Answer: D: lighting\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'qiut' to form the correct word. A: events B: greatly C: quit D: formatting\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 549 / 1338  (41.0):  67%|   | 1337/2000 [19:12<12:01,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 549 / 1338  (41.0):  67%|   | 1338/2000 [19:12<09:24,  1.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cepoor'? A: heather B: cooper C: appraisal D: soldiers\n",
      "Answer: B: cooper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 550 / 1339  (41.1):  67%|   | 1338/2000 [19:13<09:24,  1.17it/s]\u001b[A\n",
      "Average Metric: 550 / 1339  (41.1):  67%|   | 1339/2000 [19:13<09:32,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 551 / 1340  (41.1):  67%|   | 1339/2000 [19:13<09:32,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 551 / 1341  (41.1):  67%|   | 1340/2000 [19:14<09:31,  1.15it/s]\u001b[A\n",
      "Average Metric: 551 / 1341  (41.1):  67%|   | 1341/2000 [19:14<07:51,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 551 / 1342  (41.1):  67%|   | 1341/2000 [19:14<07:51,  1.40it/s]\u001b[A\n",
      "Average Metric: 551 / 1342  (41.1):  67%|   | 1342/2000 [19:14<06:59,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 552 / 1343  (41.1):  67%|   | 1342/2000 [19:15<06:59,  1.57it/s]\u001b[A\n",
      "Average Metric: 552 / 1343  (41.1):  67%|   | 1343/2000 [19:15<07:33,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ptocepsrs' represent when unscrambled? A: robot B: catalog C: prospects D: flags\n",
      "Answer: A: robot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 552 / 1344  (41.1):  67%|   | 1343/2000 [19:17<07:33,  1.45it/s]\u001b[A\n",
      "Average Metric: 552 / 1344  (41.1):  67%|   | 1344/2000 [19:17<12:26,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 552 / 1345  (41.0):  67%|   | 1344/2000 [19:17<12:26,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1346  (41.1):  67%|   | 1345/2000 [19:18<12:25,  1.14s/it]\u001b[A\n",
      "Average Metric: 553 / 1346  (41.1):  67%|   | 1346/2000 [19:18<07:34,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'nceliy' to form the correct word. A: nicely B: yamaha C: ellen D: pole\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'avehiced'? A: achieved B: statutory C: depend D: hall\n",
      "Answer: achieved\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'birany'. A: trembl B: binary C: approved D: marino\n",
      "Answer: B: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1347  (41.1):  67%|   | 1346/2000 [19:19<07:34,  1.44it/s]\u001b[A\n",
      "Average Metric: 553 / 1347  (41.1):  67%|   | 1347/2000 [19:19<08:33,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 553 / 1348  (41.0):  67%|   | 1347/2000 [19:19<08:33,  1.27it/s]\u001b[A\n",
      "Average Metric: 553 / 1348  (41.0):  67%|   | 1348/2000 [19:19<06:49,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1349  (41.0):  67%|   | 1348/2000 [19:19<06:49,  1.59it/s]\u001b[A\n",
      "Average Metric: 553 / 1349  (41.0):  67%|   | 1349/2000 [19:19<05:18,  2.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'teinarr' to form the correct word. A: scottish B: potatoes C: outlook D: trainer\n",
      "Answer: C\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'tsak' represent when unscrambled? A: fairfield B: task C: critical D: holland\n",
      "Answer: B: task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 553 / 1350  (41.0):  67%|   | 1349/2000 [19:19<05:18,  2.05it/s]\u001b[A\n",
      "Average Metric: 553 / 1350  (41.0):  68%|   | 1350/2000 [19:19<04:41,  2.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 554 / 1351  (41.0):  68%|   | 1350/2000 [19:21<04:41,  2.31it/s]\u001b[A\n",
      "Average Metric: 554 / 1351  (41.0):  68%|   | 1351/2000 [19:21<07:18,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'tmroroow'? A: accountant B: tomorrow C: optical D: chandler\n",
      "Answer: C: optical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'geek' to form the correct word. A: geek B: oliver C: alternatively D: trailers\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lcak'? A: lack B: approval C: anchorage D: arthritis\n",
      "Answer: A: lack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ryas'. A: suggesting B: rays C: packing D: voyeurweb\n",
      "Answer: D: voyeurweb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 555 / 1352  (41.1):  68%|   | 1351/2000 [19:23<07:18,  1.48it/s]\u001b[A\n",
      "Average Metric: 555 / 1352  (41.1):  68%|   | 1352/2000 [19:23<13:02,  1.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 555 / 1353  (41.0):  68%|   | 1352/2000 [19:26<13:02,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 555 / 1353  (41.0):  68%|   | 1353/2000 [19:26<17:29,  1.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 555 / 1354  (41.0):  68%|   | 1353/2000 [19:27<17:29,  1.62s/it]\u001b[A\n",
      "Average Metric: 555 / 1354  (41.0):  68%|   | 1354/2000 [19:27<16:28,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 555 / 1355  (41.0):  68%|   | 1354/2000 [19:28<16:28,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 555 / 1355  (41.0):  68%|   | 1355/2000 [19:28<15:31,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'gdenraa'. A: grenada B: points C: instantly D: novell\n",
      "Answer: D: novell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 556 / 1356  (41.0):  68%|   | 1355/2000 [19:29<15:31,  1.44s/it]\u001b[A\n",
      "Average Metric: 556 / 1356  (41.0):  68%|   | 1356/2000 [19:29<11:49,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 557 / 1357  (41.0):  68%|   | 1356/2000 [19:30<11:49,  1.10s/it]\u001b[A\n",
      "Average Metric: 557 / 1357  (41.0):  68%|   | 1357/2000 [19:30<11:54,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 557 / 1358  (41.0):  68%|   | 1357/2000 [19:30<11:54,  1.11s/it]\u001b[A\n",
      "Average Metric: 557 / 1358  (41.0):  68%|   | 1358/2000 [19:30<09:01,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'tgaerpleh' to form the correct word. A: wage B: telegraph C: abilities D: administration\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1359  (41.1):  68%|   | 1358/2000 [19:32<09:01,  1.19it/s]\u001b[A\n",
      "Average Metric: 558 / 1359  (41.1):  68%|   | 1359/2000 [19:32<12:09,  1.14s/it]\u001b[A\n",
      "Average Metric: 558 / 1360  (41.0):  68%|   | 1359/2000 [19:32<12:09,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 558 / 1360  (41.0):  68%|   | 1360/2000 [19:32<09:01,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'deaelyd'. A: delayed B: teachers C: picture D: buck\n",
      "Answer: D: buck\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'wliissht'. A: wishlist B: rarely C: oregon D: fatty\n",
      "Answer: D: fatty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1361  (41.0):  68%|   | 1360/2000 [19:33<09:01,  1.18it/s]\u001b[A\n",
      "Average Metric: 558 / 1361  (41.0):  68%|   | 1361/2000 [19:33<08:23,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1362  (41.0):  68%|   | 1361/2000 [19:33<08:23,  1.27it/s]\u001b[A\n",
      "Average Metric: 558 / 1362  (41.0):  68%|   | 1362/2000 [19:33<06:38,  1.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fnieegls' to form the correct word. A: bangbus B: recruiting C: feelings D: prospect\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1363  (40.9):  68%|   | 1362/2000 [19:33<06:38,  1.60it/s]\u001b[A\n",
      "Average Metric: 558 / 1363  (40.9):  68%|   | 1363/2000 [19:33<05:27,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'schaolr' represent when unscrambled? A: scholar B: also C: utilizing D: pole\n",
      "Answer: A: scholar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 558 / 1364  (40.9):  68%|   | 1363/2000 [19:34<05:27,  1.94it/s]\u001b[A\n",
      "Average Metric: 558 / 1364  (40.9):  68%|   | 1364/2000 [19:34<07:09,  1.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'falvor'. A: flavor B: rival C: checklist D: gadgets\n",
      "Answer: A: flavor\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'baed'. A: bead B: sorry C: phrase D: handheld\n",
      "Answer: D: handheld\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'mlysef'? A: coated B: yukon C: myself D: museums\n",
      "Answer: B: yukon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 558 / 1365  (40.9):  68%|   | 1364/2000 [19:35<07:09,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 558 / 1365  (40.9):  68%|   | 1365/2000 [19:35<07:14,  1.46it/s]\u001b[A\n",
      "Average Metric: 559 / 1366  (40.9):  68%|   | 1365/2000 [19:35<07:14,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 559 / 1366  (40.9):  68%|   | 1366/2000 [19:35<05:57,  1.77it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 559 / 1367  (40.9):  68%|   | 1366/2000 [19:36<05:57,  1.77it/s]\u001b[A\n",
      "Average Metric: 559 / 1367  (40.9):  68%|   | 1367/2000 [19:36<05:48,  1.82it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'stutaets'? A: weapon B: statutes C: brook D: tourists\n",
      "Answer: B: statutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 560 / 1368  (40.9):  68%|   | 1367/2000 [19:36<05:48,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 560 / 1368  (40.9):  68%|   | 1368/2000 [19:36<06:15,  1.68it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'liimts' represent when unscrambled? A: admitted B: limits C: dates D: taylor\n",
      "Answer: B: limits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'reioatcn'? A: hints B: austria C: reaction D: makeup\n",
      "Answer: B: austria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 561 / 1369  (41.0):  68%|   | 1368/2000 [19:40<06:15,  1.68it/s]\u001b[A\n",
      "Average Metric: 561 / 1369  (41.0):  68%|   | 1369/2000 [19:40<15:05,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 562 / 1370  (41.0):  68%|   | 1369/2000 [19:40<15:05,  1.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 562 / 1370  (41.0):  68%|   | 1370/2000 [19:40<11:28,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 562 / 1371  (41.0):  68%|   | 1370/2000 [19:41<11:28,  1.09s/it]\u001b[A\n",
      "Average Metric: 562 / 1371  (41.0):  69%|   | 1371/2000 [19:41<11:44,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1372  (41.0):  69%|   | 1371/2000 [19:41<11:44,  1.12s/it]\u001b[A\n",
      "Average Metric: 563 / 1372  (41.0):  69%|   | 1372/2000 [19:41<08:53,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sadonkrcuts'. A: configure B: money C: soundtracks D: midnight\n",
      "Answer: D: midnight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1373  (41.0):  69%|   | 1372/2000 [19:44<08:53,  1.18it/s]\u001b[A\n",
      "Average Metric: 563 / 1373  (41.0):  69%|   | 1373/2000 [19:44<12:58,  1.24s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1374  (41.0):  69%|   | 1373/2000 [19:44<12:58,  1.24s/it]\u001b[A\n",
      "Average Metric: 563 / 1374  (41.0):  69%|   | 1374/2000 [19:44<10:27,  1.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'bokors' to form the correct word. A: flow B: brooks C: leading D: roma\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 563 / 1375  (40.9):  69%|   | 1374/2000 [19:45<10:27,  1.00s/it]\u001b[A\n",
      "Average Metric: 563 / 1375  (40.9):  69%|   | 1375/2000 [19:45<09:14,  1.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'rseos'. A: tends B: roses C: suddenly D: stay\n",
      "Answer: D: stay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 563 / 1376  (40.9):  69%|   | 1375/2000 [19:45<09:14,  1.13it/s]\u001b[A\n",
      "Average Metric: 563 / 1376  (40.9):  69%|   | 1376/2000 [19:45<09:04,  1.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 564 / 1377  (41.0):  69%|   | 1376/2000 [19:46<09:04,  1.15it/s]\u001b[A\n",
      "Average Metric: 564 / 1377  (41.0):  69%|   | 1377/2000 [19:46<08:39,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'kngihts'. A: exempt B: religious C: barrel D: knights\n",
      "Answer: D: knights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 565 / 1378  (41.0):  69%|   | 1377/2000 [19:47<08:39,  1.20it/s]\u001b[A\n",
      "Average Metric: 565 / 1378  (41.0):  69%|   | 1378/2000 [19:47<09:24,  1.10it/s]\u001b[A\n",
      "Average Metric: 565 / 1379  (41.0):  69%|   | 1378/2000 [19:47<09:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 565 / 1380  (40.9):  69%|   | 1379/2000 [19:48<09:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\u001b[A\n",
      "Average Metric: 565 / 1380  (40.9):  69%|   | 1380/2000 [19:48<05:56,  1.74it/s]\u001b[ATraceback (most recent call last):\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'oangiezrd'. A: sculpture B: appointed C: organized D: hazards\n",
      "Answer: D: hazards"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 565 / 1381  (40.9):  69%|   | 1380/2000 [19:50<05:56,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1381  (40.9):  69%|   | 1381/2000 [19:50<10:34,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cheuqe'. A: hybrid B: graduates C: cheque D: poem\n",
      "Answer: C: cheque\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1382  (40.9):  69%|   | 1381/2000 [19:51<10:34,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'menictnnaae' represent when unscrambled? A: promotes B: decay C: others D: maintenance\n",
      "Answer: D: maintenance\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dmoe'? A: steven B: dome C: escort D: animals\n",
      "Answer: B: dome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 565 / 1382  (40.9):  69%|   | 1382/2000 [19:51<11:15,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'taaiwn'? A: dropped B: chile C: blessed D: taiwan\n",
      "Answer: D: taiwan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1383  (40.9):  69%|   | 1382/2000 [19:54<11:15,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 565 / 1383  (40.9):  69%|   | 1383/2000 [19:54<15:49,  1.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aacttvie'? A: satellite B: corps C: patio D: activate\n",
      "Answer: D: activate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 566 / 1384  (40.9):  69%|   | 1383/2000 [19:56<15:49,  1.54s/it]\u001b[A\n",
      "Average Metric: 566 / 1384  (40.9):  69%|   | 1384/2000 [19:56<15:34,  1.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 566 / 1385  (40.9):  69%|   | 1384/2000 [19:56<15:34,  1.52s/it]\u001b[A\n",
      "Average Metric: 566 / 1385  (40.9):  69%|   | 1385/2000 [19:56<12:21,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 567 / 1386  (40.9):  69%|   | 1385/2000 [19:56<12:21,  1.20s/it]\u001b[A\n",
      "Average Metric: 567 / 1386  (40.9):  69%|   | 1386/2000 [19:56<09:09,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'saetrm' represent when unscrambled? A: might B: scenic C: desktop D: stream\n",
      "Answer: D: stream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 568 / 1387  (41.0):  69%|   | 1386/2000 [19:58<09:09,  1.12it/s]\u001b[A\n",
      "Average Metric: 568 / 1387  (41.0):  69%|   | 1387/2000 [19:58<11:20,  1.11s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1388  (41.0):  69%|   | 1387/2000 [19:58<11:20,  1.11s/it]\u001b[A\n",
      "Average Metric: 569 / 1388  (41.0):  69%|   | 1388/2000 [19:58<08:18,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 569 / 1389  (41.0):  69%|   | 1388/2000 [19:59<08:18,  1.23it/s]\u001b[A\n",
      "Average Metric: 569 / 1389  (41.0):  69%|   | 1389/2000 [19:59<07:59,  1.27it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1390  (40.9):  69%|   | 1389/2000 [19:59<07:59,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'fiisninhg'. A: finishing B: carefully C: cattle D: goat\n",
      "Answer: D: goat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'dvirers'. A: strange B: bibliographic C: darwin D: drivers\n",
      "Answer: D: drivers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1391  (40.9):  70%|   | 1390/2000 [20:00<07:58,  1.27it/s]\u001b[A\n",
      "Average Metric: 569 / 1391  (40.9):  70%|   | 1391/2000 [20:00<08:39,  1.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 569 / 1392  (40.9):  70%|   | 1391/2000 [20:01<08:39,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 569 / 1392  (40.9):  70%|   | 1392/2000 [20:02<09:15,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eedn' represent when unscrambled? A: jeep B: eden C: median D: poster\n",
      "Answer: A: jeep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1393  (40.8):  70%|   | 1392/2000 [20:03<09:15,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 569 / 1393  (40.8):  70%|   | 1393/2000 [20:03<10:36,  1.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'pnieunlsa'? A: homeland B: peninsula C: chances D: skirt\n",
      "Answer: B: peninsula\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'eirn'. A: erin B: focus C: kelkoo D: jonathan\n",
      "Answer: A: erin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 570 / 1394  (40.9):  70%|   | 1393/2000 [20:04<10:36,  1.05s/it]\u001b[A\n",
      "Average Metric: 570 / 1394  (40.9):  70%|   | 1394/2000 [20:04<11:11,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wilnilg'. A: bath B: away C: willing D: budget\n",
      "Answer: D: budget\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 570 / 1395  (40.9):  70%|   | 1394/2000 [20:06<11:11,  1.11s/it]\u001b[A\n",
      "Average Metric: 570 / 1395  (40.9):  70%|   | 1395/2000 [20:06<13:15,  1.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 571 / 1396  (40.9):  70%|   | 1395/2000 [20:07<13:15,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 571 / 1396  (40.9):  70%|   | 1396/2000 [20:07<12:39,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cmredaocr' to form the correct word. A: camcorder B: dedication C: atari D: gambling\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 571 / 1397  (40.9):  70%|   | 1396/2000 [20:08<12:39,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 571 / 1397  (40.9):  70%|   | 1397/2000 [20:08<11:14,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'pctiirancg'. A: ultimate B: practicing C: prototype D: hose\n",
      "Answer: D: hose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bjowlob'. A: duplicate B: newcastle C: harm D: blowjob\n",
      "Answer: D: blowjob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1398  (40.8):  70%|   | 1397/2000 [20:09<11:14,  1.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'nteos'. A: midlands B: iron C: notes D: reception\n",
      "Answer: D: reception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 571 / 1398  (40.8):  70%|   | 1398/2000 [20:09<10:20,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1399  (40.8):  70%|   | 1398/2000 [20:09<10:20,  1.03s/it]\u001b[A\n",
      "Average Metric: 571 / 1399  (40.8):  70%|   | 1399/2000 [20:09<08:57,  1.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'yenake' represent when unscrambled? A: yankee B: lawsuit C: publishing D: foundations\n",
      "Answer: A: yankee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 571 / 1400  (40.8):  70%|   | 1399/2000 [20:10<08:57,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 571 / 1400  (40.8):  70%|   | 1400/2000 [20:10<09:03,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1401  (40.8):  70%|   | 1400/2000 [20:10<09:03,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1401  (40.8):  70%|   | 1401/2000 [20:10<06:52,  1.45it/s]\u001b[A\n",
      "Average Metric: 571 / 1402  (40.7):  70%|   | 1401/2000 [20:10<06:52,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1403  (40.7):  70%|   | 1402/2000 [20:11<06:52,  1.45it/s]\u001b[A\n",
      "Average Metric: 571 / 1403  (40.7):  70%|   | 1403/2000 [20:11<05:13,  1.91it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 571 / 1404  (40.7):  70%|   | 1403/2000 [20:12<05:13,  1.91it/s]\u001b[A\n",
      "Average Metric: 571 / 1404  (40.7):  70%|   | 1404/2000 [20:12<05:40,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'uetarndekn'? A: kyoto B: hospital C: undertaken D: ever\n",
      "Answer: D: ever\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 571 / 1405  (40.6):  70%|   | 1404/2000 [20:12<05:40,  1.75it/s]\u001b[A\n",
      "Average Metric: 571 / 1405  (40.6):  70%|   | 1405/2000 [20:12<04:28,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'gian' represent when unscrambled? A: valued B: dietary C: recruitment D: gain\n",
      "Answer: A: valued"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'teunr'. A: tuner B: blast C: obesity D: bangbus\n",
      "Answer: A: tuner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'ptnaoesirntes'. A: presentations B: collaboration C: various D: known\n",
      "Answer: D: known\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 572 / 1406  (40.7):  70%|   | 1405/2000 [20:16<04:28,  2.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 572 / 1406  (40.7):  70%|   | 1406/2000 [20:16<13:24,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'lwsaiut'. A: lawsuit B: candles C: terminate D: explaining\n",
      "Answer: D: explaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ingndeuios'? A: schedule B: indigenous C: immigration D: traders\n",
      "Answer: D: traders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'nmaewn' to form the correct word. A: excellence B: newman C: securities D: marking\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 573 / 1407  (40.7):  70%|   | 1406/2000 [20:18<13:24,  1.36s/it]\u001b[A\n",
      "Average Metric: 573 / 1407  (40.7):  70%|   | 1407/2000 [20:18<16:40,  1.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rzgoceiend'? A: race B: initial C: solely D: recognized\n",
      "Answer: D: recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 574 / 1408  (40.8):  70%|   | 1407/2000 [20:19<16:40,  1.69s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1408  (40.8):  70%|   | 1408/2000 [20:19<13:29,  1.37s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1409  (40.7):  70%|   | 1408/2000 [20:19<13:29,  1.37s/it]\u001b[A\n",
      "Average Metric: 574 / 1409  (40.7):  70%|   | 1409/2000 [20:19<10:17,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'barnch'. A: worked B: branch C: mistress D: surplus\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 574 / 1410  (40.7):  70%|   | 1409/2000 [20:21<10:17,  1.04s/it]\u001b[A\n",
      "Average Metric: 574 / 1410  (40.7):  70%|   | 1410/2000 [20:21<11:47,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 574 / 1411  (40.7):  70%|   | 1410/2000 [20:21<11:47,  1.20s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1411  (40.7):  71%|   | 1411/2000 [20:21<09:29,  1.03it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1412  (40.7):  71%|   | 1411/2000 [20:21<09:29,  1.03it/s]\u001b[A\n",
      "Average Metric: 574 / 1412  (40.7):  71%|   | 1412/2000 [20:21<07:30,  1.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1413  (40.6):  71%|   | 1412/2000 [20:22<07:30,  1.30it/s]\u001b[A\n",
      "Average Metric: 574 / 1413  (40.6):  71%|   | 1413/2000 [20:22<06:25,  1.52it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ktae'? A: died B: hardwood C: kate D: thank\n",
      "Answer: D: thank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1414  (40.6):  71%|   | 1413/2000 [20:22<06:25,  1.52it/s]\u001b[A\n",
      "Average Metric: 574 / 1414  (40.6):  71%|   | 1414/2000 [20:22<05:35,  1.75it/s]\u001b[A\n",
      "Average Metric: 574 / 1415  (40.6):  71%|   | 1414/2000 [20:23<05:35,  1.75it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 574 / 1415  (40.6):  71%|   | 1415/2000 [20:23<07:34,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1416  (40.5):  71%|   | 1415/2000 [20:24<07:34,  1.29it/s]\u001b[A\n",
      "Average Metric: 574 / 1416  (40.5):  71%|   | 1416/2000 [20:24<07:34,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cetelcloblis'? A: korn B: palace C: nascar D: collectibles\n",
      "Answer: B: palace\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'tlit'. A: tilt B: lost C: spoke D: critic\n",
      "Answer: D: critic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 574 / 1417  (40.5):  71%|   | 1416/2000 [20:26<07:34,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1417  (40.5):  71%|   | 1417/2000 [20:26<11:03,  1.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'avertiredss' to form the correct word. A: photographer B: modular C: advertisers D: nelson\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 0.5  B: 0.2  C: 0.1  D: 0.01\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the correct spelling of the word 'col\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1418  (40.5):  71%|   | 1417/2000 [20:27<11:03,  1.14s/it]\u001b[A\n",
      "Average Metric: 574 / 1418  (40.5):  71%|   | 1418/2000 [20:27<09:14,  1.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'snpak'. A: spank B: unified C: decorated D: theater\n",
      "Answer: D: theater\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 574 / 1419  (40.5):  71%|   | 1418/2000 [20:29<09:14,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 574 / 1419  (40.5):  71%|   | 1419/2000 [20:29<12:28,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ptorlmpy'? A: bonds B: crowd C: promptly D: surrounded\n",
      "Answer: D: surrounded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 574 / 1420  (40.4):  71%|   | 1419/2000 [20:29<12:28,  1.29s/it]\u001b[A\n",
      "Average Metric: 574 / 1420  (40.4):  71%|   | 1420/2000 [20:29<10:46,  1.11s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 1421  (40.5):  71%|   | 1420/2000 [20:30<10:46,  1.11s/it]\u001b[A\n",
      "Average Metric: 575 / 1421  (40.5):  71%|   | 1421/2000 [20:30<08:18,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 1422  (40.4):  71%|   | 1421/2000 [20:30<08:18,  1.16it/s]\u001b[A\n",
      "Average Metric: 575 / 1422  (40.4):  71%|   | 1422/2000 [20:30<06:42,  1.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 575 / 1423  (40.4):  71%|   | 1422/2000 [20:33<06:42,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 575 / 1423  (40.4):  71%|   | 1423/2000 [20:33<13:38,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 575 / 1424  (40.4):  71%|   | 1423/2000 [20:33<13:38,  1.42s/it]\u001b[A\n",
      "Average Metric: 575 / 1424  (40.4):  71%|   | 1424/2000 [20:33<09:53,  1.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'xxnx'? A: guild B: clarity C: belarus D: xnxx\n",
      "Answer: xnxx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 576 / 1425  (40.4):  71%|   | 1424/2000 [20:34<09:53,  1.03s/it]\u001b[A\n",
      "Average Metric: 576 / 1425  (40.4):  71%|  | 1425/2000 [20:34<08:36,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'houisng'? A: housing B: terrorist C: capabilities D: profiles\n",
      "Answer: A: housing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'dirvceite' represent when unscrambled? A: directive B: venus C: contests D: dildo\n",
      "Answer: A: directive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 576 / 1426  (40.4):  71%|  | 1425/2000 [20:36<08:36,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 576 / 1426  (40.4):  71%|  | 1426/2000 [20:36<11:05,  1.16s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 576 / 1427  (40.4):  71%|  | 1426/2000 [20:36<11:05,  1.16s/it]\u001b[A\n",
      "Average Metric: 576 / 1427  (40.4):  71%|  | 1427/2000 [20:36<08:11,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 577 / 1428  (40.4):  71%|  | 1427/2000 [20:36<08:11,  1.17it/s]\u001b[A\n",
      "Average Metric: 577 / 1428  (40.4):  71%|  | 1428/2000 [20:36<06:40,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 577 / 1429  (40.4):  71%|  | 1428/2000 [20:37<06:40,  1.43it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 577 / 1429  (40.4):  71%|  | 1429/2000 [20:37<06:46,  1.40it/s]\u001b[A\n",
      "Average Metric: 577 / 1430  (40.3):  71%|  | 1429/2000 [20:37<06:46,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 577 / 1430  (40.3):  72%|  | 1430/2000 [20:37<05:08,  1.85it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 577 / 1431  (40.3):  72%|  | 1430/2000 [20:37<05:08,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 578 / 1432  (40.4):  72%|  | 1431/2000 [20:40<05:07,  1.85it/s]\u001b[A\n",
      "Average Metric: 578 / 1432  (40.4):  72%|  | 1432/2000 [20:40<08:22,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sitvreey'. A: severity B: reputation C: restaurants D: credit\n",
      "Answer: A: severity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'balme' to form the correct word. A: blame B: slip C: colorado D: grill\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'meovd'. A: flashing B: defect C: reprints D: moved\n",
      "Answer: D: moved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 579 / 1433  (40.4):  72%|  | 1432/2000 [20:41<08:22,  1.13it/s]\u001b[A\n",
      "Average Metric: 579 / 1433  (40.4):  72%|  | 1433/2000 [20:41<09:56,  1.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hbioebs' to form the correct word. A: nearby B: virtual C: hobbies D: specifically\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 579 / 1434  (40.4):  72%|  | 1433/2000 [20:42<09:56,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 579 / 1434  (40.4):  72%|  | 1434/2000 [20:42<10:03,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'wtaosn' represent when unscrambled? A: titten B: watson C: december D: figures\n",
      "Answer: B: watson\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cesalss'. A: classes B: trophy C: rear D: dedication\n",
      "Answer: D: dedication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 579 / 1435  (40.3):  72%|  | 1434/2000 [20:43<10:03,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 579 / 1435  (40.3):  72%|  | 1435/2000 [20:43<10:07,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'mieralns'. A: minerals B: opportunity C: hang D: efficiency\n",
      "Answer: A: minerals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1436  (40.4):  72%|  | 1435/2000 [20:47<10:07,  1.08s/it]\u001b[A\n",
      "Average Metric: 580 / 1436  (40.4):  72%|  | 1436/2000 [20:47<15:45,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'atvilecy'. A: round B: china C: clayton D: actively\n",
      "Answer: D: actively\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1437  (40.4):  72%|  | 1436/2000 [20:47<15:45,  1.68s/it]\u001b[A\n",
      "Average Metric: 580 / 1437  (40.4):  72%|  | 1437/2000 [20:47<11:47,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'beelkrey' represent when unscrambled? A: randy B: bridal C: berkeley D: printable\n",
      "Answer: A: randy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'wram'? A: wilson B: tied C: warm D: hardy\n",
      "Answer: A: wilson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 580 / 1438  (40.3):  72%|  | 1437/2000 [20:48<11:47,  1.26s/it]\u001b[A\n",
      "Average Metric: 580 / 1438  (40.3):  72%|  | 1438/2000 [20:48<12:53,  1.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'dnaa'? A: continental B: restricted C: holy D: dana\n",
      "Answer: D: dana\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'andlae'? A: potentially B: andale C: daily D: developer\n",
      "Answer: D: developer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1439  (40.3):  72%|  | 1438/2000 [20:49<12:53,  1.38s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 580 / 1439  (40.3):  72%|  | 1439/2000 [20:49<11:11,  1.20s/it]\u001b[A\n",
      "Average Metric: 580 / 1440  (40.3):  72%|  | 1439/2000 [20:49<11:11,  1.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cliceaalnotn'? A: keeps B: duplicate C: cancellation D: indiana\n",
      "Answer: D: indiana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 580 / 1441  (40.2):  72%|  | 1440/2000 [20:50<11:10,  1.20s/it]\u001b[A\n",
      "Average Metric: 580 / 1441  (40.2):  72%|  | 1441/2000 [20:50<08:26,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 581 / 1442  (40.3):  72%|  | 1441/2000 [20:51<08:26,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 581 / 1442  (40.3):  72%|  | 1442/2000 [20:51<08:51,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peetr'. A: halloween B: pierce C: freeman D: peter\n",
      "Answer: D: peter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 581 / 1443  (40.3):  72%|  | 1442/2000 [20:52<08:51,  1.05it/s]\u001b[A\n",
      "Average Metric: 581 / 1443  (40.3):  72%|  | 1443/2000 [20:52<07:38,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 582 / 1444  (40.3):  72%|  | 1443/2000 [20:53<07:38,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 582 / 1444  (40.3):  72%|  | 1444/2000 [20:53<07:29,  1.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'seiphpd'. A: size B: celebrate C: shipped D: discrepancies\n",
      "Answer: D: discrepancies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 583 / 1445  (40.3):  72%|  | 1444/2000 [20:53<07:29,  1.24it/s]\u001b[A\n",
      "Average Metric: 583 / 1445  (40.3):  72%|  | 1445/2000 [20:53<07:22,  1.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 583 / 1446  (40.3):  72%|  | 1445/2000 [20:53<07:22,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 584 / 1447  (40.4):  72%|  | 1446/2000 [20:54<07:22,  1.25it/s]\u001b[A\n",
      "Average Metric: 584 / 1447  (40.4):  72%|  | 1447/2000 [20:54<05:34,  1.65it/s]\u001b[A\n",
      "Average Metric: 584 / 1448  (40.3):  72%|  | 1447/2000 [20:55<05:34,  1.65it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 584 / 1448  (40.3):  72%|  | 1448/2000 [20:55<06:15,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anluuimm'. A: spiral B: council C: preserved D: aluminum\n",
      "Answer: D: aluminum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 585 / 1449  (40.4):  72%|  | 1448/2000 [20:56<06:15,  1.47it/s]\u001b[A\n",
      "Average Metric: 585 / 1449  (40.4):  72%|  | 1449/2000 [20:56<08:02,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 586 / 1450  (40.4):  72%|  | 1449/2000 [20:57<08:02,  1.14it/s]\u001b[A\n",
      "Average Metric: 586 / 1450  (40.4):  72%|  | 1450/2000 [20:57<07:32,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'heelwtt' represent when unscrambled? A: palmer B: hewlett C: rebecca D: threat\n",
      "Answer: A: palmer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 586 / 1451  (40.4):  72%|  | 1450/2000 [20:58<07:32,  1.22it/s]\u001b[A\n",
      "Average Metric: 586 / 1451  (40.4):  73%|  | 1451/2000 [20:58<07:12,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'amuesss' represent when unscrambled? A: assumes B: canterbury C: floral D: passwords\n",
      "Answer: A: assumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 587 / 1452  (40.4):  73%|  | 1451/2000 [20:59<07:12,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 587 / 1452  (40.4):  73%|  | 1452/2000 [20:59<08:04,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'qruretlay' to form the correct word. A: subjects B: forbidden C: minimal D: quarterly\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cpoomiteln'. A: completion B: level C: anxiety D: trust\n",
      "Answer: D: trust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 587 / 1453  (40.4):  73%|  | 1452/2000 [21:00<08:04,  1.13it/s]\u001b[A\n",
      "Average Metric: 587 / 1453  (40.4):  73%|  | 1453/2000 [21:00<08:16,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 587 / 1454  (40.4):  73%|  | 1453/2000 [21:01<08:16,  1.10it/s]\u001b[A\n",
      "Average Metric: 587 / 1454  (40.4):  73%|  | 1454/2000 [21:01<08:29,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 587 / 1455  (40.3):  73%|  | 1454/2000 [21:02<08:29,  1.07it/s]\u001b[A\n",
      "Average Metric: 587 / 1455  (40.3):  73%|  | 1455/2000 [21:02<09:14,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 588 / 1456  (40.4):  73%|  | 1455/2000 [21:04<09:14,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 588 / 1456  (40.4):  73%|  | 1456/2000 [21:04<10:36,  1.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fianlly' to form the correct word. A: gays B: operation C: finally D: titled\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gaxaly' to form the correct word. A: galaxy B: christmas C: inherited D: writings\n",
      "Answer: A: galaxy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 589 / 1457  (40.4):  73%|  | 1456/2000 [21:05<10:36,  1.17s/it]\u001b[A\n",
      "Average Metric: 589 / 1457  (40.4):  73%|  | 1457/2000 [21:05<11:14,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'amrs' to form the correct word. A: henry B: arms C: mint D: exchange\n",
      "Answer: D: exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'raenl'. A: renal B: bones C: therapeutic D: reproductive\n",
      "Answer: A: renal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 590 / 1458  (40.5):  73%|  | 1457/2000 [21:06<11:14,  1.24s/it]\u001b[A\n",
      "Average Metric: 590 / 1458  (40.5):  73%|  | 1458/2000 [21:06<09:14,  1.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'peiord'? A: nature B: period C: arise D: shemale\n",
      "Answer: B: period\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'paaranmreitly'. A: parliamentary B: pause C: discussed D: treasure\n",
      "Answer: D: treasure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 590 / 1459  (40.4):  73%|  | 1458/2000 [21:07<09:14,  1.02s/it]\u001b[A\n",
      "Average Metric: 590 / 1459  (40.4):  73%|  | 1459/2000 [21:07<09:27,  1.05s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 591 / 1460  (40.5):  73%|  | 1459/2000 [21:07<09:27,  1.05s/it]\u001b[A\n",
      "Average Metric: 591 / 1460  (40.5):  73%|  | 1460/2000 [21:07<07:53,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 592 / 1461  (40.5):  73%|  | 1460/2000 [21:08<07:53,  1.14it/s]\u001b[A\n",
      "Average Metric: 592 / 1461  (40.5):  73%|  | 1461/2000 [21:08<06:47,  1.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'faer' represent when unscrambled? A: fear B: thousand C: camera D: intersection\n",
      "Answer: A: fear"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 592 / 1462  (40.5):  73%|  | 1461/2000 [21:09<06:47,  1.32it/s]\u001b[A\n",
      "Average Metric: 592 / 1462  (40.5):  73%|  | 1462/2000 [21:10<09:41,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dntermepaatl'. A: departmental B: stronger C: approaching D: lopez\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'wnig'. A: authorities B: johnston C: zshops D: wing\n",
      "Answer: D: wing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'msuuem'? A: mann B: museum C: treated D: palm\n",
      "Answer: B: museum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anghsaaitfn'. A: afghanistan B: designer C: owners D: baked\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 593 / 1463  (40.5):  73%|  | 1462/2000 [21:12<09:41,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 593 / 1463  (40.5):  73%|  | 1463/2000 [21:12<13:54,  1.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 594 / 1464  (40.6):  73%|  | 1463/2000 [21:13<13:54,  1.55s/it]\u001b[A\n",
      "Average Metric: 594 / 1464  (40.6):  73%|  | 1464/2000 [21:13<12:42,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 595 / 1465  (40.6):  73%|  | 1464/2000 [21:14<12:42,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 595 / 1465  (40.6):  73%|  | 1465/2000 [21:14<10:22,  1.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'coecrltlos' represent when unscrambled? A: currencies B: truth C: collectors D: beliefs\n",
      "Answer: B: truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 595 / 1466  (40.6):  73%|  | 1465/2000 [21:14<10:22,  1.16s/it]\u001b[A\n",
      "Average Metric: 595 / 1466  (40.6):  73%|  | 1466/2000 [21:14<08:19,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'slehter'. A: forming B: shelter C: isle D: oman\n",
      "Answer: C: isle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 596 / 1467  (40.6):  73%|  | 1466/2000 [21:15<08:19,  1.07it/s]\u001b[A\n",
      "Average Metric: 596 / 1467  (40.6):  73%|  | 1467/2000 [21:15<07:06,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'jeoks' represent when unscrambled? A: highly B: subsidiary C: apparent D: jokes\n",
      "Answer: D: jokes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'satr'? A: bathroom B: recognize C: star D: plaintiff\n",
      "Answer: A: bathroom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 596 / 1468  (40.6):  73%|  | 1467/2000 [21:18<07:06,  1.25it/s]\u001b[A\n",
      "Average Metric: 596 / 1468  (40.6):  73%|  | 1468/2000 [21:18<12:44,  1.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 596 / 1469  (40.6):  73%|  | 1468/2000 [21:18<12:44,  1.44s/it]\u001b[A\n",
      "Average Metric: 596 / 1469  (40.6):  73%|  | 1469/2000 [21:18<10:25,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'poettr'? A: accept B: potter C: webcast D: updated\n",
      "Answer: B: potter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 597 / 1470  (40.6):  73%|  | 1469/2000 [21:19<10:25,  1.18s/it]\u001b[A\n",
      "Average Metric: 597 / 1470  (40.6):  74%|  | 1470/2000 [21:19<08:56,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ueurcnsed' represent when unscrambled? A: injured B: hoping C: unsecured D: democrat\n",
      "Answer: D: democrat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'revsere'? A: iraqi B: reverse C: clue D: impossible\n",
      "Answer: B: reverse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 597 / 1471  (40.6):  74%|  | 1470/2000 [21:22<08:56,  1.01s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 597 / 1471  (40.6):  74%|  | 1471/2000 [21:22<14:57,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fotry' to form the correct word. A: forty B: predict C: funny D: explanation\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cosenlos'. A: consoles B: arrange C: wars D: illustrations\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 598 / 1472  (40.6):  74%|  | 1471/2000 [21:23<14:57,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 598 / 1472  (40.6):  74%|  | 1472/2000 [21:23<14:01,  1.59s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 599 / 1473  (40.7):  74%|  | 1472/2000 [21:24<14:01,  1.59s/it]\u001b[A\n",
      "Average Metric: 599 / 1473  (40.7):  74%|  | 1473/2000 [21:24<11:55,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 600 / 1474  (40.7):  74%|  | 1473/2000 [21:25<11:55,  1.36s/it]\u001b[A\n",
      "Average Metric: 600 / 1474  (40.7):  74%|  | 1474/2000 [21:25<10:51,  1.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 600 / 1475  (40.7):  74%|  | 1474/2000 [21:26<10:51,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 600 / 1475  (40.7):  74%|  | 1475/2000 [21:26<08:43,  1.00it/s]\u001b[A\n",
      "Average Metric: 600 / 1476  (40.7):  74%|  | 1475/2000 [21:26<08:43,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 600 / 1476  (40.7):  74%|  | 1476/2000 [21:26<06:27,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'gsetus' to form the correct word. A: contribute B: guests C: blowjobs D: roman\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 600 / 1477  (40.6):  74%|  | 1476/2000 [21:28<06:27,  1.35it/s]\u001b[A\n",
      "Average Metric: 600 / 1477  (40.6):  74%|  | 1477/2000 [21:28<10:03,  1.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 601 / 1478  (40.7):  74%|  | 1477/2000 [21:29<10:03,  1.15s/it]\u001b[A\n",
      "Average Metric: 601 / 1478  (40.7):  74%|  | 1478/2000 [21:29<08:47,  1.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'flirdoa'. A: samuel B: decent C: florida D: greenhouse\n",
      "Answer: D: greenhouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 601 / 1479  (40.6):  74%|  | 1478/2000 [21:30<08:47,  1.01s/it]\u001b[A\n",
      "Average Metric: 601 / 1479  (40.6):  74%|  | 1479/2000 [21:30<08:56,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aacfrin' to form the correct word. A: african B: systematic C: mode D: moderate\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 601 / 1480  (40.6):  74%|  | 1479/2000 [21:30<08:56,  1.03s/it]\u001b[A\n",
      "Average Metric: 601 / 1480  (40.6):  74%|  | 1480/2000 [21:30<07:36,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'eupraeon' represent when unscrambled? A: european B: plated C: oriental D: school\n",
      "Answer: A: european\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'brduen'. A: criminal B: secretariat C: burden D: cracks\n",
      "Answer: A: criminal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'innndeeepdt' represent when unscrambled? A: aimed B: independent C: mesh D: dimensions\n",
      "Answer: D: dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 602 / 1481  (40.6):  74%|  | 1480/2000 [21:33<07:36,  1.14it/s]\u001b[A\n",
      "Average Metric: 602 / 1481  (40.6):  74%|  | 1481/2000 [21:33<12:17,  1.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 603 / 1482  (40.7):  74%|  | 1481/2000 [21:34<12:17,  1.42s/it]\u001b[A\n",
      "Average Metric: 603 / 1482  (40.7):  74%|  | 1482/2000 [21:34<12:05,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hladne'? A: sediment B: todd C: latter D: handle\n",
      "Answer: B: todd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'iiadstrunl'. A: bubble B: industrial C: flood D: pubmed\n",
      "Answer: D: pubmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'amuutn'. A: creative B: vacuum C: autumn D: cuisine\n",
      "Answer: D: cuisine\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'siuotprpve'? A: transsexual B: alarms C: supportive D: visitors\n",
      "Answer: D: visitors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 603 / 1483  (40.7):  74%|  | 1482/2000 [21:36<12:05,  1.40s/it]\u001b[A\n",
      "Average Metric: 603 / 1483  (40.7):  74%|  | 1483/2000 [21:36<13:35,  1.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'seewt' represent when unscrambled? A: slovakia B: panties C: barry D: sweet\n",
      "Answer: D: sweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 1484  (40.7):  74%|  | 1483/2000 [21:38<13:35,  1.58s/it]\u001b[A\n",
      "Average Metric: 604 / 1484  (40.7):  74%|  | 1484/2000 [21:38<13:11,  1.53s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 604 / 1485  (40.7):  74%|  | 1484/2000 [21:38<13:11,  1.53s/it]\u001b[A\n",
      "Average Metric: 604 / 1485  (40.7):  74%|  | 1485/2000 [21:38<10:06,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sgitraht' to form the correct word. A: straight B: tuesday C: scheduling D: series\n",
      "Answer: D: series\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 604 / 1486  (40.6):  74%|  | 1485/2000 [21:39<10:06,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 604 / 1486  (40.6):  74%|  | 1486/2000 [21:39<08:52,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'plao'? A: northern B: palo C: genus D: algebra\n",
      "Answer: B: paloAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'cmmiot'. A: hitachi B: backing C: commit D: except\n",
      "Answer: D: except\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cliavn' to form the correct word. A: blank B: calvin C: meeting D: eliminated\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'serhpehd' represent when unscrambled? A: back B: reward C: masks D: shepherd\n",
      "Answer: D: shepherd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 1487  (40.7):  74%|  | 1486/2000 [21:42<08:52,  1.04s/it]\u001b[A\n",
      "Average Metric: 605 / 1487  (40.7):  74%|  | 1487/2000 [21:42<15:18,  1.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 1488  (40.7):  74%|  | 1487/2000 [21:43<15:18,  1.79s/it]\u001b[A\n",
      "Average Metric: 605 / 1488  (40.7):  74%|  | 1488/2000 [21:43<11:30,  1.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'sfaari' to form the correct word. A: charles B: approx C: safari D: kodak\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 605 / 1489  (40.6):  74%|  | 1488/2000 [21:43<11:30,  1.35s/it]\u001b[A\n",
      "Average Metric: 605 / 1489  (40.6):  74%|  | 1489/2000 [21:43<09:00,  1.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cunot'? A: continuous B: clearing C: count D: locally\n",
      "Answer: D: locally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 1490  (40.7):  74%|  | 1489/2000 [21:44<09:00,  1.06s/it]\u001b[A\n",
      "Average Metric: 606 / 1490  (40.7):  74%|  | 1490/2000 [21:44<07:41,  1.10it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 1491  (40.6):  74%|  | 1490/2000 [21:44<07:41,  1.10it/s]\u001b[A\n",
      "Average Metric: 606 / 1491  (40.6):  75%|  | 1491/2000 [21:44<06:01,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 606 / 1492  (40.6):  75%|  | 1491/2000 [21:45<06:01,  1.41it/s]\u001b[A\n",
      "Average Metric: 606 / 1492  (40.6):  75%|  | 1492/2000 [21:45<08:24,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rnad'? A: houston B: aggressive C: rand D: feeling\n",
      "Answer: D: feeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 607 / 1493  (40.7):  75%|  | 1492/2000 [21:46<08:24,  1.01it/s]\u001b[A\n",
      "Average Metric: 607 / 1493  (40.7):  75%|  | 1493/2000 [21:46<06:52,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fweer' to form the correct word. A: fewer B: grain C: infinite D: brook\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'mlaotprieton' to form the correct word. A: auditing B: raise C: varying D: metropolitan\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 607 / 1494  (40.6):  75%|  | 1493/2000 [21:47<06:52,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 607 / 1494  (40.6):  75%|  | 1494/2000 [21:47<07:50,  1.08it/s]\u001b[A\n",
      "Average Metric: 608 / 1495  (40.7):  75%|  | 1494/2000 [21:47<07:50,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'mree'. A: mere B: jessica C: control D: athlon\n",
      "Answer: D: athlon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'toreapml'? A: deputy B: find C: temporal D: elimination\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 609 / 1496  (40.7):  75%|  | 1495/2000 [21:50<07:49,  1.08it/s]\u001b[A\n",
      "Average Metric: 609 / 1496  (40.7):  75%|  | 1496/2000 [21:50<09:03,  1.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'kegdwlnoe' represent when unscrambled? A: yale B: bingo C: knowledge D: edited\n",
      "Answer: D: edited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'berhancs' to form the correct word. A: notice B: float C: branches D: working\n",
      "Answer: D"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 610 / 1497  (40.7):  75%|  | 1496/2000 [21:52<09:03,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 610 / 1497  (40.7):  75%|  | 1497/2000 [21:52<11:24,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'eatluvaing'? A: battlefield B: wars C: evaluating D: depend\n",
      "Answer: D: depend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 611 / 1498  (40.8):  75%|  | 1497/2000 [21:53<11:24,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fxtuiers' to form the correct word. A: traffic B: assault C: fixtures D: respond\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 611 / 1498  (40.8):  75%|  | 1498/2000 [21:53<11:25,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 612 / 1499  (40.8):  75%|  | 1498/2000 [21:54<11:25,  1.36s/it]\u001b[A\n",
      "Average Metric: 612 / 1499  (40.8):  75%|  | 1499/2000 [21:54<09:12,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cianorla'? A: sandwich B: electron C: carolina D: collected\n",
      "Answer: D: collected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1500  (40.9):  75%|  | 1499/2000 [21:54<09:12,  1.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1500  (40.9):  75%|  | 1500/2000 [21:54<08:02,  1.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'peirottncg'. A: protecting B: fold C: surveys D: identify\n",
      "Answer: D: identify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'snas'. A: friends B: sans C: expectations D: relevance\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'spcheees' to form the correct word. A: lights B: proper C: hartford D: speeches\n",
      "Answer: D: speeches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1501  (40.8):  75%|  | 1500/2000 [21:56<08:02,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 613 / 1501  (40.8):  75%|  | 1501/2000 [21:56<09:32,  1.15s/it]\u001b[A\n",
      "Average Metric: 613 / 1502  (40.8):  75%|  | 1501/2000 [21:57<09:32,  1.15s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1502  (40.8):  75%|  | 1502/2000 [21:57<08:52,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1503  (40.8):  75%|  | 1502/2000 [21:58<08:52,  1.07s/it]\u001b[A\n",
      "Average Metric: 613 / 1503  (40.8):  75%|  | 1503/2000 [21:58<09:13,  1.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1504  (40.8):  75%|  | 1503/2000 [21:59<09:13,  1.11s/it]\u001b[A\n",
      "Average Metric: 613 / 1504  (40.8):  75%|  | 1504/2000 [21:59<08:51,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ittisaollurn' represent when unscrambled? A: consumption B: taxes C: prefer D: illustration\n",
      "Answer: A: consumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 613 / 1505  (40.7):  75%|  | 1504/2000 [21:59<08:51,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 613 / 1505  (40.7):  75%|  | 1505/2000 [21:59<06:34,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'puopp' to form the correct word. A: popup B: partly C: architects D: kills\n",
      "Answer: B\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'hunragy' to form the correct word. A: hungary B: optimization C: condos D: stroke\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1506  (40.7):  75%|  | 1505/2000 [22:00<06:34,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 613 / 1506  (40.7):  75%|  | 1506/2000 [22:00<07:54,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'rreushiebfd'. A: refurbished B: trim C: write D: move\n",
      "Answer: D: move\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'rngares' to form the correct word. A: purpose B: guides C: rangers D: glasgow\n",
      "Answer: DAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'asissts'. A: appliances B: kitchen C: pete D: assists\n",
      "Answer: D: assists\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which planet is closest to the sun? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: Which country invented the light bulb? A: Germany B: United States C: Italy D: France\n",
      "Answer: B: United States\n",
      "\n",
      "Question: What is the\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cnlooy' represent when unscrambled? A: amateur B: accounting C: colony D: heart\n",
      "Answer: D: heart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1507  (40.7):  75%|  | 1506/2000 [22:03<07:54,  1.04it/s]\u001b[A\n",
      "Average Metric: 613 / 1507  (40.7):  75%|  | 1507/2000 [22:03<12:28,  1.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'anitlrgon'. A: thinkpad B: arlington C: windows D: wilderness\n",
      "Answer: D: wilderness\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'caameinottnd'. A: contaminated B: supervisors C: portrait D: agencies\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'martnoey' to form the correct word. A: conversation B: monetary C: regression D: circumstances\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 613 / 1508  (40.6):  75%|  | 1507/2000 [22:05<12:28,  1.52s/it]\u001b[A\n",
      "Average Metric: 613 / 1508  (40.6):  75%|  | 1508/2000 [22:05<13:39,  1.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'hloets' represent when unscrambled? A: hotels B: summaries C: frost D: improved\n",
      "Answer: A: hotels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 613 / 1509  (40.6):  75%|  | 1508/2000 [22:06<13:39,  1.67s/it]\u001b[A\n",
      "Average Metric: 613 / 1509  (40.6):  75%|  | 1509/2000 [22:06<11:27,  1.40s/it]\u001b[A\n",
      "Average Metric: 614 / 1510  (40.7):  75%|  | 1509/2000 [22:06<11:27,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1511  (40.6):  76%|  | 1510/2000 [22:06<11:26,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1511  (40.6):  76%|  | 1511/2000 [22:06<06:45,  1.20it/s]\u001b[A\n",
      "Average Metric: 614 / 1512  (40.6):  76%|  | 1511/2000 [22:07<06:45,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1512  (40.6):  76%|  | 1512/2000 [22:07<07:21,  1.10it/s]\u001b[A\n",
      "Average Metric: 614 / 1513  (40.6):  76%|  | 1512/2000 [22:07<07:21,  1.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 614 / 1514  (40.6):  76%|  | 1513/2000 [22:08<07:21,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 614 / 1514  (40.6):  76%|  | 1514/2000 [22:08<05:13,  1.55it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 615 / 1515  (40.6):  76%|  | 1514/2000 [22:08<05:13,  1.55it/s]\u001b[A\n",
      "Average Metric: 615 / 1515  (40.6):  76%|  | 1515/2000 [22:08<04:27,  1.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fcaed' represent when unscrambled? A: distribute B: pissing C: faced D: phentermine\n",
      "Answer: A: distribute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'lnae'? A: lane B: accomplish C: household D: bath\n",
      "Answer: D: bath\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'ofroxd' represent when unscrambled? A: oxford B: jackets C: ncaa D: boxed\n",
      "Answer: A: oxford\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 615 / 1516  (40.6):  76%|  | 1515/2000 [22:10<04:27,  1.81it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 615 / 1516  (40.6):  76%|  | 1516/2000 [22:10<06:20,  1.27it/s]\u001b[A\n",
      "Average Metric: 616 / 1517  (40.6):  76%|  | 1516/2000 [22:10<06:20,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 616 / 1517  (40.6):  76%|  | 1517/2000 [22:10<05:58,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 616 / 1518  (40.6):  76%|  | 1517/2000 [22:12<05:58,  1.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'durg'. A: filters B: reader C: drug D: cent\n",
      "Answer: C: drug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 616 / 1518  (40.6):  76%|  | 1518/2000 [22:12<08:46,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'psoreimd' to form the correct word. A: dolls B: disagree C: security D: promised\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 617 / 1519  (40.6):  76%|  | 1518/2000 [22:17<08:46,  1.09s/it]\u001b[A\n",
      "Average Metric: 617 / 1519  (40.6):  76%|  | 1519/2000 [22:17<15:45,  1.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'massttasheucs'. A: dildos B: dies C: massachusetts D: easy\n",
      "Answer: d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'clriecs' represent when unscrambled? A: circles B: website C: sheep D: sight\n",
      "Answer: D: sight\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'analittc'? A: atlantic B: atlanta C: note D: restore\n",
      "Answer: D: restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 617 / 1520  (40.6):  76%|  | 1519/2000 [22:19<15:45,  1.96s/it]\u001b[A\n",
      "Average Metric: 617 / 1520  (40.6):  76%|  | 1520/2000 [22:19<16:05,  2.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 618 / 1521  (40.6):  76%|  | 1520/2000 [22:19<16:05,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 618 / 1521  (40.6):  76%|  | 1521/2000 [22:19<12:27,  1.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 619 / 1522  (40.7):  76%|  | 1521/2000 [22:21<12:27,  1.56s/it]\u001b[A\n",
      "Average Metric: 619 / 1522  (40.7):  76%|  | 1522/2000 [22:21<12:10,  1.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 619 / 1523  (40.6):  76%|  | 1522/2000 [22:21<12:10,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 619 / 1523  (40.6):  76%|  | 1523/2000 [22:21<09:48,  1.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'cplioxemty' to form the correct word. A: variant B: journals C: complexity D: glen\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 619 / 1524  (40.6):  76%|  | 1523/2000 [22:21<09:48,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 619 / 1524  (40.6):  76%|  | 1524/2000 [22:21<07:26,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 620 / 1525  (40.7):  76%|  | 1524/2000 [22:22<07:26,  1.07it/s]\u001b[A\n",
      "Average Metric: 620 / 1525  (40.7):  76%|  | 1525/2000 [22:22<06:40,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'weed'? A: weed B: internationally C: amateur D: inventory\n",
      "Answer: D: inventory\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'valibe'. A: viable B: char C: assisted D: movie\n",
      "Answer: A: viable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 621 / 1526  (40.7):  76%|  | 1525/2000 [22:23<06:40,  1.19it/s]\u001b[A\n",
      "Average Metric: 621 / 1526  (40.7):  76%|  | 1526/2000 [22:23<07:07,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cignoinufrg' represent when unscrambled? A: controllers B: configuring C: quit D: though\n",
      "Answer: D: though\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/3519022564.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'drak'? A: dark B: numerical C: cocks D: observation\n",
      "Answer: A: darkAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'radny' represent when unscrambled? A: gamecube B: recipes C: randy D: dennis\n",
      "Answer: A: gamecube\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lebrial' represent when unscrambled? A: ideas B: sparc C: interaction D: liberal\n",
      "Answer: D: liberal\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'femrad'. A: affiliated B: configuration C: framed D: endless\n",
      "Answer: D: endless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 622 / 1527  (40.7):  76%|  | 1526/2000 [22:27<07:07,  1.11it/s]\u001b[A\n",
      "Average Metric: 622 / 1527  (40.7):  76%|  | 1527/2000 [22:27<15:08,  1.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cntenaiod' represent when unscrambled? A: extends B: finds C: principal D: contained\n",
      "Answer: D: contained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 622 / 1528  (40.7):  76%|  | 1527/2000 [22:28<15:08,  1.92s/it]\u001b[A\n",
      "Average Metric: 622 / 1528  (40.7):  76%|  | 1528/2000 [22:28<12:20,  1.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 623 / 1529  (40.7):  76%|  | 1528/2000 [22:29<12:20,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 623 / 1529  (40.7):  76%|  | 1529/2000 [22:29<10:09,  1.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 623 / 1530  (40.7):  76%|  | 1529/2000 [22:29<10:09,  1.29s/it]\u001b[A\n",
      "Average Metric: 623 / 1530  (40.7):  76%|  | 1530/2000 [22:29<07:45,  1.01it/s]\u001b[A\n",
      "Average Metric: 624 / 1531  (40.8):  76%|  | 1530/2000 [22:29<07:45,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 624 / 1531  (40.8):  77%|  | 1531/2000 [22:29<05:51,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ceerk'? A: seek B: affairs C: midlands D: creek\n",
      "Answer: creek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'fctas' represent when unscrambled? A: forwarded B: facts C: lender D: clocks\n",
      "Answer: A: forwarded\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'bnealkt'. A: belkin B: blanket C: connectors D: caribbean\n",
      "Answer: D: caribbean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 1532  (40.8):  77%|  | 1531/2000 [22:31<05:51,  1.34it/s]\u001b[A\n",
      "Average Metric: 625 / 1532  (40.8):  77%|  | 1532/2000 [22:31<08:32,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 625 / 1533  (40.8):  77%|  | 1532/2000 [22:31<08:32,  1.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 1534  (40.7):  77%|  | 1533/2000 [22:31<08:31,  1.09s/it]\u001b[A\n",
      "Average Metric: 625 / 1534  (40.7):  77%|  | 1534/2000 [22:31<05:16,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rduece'? A: client B: reduce C: longer D: kill\n",
      "Answer: B: reduce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 625 / 1535  (40.7):  77%|  | 1534/2000 [22:32<05:16,  1.47it/s]\u001b[A\n",
      "Average Metric: 625 / 1535  (40.7):  77%|  | 1535/2000 [22:32<05:53,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1536  (40.8):  77%|  | 1535/2000 [22:33<05:53,  1.32it/s]\u001b[A\n",
      "Average Metric: 626 / 1536  (40.8):  77%|  | 1536/2000 [22:33<05:50,  1.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'atshma' to form the correct word. A: resolution B: asthma C: children D: phpbb\n",
      "Answer: B: asthma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 626 / 1537  (40.7):  77%|  | 1536/2000 [22:35<05:50,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 626 / 1537  (40.7):  77%|  | 1537/2000 [22:35<08:13,  1.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'cliitooan' represent when unscrambled? A: coalition B: dirty C: guitars D: charges\n",
      "Answer: A: coalition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'aobrr' to form the correct word. A: discounts B: researcher C: arbor D: situated\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'retoprs' to form the correct word. A: according B: allowed C: reports D: combined\n",
      "Answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1538  (40.7):  77%|  | 1537/2000 [22:39<08:13,  1.07s/it]\u001b[A\n",
      "Average Metric: 626 / 1538  (40.7):  77%|  | 1538/2000 [22:39<15:05,  1.96s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1539  (40.7):  77%|  | 1538/2000 [22:39<15:05,  1.96s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 626 / 1540  (40.6):  77%|  | 1539/2000 [22:40<15:03,  1.96s/it]\u001b[A\n",
      "Average Metric: 626 / 1540  (40.6):  77%|  | 1540/2000 [22:40<09:02,  1.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 626 / 1541  (40.6):  77%|  | 1540/2000 [22:40<09:02,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 626 / 1541  (40.6):  77%|  | 1541/2000 [22:40<07:36,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'dleay'. A: tools B: screw C: handmade D: delay\n",
      "Answer: D: delay\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'stie'. A: covering B: researcher C: khan D: site\n",
      "Answer: A: covering\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'rael'? A: real B: scripts C: pretty D: innocent\n",
      "Answer: real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 627 / 1542  (40.7):  77%|  | 1541/2000 [22:41<07:36,  1.01it/s]\u001b[A\n",
      "Average Metric: 627 / 1542  (40.7):  77%|  | 1542/2000 [22:41<07:20,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 627 / 1543  (40.6):  77%|  | 1542/2000 [22:41<07:20,  1.04it/s]\u001b[A\n",
      "Average Metric: 627 / 1543  (40.6):  77%|  | 1543/2000 [22:41<06:06,  1.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'alriutsaa'. A: pediatric B: bent C: australia D: podcast\n",
      "Answer: A: pediatric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 1544  (40.7):  77%|  | 1543/2000 [22:42<06:06,  1.25it/s]\u001b[A\n",
      "Average Metric: 628 / 1544  (40.7):  77%|  | 1544/2000 [22:42<06:14,  1.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 1545  (40.6):  77%|  | 1544/2000 [22:43<06:14,  1.22it/s]\u001b[A\n",
      "Average Metric: 628 / 1545  (40.6):  77%|  | 1545/2000 [22:43<05:29,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 628 / 1546  (40.6):  77%|  | 1545/2000 [22:43<05:29,  1.38it/s]\u001b[A\n",
      "Average Metric: 628 / 1546  (40.6):  77%|  | 1546/2000 [22:43<04:29,  1.69it/s]\u001b[A\n",
      "Average Metric: 629 / 1547  (40.7):  77%|  | 1546/2000 [22:44<04:29,  1.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 629 / 1547  (40.7):  77%|  | 1547/2000 [22:44<04:37,  1.63it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'cdaseiilfss'. A: coaches B: classifieds C: floating D: villages\n",
      "Answer: C: floating\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'srvee'. A: belize B: ought C: attend D: serve\n",
      "Answer: D: serve\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'waogn' to form the correct word. A: pushed B: seventh C: wagon D: adsl\n",
      "Answer: D\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'lrbotaraoy' represent when unscrambled? A: laboratory B: keep C: adjusted D: debates\n",
      "Answer: A: laboratory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sehpad'. A: serbia B: threshold C: shaped D: boyfriend\n",
      "Answer: A: serbia\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'piaentt'. A: patient B: tubes C: heads D: attachments\n",
      "Answer: A: patient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'vgteearain' represent when unscrambled? A: accordingly B: newsletters C: vegetarian D: commented\n",
      "Answer: D: commentedAnswer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'kpbs'? A: kbps B: shuttle C: album D: beatles\n",
      "Answer: kbps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1548  (40.6):  77%|  | 1547/2000 [22:49<04:37,  1.63it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1548  (40.6):  77%|  | 1548/2000 [22:49<14:51,  1.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 629 / 1549  (40.6):  77%|  | 1548/2000 [22:50<14:51,  1.97s/it]\u001b[A\n",
      "Average Metric: 629 / 1549  (40.6):  77%|  | 1549/2000 [22:50<12:17,  1.64s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1550  (40.6):  77%|  | 1549/2000 [22:50<12:17,  1.64s/it]\u001b[A\n",
      "Average Metric: 629 / 1550  (40.6):  78%|  | 1550/2000 [22:50<09:36,  1.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 629 / 1551  (40.6):  78%|  | 1550/2000 [22:50<09:36,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1552  (40.5):  78%|  | 1551/2000 [22:50<09:34,  1.28s/it]\u001b[A\n",
      "Average Metric: 629 / 1552  (40.5):  78%|  | 1552/2000 [22:50<05:33,  1.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1553  (40.5):  78%|  | 1552/2000 [22:51<05:33,  1.34it/s]\u001b[A\n",
      "Average Metric: 629 / 1553  (40.5):  78%|  | 1553/2000 [22:51<04:32,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'setnueqlbusy' to form the correct word. A: step B: subsequently C: start D: furnishings\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1554  (40.5):  78%|  | 1553/2000 [22:52<04:32,  1.64it/s]\u001b[A\n",
      "Average Metric: 629 / 1554  (40.5):  78%|  | 1554/2000 [22:52<06:14,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1555  (40.5):  78%|  | 1554/2000 [22:53<06:14,  1.19it/s]\u001b[A\n",
      "Average Metric: 629 / 1555  (40.5):  78%|  | 1555/2000 [22:53<05:31,  1.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1556  (40.4):  78%|  | 1555/2000 [22:53<05:31,  1.34it/s]\u001b[A\n",
      "Average Metric: 629 / 1556  (40.4):  78%|  | 1556/2000 [22:53<04:18,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 629 / 1557  (40.4):  78%|  | 1556/2000 [22:53<04:18,  1.72it/s]\u001b[A\n",
      "Average Metric: 629 / 1557  (40.4):  78%|  | 1557/2000 [22:53<03:26,  2.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'ltifmiee'. A: lifetime B: segments C: brutal D: arcade\n",
      "Answer: D: arcade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 630 / 1558  (40.4):  78%|  | 1557/2000 [22:53<03:26,  2.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'sroce'. A: score B: halo C: fundamental D: vegetarian\n",
      "Answer: A: score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 630 / 1559  (40.4):  78%|  | 1558/2000 [22:54<03:25,  2.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 630 / 1559  (40.4):  78%|  | 1559/2000 [22:54<03:07,  2.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 630 / 1560  (40.4):  78%|  | 1559/2000 [22:54<03:07,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 631 / 1561  (40.4):  78%|  | 1560/2000 [22:54<03:07,  2.35it/s]\u001b[A\n",
      "Average Metric: 631 / 1561  (40.4):  78%|  | 1561/2000 [22:54<02:11,  3.35it/s]\u001b[A\n",
      "Average Metric: 631 / 1562  (40.4):  78%|  | 1561/2000 [22:54<02:11,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 631 / 1562  (40.4):  78%|  | 1562/2000 [22:54<01:55,  3.80it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'flians'. A: ports B: pathway C: vietnamese D: finals\n",
      "Answer: D: finals\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'derefred'. A: assume B: query C: sure D: deferred\n",
      "Answer: D: deferred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 631 / 1563  (40.4):  78%|  | 1562/2000 [23:00<01:55,  3.80it/s]\u001b[A\n",
      "Average Metric: 631 / 1563  (40.4):  78%|  | 1563/2000 [23:00<11:43,  1.61s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 631 / 1564  (40.3):  78%|  | 1563/2000 [23:00<11:43,  1.61s/it]\u001b[A\n",
      "Average Metric: 631 / 1564  (40.3):  78%|  | 1564/2000 [23:00<09:09,  1.26s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 631 / 1565  (40.3):  78%|  | 1564/2000 [23:00<09:09,  1.26s/it]\u001b[A\n",
      "Average Metric: 631 / 1565  (40.3):  78%|  | 1565/2000 [23:00<07:08,  1.02it/s]\u001b[A\n",
      "Average Metric: 631 / 1566  (40.3):  78%|  | 1565/2000 [23:00<07:08,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'ecnveide'? A: parent B: pays C: entering D: evidence\n",
      "Answer: D: evidence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 632 / 1567  (40.3):  78%|  | 1566/2000 [23:01<07:07,  1.02it/s]\u001b[A\n",
      "Average Metric: 632 / 1567  (40.3):  78%|  | 1567/2000 [23:01<05:18,  1.36it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 632 / 1568  (40.3):  78%|  | 1567/2000 [23:01<05:18,  1.36it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 632 / 1569  (40.3):  78%|  | 1568/2000 [23:01<05:17,  1.36it/s]\u001b[A\n",
      "Average Metric: 632 / 1569  (40.3):  78%|  | 1569/2000 [23:01<03:31,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'renvaecle' represent when unscrambled? A: relevance B: appropriately C: april D: groundwater\n",
      "Answer: A: relevance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 633 / 1570  (40.3):  78%|  | 1569/2000 [23:02<03:31,  2.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 633 / 1570  (40.3):  78%|  | 1570/2000 [23:02<04:13,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 633 / 1571  (40.3):  78%|  | 1570/2000 [23:03<04:13,  1.69it/s]\u001b[A\n",
      "Average Metric: 633 / 1571  (40.3):  79%|  | 1571/2000 [23:03<03:34,  2.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 633 / 1572  (40.3):  79%|  | 1571/2000 [23:04<03:34,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'srbuaubn'. A: vivid B: utah C: queens D: suburban\n",
      "Answer: D: suburban\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 633 / 1572  (40.3):  79%|  | 1572/2000 [23:04<04:21,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'aodmbssaar'? A: ambassador B: expired C: webmasters D: bedrooms\n",
      "Answer: B: expired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 634 / 1573  (40.3):  79%|  | 1572/2000 [23:04<04:21,  1.64it/s]\u001b[A\n",
      "Average Metric: 634 / 1573  (40.3):  79%|  | 1573/2000 [23:04<04:48,  1.48it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 634 / 1574  (40.3):  79%|  | 1573/2000 [23:05<04:48,  1.48it/s]\u001b[A\n",
      "Average Metric: 634 / 1574  (40.3):  79%|  | 1574/2000 [23:05<03:50,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Average Metric: 634 / 1575  (40.3):  79%|  | 1574/2000 [23:08<03:50,  1.85it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 634 / 1575  (40.3):  79%|  | 1575/2000 [23:08<09:28,  1.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 635 / 1576  (40.3):  79%|  | 1575/2000 [23:11<09:28,  1.34s/it]\u001b[A\n",
      "Average Metric: 635 / 1576  (40.3):  79%|  | 1576/2000 [23:11<13:22,  1.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 1577  (40.3):  79%|  | 1576/2000 [23:12<13:22,  1.89s/it]\u001b[A\n",
      "Average Metric: 636 / 1577  (40.3):  79%|  | 1577/2000 [23:12<10:24,  1.48s/it]\u001b[A\n",
      "Average Metric: 636 / 1578  (40.3):  79%|  | 1577/2000 [23:12<10:24,  1.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 636 / 1578  (40.3):  79%|  | 1578/2000 [23:12<08:15,  1.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 1579  (40.3):  79%|  | 1578/2000 [23:12<08:15,  1.17s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 636 / 1580  (40.3):  79%|  | 1579/2000 [23:12<08:14,  1.17s/it]\u001b[A\n",
      "Average Metric: 636 / 1580  (40.3):  79%|  | 1580/2000 [23:12<04:41,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 637 / 1581  (40.3):  79%|  | 1580/2000 [23:13<04:41,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 637 / 1581  (40.3):  79%|  | 1581/2000 [23:13<05:30,  1.27it/s]\u001b[A\n",
      "Average Metric: 637 / 1582  (40.3):  79%|  | 1581/2000 [23:14<05:30,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 637 / 1582  (40.3):  79%|  | 1582/2000 [23:14<05:24,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 637 / 1583  (40.2):  79%|  | 1582/2000 [23:18<05:24,  1.29it/s]\u001b[A\n",
      "Average Metric: 637 / 1583  (40.2):  79%|  | 1583/2000 [23:18<11:15,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 638 / 1584  (40.3):  79%|  | 1583/2000 [23:19<11:15,  1.62s/it]\u001b[A\n",
      "Average Metric: 638 / 1584  (40.3):  79%|  | 1584/2000 [23:19<09:01,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 639 / 1585  (40.3):  79%|  | 1584/2000 [23:19<09:01,  1.30s/it]\u001b[A\n",
      "Average Metric: 639 / 1585  (40.3):  79%|  | 1585/2000 [23:19<07:45,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 640 / 1586  (40.4):  79%|  | 1585/2000 [23:19<07:45,  1.12s/it]\u001b[A\n",
      "Average Metric: 640 / 1586  (40.4):  79%|  | 1586/2000 [23:19<05:45,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 640 / 1587  (40.3):  79%|  | 1586/2000 [23:20<05:45,  1.20it/s]\u001b[A\n",
      "Average Metric: 640 / 1587  (40.3):  79%|  | 1587/2000 [23:20<05:27,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 641 / 1588  (40.4):  79%|  | 1587/2000 [23:20<05:27,  1.26it/s]\u001b[A\n",
      "Average Metric: 641 / 1588  (40.4):  79%|  | 1588/2000 [23:20<04:19,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 642 / 1589  (40.4):  79%|  | 1588/2000 [23:21<04:19,  1.59it/s]\u001b[A\n",
      "Average Metric: 642 / 1589  (40.4):  79%|  | 1589/2000 [23:21<03:38,  1.88it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 642 / 1590  (40.4):  79%|  | 1589/2000 [23:21<03:38,  1.88it/s]\u001b[A\n",
      "Average Metric: 643 / 1591  (40.4):  80%|  | 1590/2000 [23:21<03:37,  1.88it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 643 / 1591  (40.4):  80%|  | 1591/2000 [23:21<02:10,  3.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 644 / 1592  (40.5):  80%|  | 1591/2000 [23:21<02:10,  3.13it/s]\u001b[A\n",
      "Average Metric: 644 / 1592  (40.5):  80%|  | 1592/2000 [23:21<02:20,  2.90it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 644 / 1593  (40.4):  80%|  | 1592/2000 [23:21<02:20,  2.90it/s]\u001b[A\n",
      "Average Metric: 644 / 1593  (40.4):  80%|  | 1593/2000 [23:21<02:21,  2.87it/s]\u001b[A\n",
      "Average Metric: 645 / 1594  (40.5):  80%|  | 1593/2000 [23:22<02:21,  2.87it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 645 / 1594  (40.5):  80%|  | 1594/2000 [23:22<03:24,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 645 / 1595  (40.4):  80%|  | 1594/2000 [23:22<03:24,  1.98it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 645 / 1596  (40.4):  80%|  | 1595/2000 [23:23<03:24,  1.98it/s]\u001b[A\n",
      "Average Metric: 645 / 1596  (40.4):  80%|  | 1596/2000 [23:23<03:02,  2.22it/s]\u001b[A\n",
      "Average Metric: 646 / 1597  (40.5):  80%|  | 1596/2000 [23:23<03:02,  2.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 646 / 1597  (40.5):  80%|  | 1597/2000 [23:23<02:34,  2.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 646 / 1598  (40.4):  80%|  | 1597/2000 [23:23<02:34,  2.61it/s]\u001b[A\n",
      "Average Metric: 646 / 1599  (40.4):  80%|  | 1598/2000 [23:27<02:33,  2.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 646 / 1599  (40.4):  80%|  | 1599/2000 [23:27<06:24,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 646 / 1600  (40.4):  80%|  | 1599/2000 [23:29<06:24,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 646 / 1600  (40.4):  80%|  | 1600/2000 [23:29<08:40,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 647 / 1601  (40.4):  80%|  | 1600/2000 [23:29<08:40,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 647 / 1602  (40.4):  80%|  | 1601/2000 [23:30<08:39,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 647 / 1602  (40.4):  80%|  | 1602/2000 [23:30<06:14,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 647 / 1603  (40.4):  80%|  | 1602/2000 [23:31<06:14,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 647 / 1603  (40.4):  80%|  | 1603/2000 [23:31<05:27,  1.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 648 / 1604  (40.4):  80%|  | 1603/2000 [23:31<05:27,  1.21it/s]\u001b[A\n",
      "Average Metric: 648 / 1604  (40.4):  80%|  | 1604/2000 [23:31<04:26,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'gstereat'? A: belle B: shoot C: driver D: greatest\n",
      "Answer: D: greatest\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which planet is closest to the sun? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: elephant B: whale C: bear D: giraffe\n",
      "Answer: B: whale\n",
      "\n",
      "Question: Which country invented the light bulb? A: Germany B: United States C: Italy D: France\n",
      "Answer: A: Germany\n",
      "\n",
      "Question: What is the smallest country in the world? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 648 / 1605  (40.4):  80%|  | 1604/2000 [23:32<04:26,  1.49it/s]\u001b[A\n",
      "Average Metric: 648 / 1605  (40.4):  80%|  | 1605/2000 [23:32<04:48,  1.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 648 / 1606  (40.3):  80%|  | 1605/2000 [23:39<04:48,  1.37it/s]\u001b[A\n",
      "Average Metric: 648 / 1606  (40.3):  80%|  | 1606/2000 [23:39<15:31,  2.37s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 649 / 1607  (40.4):  80%|  | 1606/2000 [23:39<15:31,  2.37s/it]\u001b[A\n",
      "Average Metric: 649 / 1607  (40.4):  80%|  | 1607/2000 [23:39<12:02,  1.84s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 650 / 1608  (40.4):  80%|  | 1607/2000 [23:39<12:02,  1.84s/it]\u001b[A\n",
      "Average Metric: 650 / 1608  (40.4):  80%|  | 1608/2000 [23:39<09:09,  1.40s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 650 / 1609  (40.4):  80%|  | 1608/2000 [23:39<09:09,  1.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 650 / 1610  (40.4):  80%|  | 1609/2000 [23:40<09:07,  1.40s/it]\u001b[A\n",
      "Average Metric: 650 / 1610  (40.4):  80%|  | 1610/2000 [23:40<06:44,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 651 / 1611  (40.4):  80%|  | 1610/2000 [23:41<06:44,  1.04s/it]\u001b[A\n",
      "Average Metric: 651 / 1611  (40.4):  81%|  | 1611/2000 [23:41<06:12,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 651 / 1612  (40.4):  81%|  | 1611/2000 [23:42<06:12,  1.04it/s]\u001b[A\n",
      "Average Metric: 651 / 1612  (40.4):  81%|  | 1612/2000 [23:42<05:10,  1.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 652 / 1613  (40.4):  81%|  | 1612/2000 [23:42<05:10,  1.25it/s]\u001b[A\n",
      "Average Metric: 652 / 1613  (40.4):  81%|  | 1613/2000 [23:42<04:24,  1.47it/s]\u001b[A\n",
      "Average Metric: 653 / 1614  (40.5):  81%|  | 1613/2000 [23:42<04:24,  1.47it/s]\u001b[A\n",
      "Average Metric: 653 / 1615  (40.4):  81%|  | 1614/2000 [23:43<04:23,  1.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 653 / 1615  (40.4):  81%|  | 1615/2000 [23:43<03:58,  1.62it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 653 / 1616  (40.4):  81%|  | 1615/2000 [23:45<03:58,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 653 / 1616  (40.4):  81%|  | 1616/2000 [23:45<06:00,  1.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 654 / 1617  (40.4):  81%|  | 1616/2000 [23:46<06:00,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 654 / 1617  (40.4):  81%|  | 1617/2000 [23:46<05:35,  1.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 654 / 1618  (40.4):  81%|  | 1617/2000 [23:46<05:35,  1.14it/s]\u001b[A\n",
      "Average Metric: 654 / 1618  (40.4):  81%|  | 1618/2000 [23:46<04:34,  1.39it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 655 / 1619  (40.5):  81%|  | 1618/2000 [23:46<04:34,  1.39it/s]\u001b[A\n",
      "Average Metric: 655 / 1619  (40.5):  81%|  | 1619/2000 [23:46<03:41,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 656 / 1620  (40.5):  81%|  | 1619/2000 [23:48<03:41,  1.72it/s]\u001b[A\n",
      "Average Metric: 656 / 1620  (40.5):  81%|  | 1620/2000 [23:48<06:06,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 657 / 1621  (40.5):  81%|  | 1620/2000 [23:48<06:06,  1.04it/s]\u001b[A\n",
      "Average Metric: 658 / 1622  (40.6):  81%|  | 1621/2000 [23:48<06:05,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 658 / 1622  (40.6):  81%|  | 1622/2000 [23:48<03:35,  1.75it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 659 / 1623  (40.6):  81%|  | 1622/2000 [23:49<03:35,  1.75it/s]\u001b[A\n",
      "Average Metric: 659 / 1623  (40.6):  81%|  | 1623/2000 [23:49<03:48,  1.65it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 660 / 1624  (40.6):  81%|  | 1623/2000 [23:49<03:48,  1.65it/s]\u001b[A\n",
      "Average Metric: 660 / 1624  (40.6):  81%|  | 1624/2000 [23:49<03:25,  1.83it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 660 / 1625  (40.6):  81%|  | 1624/2000 [23:51<03:25,  1.83it/s]\u001b[A\n",
      "Average Metric: 660 / 1625  (40.6):  81%| | 1625/2000 [23:51<06:05,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1626  (40.7):  81%| | 1625/2000 [23:52<06:05,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "\u001b[ATraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "Average Metric: 661 / 1626  (40.7):  81%| | 1626/2000 [23:52<05:38,  1.11it/s]  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 661 / 1627  (40.6):  81%| | 1626/2000 [23:53<05:38,  1.11it/s]\u001b[A\n",
      "Average Metric: 661 / 1627  (40.6):  81%| | 1627/2000 [23:53<04:51,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 661 / 1628  (40.6):  81%| | 1627/2000 [23:56<04:51,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 661 / 1628  (40.6):  81%| | 1628/2000 [23:56<09:53,  1.59s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1629  (40.6):  81%| | 1628/2000 [23:56<09:53,  1.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1630  (40.6):  81%| | 1629/2000 [23:57<09:51,  1.59s/it]\u001b[A\n",
      "Average Metric: 661 / 1630  (40.6):  82%| | 1630/2000 [23:57<06:25,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1631  (40.5):  82%| | 1630/2000 [23:58<06:25,  1.04s/it]\u001b[A\n",
      "Average Metric: 661 / 1631  (40.5):  82%| | 1631/2000 [23:58<06:07,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 661 / 1632  (40.5):  82%| | 1631/2000 [23:59<06:07,  1.00it/s]\u001b[A\n",
      "Average Metric: 661 / 1632  (40.5):  82%| | 1632/2000 [23:59<06:53,  1.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 662 / 1633  (40.5):  82%| | 1632/2000 [24:00<06:53,  1.12s/it]\u001b[A\n",
      "Average Metric: 662 / 1633  (40.5):  82%| | 1633/2000 [24:00<06:37,  1.08s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 663 / 1634  (40.6):  82%| | 1633/2000 [24:01<06:37,  1.08s/it]\u001b[A\n",
      "Average Metric: 663 / 1634  (40.6):  82%| | 1634/2000 [24:01<05:53,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 663 / 1635  (40.6):  82%| | 1634/2000 [24:01<05:53,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 663 / 1635  (40.6):  82%| | 1635/2000 [24:01<04:44,  1.28it/s]\u001b[A\n",
      "Average Metric: 663 / 1636  (40.5):  82%| | 1635/2000 [24:01<04:44,  1.28it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 664 / 1637  (40.6):  82%| | 1636/2000 [24:03<04:43,  1.28it/s]\u001b[A\n",
      "Average Metric: 664 / 1637  (40.6):  82%| | 1637/2000 [24:03<04:39,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 664 / 1638  (40.5):  82%| | 1637/2000 [24:03<04:39,  1.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 664 / 1638  (40.5):  82%| | 1638/2000 [24:03<04:11,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 665 / 1639  (40.6):  82%| | 1638/2000 [24:04<04:11,  1.44it/s]\u001b[A\n",
      "Average Metric: 665 / 1639  (40.6):  82%| | 1639/2000 [24:04<03:50,  1.56it/s]\u001b[A\n",
      "Average Metric: 665 / 1640  (40.5):  82%| | 1639/2000 [24:04<03:50,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 665 / 1640  (40.5):  82%| | 1640/2000 [24:04<03:22,  1.78it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 665 / 1641  (40.5):  82%| | 1640/2000 [24:04<03:22,  1.78it/s]\u001b[A\n",
      "Average Metric: 665 / 1641  (40.5):  82%| | 1641/2000 [24:04<02:47,  2.15it/s]\u001b[A\n",
      "Average Metric: 666 / 1642  (40.6):  82%| | 1641/2000 [24:05<02:47,  2.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 666 / 1642  (40.6):  82%| | 1642/2000 [24:05<02:26,  2.44it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1643  (40.5):  82%| | 1642/2000 [24:06<02:26,  2.44it/s]\u001b[A\n",
      "Average Metric: 666 / 1643  (40.5):  82%| | 1643/2000 [24:06<03:43,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 666 / 1644  (40.5):  82%| | 1643/2000 [24:06<03:43,  1.60it/s]\u001b[A\n",
      "Average Metric: 666 / 1644  (40.5):  82%| | 1644/2000 [24:06<02:49,  2.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 666 / 1645  (40.5):  82%| | 1644/2000 [24:07<02:49,  2.10it/s]\u001b[A\n",
      "Average Metric: 666 / 1645  (40.5):  82%| | 1645/2000 [24:07<04:11,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1646  (40.5):  82%| | 1645/2000 [24:08<04:11,  1.41it/s]\u001b[A\n",
      "Average Metric: 666 / 1646  (40.5):  82%| | 1646/2000 [24:08<04:52,  1.21it/s]\u001b[A\n",
      "Average Metric: 666 / 1647  (40.4):  82%| | 1646/2000 [24:09<04:52,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 666 / 1647  (40.4):  82%| | 1647/2000 [24:09<04:21,  1.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 666 / 1648  (40.4):  82%| | 1647/2000 [24:09<04:21,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 666 / 1648  (40.4):  82%| | 1648/2000 [24:09<04:09,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1649  (40.4):  82%| | 1648/2000 [24:10<04:09,  1.41it/s]\u001b[A\n",
      "Average Metric: 666 / 1649  (40.4):  82%| | 1649/2000 [24:10<04:42,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 666 / 1650  (40.4):  82%| | 1649/2000 [24:13<04:42,  1.24it/s]\u001b[A\n",
      "Average Metric: 666 / 1650  (40.4):  82%| | 1650/2000 [24:13<07:46,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 667 / 1651  (40.4):  82%| | 1650/2000 [24:14<07:46,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 667 / 1651  (40.4):  83%| | 1651/2000 [24:14<07:19,  1.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 667 / 1652  (40.4):  83%| | 1651/2000 [24:15<07:19,  1.26s/it]\u001b[A\n",
      "Average Metric: 667 / 1652  (40.4):  83%| | 1652/2000 [24:15<06:00,  1.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 667 / 1653  (40.4):  83%| | 1652/2000 [24:15<06:00,  1.04s/it]\u001b[A\n",
      "Average Metric: 667 / 1653  (40.4):  83%| | 1653/2000 [24:15<04:55,  1.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 668 / 1654  (40.4):  83%| | 1653/2000 [24:19<04:55,  1.18it/s]\u001b[A\n",
      "Average Metric: 668 / 1654  (40.4):  83%| | 1654/2000 [24:19<10:24,  1.80s/it]\u001b[A\n",
      "Average Metric: 668 / 1655  (40.4):  83%| | 1654/2000 [24:19<10:24,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 668 / 1656  (40.3):  83%| | 1655/2000 [24:19<10:22,  1.80s/it]\u001b[A\n",
      "Average Metric: 668 / 1656  (40.3):  83%| | 1656/2000 [24:19<05:57,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 668 / 1657  (40.3):  83%| | 1656/2000 [24:21<05:57,  1.04s/it]\u001b[A\n",
      "Average Metric: 668 / 1657  (40.3):  83%| | 1657/2000 [24:21<06:14,  1.09s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 669 / 1658  (40.3):  83%| | 1657/2000 [24:21<06:14,  1.09s/it]\u001b[A\n",
      "Average Metric: 669 / 1658  (40.3):  83%| | 1658/2000 [24:21<05:27,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 670 / 1659  (40.4):  83%| | 1658/2000 [24:22<05:27,  1.04it/s]\u001b[A\n",
      "Average Metric: 670 / 1659  (40.4):  83%| | 1659/2000 [24:22<04:57,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 670 / 1660  (40.4):  83%| | 1659/2000 [24:23<04:57,  1.15it/s]\u001b[A\n",
      "Average Metric: 670 / 1660  (40.4):  83%| | 1660/2000 [24:23<04:57,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 670 / 1661  (40.3):  83%| | 1660/2000 [24:23<04:57,  1.14it/s]\u001b[A\n",
      "Average Metric: 670 / 1661  (40.3):  83%| | 1661/2000 [24:23<04:13,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 671 / 1662  (40.4):  83%| | 1661/2000 [24:23<04:13,  1.34it/s]\u001b[A\n",
      "Average Metric: 671 / 1662  (40.4):  83%| | 1662/2000 [24:23<03:35,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 671 / 1663  (40.3):  83%| | 1662/2000 [24:24<03:35,  1.57it/s]\u001b[A\n",
      "Average Metric: 671 / 1663  (40.3):  83%| | 1663/2000 [24:24<03:15,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 671 / 1664  (40.3):  83%| | 1663/2000 [24:25<03:15,  1.72it/s]\u001b[A\n",
      "Average Metric: 671 / 1664  (40.3):  83%| | 1664/2000 [24:25<04:26,  1.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 672 / 1665  (40.4):  83%| | 1664/2000 [24:26<04:26,  1.26it/s]\u001b[A\n",
      "Average Metric: 672 / 1665  (40.4):  83%| | 1665/2000 [24:26<05:01,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 672 / 1666  (40.3):  83%| | 1665/2000 [24:27<05:01,  1.11it/s]\u001b[A\n",
      "Average Metric: 672 / 1666  (40.3):  83%| | 1666/2000 [24:27<03:56,  1.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1667  (40.3):  83%| | 1666/2000 [24:27<03:56,  1.41it/s]\u001b[A\n",
      "Average Metric: 672 / 1667  (40.3):  83%| | 1667/2000 [24:27<03:50,  1.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1668  (40.3):  83%| | 1667/2000 [24:28<03:50,  1.45it/s]\u001b[A\n",
      "Average Metric: 672 / 1668  (40.3):  83%| | 1668/2000 [24:28<04:20,  1.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1669  (40.3):  83%| | 1668/2000 [24:29<04:20,  1.28it/s]\u001b[A\n",
      "Average Metric: 672 / 1669  (40.3):  83%| | 1669/2000 [24:29<03:31,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 672 / 1670  (40.2):  83%| | 1669/2000 [24:29<03:31,  1.57it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 673 / 1671  (40.3):  84%| | 1670/2000 [24:30<03:30,  1.57it/s]\u001b[A\n",
      "Average Metric: 673 / 1671  (40.3):  84%| | 1671/2000 [24:30<03:54,  1.40it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 673 / 1672  (40.3):  84%| | 1671/2000 [24:31<03:54,  1.40it/s]\u001b[A\n",
      "Average Metric: 673 / 1672  (40.3):  84%| | 1672/2000 [24:31<03:44,  1.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 673 / 1673  (40.2):  84%| | 1672/2000 [24:31<03:44,  1.46it/s]\u001b[A\n",
      "Average Metric: 673 / 1673  (40.2):  84%| | 1673/2000 [24:31<03:42,  1.47it/s]\u001b[A\n",
      "Average Metric: 674 / 1674  (40.3):  84%| | 1673/2000 [24:32<03:42,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 674 / 1674  (40.3):  84%| | 1674/2000 [24:32<02:55,  1.86it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 675 / 1675  (40.3):  84%| | 1674/2000 [24:33<02:55,  1.86it/s]\u001b[A\n",
      "Average Metric: 675 / 1675  (40.3):  84%| | 1675/2000 [24:33<03:36,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 675 / 1676  (40.3):  84%| | 1675/2000 [24:33<03:36,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 675 / 1677  (40.3):  84%| | 1676/2000 [24:33<03:36,  1.50it/s]\u001b[A\n",
      "Average Metric: 675 / 1677  (40.3):  84%| | 1677/2000 [24:33<02:20,  2.31it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 676 / 1678  (40.3):  84%| | 1677/2000 [24:34<02:20,  2.31it/s]\u001b[A\n",
      "Average Metric: 676 / 1678  (40.3):  84%| | 1678/2000 [24:34<03:12,  1.67it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 676 / 1679  (40.3):  84%| | 1678/2000 [24:37<03:12,  1.67it/s]\u001b[A\n",
      "Average Metric: 676 / 1679  (40.3):  84%| | 1679/2000 [24:37<06:05,  1.14s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 677 / 1680  (40.3):  84%| | 1679/2000 [24:37<06:05,  1.14s/it]\u001b[A\n",
      "Average Metric: 677 / 1680  (40.3):  84%| | 1680/2000 [24:37<04:43,  1.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 677 / 1681  (40.3):  84%| | 1680/2000 [24:38<04:43,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 677 / 1681  (40.3):  84%| | 1681/2000 [24:38<05:32,  1.04s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 677 / 1682  (40.2):  84%| | 1681/2000 [24:39<05:32,  1.04s/it]\u001b[A\n",
      "Average Metric: 677 / 1682  (40.2):  84%| | 1682/2000 [24:39<05:09,  1.03it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 678 / 1683  (40.3):  84%| | 1682/2000 [24:40<05:09,  1.03it/s]\u001b[A\n",
      "Average Metric: 678 / 1683  (40.3):  84%| | 1683/2000 [24:40<04:56,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 679 / 1684  (40.3):  84%| | 1683/2000 [24:41<04:56,  1.07it/s]\u001b[A\n",
      "Average Metric: 679 / 1684  (40.3):  84%| | 1684/2000 [24:41<04:44,  1.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 679 / 1685  (40.3):  84%| | 1684/2000 [24:42<04:44,  1.11it/s]\u001b[A\n",
      "Average Metric: 679 / 1685  (40.3):  84%| | 1685/2000 [24:42<05:03,  1.04it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 679 / 1686  (40.3):  84%| | 1685/2000 [24:43<05:03,  1.04it/s]\u001b[A\n",
      "Average Metric: 679 / 1686  (40.3):  84%| | 1686/2000 [24:43<04:40,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 680 / 1687  (40.3):  84%| | 1686/2000 [24:43<04:40,  1.12it/s]\u001b[A\n",
      "Average Metric: 680 / 1687  (40.3):  84%| | 1687/2000 [24:43<03:46,  1.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 680 / 1688  (40.3):  84%| | 1687/2000 [24:46<03:46,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 680 / 1688  (40.3):  84%| | 1688/2000 [24:46<06:39,  1.28s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 681 / 1689  (40.3):  84%| | 1688/2000 [24:46<06:39,  1.28s/it]\u001b[A\n",
      "Average Metric: 681 / 1689  (40.3):  84%| | 1689/2000 [24:46<04:49,  1.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 682 / 1690  (40.4):  84%| | 1689/2000 [24:46<04:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 682 / 1690  (40.4):  84%| | 1690/2000 [24:46<04:18,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 683 / 1691  (40.4):  84%| | 1690/2000 [24:49<04:18,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 683 / 1691  (40.4):  85%| | 1691/2000 [24:49<07:01,  1.36s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 683 / 1692  (40.4):  85%| | 1691/2000 [24:49<07:01,  1.36s/it]\u001b[A\n",
      "Average Metric: 683 / 1692  (40.4):  85%| | 1692/2000 [24:49<05:17,  1.03s/it]\u001b[A\n",
      "Average Metric: 684 / 1693  (40.4):  85%| | 1692/2000 [24:49<05:17,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 664, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 561, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py\", line 93, in wrapped_program\n",
      "    prediction = program(**example.inputs())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py\", line 25, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_4019/2349247026.py\", line 12, in forward\n",
      "    prediction = self.generate_answer(question=question)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 60, in __call__\n",
      "    return self.forward(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py\", line 87, in forward\n",
      "    x, C = dsp.generate(signature, **config)(x, stage=self.stage)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py\", line 78, in do_generate\n",
      "    completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 137, in __call__\n",
      "    response = self.request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py\", line 26, in request\n",
      "    return self.basic_request(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 91, in basic_request\n",
      "    response = self._generate(prompt, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py\", line 116, in _generate\n",
      "    outputs = self.model.generate(**inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1545, in generate\n",
      "    logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
      "Message: 'Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.'\n",
      "Arguments: ()\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 685 / 1694  (40.4):  85%| | 1693/2000 [24:50<05:16,  1.03s/it]\u001b[A\n",
      "Average Metric: 685 / 1694  (40.4):  85%| | 1694/2000 [24:50<04:07,  1.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 686 / 1695  (40.5):  85%| | 1694/2000 [24:51<04:07,  1.23it/s]\u001b[A\n",
      "Average Metric: 686 / 1695  (40.5):  85%| | 1695/2000 [24:51<03:47,  1.34it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 687 / 1696  (40.5):  85%| | 1695/2000 [24:53<03:47,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 687 / 1696  (40.5):  85%| | 1696/2000 [24:53<05:18,  1.05s/it]\u001b[A\n",
      "Average Metric: 687 / 1697  (40.5):  85%| | 1696/2000 [24:53<05:18,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 687 / 1697  (40.5):  85%| | 1697/2000 [24:53<04:03,  1.24it/s]\u001b[A\n",
      "Average Metric: 688 / 1698  (40.5):  85%| | 1697/2000 [24:54<04:03,  1.24it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 688 / 1698  (40.5):  85%| | 1698/2000 [24:54<05:00,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 688 / 1699  (40.5):  85%| | 1698/2000 [24:54<05:00,  1.00it/s]\u001b[A\n",
      "Average Metric: 688 / 1700  (40.5):  85%| | 1699/2000 [24:54<04:59,  1.00it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 688 / 1701  (40.4):  85%| | 1700/2000 [24:56<04:58,  1.00it/s]\u001b[A\n",
      "Average Metric: 688 / 1701  (40.4):  85%| | 1701/2000 [24:56<03:38,  1.37it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 689 / 1702  (40.5):  85%| | 1701/2000 [24:56<03:38,  1.37it/s]\u001b[A\n",
      "Average Metric: 689 / 1702  (40.5):  85%| | 1702/2000 [24:56<03:05,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 689 / 1703  (40.5):  85%| | 1702/2000 [24:57<03:05,  1.61it/s]\u001b[A\n",
      "Average Metric: 689 / 1703  (40.5):  85%| | 1703/2000 [24:57<03:50,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 690 / 1704  (40.5):  85%| | 1703/2000 [24:58<03:50,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 690 / 1704  (40.5):  85%| | 1704/2000 [24:58<04:08,  1.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 690 / 1705  (40.5):  85%| | 1704/2000 [24:59<04:08,  1.19it/s]\u001b[A\n",
      "Average Metric: 690 / 1705  (40.5):  85%| | 1705/2000 [24:59<04:13,  1.16it/s]\u001b[A\n",
      "Average Metric: 690 / 1706  (40.4):  85%| | 1705/2000 [25:00<04:13,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 690 / 1706  (40.4):  85%| | 1706/2000 [25:00<03:49,  1.28it/s]\u001b[A\n",
      "Average Metric: 691 / 1707  (40.5):  85%| | 1706/2000 [25:00<03:49,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 691 / 1707  (40.5):  85%| | 1707/2000 [25:00<03:24,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 691 / 1708  (40.5):  85%| | 1707/2000 [25:01<03:24,  1.43it/s]\u001b[A\n",
      "Average Metric: 691 / 1708  (40.5):  85%| | 1708/2000 [25:01<03:47,  1.28it/s]\u001b[A\n",
      "Average Metric: 692 / 1709  (40.5):  85%| | 1708/2000 [25:03<03:47,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 692 / 1709  (40.5):  85%| | 1709/2000 [25:03<04:47,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 693 / 1710  (40.5):  85%| | 1709/2000 [25:03<04:47,  1.01it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 694 / 1711  (40.6):  86%| | 1710/2000 [25:03<04:46,  1.01it/s]\u001b[A\n",
      "Average Metric: 694 / 1711  (40.6):  86%| | 1711/2000 [25:03<02:43,  1.76it/s]\u001b[A\n",
      "Average Metric: 695 / 1712  (40.6):  86%| | 1711/2000 [25:04<02:43,  1.76it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 695 / 1712  (40.6):  86%| | 1712/2000 [25:04<02:43,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 695 / 1713  (40.6):  86%| | 1712/2000 [25:04<02:43,  1.76it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 695 / 1714  (40.5):  86%| | 1713/2000 [25:06<02:42,  1.76it/s]\u001b[A\n",
      "Average Metric: 695 / 1714  (40.5):  86%| | 1714/2000 [25:06<04:06,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 695 / 1715  (40.5):  86%| | 1714/2000 [25:06<04:06,  1.16it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 696 / 1716  (40.6):  86%| | 1715/2000 [25:07<04:05,  1.16it/s]\u001b[A\n",
      "Average Metric: 696 / 1716  (40.6):  86%| | 1716/2000 [25:07<02:59,  1.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 696 / 1717  (40.5):  86%| | 1716/2000 [25:07<02:59,  1.58it/s]\u001b[A\n",
      "Average Metric: 696 / 1717  (40.5):  86%| | 1717/2000 [25:07<02:39,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 696 / 1718  (40.5):  86%| | 1717/2000 [25:08<02:39,  1.78it/s]\u001b[A\n",
      "Average Metric: 696 / 1718  (40.5):  86%| | 1718/2000 [25:08<02:55,  1.60it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 696 / 1719  (40.5):  86%| | 1718/2000 [25:09<02:55,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 696 / 1719  (40.5):  86%| | 1719/2000 [25:09<03:37,  1.29it/s]\u001b[A\n",
      "Average Metric: 697 / 1720  (40.5):  86%| | 1719/2000 [25:09<03:37,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 697 / 1721  (40.5):  86%| | 1720/2000 [25:10<03:36,  1.29it/s]\u001b[A\n",
      "Average Metric: 697 / 1721  (40.5):  86%| | 1721/2000 [25:10<02:45,  1.68it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 698 / 1722  (40.5):  86%| | 1721/2000 [25:10<02:45,  1.68it/s]\u001b[A\n",
      "Average Metric: 698 / 1722  (40.5):  86%| | 1722/2000 [25:10<02:35,  1.79it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1723  (40.6):  86%| | 1722/2000 [25:12<02:35,  1.79it/s]\u001b[A\n",
      "Average Metric: 699 / 1723  (40.6):  86%| | 1723/2000 [25:12<03:45,  1.23it/s]\u001b[A\n",
      "Average Metric: 699 / 1724  (40.5):  86%| | 1723/2000 [25:13<03:45,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 699 / 1724  (40.5):  86%| | 1724/2000 [25:13<03:51,  1.19it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1725  (40.5):  86%| | 1724/2000 [25:13<03:51,  1.19it/s]\u001b[A\n",
      "Average Metric: 699 / 1725  (40.5):  86%| | 1725/2000 [25:13<03:30,  1.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1726  (40.5):  86%| | 1725/2000 [25:14<03:30,  1.31it/s]\u001b[A\n",
      "Average Metric: 699 / 1726  (40.5):  86%| | 1726/2000 [25:14<04:07,  1.11it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 699 / 1727  (40.5):  86%| | 1726/2000 [25:15<04:07,  1.11it/s]\u001b[A\n",
      "Average Metric: 699 / 1727  (40.5):  86%| | 1727/2000 [25:15<03:17,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 700 / 1728  (40.5):  86%| | 1727/2000 [25:15<03:17,  1.38it/s]\u001b[A\n",
      "Average Metric: 700 / 1729  (40.5):  86%| | 1728/2000 [25:15<03:16,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 700 / 1729  (40.5):  86%| | 1729/2000 [25:15<02:05,  2.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 700 / 1730  (40.5):  86%| | 1729/2000 [25:16<02:05,  2.16it/s]\u001b[A\n",
      "Average Metric: 700 / 1730  (40.5):  86%| | 1730/2000 [25:16<02:34,  1.75it/s]\u001b[A\n",
      "Average Metric: 701 / 1731  (40.5):  86%| | 1730/2000 [25:16<02:34,  1.75it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 701 / 1732  (40.5):  87%| | 1731/2000 [25:17<02:34,  1.75it/s]\u001b[A\n",
      "Average Metric: 701 / 1732  (40.5):  87%| | 1732/2000 [25:17<02:11,  2.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 702 / 1733  (40.5):  87%| | 1732/2000 [25:17<02:11,  2.05it/s]\u001b[A\n",
      "Average Metric: 702 / 1733  (40.5):  87%| | 1733/2000 [25:17<02:11,  2.02it/s]\u001b[A\n",
      "Average Metric: 703 / 1734  (40.5):  87%| | 1733/2000 [25:17<02:11,  2.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 703 / 1734  (40.5):  87%| | 1734/2000 [25:17<02:01,  2.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1735  (40.6):  87%| | 1734/2000 [25:20<02:01,  2.20it/s]\u001b[A\n",
      "Average Metric: 704 / 1735  (40.6):  87%| | 1735/2000 [25:20<04:07,  1.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1736  (40.6):  87%| | 1735/2000 [25:20<04:07,  1.07it/s]\u001b[A\n",
      "Average Metric: 704 / 1736  (40.6):  87%| | 1736/2000 [25:20<03:36,  1.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1737  (40.5):  87%| | 1736/2000 [25:21<03:36,  1.22it/s]\u001b[A\n",
      "Average Metric: 704 / 1737  (40.5):  87%| | 1737/2000 [25:21<03:05,  1.41it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 704 / 1738  (40.5):  87%| | 1737/2000 [25:21<03:05,  1.41it/s]\u001b[A\n",
      "Average Metric: 704 / 1738  (40.5):  87%| | 1738/2000 [25:21<02:43,  1.60it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 705 / 1739  (40.5):  87%| | 1738/2000 [25:21<02:43,  1.60it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 705 / 1739  (40.5):  87%| | 1739/2000 [25:21<02:14,  1.94it/s]\u001b[A\n",
      "Average Metric: 705 / 1740  (40.5):  87%| | 1739/2000 [25:21<02:14,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 706 / 1741  (40.6):  87%| | 1740/2000 [25:23<02:13,  1.94it/s]\u001b[A\n",
      "Average Metric: 706 / 1741  (40.6):  87%| | 1741/2000 [25:23<02:33,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 707 / 1742  (40.6):  87%| | 1741/2000 [25:23<02:33,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 707 / 1742  (40.6):  87%| | 1742/2000 [25:23<02:13,  1.93it/s]\u001b[A\n",
      "Average Metric: 707 / 1743  (40.6):  87%| | 1742/2000 [25:23<02:13,  1.93it/s]\u001b[A\n",
      "Average Metric: 707 / 1744  (40.5):  87%| | 1743/2000 [25:23<02:13,  1.93it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 707 / 1744  (40.5):  87%| | 1744/2000 [25:23<01:42,  2.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 707 / 1745  (40.5):  87%| | 1744/2000 [25:25<01:42,  2.50it/s]\u001b[A\n",
      "Average Metric: 707 / 1745  (40.5):  87%| | 1745/2000 [25:25<02:47,  1.52it/s]\u001b[A\n",
      "Average Metric: 708 / 1746  (40.5):  87%| | 1745/2000 [25:26<02:47,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 708 / 1746  (40.5):  87%| | 1746/2000 [25:26<03:00,  1.41it/s]\u001b[A\n",
      "Average Metric: 709 / 1747  (40.6):  87%| | 1746/2000 [25:27<03:00,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 709 / 1747  (40.6):  87%| | 1747/2000 [25:27<03:14,  1.30it/s]\u001b[A\n",
      "Average Metric: 709 / 1748  (40.6):  87%| | 1747/2000 [25:27<03:14,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 709 / 1748  (40.6):  87%| | 1748/2000 [25:27<02:36,  1.61it/s]\u001b[A\n",
      "Average Metric: 709 / 1749  (40.5):  87%| | 1748/2000 [25:29<02:36,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 709 / 1749  (40.5):  87%| | 1749/2000 [25:29<03:59,  1.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 709 / 1750  (40.5):  87%| | 1749/2000 [25:29<03:59,  1.05it/s]\u001b[A\n",
      "Average Metric: 709 / 1750  (40.5):  88%| | 1750/2000 [25:29<03:05,  1.35it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1751  (40.5):  88%| | 1750/2000 [25:30<03:05,  1.35it/s]\u001b[A\n",
      "Average Metric: 710 / 1751  (40.5):  88%| | 1751/2000 [25:30<02:56,  1.41it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1752  (40.5):  88%| | 1751/2000 [25:30<02:56,  1.41it/s]\u001b[A\n",
      "Average Metric: 710 / 1752  (40.5):  88%| | 1752/2000 [25:30<02:52,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1753  (40.5):  88%| | 1752/2000 [25:31<02:52,  1.44it/s]\u001b[A\n",
      "Average Metric: 710 / 1753  (40.5):  88%| | 1753/2000 [25:31<02:21,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1754  (40.5):  88%| | 1753/2000 [25:31<02:21,  1.75it/s]\u001b[A\n",
      "Average Metric: 710 / 1754  (40.5):  88%| | 1754/2000 [25:31<01:50,  2.22it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 710 / 1755  (40.5):  88%| | 1754/2000 [25:31<01:50,  2.22it/s]\u001b[A\n",
      "Average Metric: 710 / 1755  (40.5):  88%| | 1755/2000 [25:31<01:44,  2.35it/s]\u001b[A\n",
      "Average Metric: 710 / 1756  (40.4):  88%| | 1755/2000 [25:31<01:44,  2.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 710 / 1756  (40.4):  88%| | 1756/2000 [25:31<01:29,  2.73it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 710 / 1757  (40.4):  88%| | 1756/2000 [25:32<01:29,  2.73it/s]\u001b[A\n",
      "Average Metric: 710 / 1757  (40.4):  88%| | 1757/2000 [25:32<02:21,  1.72it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 711 / 1758  (40.4):  88%| | 1757/2000 [25:33<02:21,  1.72it/s]\u001b[A\n",
      "Average Metric: 711 / 1758  (40.4):  88%| | 1758/2000 [25:33<02:16,  1.78it/s]\u001b[A\n",
      "Average Metric: 711 / 1759  (40.4):  88%| | 1758/2000 [25:34<02:16,  1.78it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 711 / 1759  (40.4):  88%| | 1759/2000 [25:34<03:16,  1.23it/s]\u001b[A\n",
      "Average Metric: 711 / 1760  (40.4):  88%| | 1759/2000 [25:36<03:16,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 711 / 1760  (40.4):  88%| | 1760/2000 [25:36<03:45,  1.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 711 / 1761  (40.4):  88%| | 1760/2000 [25:36<03:45,  1.07it/s]\u001b[A\n",
      "Average Metric: 711 / 1761  (40.4):  88%| | 1761/2000 [25:36<03:04,  1.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 712 / 1762  (40.4):  88%| | 1761/2000 [25:36<03:04,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 713 / 1763  (40.4):  88%| | 1762/2000 [25:37<03:03,  1.29it/s]\u001b[A\n",
      "Average Metric: 713 / 1763  (40.4):  88%| | 1763/2000 [25:37<02:27,  1.61it/s]\u001b[A\n",
      "Average Metric: 713 / 1764  (40.4):  88%| | 1763/2000 [25:37<02:27,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 713 / 1764  (40.4):  88%| | 1764/2000 [25:37<02:18,  1.70it/s]\u001b[A\n",
      "Average Metric: 714 / 1765  (40.5):  88%| | 1764/2000 [25:37<02:18,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 714 / 1766  (40.4):  88%| | 1765/2000 [25:38<02:17,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 714 / 1766  (40.4):  88%| | 1766/2000 [25:38<01:52,  2.07it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1767  (40.5):  88%| | 1766/2000 [25:39<01:52,  2.07it/s]\u001b[A\n",
      "Average Metric: 715 / 1767  (40.5):  88%| | 1767/2000 [25:39<02:15,  1.72it/s]\u001b[A\n",
      "Average Metric: 715 / 1768  (40.4):  88%| | 1767/2000 [25:40<02:15,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 715 / 1768  (40.4):  88%| | 1768/2000 [25:40<02:28,  1.56it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1769  (40.4):  88%| | 1768/2000 [25:40<02:28,  1.56it/s]\u001b[A\n",
      "Average Metric: 715 / 1769  (40.4):  88%| | 1769/2000 [25:40<02:20,  1.64it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1770  (40.4):  88%| | 1769/2000 [25:42<02:20,  1.64it/s]\u001b[A\n",
      "Average Metric: 715 / 1770  (40.4):  88%| | 1770/2000 [25:42<03:12,  1.19it/s]\u001b[A\n",
      "Average Metric: 715 / 1771  (40.4):  88%| | 1770/2000 [25:42<03:12,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 715 / 1771  (40.4):  89%| | 1771/2000 [25:42<02:30,  1.52it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1772  (40.3):  89%| | 1771/2000 [25:42<02:30,  1.52it/s]\u001b[A\n",
      "Average Metric: 715 / 1772  (40.3):  89%| | 1772/2000 [25:42<02:14,  1.69it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 715 / 1773  (40.3):  89%| | 1772/2000 [25:43<02:14,  1.69it/s]\u001b[A\n",
      "Average Metric: 715 / 1773  (40.3):  89%| | 1773/2000 [25:43<02:08,  1.77it/s]\u001b[A\n",
      "Average Metric: 715 / 1774  (40.3):  89%| | 1773/2000 [25:43<02:08,  1.77it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 715 / 1774  (40.3):  89%| | 1774/2000 [25:43<01:57,  1.92it/s]\u001b[A\n",
      "Average Metric: 715 / 1775  (40.3):  89%| | 1774/2000 [25:44<01:57,  1.92it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 715 / 1775  (40.3):  89%| | 1775/2000 [25:44<02:12,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 716 / 1776  (40.3):  89%| | 1775/2000 [25:45<02:12,  1.69it/s]\u001b[A\n",
      "Average Metric: 716 / 1776  (40.3):  89%| | 1776/2000 [25:45<02:08,  1.74it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 716 / 1777  (40.3):  89%| | 1776/2000 [25:45<02:08,  1.74it/s]\u001b[A\n",
      "Average Metric: 716 / 1777  (40.3):  89%| | 1777/2000 [25:45<02:19,  1.59it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 716 / 1778  (40.3):  89%| | 1777/2000 [25:46<02:19,  1.59it/s]\u001b[A\n",
      "Average Metric: 716 / 1778  (40.3):  89%| | 1778/2000 [25:46<02:08,  1.73it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 716 / 1779  (40.2):  89%| | 1778/2000 [25:47<02:08,  1.73it/s]\u001b[A\n",
      "Average Metric: 716 / 1779  (40.2):  89%| | 1779/2000 [25:47<02:23,  1.54it/s]\u001b[A\n",
      "Average Metric: 717 / 1780  (40.3):  89%| | 1779/2000 [25:47<02:23,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 717 / 1780  (40.3):  89%| | 1780/2000 [25:47<01:56,  1.89it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 717 / 1781  (40.3):  89%| | 1780/2000 [25:47<01:56,  1.89it/s]\u001b[A\n",
      "Average Metric: 717 / 1781  (40.3):  89%| | 1781/2000 [25:47<01:46,  2.05it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 717 / 1782  (40.2):  89%| | 1781/2000 [25:48<01:46,  2.05it/s]\u001b[A\n",
      "Average Metric: 717 / 1782  (40.2):  89%| | 1782/2000 [25:48<02:08,  1.70it/s]\u001b[A\n",
      "Average Metric: 717 / 1783  (40.2):  89%| | 1782/2000 [25:48<02:08,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 717 / 1783  (40.2):  89%| | 1783/2000 [25:48<01:51,  1.94it/s]\u001b[A\n",
      "Average Metric: 717 / 1784  (40.2):  89%| | 1783/2000 [25:49<01:51,  1.94it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 717 / 1784  (40.2):  89%| | 1784/2000 [25:49<01:46,  2.02it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 718 / 1785  (40.2):  89%| | 1784/2000 [25:49<01:46,  2.02it/s]\u001b[A\n",
      "Average Metric: 718 / 1785  (40.2):  89%| | 1785/2000 [25:49<01:23,  2.58it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 719 / 1786  (40.3):  89%| | 1785/2000 [25:50<01:23,  2.58it/s]\u001b[A\n",
      "Average Metric: 719 / 1786  (40.3):  89%| | 1786/2000 [25:50<01:57,  1.83it/s]\u001b[A\n",
      "Average Metric: 719 / 1787  (40.2):  89%| | 1786/2000 [25:50<01:57,  1.83it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 719 / 1787  (40.2):  89%| | 1787/2000 [25:50<01:29,  2.37it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 719 / 1788  (40.2):  89%| | 1787/2000 [25:51<01:29,  2.37it/s]\u001b[A\n",
      "Average Metric: 719 / 1788  (40.2):  89%| | 1788/2000 [25:51<01:46,  1.99it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 720 / 1789  (40.2):  89%| | 1788/2000 [25:52<01:46,  1.99it/s]\u001b[A\n",
      "Average Metric: 720 / 1789  (40.2):  89%| | 1789/2000 [25:52<02:29,  1.41it/s]\u001b[A\n",
      "Average Metric: 720 / 1790  (40.2):  89%| | 1789/2000 [25:53<02:29,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 720 / 1790  (40.2):  90%| | 1790/2000 [25:53<02:28,  1.42it/s]\u001b[A\n",
      "Average Metric: 720 / 1791  (40.2):  90%| | 1790/2000 [25:53<02:28,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 720 / 1791  (40.2):  90%| | 1791/2000 [25:53<02:06,  1.65it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 721 / 1792  (40.2):  90%| | 1791/2000 [25:53<02:06,  1.65it/s]\u001b[A\n",
      "Average Metric: 721 / 1792  (40.2):  90%| | 1792/2000 [25:53<01:40,  2.08it/s]\u001b[A\n",
      "Average Metric: 721 / 1793  (40.2):  90%| | 1792/2000 [25:55<01:40,  2.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 721 / 1793  (40.2):  90%| | 1793/2000 [25:55<02:51,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 721 / 1794  (40.2):  90%| | 1793/2000 [25:55<02:51,  1.20it/s]\u001b[A\n",
      "Average Metric: 721 / 1794  (40.2):  90%| | 1794/2000 [25:55<02:23,  1.44it/s]\u001b[A\n",
      "Average Metric: 722 / 1795  (40.2):  90%| | 1794/2000 [25:56<02:23,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 722 / 1795  (40.2):  90%| | 1795/2000 [25:56<02:09,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Find the right word for 'irsih'. A: bother B: governing C: irish D: officers\n",
      "Answer: D: officers\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which is the smallest planet in our solar system? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: Elephant B: Whale C: Giraffe D: Hippopotamus\n",
      "Answer: B: Whale\n",
      "\n",
      "Question: Which is the most abundant greenhouse gas in the atmosphere? A: Carbon dioxide B: Methane C: Nitrous oxide D: Water\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'cchenas'? A: tiny B: directors C: bugs D: chances\n",
      "Answer: D: chances\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the smallest mammal? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 722 / 1796  (40.2):  90%| | 1795/2000 [25:57<02:09,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 722 / 1796  (40.2):  90%| | 1796/2000 [25:57<02:54,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 722 / 1797  (40.2):  90%| | 1796/2000 [25:57<02:54,  1.17it/s]\u001b[A\n",
      "Average Metric: 722 / 1797  (40.2):  90%| | 1797/2000 [25:57<02:16,  1.48it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 723 / 1798  (40.2):  90%| | 1797/2000 [25:58<02:16,  1.48it/s]\u001b[A\n",
      "Average Metric: 723 / 1798  (40.2):  90%| | 1798/2000 [25:58<01:45,  1.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 724 / 1799  (40.2):  90%| | 1798/2000 [25:58<01:45,  1.91it/s]\u001b[A\n",
      "Average Metric: 724 / 1799  (40.2):  90%| | 1799/2000 [25:58<01:51,  1.81it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 725 / 1800  (40.3):  90%| | 1799/2000 [25:58<01:51,  1.81it/s]\u001b[A\n",
      "Average Metric: 725 / 1800  (40.3):  90%| | 1800/2000 [25:58<01:29,  2.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 725 / 1801  (40.3):  90%| | 1800/2000 [25:59<01:29,  2.23it/s]\u001b[A\n",
      "Average Metric: 725 / 1801  (40.3):  90%| | 1801/2000 [25:59<01:41,  1.96it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 725 / 1802  (40.2):  90%| | 1801/2000 [26:00<01:41,  1.96it/s]\u001b[A\n",
      "Average Metric: 725 / 1802  (40.2):  90%| | 1802/2000 [26:00<01:57,  1.69it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1803  (40.3):  90%| | 1802/2000 [26:00<01:57,  1.69it/s]\u001b[A\n",
      "Average Metric: 726 / 1803  (40.3):  90%| | 1803/2000 [26:00<01:51,  1.77it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1804  (40.2):  90%| | 1803/2000 [26:01<01:51,  1.77it/s]\u001b[A\n",
      "Average Metric: 726 / 1804  (40.2):  90%| | 1804/2000 [26:01<02:15,  1.44it/s]\u001b[A\n",
      "Average Metric: 726 / 1805  (40.2):  90%| | 1804/2000 [26:03<02:15,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 726 / 1805  (40.2):  90%| | 1805/2000 [26:03<02:47,  1.17it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1806  (40.2):  90%| | 1805/2000 [26:04<02:47,  1.17it/s]\u001b[A\n",
      "Average Metric: 726 / 1806  (40.2):  90%| | 1806/2000 [26:04<03:07,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1807  (40.2):  90%| | 1806/2000 [26:04<03:07,  1.04it/s]\u001b[A\n",
      "Average Metric: 726 / 1807  (40.2):  90%| | 1807/2000 [26:04<02:52,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1808  (40.2):  90%| | 1807/2000 [26:05<02:52,  1.12it/s]\u001b[A\n",
      "Average Metric: 726 / 1808  (40.2):  90%| | 1808/2000 [26:05<02:40,  1.20it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1809  (40.1):  90%| | 1808/2000 [26:06<02:40,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 726 / 1809  (40.1):  90%| | 1809/2000 [26:06<02:29,  1.28it/s]\u001b[A\n",
      "Average Metric: 726 / 1810  (40.1):  90%| | 1809/2000 [26:06<02:29,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'raclles' to form the correct word. A: educate B: economic C: recalls D: streaming\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.001\n",
      "Answer: D\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Berlin  B: Madrid  C: Paris  D: Rome\n",
      "Answer: C\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 0.5  B: 0.2  C: 0.1  D: 0.01\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the correct spelling of the word 'col\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 726 / 1811  (40.1):  90%| | 1810/2000 [26:06<02:28,  1.28it/s]\u001b[A\n",
      "Average Metric: 726 / 1811  (40.1):  91%| | 1811/2000 [26:06<01:35,  1.99it/s]\u001b[A\n",
      "Average Metric: 727 / 1812  (40.1):  91%| | 1811/2000 [26:08<01:35,  1.99it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 727 / 1812  (40.1):  91%| | 1812/2000 [26:08<02:27,  1.28it/s]\u001b[A\n",
      "Average Metric: 727 / 1813  (40.1):  91%| | 1812/2000 [26:08<02:27,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 727 / 1813  (40.1):  91%| | 1813/2000 [26:08<02:04,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 728 / 1814  (40.1):  91%| | 1813/2000 [26:08<02:04,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 729 / 1815  (40.2):  91%| | 1814/2000 [26:09<02:04,  1.50it/s]\u001b[A\n",
      "Average Metric: 729 / 1815  (40.2):  91%| | 1815/2000 [26:09<01:33,  1.98it/s]\u001b[A\n",
      "Average Metric: 729 / 1816  (40.1):  91%| | 1815/2000 [26:09<01:33,  1.98it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 729 / 1816  (40.1):  91%| | 1816/2000 [26:09<01:22,  2.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 730 / 1817  (40.2):  91%| | 1816/2000 [26:10<01:22,  2.24it/s]\u001b[A\n",
      "Average Metric: 730 / 1817  (40.2):  91%| | 1817/2000 [26:10<01:28,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 730 / 1818  (40.2):  91%| | 1817/2000 [26:11<01:28,  2.08it/s]\u001b[A\n",
      "Average Metric: 730 / 1818  (40.2):  91%| | 1818/2000 [26:11<01:53,  1.61it/s]\u001b[A\n",
      "Average Metric: 731 / 1819  (40.2):  91%| | 1818/2000 [26:12<01:53,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 731 / 1819  (40.2):  91%| | 1819/2000 [26:12<02:25,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 732 / 1820  (40.2):  91%| | 1819/2000 [26:13<02:25,  1.24it/s]\u001b[A\n",
      "Average Metric: 732 / 1820  (40.2):  91%| | 1820/2000 [26:13<02:36,  1.15it/s]\u001b[A\n",
      "Average Metric: 732 / 1821  (40.2):  91%| | 1820/2000 [26:14<02:36,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 732 / 1821  (40.2):  91%| | 1821/2000 [26:14<02:32,  1.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Decode the word 'orthes'. A: vacant B: donald C: tension D: others\n",
      "Answer: D: others\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Jupiter D: Mars\n",
      "Answer: C: Jupiter\n",
      "\n",
      "Question: What is the smallest mammal? A: elephant B: mouse C: whale D: giraffe\n",
      "Answer: B: mouse\n",
      "\n",
      "Question: What is the smallest country in the world\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 732 / 1822  (40.2):  91%| | 1821/2000 [26:15<02:32,  1.18it/s]\u001b[A\n",
      "Average Metric: 732 / 1822  (40.2):  91%| | 1822/2000 [26:15<02:33,  1.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 733 / 1823  (40.2):  91%| | 1822/2000 [26:16<02:33,  1.16it/s]\u001b[A\n",
      "Average Metric: 733 / 1823  (40.2):  91%| | 1823/2000 [26:16<02:55,  1.01it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 734 / 1824  (40.2):  91%| | 1823/2000 [26:16<02:55,  1.01it/s]\u001b[A\n",
      "Average Metric: 734 / 1824  (40.2):  91%| | 1824/2000 [26:16<02:24,  1.22it/s]\u001b[A\n",
      "Average Metric: 735 / 1825  (40.3):  91%| | 1824/2000 [26:17<02:24,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 735 / 1825  (40.3):  91%|| 1825/2000 [26:17<02:21,  1.24it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 736 / 1826  (40.3):  91%|| 1825/2000 [26:18<02:21,  1.24it/s]\u001b[A\n",
      "Average Metric: 736 / 1826  (40.3):  91%|| 1826/2000 [26:18<02:00,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 737 / 1827  (40.3):  91%|| 1826/2000 [26:18<02:00,  1.44it/s]\u001b[A\n",
      "Average Metric: 737 / 1827  (40.3):  91%|| 1827/2000 [26:18<01:40,  1.72it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 738 / 1828  (40.4):  91%|| 1827/2000 [26:19<01:40,  1.72it/s]\u001b[A\n",
      "Average Metric: 738 / 1828  (40.4):  91%|| 1828/2000 [26:19<01:52,  1.53it/s]\u001b[A\n",
      "Average Metric: 738 / 1829  (40.3):  91%|| 1828/2000 [26:20<01:52,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 738 / 1829  (40.3):  91%|| 1829/2000 [26:20<02:25,  1.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fveer' to form the correct word. A: initiative B: barrier C: fever D: israeli\n",
      "Answer: E\n",
      "\n",
      "Question: Which of the following is the smallest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.2\n",
      "Answer: C: 0.01\n",
      "\n",
      "Question: Which of the following is the capital of France?  A: Madrid  B: Berlin  C: Paris  D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which of the following is the largest value?  A: 1/3  B: 0.1  C: 0.01  D: 0.2\n",
      "Answer: A: 1/3\n",
      "\n",
      "Question: Which of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 739 / 1830  (40.4):  91%|| 1829/2000 [26:21<02:25,  1.17it/s]\u001b[A\n",
      "Average Metric: 739 / 1830  (40.4):  92%|| 1830/2000 [26:21<02:31,  1.12it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 739 / 1831  (40.4):  92%|| 1830/2000 [26:21<02:31,  1.12it/s]\u001b[A\n",
      "Average Metric: 739 / 1831  (40.4):  92%|| 1831/2000 [26:21<01:55,  1.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: What word does 'bcaks' represent when unscrambled? A: hood B: tobacco C: moon D: backs\n",
      "Answer: D: backs\n",
      "\n",
      "Question: Which of the following is not a primary color? A: red B: blue C: yellow D: green\n",
      "Answer: D: green\n",
      "\n",
      "Question: What is the capital of France? A: London B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which of the following is not a planet in our solar system? A: Earth B: Mars C: Jupiter D: Venus\n",
      "Answer: B: Mars\n",
      "\n",
      "Question: What is the smallest value in 0.1, 0.5, 0.01, -0.2? A: 0.1 B: 0.5 C:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 739 / 1832  (40.3):  92%|| 1831/2000 [26:23<01:55,  1.47it/s]\u001b[A\n",
      "Average Metric: 739 / 1832  (40.3):  92%|| 1832/2000 [26:23<02:35,  1.08it/s]\u001b[A\n",
      "Average Metric: 740 / 1833  (40.4):  92%|| 1832/2000 [26:23<02:35,  1.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 740 / 1833  (40.4):  92%|| 1833/2000 [26:23<01:54,  1.46it/s]\u001b[A\n",
      "Average Metric: 741 / 1834  (40.4):  92%|| 1833/2000 [26:23<01:54,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 741 / 1834  (40.4):  92%|| 1834/2000 [26:23<01:42,  1.62it/s]\u001b[A\n",
      "Average Metric: 741 / 1835  (40.4):  92%|| 1834/2000 [26:24<01:42,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 741 / 1835  (40.4):  92%|| 1835/2000 [26:24<01:46,  1.55it/s]\u001b[A\n",
      "Average Metric: 742 / 1836  (40.4):  92%|| 1835/2000 [26:25<01:46,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 742 / 1836  (40.4):  92%|| 1836/2000 [26:25<01:49,  1.49it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 742 / 1837  (40.4):  92%|| 1836/2000 [26:25<01:49,  1.49it/s]\u001b[A\n",
      "Average Metric: 742 / 1837  (40.4):  92%|| 1837/2000 [26:25<01:34,  1.73it/s]\u001b[A\n",
      "Average Metric: 742 / 1838  (40.4):  92%|| 1837/2000 [26:25<01:34,  1.73it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 742 / 1838  (40.4):  92%|| 1838/2000 [26:25<01:27,  1.85it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 742 / 1839  (40.3):  92%|| 1838/2000 [26:26<01:27,  1.85it/s]\u001b[A\n",
      "Average Metric: 742 / 1839  (40.3):  92%|| 1839/2000 [26:26<01:16,  2.09it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 743 / 1840  (40.4):  92%|| 1839/2000 [26:27<01:16,  2.09it/s]\u001b[A\n",
      "Average Metric: 743 / 1840  (40.4):  92%|| 1840/2000 [26:27<01:30,  1.76it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 744 / 1841  (40.4):  92%|| 1840/2000 [26:27<01:30,  1.76it/s]\u001b[A\n",
      "Average Metric: 744 / 1841  (40.4):  92%|| 1841/2000 [26:27<01:11,  2.23it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1842  (40.4):  92%|| 1841/2000 [26:28<01:11,  2.23it/s]\u001b[A\n",
      "Average Metric: 744 / 1842  (40.4):  92%|| 1842/2000 [26:28<01:31,  1.72it/s]\u001b[A\n",
      "Average Metric: 744 / 1843  (40.4):  92%|| 1842/2000 [26:28<01:31,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 744 / 1843  (40.4):  92%|| 1843/2000 [26:28<01:17,  2.02it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1844  (40.3):  92%|| 1843/2000 [26:29<01:17,  2.02it/s]\u001b[A\n",
      "Average Metric: 744 / 1844  (40.3):  92%|| 1844/2000 [26:29<01:41,  1.54it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1845  (40.3):  92%|| 1844/2000 [26:29<01:41,  1.54it/s]\u001b[A\n",
      "Average Metric: 744 / 1845  (40.3):  92%|| 1845/2000 [26:29<01:23,  1.86it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1846  (40.3):  92%|| 1845/2000 [26:29<01:23,  1.86it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 744 / 1847  (40.3):  92%|| 1846/2000 [26:29<01:22,  1.86it/s]\u001b[A\n",
      "Average Metric: 744 / 1847  (40.3):  92%|| 1847/2000 [26:29<00:53,  2.87it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 744 / 1848  (40.3):  92%|| 1847/2000 [26:30<00:53,  2.87it/s]\u001b[A\n",
      "Average Metric: 744 / 1848  (40.3):  92%|| 1848/2000 [26:30<00:46,  3.26it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 745 / 1849  (40.3):  92%|| 1848/2000 [26:30<00:46,  3.26it/s]\u001b[A\n",
      "Average Metric: 745 / 1849  (40.3):  92%|| 1849/2000 [26:30<00:51,  2.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 746 / 1850  (40.3):  92%|| 1849/2000 [26:30<00:51,  2.91it/s]\u001b[A\n",
      "Average Metric: 746 / 1850  (40.3):  92%|| 1850/2000 [26:30<00:50,  2.97it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1851  (40.4):  92%|| 1850/2000 [26:31<00:50,  2.97it/s]\u001b[A\n",
      "Average Metric: 747 / 1851  (40.4):  93%|| 1851/2000 [26:31<00:53,  2.76it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1852  (40.3):  93%|| 1851/2000 [26:33<00:53,  2.76it/s]\u001b[A\n",
      "Average Metric: 747 / 1852  (40.3):  93%|| 1852/2000 [26:33<01:52,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1853  (40.3):  93%|| 1852/2000 [26:33<01:52,  1.32it/s]\u001b[A\n",
      "Average Metric: 747 / 1853  (40.3):  93%|| 1853/2000 [26:33<01:29,  1.64it/s]\u001b[A\n",
      "Average Metric: 747 / 1854  (40.3):  93%|| 1853/2000 [26:34<01:29,  1.64it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 747 / 1854  (40.3):  93%|| 1854/2000 [26:34<02:07,  1.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 747 / 1855  (40.3):  93%|| 1854/2000 [26:35<02:07,  1.14it/s]\u001b[A\n",
      "Average Metric: 747 / 1855  (40.3):  93%|| 1855/2000 [26:35<01:55,  1.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 747 / 1856  (40.2):  93%|| 1855/2000 [26:36<01:55,  1.25it/s]\u001b[A\n",
      "Average Metric: 747 / 1856  (40.2):  93%|| 1856/2000 [26:36<01:51,  1.29it/s]\u001b[A\n",
      "Average Metric: 748 / 1857  (40.3):  93%|| 1856/2000 [26:37<01:51,  1.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 748 / 1857  (40.3):  93%|| 1857/2000 [26:37<02:17,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1858  (40.3):  93%|| 1857/2000 [26:37<02:17,  1.04it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1859  (40.3):  93%|| 1858/2000 [26:38<02:16,  1.04it/s]\u001b[A\n",
      "Average Metric: 749 / 1859  (40.3):  93%|| 1859/2000 [26:38<01:27,  1.60it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 749 / 1860  (40.3):  93%|| 1859/2000 [26:41<01:27,  1.60it/s]\u001b[A\n",
      "Average Metric: 749 / 1860  (40.3):  93%|| 1860/2000 [26:41<02:55,  1.25s/it]\u001b[A\n",
      "Average Metric: 750 / 1861  (40.3):  93%|| 1860/2000 [26:41<02:55,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 750 / 1861  (40.3):  93%|| 1861/2000 [26:41<02:22,  1.02s/it]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 751 / 1862  (40.3):  93%|| 1861/2000 [26:41<02:22,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 751 / 1862  (40.3):  93%|| 1862/2000 [26:41<01:48,  1.27it/s]\u001b[A\n",
      "Average Metric: 751 / 1863  (40.3):  93%|| 1862/2000 [26:41<01:48,  1.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 752 / 1864  (40.3):  93%|| 1863/2000 [26:42<01:48,  1.27it/s]\u001b[A\n",
      "Average Metric: 752 / 1864  (40.3):  93%|| 1864/2000 [26:42<01:17,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 753 / 1865  (40.4):  93%|| 1864/2000 [26:42<01:17,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 753 / 1865  (40.4):  93%|| 1865/2000 [26:42<01:16,  1.77it/s]\u001b[A\n",
      "Average Metric: 753 / 1866  (40.4):  93%|| 1865/2000 [26:42<01:16,  1.77it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 754 / 1867  (40.4):  93%|| 1866/2000 [26:43<01:15,  1.77it/s]\u001b[A\n",
      "Average Metric: 754 / 1867  (40.4):  93%|| 1867/2000 [26:43<01:09,  1.91it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 754 / 1868  (40.4):  93%|| 1867/2000 [26:44<01:09,  1.91it/s]\u001b[A\n",
      "Average Metric: 754 / 1868  (40.4):  93%|| 1868/2000 [26:44<01:10,  1.87it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 754 / 1869  (40.3):  93%|| 1868/2000 [26:44<01:10,  1.87it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 754 / 1870  (40.3):  93%|| 1869/2000 [26:44<01:09,  1.87it/s]\u001b[A\n",
      "Average Metric: 754 / 1870  (40.3):  94%|| 1870/2000 [26:44<00:45,  2.86it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 755 / 1871  (40.4):  94%|| 1870/2000 [26:44<00:45,  2.86it/s]\u001b[A\n",
      "Average Metric: 755 / 1871  (40.4):  94%|| 1871/2000 [26:44<00:38,  3.32it/s]\u001b[A\n",
      "Average Metric: 755 / 1872  (40.3):  94%|| 1871/2000 [26:44<00:38,  3.32it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 755 / 1872  (40.3):  94%|| 1872/2000 [26:44<00:37,  3.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 756 / 1873  (40.4):  94%|| 1872/2000 [26:45<00:37,  3.42it/s]\u001b[A\n",
      "Average Metric: 756 / 1873  (40.4):  94%|| 1873/2000 [26:45<00:47,  2.66it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 756 / 1874  (40.3):  94%|| 1873/2000 [26:47<00:47,  2.66it/s]\u001b[A\n",
      "Average Metric: 756 / 1874  (40.3):  94%|| 1874/2000 [26:47<01:26,  1.45it/s]\u001b[A\n",
      "Average Metric: 757 / 1875  (40.4):  94%|| 1874/2000 [26:47<01:26,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 757 / 1875  (40.4):  94%|| 1875/2000 [26:47<01:26,  1.45it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 757 / 1876  (40.4):  94%|| 1875/2000 [26:48<01:26,  1.45it/s]\u001b[A\n",
      "Average Metric: 757 / 1876  (40.4):  94%|| 1876/2000 [26:48<01:43,  1.20it/s]\u001b[A\n",
      "Average Metric: 758 / 1877  (40.4):  94%|| 1876/2000 [26:48<01:43,  1.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 758 / 1878  (40.4):  94%|| 1877/2000 [26:49<01:42,  1.20it/s]\u001b[A\n",
      "Average Metric: 758 / 1878  (40.4):  94%|| 1878/2000 [26:49<01:14,  1.64it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 759 / 1879  (40.4):  94%|| 1878/2000 [26:50<01:14,  1.64it/s]\u001b[A\n",
      "Average Metric: 759 / 1879  (40.4):  94%|| 1879/2000 [26:50<01:07,  1.79it/s]\u001b[A\n",
      "Average Metric: 759 / 1880  (40.4):  94%|| 1879/2000 [26:51<01:07,  1.79it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 759 / 1880  (40.4):  94%|| 1880/2000 [26:51<01:26,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 760 / 1881  (40.4):  94%|| 1880/2000 [26:52<01:26,  1.38it/s]\u001b[A\n",
      "Average Metric: 760 / 1881  (40.4):  94%|| 1881/2000 [26:52<01:29,  1.32it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 760 / 1882  (40.4):  94%|| 1881/2000 [26:52<01:29,  1.32it/s]\u001b[A\n",
      "Average Metric: 760 / 1882  (40.4):  94%|| 1882/2000 [26:52<01:14,  1.57it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 760 / 1883  (40.4):  94%|| 1882/2000 [26:53<01:14,  1.57it/s]\u001b[A\n",
      "Average Metric: 760 / 1883  (40.4):  94%|| 1883/2000 [26:53<01:14,  1.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 761 / 1884  (40.4):  94%|| 1883/2000 [26:53<01:14,  1.56it/s]\u001b[A\n",
      "Average Metric: 761 / 1884  (40.4):  94%|| 1884/2000 [26:53<00:56,  2.05it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 762 / 1885  (40.4):  94%|| 1884/2000 [26:53<00:56,  2.05it/s]\u001b[A\n",
      "Average Metric: 763 / 1886  (40.5):  94%|| 1885/2000 [26:53<00:56,  2.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 763 / 1886  (40.5):  94%|| 1886/2000 [26:53<00:49,  2.29it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 764 / 1887  (40.5):  94%|| 1886/2000 [26:54<00:49,  2.29it/s]\u001b[A\n",
      "Average Metric: 764 / 1887  (40.5):  94%|| 1887/2000 [26:54<00:45,  2.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 764 / 1888  (40.5):  94%|| 1887/2000 [26:54<00:45,  2.50it/s]\u001b[A\n",
      "Average Metric: 764 / 1888  (40.5):  94%|| 1888/2000 [26:54<00:47,  2.34it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 765 / 1889  (40.5):  94%|| 1888/2000 [26:55<00:47,  2.34it/s]\u001b[A\n",
      "Average Metric: 765 / 1889  (40.5):  94%|| 1889/2000 [26:55<00:48,  2.30it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 765 / 1890  (40.5):  94%|| 1889/2000 [26:55<00:48,  2.30it/s]\u001b[A\n",
      "Average Metric: 765 / 1890  (40.5):  94%|| 1890/2000 [26:55<00:52,  2.08it/s]\u001b[A\n",
      "Average Metric: 765 / 1891  (40.5):  94%|| 1890/2000 [26:55<00:52,  2.08it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 765 / 1891  (40.5):  95%|| 1891/2000 [26:55<00:42,  2.56it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 766 / 1892  (40.5):  95%|| 1891/2000 [26:56<00:42,  2.56it/s]\u001b[A\n",
      "Average Metric: 766 / 1892  (40.5):  95%|| 1892/2000 [26:56<00:42,  2.55it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 766 / 1893  (40.5):  95%|| 1892/2000 [26:56<00:42,  2.55it/s]\u001b[A\n",
      "Average Metric: 766 / 1893  (40.5):  95%|| 1893/2000 [26:56<00:37,  2.82it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 766 / 1894  (40.4):  95%|| 1893/2000 [26:58<00:37,  2.82it/s]\u001b[A\n",
      "Average Metric: 766 / 1894  (40.4):  95%|| 1894/2000 [26:58<01:16,  1.38it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 767 / 1895  (40.5):  95%|| 1894/2000 [26:58<01:16,  1.38it/s]\u001b[A\n",
      "Average Metric: 767 / 1895  (40.5):  95%|| 1895/2000 [26:58<01:08,  1.54it/s]\u001b[A\n",
      "Average Metric: 767 / 1896  (40.5):  95%|| 1895/2000 [26:58<01:08,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 767 / 1896  (40.5):  95%|| 1896/2000 [26:58<00:51,  2.02it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 768 / 1897  (40.5):  95%|| 1896/2000 [26:59<00:51,  2.02it/s]\u001b[A\n",
      "Average Metric: 768 / 1897  (40.5):  95%|| 1897/2000 [26:59<00:50,  2.06it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 768 / 1898  (40.5):  95%|| 1897/2000 [26:59<00:50,  2.06it/s]\u001b[A\n",
      "Average Metric: 768 / 1898  (40.5):  95%|| 1898/2000 [26:59<00:52,  1.95it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 768 / 1899  (40.4):  95%|| 1898/2000 [27:00<00:52,  1.95it/s]\u001b[A\n",
      "Average Metric: 768 / 1899  (40.4):  95%|| 1899/2000 [27:00<00:52,  1.93it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 769 / 1900  (40.5):  95%|| 1899/2000 [27:01<00:52,  1.93it/s]\u001b[A\n",
      "Average Metric: 769 / 1900  (40.5):  95%|| 1900/2000 [27:01<01:09,  1.44it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 769 / 1901  (40.5):  95%|| 1900/2000 [27:02<01:09,  1.44it/s]\u001b[A\n",
      "Average Metric: 769 / 1901  (40.5):  95%|| 1901/2000 [27:02<01:33,  1.06it/s]\u001b[A\n",
      "Average Metric: 770 / 1902  (40.5):  95%|| 1901/2000 [27:03<01:33,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 770 / 1902  (40.5):  95%|| 1902/2000 [27:03<01:23,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1903  (40.5):  95%|| 1902/2000 [27:03<01:23,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1904  (40.4):  95%|| 1903/2000 [27:04<01:22,  1.18it/s]\u001b[A\n",
      "Average Metric: 770 / 1904  (40.4):  95%|| 1904/2000 [27:04<00:59,  1.62it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 770 / 1905  (40.4):  95%|| 1904/2000 [27:04<00:59,  1.62it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 770 / 1906  (40.4):  95%|| 1905/2000 [27:05<00:58,  1.62it/s]\u001b[A\n",
      "Average Metric: 770 / 1906  (40.4):  95%|| 1906/2000 [27:05<00:54,  1.73it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1907  (40.4):  95%|| 1906/2000 [27:06<00:54,  1.73it/s]\u001b[A\n",
      "Average Metric: 770 / 1907  (40.4):  95%|| 1907/2000 [27:06<00:56,  1.65it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 770 / 1908  (40.4):  95%|| 1907/2000 [27:06<00:56,  1.65it/s]\u001b[A\n",
      "Average Metric: 770 / 1908  (40.4):  95%|| 1908/2000 [27:06<00:50,  1.82it/s]\u001b[A\n",
      "Average Metric: 771 / 1909  (40.4):  95%|| 1908/2000 [27:07<00:50,  1.82it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 771 / 1909  (40.4):  95%|| 1909/2000 [27:07<00:54,  1.68it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 771 / 1910  (40.4):  95%|| 1909/2000 [27:07<00:54,  1.68it/s]\u001b[A\n",
      "Average Metric: 771 / 1910  (40.4):  96%|| 1910/2000 [27:07<00:42,  2.13it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 771 / 1911  (40.3):  96%|| 1910/2000 [27:07<00:42,  2.13it/s]\u001b[A\n",
      "Average Metric: 771 / 1911  (40.3):  96%|| 1911/2000 [27:07<00:35,  2.50it/s]\u001b[A\n",
      "Average Metric: 771 / 1912  (40.3):  96%|| 1911/2000 [27:07<00:35,  2.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 771 / 1912  (40.3):  96%|| 1912/2000 [27:07<00:31,  2.79it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 772 / 1913  (40.4):  96%|| 1912/2000 [27:08<00:31,  2.79it/s]\u001b[A\n",
      "Average Metric: 772 / 1913  (40.4):  96%|| 1913/2000 [27:08<00:38,  2.29it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 773 / 1914  (40.4):  96%|| 1913/2000 [27:09<00:38,  2.29it/s]\u001b[A\n",
      "Average Metric: 773 / 1914  (40.4):  96%|| 1914/2000 [27:09<00:50,  1.72it/s]\u001b[A\n",
      "Average Metric: 773 / 1915  (40.4):  96%|| 1914/2000 [27:09<00:50,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 773 / 1915  (40.4):  96%|| 1915/2000 [27:09<00:42,  1.99it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1916  (40.3):  96%|| 1915/2000 [27:10<00:42,  1.99it/s]\u001b[A\n",
      "Average Metric: 773 / 1916  (40.3):  96%|| 1916/2000 [27:10<00:39,  2.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1917  (40.3):  96%|| 1916/2000 [27:10<00:39,  2.14it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1918  (40.3):  96%|| 1917/2000 [27:11<00:38,  2.14it/s]\u001b[A\n",
      "Average Metric: 773 / 1918  (40.3):  96%|| 1918/2000 [27:11<00:41,  1.97it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 773 / 1919  (40.3):  96%|| 1918/2000 [27:11<00:41,  1.97it/s]\u001b[A\n",
      "Average Metric: 773 / 1919  (40.3):  96%|| 1919/2000 [27:11<00:35,  2.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 774 / 1920  (40.3):  96%|| 1919/2000 [27:11<00:35,  2.28it/s]\u001b[A\n",
      "Average Metric: 774 / 1920  (40.3):  96%|| 1920/2000 [27:11<00:37,  2.12it/s]\u001b[A\n",
      "Average Metric: 774 / 1921  (40.3):  96%|| 1920/2000 [27:12<00:37,  2.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1921  (40.3):  96%|| 1921/2000 [27:12<00:49,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1922  (40.3):  96%|| 1921/2000 [27:12<00:49,  1.61it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1923  (40.2):  96%|| 1922/2000 [27:12<00:48,  1.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 774 / 1924  (40.2):  96%|| 1923/2000 [27:13<00:47,  1.61it/s]\u001b[A\n",
      "Average Metric: 774 / 1924  (40.2):  96%|| 1924/2000 [27:13<00:32,  2.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'alein'? A: ranges B: bear C: rights D: alien\n",
      "Answer: D: alien\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the smallest mammal? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 774 / 1925  (40.2):  96%|| 1924/2000 [27:14<00:32,  2.34it/s]\u001b[A\n",
      "Average Metric: 774 / 1925  (40.2):  96%|| 1925/2000 [27:14<00:41,  1.79it/s]\u001b[A\n",
      "Average Metric: 774 / 1926  (40.2):  96%|| 1925/2000 [27:15<00:41,  1.79it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 774 / 1926  (40.2):  96%|| 1926/2000 [27:15<00:43,  1.72it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1927  (40.2):  96%|| 1926/2000 [27:15<00:43,  1.72it/s]\u001b[A\n",
      "Average Metric: 774 / 1927  (40.2):  96%|| 1927/2000 [27:15<00:35,  2.06it/s]\u001b[A\n",
      "Average Metric: 774 / 1928  (40.1):  96%|| 1927/2000 [27:15<00:35,  2.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 774 / 1928  (40.1):  96%|| 1928/2000 [27:15<00:29,  2.42it/s]\u001b[A\n",
      "Average Metric: 774 / 1929  (40.1):  96%|| 1928/2000 [27:15<00:29,  2.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 774 / 1930  (40.1):  96%|| 1929/2000 [27:16<00:29,  2.42it/s]\u001b[A\n",
      "Average Metric: 774 / 1930  (40.1):  96%|| 1930/2000 [27:16<00:21,  3.25it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1931  (40.1):  96%|| 1930/2000 [27:16<00:21,  3.25it/s]\u001b[A\n",
      "Average Metric: 775 / 1931  (40.1):  97%|| 1931/2000 [27:16<00:23,  2.99it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1932  (40.1):  97%|| 1931/2000 [27:18<00:23,  2.99it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 775 / 1932  (40.1):  97%|| 1932/2000 [27:18<00:55,  1.23it/s]\u001b[A\n",
      "Average Metric: 775 / 1933  (40.1):  97%|| 1932/2000 [27:18<00:55,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 775 / 1934  (40.1):  97%|| 1933/2000 [27:18<00:54,  1.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 775 / 1935  (40.1):  97%|| 1934/2000 [27:19<00:53,  1.23it/s]\u001b[A\n",
      "Average Metric: 775 / 1935  (40.1):  97%|| 1935/2000 [27:19<00:27,  2.33it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1936  (40.0):  97%|| 1935/2000 [27:19<00:27,  2.33it/s]\u001b[A\n",
      "Average Metric: 775 / 1936  (40.0):  97%|| 1936/2000 [27:19<00:24,  2.61it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1937  (40.0):  97%|| 1936/2000 [27:19<00:24,  2.61it/s]\u001b[A\n",
      "Average Metric: 775 / 1937  (40.0):  97%|| 1937/2000 [27:19<00:27,  2.33it/s]\u001b[A\n",
      "Average Metric: 775 / 1938  (40.0):  97%|| 1937/2000 [27:20<00:27,  2.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 775 / 1938  (40.0):  97%|| 1938/2000 [27:20<00:33,  1.84it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 775 / 1939  (40.0):  97%|| 1938/2000 [27:20<00:33,  1.84it/s]\u001b[A\n",
      "Average Metric: 775 / 1939  (40.0):  97%|| 1939/2000 [27:20<00:26,  2.28it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 776 / 1940  (40.0):  97%|| 1939/2000 [27:21<00:26,  2.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 776 / 1940  (40.0):  97%|| 1940/2000 [27:21<00:25,  2.33it/s]\u001b[A\n",
      "Average Metric: 776 / 1941  (40.0):  97%|| 1940/2000 [27:21<00:25,  2.33it/s]\u001b[A\n",
      "Average Metric: 776 / 1942  (40.0):  97%|| 1941/2000 [27:22<00:25,  2.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 776 / 1942  (40.0):  97%|| 1942/2000 [27:22<00:30,  1.90it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 776 / 1943  (39.9):  97%|| 1942/2000 [27:23<00:30,  1.90it/s]\u001b[A\n",
      "Average Metric: 776 / 1943  (39.9):  97%|| 1943/2000 [27:23<00:31,  1.81it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 777 / 1944  (40.0):  97%|| 1943/2000 [27:23<00:31,  1.81it/s]\u001b[A\n",
      "Average Metric: 777 / 1944  (40.0):  97%|| 1944/2000 [27:23<00:27,  2.03it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 778 / 1945  (40.0):  97%|| 1944/2000 [27:24<00:27,  2.03it/s]\u001b[A\n",
      "Average Metric: 778 / 1945  (40.0):  97%|| 1945/2000 [27:24<00:28,  1.93it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1946  (40.0):  97%|| 1945/2000 [27:25<00:28,  1.93it/s]\u001b[A\n",
      "Average Metric: 779 / 1946  (40.0):  97%|| 1946/2000 [27:25<00:33,  1.60it/s]\u001b[A\n",
      "Average Metric: 779 / 1947  (40.0):  97%|| 1946/2000 [27:26<00:33,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 779 / 1947  (40.0):  97%|| 1947/2000 [27:26<00:44,  1.18it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1948  (40.0):  97%|| 1947/2000 [27:26<00:44,  1.18it/s]\u001b[A\n",
      "Average Metric: 779 / 1948  (40.0):  97%|| 1948/2000 [27:26<00:34,  1.50it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1949  (40.0):  97%|| 1948/2000 [27:26<00:34,  1.50it/s]\u001b[A\n",
      "Average Metric: 779 / 1949  (40.0):  97%|| 1949/2000 [27:26<00:26,  1.90it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 779 / 1950  (39.9):  97%|| 1949/2000 [27:27<00:26,  1.90it/s]\u001b[A\n",
      "Average Metric: 779 / 1950  (39.9):  98%|| 1950/2000 [27:27<00:29,  1.70it/s]\u001b[A\n",
      "Average Metric: 779 / 1951  (39.9):  98%|| 1950/2000 [27:28<00:29,  1.70it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 779 / 1951  (39.9):  98%|| 1951/2000 [27:28<00:35,  1.36it/s]\u001b[A\n",
      "Average Metric: 779 / 1952  (39.9):  98%|| 1951/2000 [27:29<00:35,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 779 / 1952  (39.9):  98%|| 1952/2000 [27:29<00:32,  1.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 780 / 1953  (39.9):  98%|| 1952/2000 [27:29<00:32,  1.49it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 780 / 1953  (39.9):  98%|| 1953/2000 [27:29<00:27,  1.72it/s]\u001b[A\n",
      "Average Metric: 781 / 1954  (40.0):  98%|| 1953/2000 [27:29<00:27,  1.72it/s]\u001b[A\n",
      "Average Metric: 781 / 1955  (39.9):  98%|| 1954/2000 [27:31<00:26,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 781 / 1955  (39.9):  98%|| 1955/2000 [27:31<00:31,  1.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 781 / 1956  (39.9):  98%|| 1955/2000 [27:31<00:31,  1.43it/s]\u001b[A\n",
      "Average Metric: 781 / 1956  (39.9):  98%|| 1956/2000 [27:31<00:25,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 782 / 1957  (40.0):  98%|| 1956/2000 [27:31<00:25,  1.75it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 783 / 1958  (40.0):  98%|| 1957/2000 [27:31<00:24,  1.75it/s]\u001b[A\n",
      "Average Metric: 783 / 1958  (40.0):  98%|| 1958/2000 [27:31<00:18,  2.31it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 783 / 1959  (40.0):  98%|| 1958/2000 [27:32<00:18,  2.31it/s]\u001b[A\n",
      "Average Metric: 783 / 1959  (40.0):  98%|| 1959/2000 [27:32<00:16,  2.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 783 / 1960  (39.9):  98%|| 1959/2000 [27:32<00:16,  2.48it/s]\u001b[A\n",
      "Average Metric: 783 / 1960  (39.9):  98%|| 1960/2000 [27:32<00:14,  2.69it/s]\u001b[A\n",
      "Average Metric: 783 / 1961  (39.9):  98%|| 1960/2000 [27:32<00:14,  2.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 783 / 1961  (39.9):  98%|| 1961/2000 [27:32<00:13,  2.84it/s]\u001b[A\n",
      "Average Metric: 784 / 1962  (40.0):  98%|| 1961/2000 [27:33<00:13,  2.84it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 784 / 1962  (40.0):  98%|| 1962/2000 [27:34<00:22,  1.71it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 785 / 1963  (40.0):  98%|| 1962/2000 [27:34<00:22,  1.71it/s]\u001b[A\n",
      "Average Metric: 785 / 1963  (40.0):  98%|| 1963/2000 [27:35<00:26,  1.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 786 / 1964  (40.0):  98%|| 1963/2000 [27:35<00:26,  1.42it/s]\u001b[A\n",
      "Average Metric: 786 / 1964  (40.0):  98%|| 1964/2000 [27:35<00:25,  1.39it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 786 / 1965  (40.0):  98%|| 1964/2000 [27:37<00:25,  1.39it/s]\u001b[A\n",
      "Average Metric: 786 / 1965  (40.0):  98%|| 1965/2000 [27:37<00:30,  1.15it/s]\u001b[A\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 786 / 1966  (40.0):  98%|| 1965/2000 [27:37<00:30,  1.15it/s]\u001b[A\n",
      "Average Metric: 786 / 1966  (40.0):  98%|| 1966/2000 [27:37<00:25,  1.34it/s]\u001b[A\n",
      "Average Metric: 787 / 1967  (40.0):  98%|| 1966/2000 [27:37<00:25,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 787 / 1967  (40.0):  98%|| 1967/2000 [27:37<00:19,  1.72it/s]\u001b[A\n",
      "Average Metric: 787 / 1968  (40.0):  98%|| 1967/2000 [27:37<00:19,  1.72it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\u001b[A\n",
      "Average Metric: 787 / 1968  (40.0):  98%|| 1968/2000 [27:37<00:14,  2.17it/s]\u001b[A\n",
      "Average Metric: 787 / 1969  (40.0):  98%|| 1968/2000 [27:37<00:14,  2.17it/s]\u001b[A\n",
      "Average Metric: 787 / 1970  (39.9):  98%|| 1969/2000 [27:38<00:14,  2.17it/s]\u001b[A\n",
      "Average Metric: 787 / 1970  (39.9):  98%|| 1970/2000 [27:38<00:12,  2.31it/s]\u001b[A\n",
      "Average Metric: 787 / 1971  (39.9):  98%|| 1970/2000 [27:38<00:12,  2.31it/s]\u001b[A\n",
      "Average Metric: 787 / 1971  (39.9):  99%|| 1971/2000 [27:38<00:10,  2.72it/s]\u001b[A\n",
      "Average Metric: 788 / 1972  (40.0):  99%|| 1971/2000 [27:39<00:10,  2.72it/s]\u001b[A\n",
      "Average Metric: 788 / 1972  (40.0):  99%|| 1972/2000 [27:39<00:12,  2.17it/s]\u001b[A\n",
      "Average Metric: 788 / 1973  (39.9):  99%|| 1972/2000 [27:39<00:12,  2.17it/s]\u001b[A\n",
      "Average Metric: 788 / 1973  (39.9):  99%|| 1973/2000 [27:39<00:12,  2.23it/s]\u001b[A\n",
      "Average Metric: 789 / 1974  (40.0):  99%|| 1973/2000 [27:40<00:12,  2.23it/s]\u001b[A\n",
      "Average Metric: 789 / 1975  (39.9):  99%|| 1974/2000 [27:40<00:11,  2.23it/s]\u001b[A\n",
      "Average Metric: 789 / 1975  (39.9):  99%|| 1975/2000 [27:40<00:07,  3.52it/s]\u001b[A\n",
      "Average Metric: 789 / 1976  (39.9):  99%|| 1975/2000 [27:40<00:07,  3.52it/s]\u001b[A\n",
      "Average Metric: 790 / 1977  (40.0):  99%|| 1976/2000 [27:40<00:06,  3.52it/s]\u001b[A\n",
      "Average Metric: 790 / 1977  (40.0):  99%|| 1977/2000 [27:40<00:04,  4.86it/s]\u001b[A\n",
      "Average Metric: 790 / 1978  (39.9):  99%|| 1977/2000 [27:41<00:04,  4.86it/s]\u001b[A\n",
      "Average Metric: 790 / 1978  (39.9):  99%|| 1978/2000 [27:41<00:09,  2.29it/s]\u001b[A\n",
      "Average Metric: 791 / 1979  (40.0):  99%|| 1978/2000 [27:42<00:09,  2.29it/s]\u001b[A\n",
      "Average Metric: 791 / 1979  (40.0):  99%|| 1979/2000 [27:42<00:10,  2.08it/s]\u001b[A\n",
      "Average Metric: 792 / 1980  (40.0):  99%|| 1979/2000 [27:43<00:10,  2.08it/s]\u001b[A\n",
      "Average Metric: 792 / 1980  (40.0):  99%|| 1980/2000 [27:43<00:13,  1.53it/s]\u001b[A\n",
      "Average Metric: 792 / 1981  (40.0):  99%|| 1980/2000 [27:43<00:13,  1.53it/s]\u001b[A\n",
      "Average Metric: 793 / 1982  (40.0):  99%|| 1981/2000 [27:43<00:12,  1.53it/s]\u001b[A\n",
      "Average Metric: 793 / 1982  (40.0):  99%|| 1982/2000 [27:43<00:09,  1.90it/s]\u001b[A\n",
      "Average Metric: 794 / 1983  (40.0):  99%|| 1982/2000 [27:44<00:09,  1.90it/s]\u001b[A\n",
      "Average Metric: 794 / 1983  (40.0):  99%|| 1983/2000 [27:44<00:08,  2.06it/s]\u001b[A\n",
      "Average Metric: 795 / 1984  (40.1):  99%|| 1983/2000 [27:45<00:08,  2.06it/s]\u001b[A\n",
      "Average Metric: 795 / 1984  (40.1):  99%|| 1984/2000 [27:45<00:09,  1.76it/s]\u001b[A\n",
      "Average Metric: 796 / 1985  (40.1):  99%|| 1984/2000 [27:45<00:09,  1.76it/s]\u001b[A\n",
      "Average Metric: 796 / 1985  (40.1):  99%|| 1985/2000 [27:45<00:09,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1986  (40.1):  99%|| 1985/2000 [27:46<00:09,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1986  (40.1):  99%|| 1986/2000 [27:46<00:08,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1987  (40.1):  99%|| 1986/2000 [27:46<00:08,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1988  (40.1):  99%|| 1987/2000 [27:52<00:08,  1.62it/s]\u001b[A\n",
      "Average Metric: 797 / 1988  (40.1):  99%|| 1988/2000 [27:52<00:20,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'hmoes'? A: coming B: hood C: homes D: avril\n",
      "Answer: D: avril\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the smallest mammal? A: Elephant B: Whale C: Mouse D: Giraffe\n",
      "Answer: C: Mouse\n",
      "\n",
      "Question: What is the largest country in the world\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rearrange the letters in 'fahetr' to form the correct word. A: enabling B: fisher C: father D: limitations\n",
      "Answer: A\n",
      "\n",
      "Question: Which of the following is the smallest value?  (a) 0.1  (b) 0.01  (c) 0.001  (d) 0.0001\n",
      "Answer: d\n",
      "\n",
      "Question: Which of the following is the capital of France?  (a) Berlin  (b) Madrid  (c) Paris  (d) Rome\n",
      "Answer: c\n",
      "\n",
      "Question: Which of the following is the largest value?  (a) 0.1  (b) 0.01  (c) 0.001  (d) 0.0001\n",
      "Answer\n",
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vmiitnas'? A: comprised B: major C: healthy D: vitamins\n",
      "Answer: D: vitamins\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Earth B: Mars C: Jupiter D: Venus\n",
      "Answer: C: Jupiter\n",
      "\n",
      "Question: What is the smallest country in the world? A: Australia B: Canada C: Monaco D: China\n",
      "Answer: D: China\n",
      "\n",
      "Question: What is the highest mountain in the world? A: Mount Everest B: Kangchenjunga C: K2 D: Lhotse\n",
      "Answer: A: Mount Everest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 797 / 1989  (40.1):  99%|| 1988/2000 [28:32<00:20,  1.71s/it]\u001b[A\n",
      "Average Metric: 797 / 1989  (40.1):  99%|| 1989/2000 [28:32<01:57, 10.68s/it]\u001b[A\n",
      "Average Metric: 797 / 1990  (40.1):  99%|| 1989/2000 [28:32<01:57, 10.68s/it]\u001b[A\n",
      "Average Metric: 797 / 1990  (40.1): 100%|| 1990/2000 [28:32<01:20,  8.02s/it]\u001b[A\n",
      "Average Metric: 797 / 1991  (40.0): 100%|| 1990/2000 [28:34<01:20,  8.02s/it]\u001b[A\n",
      "Average Metric: 797 / 1991  (40.0): 100%|| 1991/2000 [28:34<00:57,  6.36s/it]\u001b[A\n",
      "Average Metric: 797 / 1992  (40.0): 100%|| 1991/2000 [28:35<00:57,  6.36s/it]\u001b[A\n",
      "Average Metric: 797 / 1992  (40.0): 100%|| 1992/2000 [28:35<00:40,  5.09s/it]\u001b[A\n",
      "Average Metric: 797 / 1993  (40.0): 100%|| 1992/2000 [28:37<00:40,  5.09s/it]\u001b[A\n",
      "Average Metric: 797 / 1993  (40.0): 100%|| 1993/2000 [28:37<00:28,  4.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'afnfitceg'? A: infected B: ruled C: norman D: affecting\n",
      "Answer: D: affecting\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: What is the smallest prime number? A: 2 B: 3 C: 5 D: 7\n",
      "Answer: B: 3\n",
      "\n",
      "Question: What is the largest planet in our solar system? A: Mercury B: Venus C: Earth D: Jupiter\n",
      "Answer: D: Jupiter\n",
      "\n",
      "Question: What is the chemical symbol for gold? A: Hg B: Au C: Ag D: Pd\n",
      "Answer: B: Au\n",
      "\n",
      "Question: What is the capital of Spain? A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 797 / 1994  (40.0): 100%|| 1993/2000 [28:39<00:28,  4.14s/it]\u001b[A\n",
      "Average Metric: 797 / 1994  (40.0): 100%|| 1994/2000 [28:39<00:20,  3.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions from the given options A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: 1 letter from A,B,C,D\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you unscramble 'vatil'? A: nebraska B: terrace C: testing D: vital\n",
      "Answer: D: vital\n",
      "\n",
      "Question: What is the capital of France? A: Madrid B: Berlin C: Paris D: Rome\n",
      "Answer: C: Paris\n",
      "\n",
      "Question: Which planet is closest to the sun? A: Jupiter B: Venus C: Mercury D: Mars\n",
      "Answer: C: Mercury\n",
      "\n",
      "Question: What is the largest mammal on earth? A: elephant B: whale C: bear D: giraffe\n",
      "Answer: B: whale\n",
      "\n",
      "Question: What is the smallest country in the world? A: vatican city B: monaco C: san marino D: liechtenstein\n",
      "Answer: A: vatican city\n",
      "\n",
      "Question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 797 / 1995  (39.9): 100%|| 1994/2000 [28:47<00:20,  3.35s/it]\u001b[A\n",
      "Average Metric: 797 / 1995  (39.9): 100%|| 1995/2000 [28:47<00:24,  4.89s/it]\u001b[A\n",
      "Average Metric: 798 / 1996  (40.0): 100%|| 1995/2000 [28:54<00:24,  4.89s/it]\u001b[A\n",
      "Average Metric: 798 / 1996  (40.0): 100%|| 1996/2000 [28:54<00:21,  5.33s/it]\u001b[A\n",
      "Average Metric: 799 / 1997  (40.0): 100%|| 1996/2000 [28:55<00:21,  5.33s/it]\u001b[A\n",
      "Average Metric: 799 / 1997  (40.0): 100%|| 1997/2000 [28:55<00:12,  4.25s/it]\u001b[A\n",
      "Average Metric: 799 / 1998  (40.0): 100%|| 1997/2000 [28:57<00:12,  4.25s/it]\u001b[A\n",
      "Average Metric: 799 / 1998  (40.0): 100%|| 1998/2000 [28:57<00:06,  3.38s/it]\u001b[A\n",
      "Average Metric: 799 / 1999  (40.0): 100%|| 1998/2000 [28:58<00:06,  3.38s/it]\u001b[A\n",
      "Average Metric: 799 / 1999  (40.0): 100%|| 1999/2000 [28:58<00:02,  2.81s/it]\u001b[A\n",
      "Average Metric: 799 / 2000  (40.0): 100%|| 1999/2000 [28:58<00:02,  2.81s/it]\u001b[A\n",
      "Average Metric: 799 / 2000  (40.0): 100%|| 2000/2000 [28:58<00:00,  1.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 799 / 2000  (40.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_31156 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_31156 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_31156_row0_col0, #T_31156_row0_col1, #T_31156_row0_col2, #T_31156_row0_col3, #T_31156_row0_col4, #T_31156_row0_col5, #T_31156_row1_col0, #T_31156_row1_col1, #T_31156_row1_col2, #T_31156_row1_col3, #T_31156_row1_col4, #T_31156_row1_col5, #T_31156_row2_col0, #T_31156_row2_col1, #T_31156_row2_col2, #T_31156_row2_col3, #T_31156_row2_col4, #T_31156_row2_col5, #T_31156_row3_col0, #T_31156_row3_col1, #T_31156_row3_col2, #T_31156_row3_col3, #T_31156_row3_col4, #T_31156_row3_col5, #T_31156_row4_col0, #T_31156_row4_col1, #T_31156_row4_col2, #T_31156_row4_col3, #T_31156_row4_col4, #T_31156_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_31156\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_31156_level0_col0\" class=\"col_heading level0 col0\" >example_answer</th>\n",
       "      <th id=\"T_31156_level0_col1\" class=\"col_heading level0 col1\" >word</th>\n",
       "      <th id=\"T_31156_level0_col2\" class=\"col_heading level0 col2\" >scrambled</th>\n",
       "      <th id=\"T_31156_level0_col3\" class=\"col_heading level0 col3\" >question</th>\n",
       "      <th id=\"T_31156_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_31156_level0_col5\" class=\"col_heading level0 col5\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_31156_row0_col0\" class=\"data row0 col0\" >B</td>\n",
       "      <td id=\"T_31156_row0_col1\" class=\"data row0 col1\" >knee</td>\n",
       "      <td id=\"T_31156_row0_col2\" class=\"data row0 col2\" >kene</td>\n",
       "      <td id=\"T_31156_row0_col3\" class=\"data row0 col3\" >Can you unscramble 'kene'?\n",
       "A: raymond\n",
       "B: knee\n",
       "C: take\n",
       "D: consumption</td>\n",
       "      <td id=\"T_31156_row0_col4\" class=\"data row0 col4\" >B</td>\n",
       "      <td id=\"T_31156_row0_col5\" class=\"data row0 col5\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_31156_row1_col0\" class=\"data row1 col0\" >D</td>\n",
       "      <td id=\"T_31156_row1_col1\" class=\"data row1 col1\" >camcorders</td>\n",
       "      <td id=\"T_31156_row1_col2\" class=\"data row1 col2\" >cmorarecds</td>\n",
       "      <td id=\"T_31156_row1_col3\" class=\"data row1 col3\" >Decode the word 'cmorarecds'.\n",
       "A: charitable\n",
       "B: thats\n",
       "C: univ\n",
       "D: camcorders</td>\n",
       "      <td id=\"T_31156_row1_col4\" class=\"data row1 col4\" >D</td>\n",
       "      <td id=\"T_31156_row1_col5\" class=\"data row1 col5\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_31156_row2_col0\" class=\"data row2 col0\" >C</td>\n",
       "      <td id=\"T_31156_row2_col1\" class=\"data row2 col1\" >heat</td>\n",
       "      <td id=\"T_31156_row2_col2\" class=\"data row2 col2\" >haet</td>\n",
       "      <td id=\"T_31156_row2_col3\" class=\"data row2 col3\" >Decode the word 'haet'.\n",
       "A: babes\n",
       "B: competent\n",
       "C: heat\n",
       "D: dogs</td>\n",
       "      <td id=\"T_31156_row2_col4\" class=\"data row2 col4\" >D</td>\n",
       "      <td id=\"T_31156_row2_col5\" class=\"data row2 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_31156_row3_col0\" class=\"data row3 col0\" >C</td>\n",
       "      <td id=\"T_31156_row3_col1\" class=\"data row3 col1\" >brochure</td>\n",
       "      <td id=\"T_31156_row3_col2\" class=\"data row3 col2\" >bruchore</td>\n",
       "      <td id=\"T_31156_row3_col3\" class=\"data row3 col3\" >Can you unscramble 'bruchore'?\n",
       "A: acrylic\n",
       "B: monroe\n",
       "C: brochure\n",
       "D: products</td>\n",
       "      <td id=\"T_31156_row3_col4\" class=\"data row3 col4\" >C</td>\n",
       "      <td id=\"T_31156_row3_col5\" class=\"data row3 col5\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31156_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_31156_row4_col0\" class=\"data row4 col0\" >B</td>\n",
       "      <td id=\"T_31156_row4_col1\" class=\"data row4 col1\" >grass</td>\n",
       "      <td id=\"T_31156_row4_col2\" class=\"data row4 col2\" >gasrs</td>\n",
       "      <td id=\"T_31156_row4_col3\" class=\"data row4 col3\" >Rearrange the letters in 'gasrs' to form the correct word.\n",
       "A: valuable\n",
       "B: grass\n",
       "C: fresno\n",
       "D: dept</td>\n",
       "      <td id=\"T_31156_row4_col4\" class=\"data row4 col4\" >D</td>\n",
       "      <td id=\"T_31156_row4_col5\" class=\"data row4 col5\" > [False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f46c855f280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1995 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "39.95"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=test_set, num_threads=32, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(generate_answer_with_chain_of_thought, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwpFBOZK6p0G",
    "outputId": "e778154a-cbf7-4998-e71f-6b43a358e1a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 1/100 [00:05<08:58,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|         | 2/100 [00:10<08:51,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|         | 3/100 [00:16<08:45,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|         | 4/100 [00:21<08:39,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|         | 5/100 [00:27<08:33,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|         | 6/100 [00:32<08:26,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|         | 7/100 [00:37<08:21,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|         | 8/100 [00:43<08:14,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|         | 9/100 [00:48<08:11,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    return answer_EM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_answer)\n",
    "\n",
    "uncompiled_cot = CoT()\n",
    "\n",
    "# Compile!\n",
    "compiled_cot = teleprompter.compile(uncompiled_cot, trainset=train_set[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANBEb8Ww9Ooy",
    "outputId": "98806449-8911-4200-cb00-352006f1b068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_answer\n",
      "Example({'augmented': True, 'question': \"Decode the word 'beer'.\\nA: eleven\\nB: exercise\\nC: birth\\nD: beer\", 'answer': 'D'}) (input_keys=None)\n",
      "Example({'augmented': True, 'question': \"Decode the word 'porgtahpohy'.\\nA: orleans\\nB: negotiate\\nC: kelly\\nD: photography\", 'answer': 'D'}) (input_keys=None)\n",
      "Example({'augmented': True, 'question': \"Can you unscramble 'fhtuerr'?\\nA: mere\\nB: totals\\nC: north\\nD: further\", 'answer': 'D'}) (input_keys=None)\n",
      "Example({'augmented': True, 'question': \"What word does 'srting' represent when unscrambled?\\nA: contracting\\nB: fishing\\nC: sheraton\\nD: string\", 'answer': 'D'}) (input_keys=None)\n",
      "Example({'answer': 'C', 'word': 'neat', 'scrambled': 'naet', 'question': \"Find the right word for 'naet'.\\nA: galleries\\nB: disabled\\nC: neat\\nD: changed\"}) (input_keys={'question'})\n",
      "Example({'answer': 'B', 'word': 'reforms', 'scrambled': 'remfros', 'question': \"Rearrange the letters in 'remfros' to form the correct word.\\nA: decorative\\nB: reforms\\nC: innovative\\nD: lexus\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'notable', 'scrambled': 'nlbotae', 'question': \"Can you unscramble 'nlbotae'?\\nA: inherent\\nB: acknowledged\\nC: notable\\nD: shawn\"}) (input_keys={'question'})\n",
      "Example({'answer': 'D', 'word': 'securely', 'scrambled': 'serleucy', 'question': \"Decode the word 'serleucy'.\\nA: preparation\\nB: baghdad\\nC: specifics\\nD: securely\"}) (input_keys={'question'})\n",
      "Example({'answer': 'D', 'word': 'turns', 'scrambled': 'tnrus', 'question': \"Rearrange the letters in 'tnrus' to form the correct word.\\nA: telling\\nB: intel\\nC: liable\\nD: turns\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'undefined', 'scrambled': 'unfednied', 'question': \"Find the right word for 'unfednied'.\\nA: transform\\nB: shoes\\nC: undefined\\nD: tragedy\"}) (input_keys={'question'})\n",
      "Example({'answer': 'A', 'word': 'examining', 'scrambled': 'einmxnaig', 'question': \"Rearrange the letters in 'einmxnaig' to form the correct word.\\nA: examining\\nB: hoped\\nC: diameter\\nD: rarely\"}) (input_keys={'question'})\n",
      "Example({'answer': 'B', 'word': 'karma', 'scrambled': 'krmaa', 'question': \"Can you unscramble 'krmaa'?\\nA: illness\\nB: karma\\nC: spine\\nD: churches\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'herbal', 'scrambled': 'hbearl', 'question': \"Can you unscramble 'hbearl'?\\nA: modification\\nB: refurbished\\nC: herbal\\nD: president\"}) (input_keys={'question'})\n",
      "Example({'answer': 'D', 'word': 'tender', 'scrambled': 'tedenr', 'question': \"Find the right word for 'tedenr'.\\nA: physicians\\nB: largest\\nC: cinema\\nD: tender\"}) (input_keys={'question'})\n",
      "Example({'answer': 'B', 'word': 'focused', 'scrambled': 'foucsed', 'question': \"Can you unscramble 'foucsed'?\\nA: took\\nB: focused\\nC: jack\\nD: debian\"}) (input_keys={'question'})\n",
      "Example({'answer': 'C', 'word': 'civil', 'scrambled': 'ciivl', 'question': \"Decode the word 'ciivl'.\\nA: poster\\nB: bless\\nC: civil\\nD: spiral\"}) (input_keys={'question'})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in compiled_cot.named_predictors():\n",
    "    print(name)\n",
    "    for p in parameter.demos:\n",
    "        print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 0 / 1  (0.0):   0%|          | 1/2000 [00:05<3:07:57,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 2  (50.0):   0%|          | 2/2000 [00:11<3:02:30,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 3  (33.3):   0%|          | 3/2000 [00:16<3:01:09,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 4  (25.0):   0%|          | 4/2000 [00:21<3:00:05,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 1 / 5  (20.0):   0%|          | 5/2000 [00:27<2:59:51,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 6  (33.3):   0%|          | 6/2000 [00:32<2:59:31,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 7  (28.6):   0%|          | 7/2000 [00:37<2:59:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 8  (25.0):   0%|          | 8/2000 [00:43<2:59:05,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 9  (22.2):   0%|          | 9/2000 [00:48<2:59:06,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 10  (20.0):   0%|          | 10/2000 [00:54<2:58:53,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 2 / 11  (18.2):   1%|          | 11/2000 [00:59<2:58:34,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 3 / 12  (25.0):   1%|          | 12/2000 [01:04<2:58:17,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 13  (30.8):   1%|          | 13/2000 [01:10<2:57:56,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 14  (28.6):   1%|          | 14/2000 [01:15<2:57:54,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 15  (26.7):   1%|          | 15/2000 [01:20<2:57:36,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 4 / 16  (25.0):   1%|          | 16/2000 [01:26<2:57:25,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 5 / 17  (29.4):   1%|          | 17/2000 [01:31<2:57:11,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 5 / 18  (27.8):   1%|          | 18/2000 [01:37<2:57:02,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 5 / 19  (26.3):   1%|          | 19/2000 [01:42<2:57:12,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 20  (30.0):   1%|          | 20/2000 [01:47<2:56:57,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 21  (28.6):   1%|          | 21/2000 [01:53<2:57:07,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 22  (27.3):   1%|          | 22/2000 [01:58<2:56:59,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 6 / 23  (26.1):   1%|          | 23/2000 [02:03<2:56:49,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 7 / 24  (29.2):   1%|          | 24/2000 [02:09<2:56:56,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 7 / 25  (28.0):   1%|         | 25/2000 [02:14<2:56:46,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 7 / 26  (26.9):   1%|         | 26/2000 [02:20<2:56:48,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 7 / 27  (25.9):   1%|         | 27/2000 [02:25<2:56:36,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 7 / 28  (25.0):   1%|         | 28/2000 [02:30<2:56:37,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 7 / 29  (24.1):   1%|         | 29/2000 [02:36<2:56:27,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 30  (26.7):   2%|         | 30/2000 [02:41<2:56:20,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 31  (25.8):   2%|         | 31/2000 [02:46<2:56:22,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 32  (25.0):   2%|         | 32/2000 [02:52<2:56:05,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 33  (24.2):   2%|         | 33/2000 [02:57<2:56:09,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 34  (23.5):   2%|         | 34/2000 [03:02<2:55:58,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 35  (22.9):   2%|         | 35/2000 [03:08<2:55:59,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 36  (22.2):   2%|         | 36/2000 [03:13<2:55:45,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 37  (21.6):   2%|         | 37/2000 [03:19<2:55:41,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 38  (21.1):   2%|         | 38/2000 [03:24<2:55:49,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 39  (20.5):   2%|         | 39/2000 [03:29<2:55:47,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 8 / 40  (20.0):   2%|         | 40/2000 [03:35<2:55:51,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 41  (22.0):   2%|         | 41/2000 [03:40<2:55:40,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 42  (21.4):   2%|         | 42/2000 [03:46<2:55:46,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 43  (20.9):   2%|         | 43/2000 [03:51<2:55:37,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 9 / 44  (20.5):   2%|         | 44/2000 [03:56<2:55:27,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 10 / 45  (22.2):   2%|         | 45/2000 [04:02<2:55:28,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 10 / 46  (21.7):   2%|         | 46/2000 [04:07<2:55:26,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 10 / 47  (21.3):   2%|         | 47/2000 [04:12<2:55:11,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 10 / 48  (20.8):   2%|         | 48/2000 [04:18<2:55:03,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 49  (22.4):   2%|         | 49/2000 [04:23<2:54:52,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 50  (22.0):   2%|         | 50/2000 [04:29<2:54:51,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 51  (21.6):   3%|         | 51/2000 [04:34<2:54:46,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 52  (21.2):   3%|         | 52/2000 [04:39<2:54:31,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 53  (20.8):   3%|         | 53/2000 [04:45<2:54:28,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 54  (20.4):   3%|         | 54/2000 [04:50<2:54:11,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 55  (20.0):   3%|         | 55/2000 [04:55<2:54:11,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 11 / 56  (19.6):   3%|         | 56/2000 [05:01<2:54:05,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 12 / 57  (21.1):   3%|         | 57/2000 [05:06<2:53:57,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 12 / 58  (20.7):   3%|         | 58/2000 [05:12<2:53:55,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 59  (22.0):   3%|         | 59/2000 [05:17<2:54:01,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 60  (21.7):   3%|         | 60/2000 [05:22<2:54:06,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 61  (21.3):   3%|         | 61/2000 [05:28<2:53:56,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 62  (21.0):   3%|         | 62/2000 [05:33<2:53:59,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 13 / 63  (20.6):   3%|         | 63/2000 [05:39<2:53:49,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 64  (21.9):   3%|         | 64/2000 [05:44<2:53:44,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 65  (21.5):   3%|         | 65/2000 [05:49<2:53:31,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 66  (21.2):   3%|         | 66/2000 [05:55<2:53:31,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 67  (20.9):   3%|         | 67/2000 [06:00<2:53:38,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 68  (20.6):   3%|         | 68/2000 [06:05<2:53:35,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 69  (20.3):   3%|         | 69/2000 [06:11<2:53:33,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 14 / 70  (20.0):   4%|         | 70/2000 [06:16<2:53:24,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 71  (21.1):   4%|         | 71/2000 [06:22<2:53:32,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 15 / 72  (20.8):   4%|         | 72/2000 [06:27<2:53:11,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 16 / 73  (21.9):   4%|         | 73/2000 [06:32<2:53:10,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 16 / 74  (21.6):   4%|         | 74/2000 [06:38<2:53:17,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 17 / 75  (22.7):   4%|         | 75/2000 [06:43<2:52:56,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 18 / 76  (23.7):   4%|         | 76/2000 [06:49<2:53:11,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 18 / 77  (23.4):   4%|         | 77/2000 [06:54<2:52:56,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 18 / 78  (23.1):   4%|         | 78/2000 [06:59<2:52:47,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 79  (24.1):   4%|         | 79/2000 [07:05<2:52:51,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 80  (23.8):   4%|         | 80/2000 [07:10<2:52:34,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 81  (23.5):   4%|         | 81/2000 [07:16<2:52:30,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 82  (23.2):   4%|         | 82/2000 [07:21<2:52:13,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 19 / 83  (22.9):   4%|         | 83/2000 [07:26<2:52:20,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 84  (23.8):   4%|         | 84/2000 [07:32<2:52:03,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 85  (23.5):   4%|         | 85/2000 [07:37<2:51:46,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 86  (23.3):   4%|         | 86/2000 [07:43<2:51:51,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 87  (23.0):   4%|         | 87/2000 [07:48<2:51:43,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 88  (22.7):   4%|         | 88/2000 [07:53<2:51:42,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 89  (22.5):   4%|         | 89/2000 [07:59<2:51:21,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 20 / 90  (22.2):   4%|         | 90/2000 [08:04<2:51:27,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 21 / 91  (23.1):   5%|         | 91/2000 [08:09<2:51:16,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 21 / 92  (22.8):   5%|         | 92/2000 [08:15<2:51:02,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 22 / 93  (23.7):   5%|         | 93/2000 [08:20<2:51:00,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 22 / 94  (23.4):   5%|         | 94/2000 [08:26<2:51:04,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 23 / 95  (24.2):   5%|         | 95/2000 [08:31<2:51:05,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 23 / 96  (24.0):   5%|         | 96/2000 [08:37<2:54:37,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 23 / 97  (23.7):   5%|         | 97/2000 [08:42<2:53:31,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 98  (24.5):   5%|         | 98/2000 [08:48<2:52:45,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 99  (24.2):   5%|         | 99/2000 [08:53<2:52:05,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 24 / 100  (24.0):   5%|         | 100/2000 [08:58<2:51:56,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 25 / 101  (24.8):   5%|         | 101/2000 [09:04<2:51:41,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 102  (25.5):   5%|         | 102/2000 [09:09<2:51:34,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 103  (25.2):   5%|         | 103/2000 [09:15<2:54:40,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 104  (25.0):   5%|         | 104/2000 [09:20<2:53:22,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 105  (24.8):   5%|         | 105/2000 [09:26<2:52:19,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 106  (24.5):   5%|         | 106/2000 [09:31<2:51:54,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 107  (24.3):   5%|         | 107/2000 [09:37<2:51:15,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 26 / 108  (24.1):   5%|         | 108/2000 [09:42<2:50:54,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 109  (24.8):   5%|         | 109/2000 [09:47<2:50:45,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 110  (24.5):   6%|         | 110/2000 [09:53<2:50:18,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 111  (24.3):   6%|         | 111/2000 [09:58<2:50:26,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 112  (24.1):   6%|         | 112/2000 [10:04<2:50:05,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 113  (23.9):   6%|         | 113/2000 [10:09<2:50:05,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 114  (23.7):   6%|         | 114/2000 [10:14<2:49:52,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 27 / 115  (23.5):   6%|         | 115/2000 [10:20<2:49:39,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 28 / 116  (24.1):   6%|         | 116/2000 [10:25<2:49:39,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 117  (24.8):   6%|         | 117/2000 [10:31<2:49:33,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 118  (24.6):   6%|         | 118/2000 [10:36<2:49:29,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 119  (24.4):   6%|         | 119/2000 [10:41<2:49:19,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 120  (24.2):   6%|         | 120/2000 [10:47<2:49:10,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 29 / 121  (24.0):   6%|         | 121/2000 [10:52<2:49:15,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 122  (24.6):   6%|         | 122/2000 [10:58<2:49:18,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 123  (24.4):   6%|         | 123/2000 [11:03<2:51:34,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 124  (24.2):   6%|         | 124/2000 [11:09<2:50:50,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 30 / 125  (24.0):   6%|         | 125/2000 [11:14<2:49:51,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 126  (24.6):   6%|         | 126/2000 [11:19<2:49:19,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 127  (24.4):   6%|         | 127/2000 [11:25<2:48:46,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 128  (24.2):   6%|         | 128/2000 [11:30<2:48:14,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 129  (24.0):   6%|         | 129/2000 [11:36<2:47:57,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 130  (23.8):   6%|         | 130/2000 [11:41<2:47:47,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 131  (23.7):   7%|         | 131/2000 [11:46<2:47:19,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 132  (23.5):   7%|         | 132/2000 [11:52<2:47:01,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 31 / 133  (23.3):   7%|         | 133/2000 [11:57<2:46:53,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 32 / 134  (23.9):   7%|         | 134/2000 [12:02<2:46:37,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 33 / 135  (24.4):   7%|         | 135/2000 [12:08<2:46:28,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 34 / 136  (25.0):   7%|         | 136/2000 [12:13<2:46:21,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 35 / 137  (25.5):   7%|         | 137/2000 [12:18<2:46:08,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 36 / 138  (26.1):   7%|         | 138/2000 [12:24<2:46:00,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 36 / 139  (25.9):   7%|         | 139/2000 [12:29<2:45:53,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 140  (26.4):   7%|         | 140/2000 [12:34<2:45:49,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 37 / 141  (26.2):   7%|         | 141/2000 [12:40<2:45:53,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 38 / 142  (26.8):   7%|         | 142/2000 [12:45<2:45:48,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 38 / 143  (26.6):   7%|         | 143/2000 [12:50<2:45:51,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 144  (27.1):   7%|         | 144/2000 [12:56<2:45:46,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 145  (26.9):   7%|         | 145/2000 [13:01<2:45:40,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 146  (26.7):   7%|         | 146/2000 [13:07<2:45:43,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 147  (26.5):   7%|         | 147/2000 [13:12<2:45:36,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 148  (26.4):   7%|         | 148/2000 [13:17<2:45:29,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 149  (26.2):   7%|         | 149/2000 [13:23<2:45:18,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 150  (26.0):   8%|         | 150/2000 [13:28<2:45:07,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 151  (25.8):   8%|         | 151/2000 [13:33<2:45:01,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 152  (25.7):   8%|         | 152/2000 [13:39<2:44:52,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 39 / 153  (25.5):   8%|         | 153/2000 [13:44<2:44:50,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 40 / 154  (26.0):   8%|         | 154/2000 [13:49<2:44:51,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 155  (26.5):   8%|         | 155/2000 [13:55<2:44:47,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 156  (26.3):   8%|         | 156/2000 [14:00<2:44:39,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 157  (26.1):   8%|         | 157/2000 [14:06<2:44:52,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 158  (25.9):   8%|         | 158/2000 [14:11<2:44:46,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 41 / 159  (25.8):   8%|         | 159/2000 [14:16<2:44:39,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 160  (26.2):   8%|         | 160/2000 [14:22<2:44:34,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 161  (26.1):   8%|         | 161/2000 [14:27<2:44:34,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 162  (25.9):   8%|         | 162/2000 [14:32<2:44:22,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 163  (25.8):   8%|         | 163/2000 [14:38<2:44:16,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 164  (25.6):   8%|         | 164/2000 [14:43<2:44:06,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 165  (25.5):   8%|         | 165/2000 [14:48<2:43:54,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 166  (25.3):   8%|         | 166/2000 [14:54<2:43:55,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 167  (25.1):   8%|         | 167/2000 [14:59<2:44:11,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 168  (25.0):   8%|         | 168/2000 [15:05<2:44:11,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 169  (24.9):   8%|         | 169/2000 [15:10<2:44:06,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 170  (24.7):   8%|         | 170/2000 [15:15<2:43:54,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 171  (24.6):   9%|         | 171/2000 [15:21<2:43:48,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 172  (24.4):   9%|         | 172/2000 [15:26<2:43:52,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 173  (24.3):   9%|         | 173/2000 [15:31<2:43:39,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 174  (24.1):   9%|         | 174/2000 [15:37<2:43:29,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 175  (24.0):   9%|         | 175/2000 [15:42<2:43:20,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 176  (23.9):   9%|         | 176/2000 [15:48<2:43:29,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 177  (23.7):   9%|         | 177/2000 [15:53<2:43:22,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 178  (23.6):   9%|         | 178/2000 [15:58<2:43:25,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 179  (23.5):   9%|         | 179/2000 [16:04<2:43:16,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 42 / 180  (23.3):   9%|         | 180/2000 [16:09<2:43:16,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 43 / 181  (23.8):   9%|         | 181/2000 [16:15<2:43:17,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 43 / 182  (23.6):   9%|         | 182/2000 [16:20<2:43:12,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 183  (24.0):   9%|         | 183/2000 [16:25<2:43:03,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 184  (23.9):   9%|         | 184/2000 [16:31<2:42:51,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 185  (23.8):   9%|         | 185/2000 [16:36<2:43:01,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 186  (23.7):   9%|         | 186/2000 [16:41<2:42:59,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 187  (23.5):   9%|         | 187/2000 [16:47<2:42:56,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 44 / 188  (23.4):   9%|         | 188/2000 [16:52<2:42:45,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 45 / 189  (23.8):   9%|         | 189/2000 [16:58<2:42:40,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 46 / 190  (24.2):  10%|         | 190/2000 [17:03<2:42:49,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 47 / 191  (24.6):  10%|         | 191/2000 [17:08<2:42:44,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 47 / 192  (24.5):  10%|         | 192/2000 [17:14<2:42:35,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 48 / 193  (24.9):  10%|         | 193/2000 [17:19<2:42:32,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 48 / 194  (24.7):  10%|         | 194/2000 [17:25<2:42:25,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 48 / 195  (24.6):  10%|         | 195/2000 [17:30<2:42:22,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 196  (25.0):  10%|         | 196/2000 [17:35<2:42:20,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 197  (24.9):  10%|         | 197/2000 [17:41<2:42:04,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 198  (24.7):  10%|         | 198/2000 [17:46<2:41:55,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 199  (24.6):  10%|         | 199/2000 [17:52<2:41:54,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 49 / 200  (24.5):  10%|         | 200/2000 [17:57<2:41:34,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 201  (24.9):  10%|         | 201/2000 [18:02<2:41:31,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 202  (24.8):  10%|         | 202/2000 [18:08<2:41:26,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 50 / 203  (24.6):  10%|         | 203/2000 [18:13<2:41:14,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 204  (25.0):  10%|         | 204/2000 [18:19<2:41:20,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 205  (24.9):  10%|         | 205/2000 [18:24<2:41:01,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 206  (24.8):  10%|         | 206/2000 [18:29<2:41:01,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 207  (24.6):  10%|         | 207/2000 [18:35<2:40:49,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 51 / 208  (24.5):  10%|         | 208/2000 [18:40<2:40:36,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 52 / 209  (24.9):  10%|         | 209/2000 [18:45<2:40:39,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 52 / 210  (24.8):  10%|         | 210/2000 [18:51<2:40:24,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 211  (25.1):  11%|         | 211/2000 [18:56<2:40:19,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 212  (25.0):  11%|         | 212/2000 [19:02<2:40:07,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 213  (24.9):  11%|         | 213/2000 [19:07<2:40:03,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 214  (24.8):  11%|         | 214/2000 [19:12<2:40:18,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 215  (24.7):  11%|         | 215/2000 [19:18<2:40:10,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 216  (24.5):  11%|         | 216/2000 [19:23<2:39:49,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 53 / 217  (24.4):  11%|         | 217/2000 [19:28<2:39:54,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 218  (24.8):  11%|         | 218/2000 [19:34<2:39:53,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 219  (24.7):  11%|         | 219/2000 [19:39<2:39:58,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 54 / 220  (24.5):  11%|         | 220/2000 [19:45<2:39:45,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 221  (24.9):  11%|         | 221/2000 [19:50<2:39:37,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 55 / 222  (24.8):  11%|         | 222/2000 [19:55<2:39:26,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 223  (25.1):  11%|         | 223/2000 [20:01<2:39:35,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 224  (25.0):  11%|         | 224/2000 [20:06<2:39:46,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 225  (24.9):  11%|        | 225/2000 [20:12<2:39:32,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 226  (24.8):  11%|        | 226/2000 [20:17<2:39:21,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 227  (24.7):  11%|        | 227/2000 [20:22<2:39:23,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 228  (24.6):  11%|        | 228/2000 [20:28<2:39:07,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 56 / 229  (24.5):  11%|        | 229/2000 [20:33<2:39:14,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 230  (24.8):  12%|        | 230/2000 [20:39<2:39:01,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 231  (24.7):  12%|        | 231/2000 [20:44<2:38:59,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 57 / 232  (24.6):  12%|        | 232/2000 [20:49<2:39:15,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 58 / 233  (24.9):  12%|        | 233/2000 [20:55<2:38:56,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 234  (25.2):  12%|        | 234/2000 [21:00<2:39:07,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 59 / 235  (25.1):  12%|        | 235/2000 [21:06<2:38:54,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 236  (25.4):  12%|        | 236/2000 [21:11<2:38:36,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 237  (25.3):  12%|        | 237/2000 [21:16<2:38:34,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 238  (25.2):  12%|        | 238/2000 [21:22<2:38:24,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 239  (25.1):  12%|        | 239/2000 [21:27<2:38:31,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 60 / 240  (25.0):  12%|        | 240/2000 [21:33<2:38:17,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 241  (25.3):  12%|        | 241/2000 [21:38<2:38:06,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 242  (25.2):  12%|        | 242/2000 [21:43<2:38:04,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 243  (25.1):  12%|        | 243/2000 [21:49<2:37:52,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 244  (25.0):  12%|        | 244/2000 [21:54<2:38:12,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 245  (24.9):  12%|        | 245/2000 [22:00<2:38:02,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 246  (24.8):  12%|        | 246/2000 [22:05<2:37:48,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 247  (24.7):  12%|        | 247/2000 [22:10<2:38:07,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 61 / 248  (24.6):  12%|        | 248/2000 [22:16<2:37:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 62 / 249  (24.9):  12%|        | 249/2000 [22:21<2:37:44,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 62 / 250  (24.8):  12%|        | 250/2000 [22:27<2:37:26,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 62 / 251  (24.7):  13%|        | 251/2000 [22:32<2:37:22,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 62 / 252  (24.6):  13%|        | 252/2000 [22:37<2:37:19,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 62 / 253  (24.5):  13%|        | 253/2000 [22:43<2:37:00,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 254  (24.8):  13%|        | 254/2000 [22:48<2:36:41,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 255  (24.7):  13%|        | 255/2000 [22:53<2:36:41,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 256  (24.6):  13%|        | 256/2000 [22:59<2:36:56,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 63 / 257  (24.5):  13%|        | 257/2000 [23:04<2:37:11,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 64 / 258  (24.8):  13%|        | 258/2000 [23:10<2:37:57,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 259  (25.1):  13%|        | 259/2000 [23:15<2:38:45,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 260  (25.0):  13%|        | 260/2000 [23:21<2:37:43,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 261  (24.9):  13%|        | 261/2000 [23:26<2:37:13,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 262  (24.8):  13%|        | 262/2000 [23:32<2:36:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 263  (24.7):  13%|        | 263/2000 [23:37<2:36:38,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 264  (24.6):  13%|        | 264/2000 [23:42<2:36:21,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 265  (24.5):  13%|        | 265/2000 [23:48<2:36:11,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 266  (24.4):  13%|        | 266/2000 [23:53<2:36:03,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 65 / 267  (24.3):  13%|        | 267/2000 [23:59<2:36:04,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 66 / 268  (24.6):  13%|        | 268/2000 [24:04<2:35:52,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 67 / 269  (24.9):  13%|        | 269/2000 [24:09<2:35:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 68 / 270  (25.2):  14%|        | 270/2000 [24:15<2:35:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 69 / 271  (25.5):  14%|        | 271/2000 [24:20<2:35:42,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 69 / 272  (25.4):  14%|        | 272/2000 [24:26<2:35:33,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 69 / 273  (25.3):  14%|        | 273/2000 [24:31<2:35:24,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 69 / 274  (25.2):  14%|        | 274/2000 [24:36<2:35:14,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 69 / 275  (25.1):  14%|        | 275/2000 [24:42<2:35:16,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 69 / 276  (25.0):  14%|        | 276/2000 [24:47<2:35:06,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 70 / 277  (25.3):  14%|        | 277/2000 [24:53<2:34:58,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 70 / 278  (25.2):  14%|        | 278/2000 [24:58<2:34:51,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 71 / 279  (25.4):  14%|        | 279/2000 [25:03<2:34:52,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 72 / 280  (25.7):  14%|        | 280/2000 [25:09<2:38:44,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 72 / 281  (25.6):  14%|        | 281/2000 [25:15<2:40:58,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 72 / 282  (25.5):  14%|        | 282/2000 [25:21<2:41:01,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 73 / 283  (25.8):  14%|        | 283/2000 [25:26<2:38:14,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 73 / 284  (25.7):  14%|        | 284/2000 [25:31<2:36:49,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 74 / 285  (26.0):  14%|        | 285/2000 [25:37<2:35:55,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 74 / 286  (25.9):  14%|        | 286/2000 [25:42<2:35:26,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 74 / 287  (25.8):  14%|        | 287/2000 [25:48<2:35:08,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 74 / 288  (25.7):  14%|        | 288/2000 [25:53<2:34:40,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 289  (26.0):  14%|        | 289/2000 [25:58<2:34:15,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 290  (25.9):  14%|        | 290/2000 [26:04<2:34:03,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 75 / 291  (25.8):  15%|        | 291/2000 [26:09<2:34:04,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 76 / 292  (26.0):  15%|        | 292/2000 [26:15<2:33:55,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 76 / 293  (25.9):  15%|        | 293/2000 [26:20<2:33:49,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 294  (26.2):  15%|        | 294/2000 [26:25<2:33:37,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 295  (26.1):  15%|        | 295/2000 [26:31<2:33:36,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 296  (26.0):  15%|        | 296/2000 [26:36<2:33:37,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 297  (25.9):  15%|        | 297/2000 [26:42<2:33:31,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 298  (25.8):  15%|        | 298/2000 [26:47<2:33:19,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 299  (25.8):  15%|        | 299/2000 [26:52<2:33:13,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 77 / 300  (25.7):  15%|        | 300/2000 [26:58<2:33:11,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 78 / 301  (25.9):  15%|        | 301/2000 [27:03<2:33:08,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 78 / 302  (25.8):  15%|        | 302/2000 [27:09<2:33:00,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 303  (26.1):  15%|        | 303/2000 [27:14<2:32:52,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 304  (26.0):  15%|        | 304/2000 [27:19<2:32:41,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 305  (25.9):  15%|        | 305/2000 [27:25<2:32:44,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 306  (25.8):  15%|        | 306/2000 [27:30<2:32:35,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 307  (25.7):  15%|        | 307/2000 [27:36<2:32:29,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 308  (25.6):  15%|        | 308/2000 [27:41<2:32:25,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 79 / 309  (25.6):  15%|        | 309/2000 [27:46<2:32:26,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 80 / 310  (25.8):  16%|        | 310/2000 [27:52<2:32:17,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 80 / 311  (25.7):  16%|        | 311/2000 [27:57<2:32:06,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 81 / 312  (26.0):  16%|        | 312/2000 [28:03<2:31:54,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 82 / 313  (26.2):  16%|        | 313/2000 [28:08<2:32:02,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 82 / 314  (26.1):  16%|        | 314/2000 [28:13<2:31:55,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 83 / 315  (26.3):  16%|        | 315/2000 [28:19<2:31:53,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 83 / 316  (26.3):  16%|        | 316/2000 [28:24<2:31:53,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 83 / 317  (26.2):  16%|        | 317/2000 [28:30<2:31:46,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 83 / 318  (26.1):  16%|        | 318/2000 [28:35<2:31:43,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 83 / 319  (26.0):  16%|        | 319/2000 [28:41<2:31:37,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 320  (26.2):  16%|        | 320/2000 [28:46<2:31:20,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 321  (26.2):  16%|        | 321/2000 [28:51<2:31:14,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 322  (26.1):  16%|        | 322/2000 [28:57<2:31:09,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 323  (26.0):  16%|        | 323/2000 [29:02<2:30:57,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 324  (25.9):  16%|        | 324/2000 [29:07<2:30:51,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 325  (25.8):  16%|        | 325/2000 [29:13<2:30:40,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 326  (25.8):  16%|        | 326/2000 [29:18<2:30:33,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 327  (25.7):  16%|        | 327/2000 [29:24<2:30:34,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 84 / 328  (25.6):  16%|        | 328/2000 [29:29<2:30:36,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 85 / 329  (25.8):  16%|        | 329/2000 [29:34<2:30:22,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 85 / 330  (25.8):  16%|        | 330/2000 [29:40<2:30:15,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 331  (26.0):  17%|        | 331/2000 [29:45<2:30:13,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 332  (25.9):  17%|        | 332/2000 [29:51<2:30:12,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 86 / 333  (25.8):  17%|        | 333/2000 [29:56<2:30:13,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 334  (26.0):  17%|        | 334/2000 [30:02<2:30:16,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 335  (26.0):  17%|        | 335/2000 [30:07<2:30:06,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 87 / 336  (25.9):  17%|        | 336/2000 [30:12<2:30:08,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 337  (26.1):  17%|        | 337/2000 [30:18<2:29:59,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 88 / 338  (26.0):  17%|        | 338/2000 [30:23<2:29:48,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 339  (26.3):  17%|        | 339/2000 [30:29<2:29:39,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 340  (26.2):  17%|        | 340/2000 [30:34<2:29:33,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 341  (26.1):  17%|        | 341/2000 [30:39<2:29:35,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 342  (26.0):  17%|        | 342/2000 [30:45<2:29:24,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 89 / 343  (25.9):  17%|        | 343/2000 [30:50<2:29:15,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 344  (26.2):  17%|        | 344/2000 [30:56<2:29:03,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 345  (26.1):  17%|        | 345/2000 [31:01<2:28:50,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 346  (26.0):  17%|        | 346/2000 [31:06<2:28:54,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 347  (25.9):  17%|        | 347/2000 [31:12<2:28:51,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 348  (25.9):  17%|        | 348/2000 [31:17<2:28:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 349  (25.8):  17%|        | 349/2000 [31:23<2:28:48,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 90 / 350  (25.7):  18%|        | 350/2000 [31:28<2:28:48,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 351  (25.9):  18%|        | 351/2000 [31:33<2:28:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 352  (25.9):  18%|        | 352/2000 [31:39<2:28:29,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 353  (25.8):  18%|        | 353/2000 [31:44<2:28:26,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 354  (25.7):  18%|        | 354/2000 [31:50<2:28:22,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 91 / 355  (25.6):  18%|        | 355/2000 [31:55<2:28:09,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 92 / 356  (25.8):  18%|        | 356/2000 [32:00<2:28:04,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 92 / 357  (25.8):  18%|        | 357/2000 [32:06<2:27:54,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 358  (26.0):  18%|        | 358/2000 [32:11<2:27:42,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 359  (25.9):  18%|        | 359/2000 [32:17<2:27:47,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 93 / 360  (25.8):  18%|        | 360/2000 [32:22<2:27:53,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 361  (26.0):  18%|        | 361/2000 [32:27<2:27:39,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 94 / 362  (26.0):  18%|        | 362/2000 [32:33<2:27:33,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 95 / 363  (26.2):  18%|        | 363/2000 [32:38<2:27:29,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 96 / 364  (26.4):  18%|        | 364/2000 [32:44<2:27:13,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 96 / 365  (26.3):  18%|        | 365/2000 [32:49<2:27:02,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 366  (26.5):  18%|        | 366/2000 [32:54<2:26:44,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 367  (26.4):  18%|        | 367/2000 [33:00<2:26:28,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 368  (26.4):  18%|        | 368/2000 [33:05<2:26:12,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 97 / 369  (26.3):  18%|        | 369/2000 [33:11<2:26:02,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 98 / 370  (26.5):  18%|        | 370/2000 [33:16<2:25:54,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 98 / 371  (26.4):  19%|        | 371/2000 [33:21<2:25:55,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 98 / 372  (26.3):  19%|        | 372/2000 [33:27<2:25:51,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 373  (26.5):  19%|        | 373/2000 [33:32<2:26:03,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 374  (26.5):  19%|        | 374/2000 [33:37<2:25:23,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 375  (26.4):  19%|        | 375/2000 [33:43<2:24:56,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 376  (26.3):  19%|        | 376/2000 [33:48<2:24:40,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 377  (26.3):  19%|        | 377/2000 [33:53<2:24:26,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 378  (26.2):  19%|        | 378/2000 [33:59<2:24:28,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 379  (26.1):  19%|        | 379/2000 [34:04<2:24:22,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 380  (26.1):  19%|        | 380/2000 [34:09<2:24:12,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 381  (26.0):  19%|        | 381/2000 [34:15<2:24:02,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 382  (25.9):  19%|        | 382/2000 [34:20<2:24:07,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 383  (25.8):  19%|        | 383/2000 [34:25<2:23:58,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 384  (25.8):  19%|        | 384/2000 [34:31<2:23:48,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 385  (25.7):  19%|        | 385/2000 [34:36<2:23:45,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 386  (25.6):  19%|        | 386/2000 [34:41<2:23:42,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 387  (25.6):  19%|        | 387/2000 [34:47<2:23:33,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 388  (25.5):  19%|        | 388/2000 [34:52<2:23:24,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 389  (25.4):  19%|        | 389/2000 [34:57<2:23:16,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 99 / 390  (25.4):  20%|        | 390/2000 [35:03<2:23:15,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 391  (25.6):  20%|        | 391/2000 [35:08<2:23:10,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 392  (25.5):  20%|        | 392/2000 [35:13<2:23:07,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 393  (25.4):  20%|        | 393/2000 [35:19<2:23:04,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 394  (25.4):  20%|        | 394/2000 [35:24<2:23:00,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 395  (25.3):  20%|        | 395/2000 [35:30<2:22:56,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 396  (25.3):  20%|        | 396/2000 [35:35<2:22:50,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 397  (25.2):  20%|        | 397/2000 [35:40<2:22:41,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 100 / 398  (25.1):  20%|        | 398/2000 [35:46<2:22:34,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 399  (25.3):  20%|        | 399/2000 [35:51<2:22:32,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 400  (25.2):  20%|        | 400/2000 [35:56<2:22:28,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 101 / 401  (25.2):  20%|        | 401/2000 [36:02<2:22:22,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 102 / 402  (25.4):  20%|        | 402/2000 [36:07<2:22:17,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 102 / 403  (25.3):  20%|        | 403/2000 [36:12<2:22:20,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 103 / 404  (25.5):  20%|        | 404/2000 [36:18<2:22:20,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 405  (25.7):  20%|        | 405/2000 [36:23<2:22:18,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 406  (25.6):  20%|        | 406/2000 [36:28<2:22:12,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 407  (25.6):  20%|        | 407/2000 [36:34<2:21:59,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 408  (25.5):  20%|        | 408/2000 [36:39<2:21:50,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 409  (25.4):  20%|        | 409/2000 [36:44<2:21:50,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 410  (25.4):  20%|        | 410/2000 [36:50<2:23:15,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 104 / 411  (25.3):  21%|        | 411/2000 [36:55<2:22:53,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 412  (25.5):  21%|        | 412/2000 [37:01<2:22:24,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 413  (25.4):  21%|        | 413/2000 [37:06<2:24:24,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 414  (25.4):  21%|        | 414/2000 [37:12<2:26:01,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 415  (25.3):  21%|        | 415/2000 [37:18<2:28:39,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 105 / 416  (25.2):  21%|        | 416/2000 [37:23<2:28:15,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 417  (25.4):  21%|        | 417/2000 [37:29<2:28:24,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 418  (25.4):  21%|        | 418/2000 [37:35<2:27:40,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 419  (25.3):  21%|        | 419/2000 [37:40<2:29:11,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 420  (25.2):  21%|        | 420/2000 [37:46<2:29:07,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 421  (25.2):  21%|        | 421/2000 [37:52<2:28:13,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 106 / 422  (25.1):  21%|        | 422/2000 [37:57<2:25:21,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 423  (25.3):  21%|        | 423/2000 [38:02<2:23:22,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 424  (25.2):  21%|        | 424/2000 [38:07<2:22:02,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 425  (25.2):  21%|       | 425/2000 [38:13<2:21:06,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 426  (25.1):  21%|       | 426/2000 [38:18<2:20:46,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 427  (25.1):  21%|       | 427/2000 [38:23<2:20:08,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 428  (25.0):  21%|       | 428/2000 [38:29<2:19:47,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 429  (24.9):  21%|       | 429/2000 [38:34<2:19:32,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 107 / 430  (24.9):  22%|       | 430/2000 [38:39<2:19:26,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 108 / 431  (25.1):  22%|       | 431/2000 [38:45<2:19:25,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 432  (25.2):  22%|       | 432/2000 [38:50<2:19:20,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 433  (25.2):  22%|       | 433/2000 [38:55<2:19:48,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 434  (25.1):  22%|       | 434/2000 [39:01<2:19:58,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 435  (25.1):  22%|       | 435/2000 [39:06<2:20:17,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 436  (25.0):  22%|       | 436/2000 [39:12<2:20:37,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 437  (24.9):  22%|       | 437/2000 [39:17<2:20:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 438  (24.9):  22%|       | 438/2000 [39:23<2:20:41,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 109 / 439  (24.8):  22%|       | 439/2000 [39:28<2:20:41,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 440  (25.0):  22%|       | 440/2000 [39:33<2:20:38,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 441  (24.9):  22%|       | 441/2000 [39:39<2:20:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 442  (24.9):  22%|       | 442/2000 [39:44<2:20:39,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 443  (24.8):  22%|       | 443/2000 [39:50<2:20:25,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 444  (24.8):  22%|       | 444/2000 [39:55<2:20:15,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 445  (24.7):  22%|       | 445/2000 [40:00<2:20:11,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 446  (24.7):  22%|       | 446/2000 [40:06<2:20:14,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 447  (24.6):  22%|       | 447/2000 [40:11<2:20:04,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 448  (24.6):  22%|       | 448/2000 [40:17<2:19:54,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 110 / 449  (24.5):  22%|       | 449/2000 [40:22<2:19:47,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 111 / 450  (24.7):  22%|       | 450/2000 [40:27<2:19:35,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 111 / 451  (24.6):  23%|       | 451/2000 [40:33<2:19:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 111 / 452  (24.6):  23%|       | 452/2000 [40:38<2:19:32,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 112 / 453  (24.7):  23%|       | 453/2000 [40:44<2:19:18,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 112 / 454  (24.7):  23%|       | 454/2000 [40:49<2:19:17,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 113 / 455  (24.8):  23%|       | 455/2000 [40:54<2:19:06,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 113 / 456  (24.8):  23%|       | 456/2000 [41:00<2:19:15,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 113 / 457  (24.7):  23%|       | 457/2000 [41:05<2:19:11,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 114 / 458  (24.9):  23%|       | 458/2000 [41:11<2:19:14,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 459  (25.1):  23%|       | 459/2000 [41:16<2:19:18,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 460  (25.0):  23%|       | 460/2000 [41:22<2:19:06,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 461  (24.9):  23%|       | 461/2000 [41:27<2:19:07,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 462  (24.9):  23%|       | 462/2000 [41:32<2:18:54,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 463  (24.8):  23%|       | 463/2000 [41:38<2:18:51,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 464  (24.8):  23%|       | 464/2000 [41:43<2:18:41,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 115 / 465  (24.7):  23%|       | 465/2000 [41:49<2:18:41,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 116 / 466  (24.9):  23%|       | 466/2000 [41:54<2:18:31,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 467  (25.1):  23%|       | 467/2000 [41:59<2:18:17,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 468  (25.0):  23%|       | 468/2000 [42:05<2:18:14,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 469  (24.9):  23%|       | 469/2000 [42:10<2:18:01,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 470  (24.9):  24%|       | 470/2000 [42:16<2:17:58,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 471  (24.8):  24%|       | 471/2000 [42:21<2:17:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 472  (24.8):  24%|       | 472/2000 [42:27<2:17:47,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 473  (24.7):  24%|       | 473/2000 [42:32<2:17:43,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 117 / 474  (24.7):  24%|       | 474/2000 [42:37<2:17:51,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 475  (24.8):  24%|       | 475/2000 [42:43<2:17:43,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 118 / 476  (24.8):  24%|       | 476/2000 [42:48<2:17:41,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 477  (24.9):  24%|       | 477/2000 [42:54<2:17:37,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 478  (24.9):  24%|       | 478/2000 [42:59<2:17:26,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 479  (24.8):  24%|       | 479/2000 [43:04<2:17:22,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 480  (24.8):  24%|       | 480/2000 [43:10<2:17:07,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 119 / 481  (24.7):  24%|       | 481/2000 [43:15<2:17:06,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 482  (24.9):  24%|       | 482/2000 [43:21<2:16:51,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 483  (24.8):  24%|       | 483/2000 [43:26<2:16:39,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 484  (24.8):  24%|       | 484/2000 [43:32<2:16:45,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 485  (24.7):  24%|       | 485/2000 [43:37<2:16:30,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 120 / 486  (24.7):  24%|       | 486/2000 [43:42<2:16:27,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 121 / 487  (24.8):  24%|       | 487/2000 [43:48<2:16:18,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 121 / 488  (24.8):  24%|       | 488/2000 [43:53<2:16:13,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 121 / 489  (24.7):  24%|       | 489/2000 [43:59<2:16:08,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 122 / 490  (24.9):  24%|       | 490/2000 [44:04<2:16:21,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 123 / 491  (25.1):  25%|       | 491/2000 [44:09<2:16:10,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 124 / 492  (25.2):  25%|       | 492/2000 [44:15<2:16:02,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 124 / 493  (25.2):  25%|       | 493/2000 [44:20<2:15:56,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 494  (25.3):  25%|       | 494/2000 [44:26<2:16:40,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 495  (25.3):  25%|       | 495/2000 [44:31<2:16:17,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 496  (25.2):  25%|       | 496/2000 [44:37<2:15:57,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 497  (25.2):  25%|       | 497/2000 [44:42<2:15:44,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 125 / 498  (25.1):  25%|       | 498/2000 [44:47<2:15:34,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 499  (25.3):  25%|       | 499/2000 [44:53<2:15:39,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 500  (25.2):  25%|       | 500/2000 [44:58<2:15:51,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 501  (25.1):  25%|       | 501/2000 [45:04<2:15:51,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 126 / 502  (25.1):  25%|       | 502/2000 [45:09<2:15:40,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 127 / 503  (25.2):  25%|       | 503/2000 [45:15<2:15:39,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 504  (25.4):  25%|       | 504/2000 [45:20<2:15:44,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 128 / 505  (25.3):  25%|       | 505/2000 [45:25<2:15:37,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 129 / 506  (25.5):  25%|       | 506/2000 [45:31<2:15:34,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 507  (25.6):  25%|       | 507/2000 [45:36<2:15:30,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 508  (25.6):  25%|       | 508/2000 [45:42<2:15:22,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 509  (25.5):  25%|       | 509/2000 [45:47<2:15:19,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 510  (25.5):  26%|       | 510/2000 [45:53<2:15:10,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 511  (25.4):  26%|       | 511/2000 [45:58<2:14:59,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 512  (25.4):  26%|       | 512/2000 [46:04<2:14:53,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 513  (25.3):  26%|       | 513/2000 [46:09<2:14:43,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 514  (25.3):  26%|       | 514/2000 [46:14<2:14:37,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 515  (25.2):  26%|       | 515/2000 [46:20<2:14:33,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 516  (25.2):  26%|       | 516/2000 [46:25<2:14:27,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 130 / 517  (25.1):  26%|       | 517/2000 [46:31<2:14:21,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 518  (25.3):  26%|       | 518/2000 [46:36<2:14:19,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 519  (25.2):  26%|       | 519/2000 [46:42<2:14:14,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 520  (25.2):  26%|       | 520/2000 [46:47<2:14:07,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 521  (25.1):  26%|       | 521/2000 [46:53<2:14:05,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 522  (25.1):  26%|       | 522/2000 [46:58<2:13:58,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 131 / 523  (25.0):  26%|       | 523/2000 [47:03<2:13:51,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 132 / 524  (25.2):  26%|       | 524/2000 [47:09<2:13:48,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 132 / 525  (25.1):  26%|       | 525/2000 [47:14<2:13:45,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 132 / 526  (25.1):  26%|       | 526/2000 [47:20<2:13:44,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 133 / 527  (25.2):  26%|       | 527/2000 [47:25<2:13:40,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 133 / 528  (25.2):  26%|       | 528/2000 [47:31<2:13:31,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 529  (25.3):  26%|       | 529/2000 [47:36<2:13:26,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 530  (25.3):  26%|       | 530/2000 [47:42<2:13:26,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 531  (25.2):  27%|       | 531/2000 [47:47<2:13:27,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 532  (25.2):  27%|       | 532/2000 [47:52<2:13:18,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 533  (25.1):  27%|       | 533/2000 [47:58<2:13:16,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 534  (25.1):  27%|       | 534/2000 [48:03<2:13:08,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 134 / 535  (25.0):  27%|       | 535/2000 [48:09<2:12:57,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 135 / 536  (25.2):  27%|       | 536/2000 [48:14<2:12:53,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 136 / 537  (25.3):  27%|       | 537/2000 [48:20<2:12:46,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 137 / 538  (25.5):  27%|       | 538/2000 [48:25<2:12:53,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 138 / 539  (25.6):  27%|       | 539/2000 [48:31<2:12:47,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 138 / 540  (25.6):  27%|       | 540/2000 [48:36<2:12:40,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 139 / 541  (25.7):  27%|       | 541/2000 [48:41<2:12:32,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 140 / 542  (25.8):  27%|       | 542/2000 [48:47<2:12:29,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 140 / 543  (25.8):  27%|       | 543/2000 [48:52<2:12:17,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 544  (25.9):  27%|       | 544/2000 [48:58<2:12:05,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 545  (25.9):  27%|       | 545/2000 [49:03<2:12:07,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 546  (25.8):  27%|       | 546/2000 [49:09<2:12:10,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 547  (25.8):  27%|       | 547/2000 [49:14<2:12:12,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 141 / 548  (25.7):  27%|       | 548/2000 [49:20<2:11:55,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 142 / 549  (25.9):  27%|       | 549/2000 [49:25<2:11:48,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 142 / 550  (25.8):  28%|       | 550/2000 [49:31<2:11:39,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 142 / 551  (25.8):  28%|       | 551/2000 [49:36<2:11:32,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 552  (25.9):  28%|       | 552/2000 [49:41<2:11:32,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 553  (25.9):  28%|       | 553/2000 [49:47<2:11:33,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 554  (25.8):  28%|       | 554/2000 [49:52<2:11:24,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 143 / 555  (25.8):  28%|       | 555/2000 [49:58<2:11:23,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 144 / 556  (25.9):  28%|       | 556/2000 [50:03<2:11:20,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 145 / 557  (26.0):  28%|       | 557/2000 [50:09<2:11:02,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 146 / 558  (26.2):  28%|       | 558/2000 [50:14<2:11:12,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 146 / 559  (26.1):  28%|       | 559/2000 [50:20<2:11:14,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 147 / 560  (26.2):  28%|       | 560/2000 [50:25<2:11:03,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 147 / 561  (26.2):  28%|       | 561/2000 [50:31<2:10:56,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 147 / 562  (26.2):  28%|       | 562/2000 [50:36<2:10:55,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 563  (26.3):  28%|       | 563/2000 [50:41<2:10:39,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 564  (26.2):  28%|       | 564/2000 [50:47<2:10:32,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 565  (26.2):  28%|       | 565/2000 [50:52<2:10:27,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 566  (26.1):  28%|       | 566/2000 [50:58<2:10:13,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 148 / 567  (26.1):  28%|       | 567/2000 [51:03<2:10:06,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 149 / 568  (26.2):  28%|       | 568/2000 [51:09<2:10:05,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 149 / 569  (26.2):  28%|       | 569/2000 [51:14<2:09:56,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 149 / 570  (26.1):  28%|       | 570/2000 [51:20<2:09:54,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 150 / 571  (26.3):  29%|       | 571/2000 [51:25<2:09:51,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 150 / 572  (26.2):  29%|       | 572/2000 [51:30<2:09:40,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 573  (26.4):  29%|       | 573/2000 [51:36<2:09:30,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 574  (26.3):  29%|       | 574/2000 [51:41<2:09:27,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 575  (26.3):  29%|       | 575/2000 [51:47<2:09:27,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 576  (26.2):  29%|       | 576/2000 [51:52<2:09:17,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 151 / 577  (26.2):  29%|       | 577/2000 [51:58<2:09:19,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 578  (26.3):  29%|       | 578/2000 [52:03<2:09:15,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 579  (26.3):  29%|       | 579/2000 [52:09<2:09:03,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 580  (26.2):  29%|       | 580/2000 [52:14<2:09:06,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 581  (26.2):  29%|       | 581/2000 [52:20<2:09:00,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 582  (26.1):  29%|       | 582/2000 [52:25<2:08:45,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 152 / 583  (26.1):  29%|       | 583/2000 [52:30<2:08:39,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 584  (26.2):  29%|       | 584/2000 [52:36<2:08:28,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 585  (26.2):  29%|       | 585/2000 [52:41<2:08:28,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 153 / 586  (26.1):  29%|       | 586/2000 [52:47<2:08:24,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 154 / 587  (26.2):  29%|       | 587/2000 [52:52<2:08:29,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 588  (26.4):  29%|       | 588/2000 [52:58<2:08:20,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 589  (26.3):  29%|       | 589/2000 [53:03<2:08:14,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 590  (26.3):  30%|       | 590/2000 [53:09<2:08:03,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 591  (26.2):  30%|       | 591/2000 [53:14<2:07:57,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 592  (26.2):  30%|       | 592/2000 [53:19<2:07:50,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 593  (26.1):  30%|       | 593/2000 [53:25<2:07:47,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 594  (26.1):  30%|       | 594/2000 [53:30<2:07:37,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 595  (26.1):  30%|       | 595/2000 [53:36<2:07:39,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 155 / 596  (26.0):  30%|       | 596/2000 [53:41<2:07:31,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 597  (26.1):  30%|       | 597/2000 [53:47<2:07:22,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 598  (26.1):  30%|       | 598/2000 [53:52<2:07:29,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 156 / 599  (26.0):  30%|       | 599/2000 [53:58<2:07:27,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 600  (26.2):  30%|       | 600/2000 [54:03<2:07:12,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 601  (26.1):  30%|       | 601/2000 [54:09<2:06:54,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 602  (26.1):  30%|       | 602/2000 [54:14<2:06:48,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 603  (26.0):  30%|       | 603/2000 [54:19<2:06:37,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 604  (26.0):  30%|       | 604/2000 [54:25<2:06:34,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 605  (26.0):  30%|       | 605/2000 [54:30<2:06:25,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 157 / 606  (25.9):  30%|       | 606/2000 [54:36<2:06:22,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 158 / 607  (26.0):  30%|       | 607/2000 [54:41<2:06:15,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 158 / 608  (26.0):  30%|       | 608/2000 [54:47<2:06:13,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 158 / 609  (25.9):  30%|       | 609/2000 [54:52<2:06:04,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 159 / 610  (26.1):  30%|       | 610/2000 [54:57<2:06:01,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 611  (26.2):  31%|       | 611/2000 [55:03<2:05:58,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 612  (26.1):  31%|       | 612/2000 [55:08<2:05:55,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 613  (26.1):  31%|       | 613/2000 [55:14<2:05:48,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 614  (26.1):  31%|       | 614/2000 [55:19<2:05:45,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 160 / 615  (26.0):  31%|       | 615/2000 [55:25<2:05:42,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 616  (26.1):  31%|       | 616/2000 [55:30<2:05:37,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 617  (26.1):  31%|       | 617/2000 [55:36<2:05:27,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 618  (26.1):  31%|       | 618/2000 [55:41<2:05:15,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 619  (26.0):  31%|       | 619/2000 [55:46<2:05:05,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 620  (26.0):  31%|       | 620/2000 [55:52<2:04:57,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 621  (25.9):  31%|       | 621/2000 [55:57<2:04:58,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 622  (25.9):  31%|       | 622/2000 [56:03<2:04:54,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 623  (25.8):  31%|       | 623/2000 [56:08<2:04:58,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 161 / 624  (25.8):  31%|       | 624/2000 [56:14<2:04:52,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 625  (25.9):  31%|      | 625/2000 [56:19<2:04:44,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 626  (25.9):  31%|      | 626/2000 [56:25<2:04:39,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 162 / 627  (25.8):  31%|      | 627/2000 [56:30<2:04:28,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 628  (26.0):  31%|      | 628/2000 [56:35<2:04:25,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 629  (25.9):  31%|      | 629/2000 [56:41<2:04:23,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 630  (25.9):  32%|      | 630/2000 [56:46<2:04:12,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 631  (25.8):  32%|      | 631/2000 [56:52<2:04:06,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 632  (25.8):  32%|      | 632/2000 [56:57<2:04:02,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 633  (25.8):  32%|      | 633/2000 [57:03<2:04:00,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 634  (25.7):  32%|      | 634/2000 [57:08<2:03:59,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 635  (25.7):  32%|      | 635/2000 [57:14<2:03:53,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 636  (25.6):  32%|      | 636/2000 [57:19<2:03:52,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 637  (25.6):  32%|      | 637/2000 [57:24<2:03:43,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 638  (25.5):  32%|      | 638/2000 [57:30<2:03:34,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 639  (25.5):  32%|      | 639/2000 [57:35<2:03:33,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 640  (25.5):  32%|      | 640/2000 [57:41<2:03:23,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 641  (25.4):  32%|      | 641/2000 [57:46<2:03:22,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 642  (25.4):  32%|      | 642/2000 [57:52<2:03:14,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 643  (25.3):  32%|      | 643/2000 [57:57<2:03:09,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 644  (25.3):  32%|      | 644/2000 [58:03<2:04:21,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 645  (25.3):  32%|      | 645/2000 [58:08<2:03:51,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 646  (25.2):  32%|      | 646/2000 [58:14<2:03:19,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 163 / 647  (25.2):  32%|      | 647/2000 [58:19<2:02:57,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 164 / 648  (25.3):  32%|      | 648/2000 [58:24<2:02:34,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 649  (25.4):  32%|      | 649/2000 [58:30<2:02:20,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 165 / 650  (25.4):  32%|      | 650/2000 [58:35<2:02:09,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 166 / 651  (25.5):  33%|      | 651/2000 [58:41<2:01:56,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 652  (25.6):  33%|      | 652/2000 [58:46<2:01:51,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 653  (25.6):  33%|      | 653/2000 [58:52<2:01:38,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 654  (25.5):  33%|      | 654/2000 [58:57<2:01:29,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 655  (25.5):  33%|      | 655/2000 [59:02<2:01:28,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 656  (25.5):  33%|      | 656/2000 [59:08<2:01:22,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 657  (25.4):  33%|      | 657/2000 [59:13<2:01:13,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 658  (25.4):  33%|      | 658/2000 [59:19<2:01:03,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 167 / 659  (25.3):  33%|      | 659/2000 [59:24<2:00:54,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 168 / 660  (25.5):  33%|      | 660/2000 [59:29<2:00:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 169 / 661  (25.6):  33%|      | 661/2000 [59:35<2:00:42,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 169 / 662  (25.5):  33%|      | 662/2000 [59:40<2:00:39,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 663  (25.6):  33%|      | 663/2000 [59:46<2:00:35,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 170 / 664  (25.6):  33%|      | 664/2000 [59:51<2:00:19,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 665  (25.7):  33%|      | 665/2000 [59:56<2:00:13,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 171 / 666  (25.7):  33%|      | 666/2000 [1:00:02<2:00:05,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 172 / 667  (25.8):  33%|      | 667/2000 [1:00:07<2:00:01,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 172 / 668  (25.7):  33%|      | 668/2000 [1:00:13<1:59:56,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 172 / 669  (25.7):  33%|      | 669/2000 [1:00:18<1:59:55,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 172 / 670  (25.7):  34%|      | 670/2000 [1:00:23<1:59:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 671  (25.8):  34%|      | 671/2000 [1:00:29<1:59:40,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 672  (25.7):  34%|      | 672/2000 [1:00:34<1:59:37,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 673  (25.7):  34%|      | 673/2000 [1:00:40<1:59:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 674  (25.7):  34%|      | 674/2000 [1:00:45<1:59:26,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 675  (25.6):  34%|      | 675/2000 [1:00:50<1:59:27,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 676  (25.6):  34%|      | 676/2000 [1:00:56<1:59:18,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 677  (25.6):  34%|      | 677/2000 [1:01:01<1:59:21,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 678  (25.5):  34%|      | 678/2000 [1:01:07<1:59:13,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 173 / 679  (25.5):  34%|      | 679/2000 [1:01:12<1:59:02,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 174 / 680  (25.6):  34%|      | 680/2000 [1:01:18<1:59:00,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 174 / 681  (25.6):  34%|      | 681/2000 [1:01:23<1:58:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 174 / 682  (25.5):  34%|      | 682/2000 [1:01:28<1:58:43,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 175 / 683  (25.6):  34%|      | 683/2000 [1:01:34<1:58:38,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 175 / 684  (25.6):  34%|      | 684/2000 [1:01:39<1:58:40,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 175 / 685  (25.5):  34%|      | 685/2000 [1:01:45<1:58:31,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 176 / 686  (25.7):  34%|      | 686/2000 [1:01:50<1:58:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 687  (25.8):  34%|      | 687/2000 [1:01:55<1:58:19,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 177 / 688  (25.7):  34%|      | 688/2000 [1:02:01<1:58:08,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 689  (25.8):  34%|      | 689/2000 [1:02:06<1:58:08,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 690  (25.8):  34%|      | 690/2000 [1:02:12<1:58:09,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 691  (25.8):  35%|      | 691/2000 [1:02:17<1:58:00,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 692  (25.7):  35%|      | 692/2000 [1:02:22<1:57:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 178 / 693  (25.7):  35%|      | 693/2000 [1:02:28<1:57:41,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 179 / 694  (25.8):  35%|      | 694/2000 [1:02:33<1:57:34,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 180 / 695  (25.9):  35%|      | 695/2000 [1:02:39<1:57:26,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 180 / 696  (25.9):  35%|      | 696/2000 [1:02:44<1:57:24,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 180 / 697  (25.8):  35%|      | 697/2000 [1:02:49<1:57:26,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 180 / 698  (25.8):  35%|      | 698/2000 [1:02:55<1:57:23,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 181 / 699  (25.9):  35%|      | 699/2000 [1:03:00<1:57:13,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 181 / 700  (25.9):  35%|      | 700/2000 [1:03:06<1:57:11,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 181 / 701  (25.8):  35%|      | 701/2000 [1:03:11<1:57:01,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 182 / 702  (25.9):  35%|      | 702/2000 [1:03:16<1:56:54,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 182 / 703  (25.9):  35%|      | 703/2000 [1:03:22<1:56:47,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 183 / 704  (26.0):  35%|      | 704/2000 [1:03:27<1:56:41,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 705  (26.1):  35%|      | 705/2000 [1:03:33<1:56:43,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 706  (26.1):  35%|      | 706/2000 [1:03:38<1:56:38,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 184 / 707  (26.0):  35%|      | 707/2000 [1:03:44<1:56:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 185 / 708  (26.1):  35%|      | 708/2000 [1:03:49<1:56:29,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 185 / 709  (26.1):  35%|      | 709/2000 [1:03:54<1:56:25,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 185 / 710  (26.1):  36%|      | 710/2000 [1:04:00<1:56:20,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 711  (26.2):  36%|      | 711/2000 [1:04:05<1:56:22,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 712  (26.1):  36%|      | 712/2000 [1:04:11<1:56:18,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 713  (26.1):  36%|      | 713/2000 [1:04:16<1:56:11,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 714  (26.1):  36%|      | 714/2000 [1:04:21<1:56:10,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 715  (26.0):  36%|      | 715/2000 [1:04:27<1:56:01,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 716  (26.0):  36%|      | 716/2000 [1:04:32<1:55:54,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 717  (25.9):  36%|      | 717/2000 [1:04:38<1:55:40,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 718  (25.9):  36%|      | 718/2000 [1:04:43<1:55:34,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 186 / 719  (25.9):  36%|      | 719/2000 [1:04:48<1:55:23,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 720  (26.0):  36%|      | 720/2000 [1:04:54<1:55:15,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 721  (25.9):  36%|      | 721/2000 [1:04:59<1:55:16,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 722  (25.9):  36%|      | 722/2000 [1:05:05<1:55:15,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 723  (25.9):  36%|      | 723/2000 [1:05:10<1:55:16,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 187 / 724  (25.8):  36%|      | 724/2000 [1:05:16<1:55:09,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 188 / 725  (25.9):  36%|      | 725/2000 [1:05:21<1:55:03,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 188 / 726  (25.9):  36%|      | 726/2000 [1:05:26<1:54:56,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 188 / 727  (25.9):  36%|      | 727/2000 [1:05:32<1:54:51,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 188 / 728  (25.8):  36%|      | 728/2000 [1:05:37<1:54:41,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 188 / 729  (25.8):  36%|      | 729/2000 [1:05:43<1:54:31,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 188 / 730  (25.8):  36%|      | 730/2000 [1:05:48<1:54:27,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 731  (25.9):  37%|      | 731/2000 [1:05:53<1:54:20,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 732  (25.8):  37%|      | 732/2000 [1:05:59<1:54:12,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 189 / 733  (25.8):  37%|      | 733/2000 [1:06:04<1:54:04,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 734  (25.9):  37%|      | 734/2000 [1:06:10<1:53:59,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 735  (25.9):  37%|      | 735/2000 [1:06:15<1:53:57,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 736  (25.8):  37%|      | 736/2000 [1:06:20<1:53:53,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 737  (25.8):  37%|      | 737/2000 [1:06:26<1:53:54,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 190 / 738  (25.7):  37%|      | 738/2000 [1:06:31<1:53:52,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 191 / 739  (25.8):  37%|      | 739/2000 [1:06:37<1:53:46,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 740  (25.9):  37%|      | 740/2000 [1:06:42<1:53:38,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 741  (25.9):  37%|      | 741/2000 [1:06:47<1:53:33,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 742  (25.9):  37%|      | 742/2000 [1:06:53<1:53:24,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 192 / 743  (25.8):  37%|      | 743/2000 [1:06:58<1:53:19,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 744  (25.9):  37%|      | 744/2000 [1:07:04<1:53:15,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 745  (25.9):  37%|      | 745/2000 [1:07:09<1:53:12,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 193 / 746  (25.9):  37%|      | 746/2000 [1:07:15<1:53:12,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 194 / 747  (26.0):  37%|      | 747/2000 [1:07:20<1:53:04,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 195 / 748  (26.1):  37%|      | 748/2000 [1:07:25<1:53:04,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 195 / 749  (26.0):  37%|      | 749/2000 [1:07:31<1:52:55,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 195 / 750  (26.0):  38%|      | 750/2000 [1:07:36<1:52:51,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 196 / 751  (26.1):  38%|      | 751/2000 [1:07:42<1:52:40,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 197 / 752  (26.2):  38%|      | 752/2000 [1:07:47<1:52:37,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 753  (26.3):  38%|      | 753/2000 [1:07:52<1:52:30,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 754  (26.3):  38%|      | 754/2000 [1:07:58<1:52:24,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 755  (26.2):  38%|      | 755/2000 [1:08:03<1:52:18,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 756  (26.2):  38%|      | 756/2000 [1:08:09<1:52:11,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 757  (26.2):  38%|      | 757/2000 [1:08:14<1:52:05,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 758  (26.1):  38%|      | 758/2000 [1:08:19<1:51:59,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 198 / 759  (26.1):  38%|      | 759/2000 [1:08:25<1:52:04,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 760  (26.2):  38%|      | 760/2000 [1:08:30<1:51:53,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 761  (26.1):  38%|      | 761/2000 [1:08:36<1:51:53,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 762  (26.1):  38%|      | 762/2000 [1:08:41<1:52:31,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 763  (26.1):  38%|      | 763/2000 [1:08:47<1:52:20,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 764  (26.0):  38%|      | 764/2000 [1:08:52<1:52:08,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 765  (26.0):  38%|      | 765/2000 [1:08:58<1:52:13,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 766  (26.0):  38%|      | 766/2000 [1:09:03<1:51:53,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 767  (25.9):  38%|      | 767/2000 [1:09:08<1:51:44,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 768  (25.9):  38%|      | 768/2000 [1:09:14<1:51:30,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 199 / 769  (25.9):  38%|      | 769/2000 [1:09:19<1:51:19,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 770  (26.0):  38%|      | 770/2000 [1:09:25<1:51:09,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 771  (25.9):  39%|      | 771/2000 [1:09:30<1:51:06,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 772  (25.9):  39%|      | 772/2000 [1:09:36<1:50:56,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 773  (25.9):  39%|      | 773/2000 [1:09:41<1:50:57,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 774  (25.8):  39%|      | 774/2000 [1:09:46<1:50:48,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 775  (25.8):  39%|      | 775/2000 [1:09:52<1:50:46,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 776  (25.8):  39%|      | 776/2000 [1:09:57<1:50:39,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 777  (25.7):  39%|      | 777/2000 [1:10:03<1:50:36,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 200 / 778  (25.7):  39%|      | 778/2000 [1:10:08<1:50:27,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 779  (25.8):  39%|      | 779/2000 [1:10:14<1:50:21,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 780  (25.8):  39%|      | 780/2000 [1:10:19<1:50:14,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 781  (25.7):  39%|      | 781/2000 [1:10:25<1:52:20,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 782  (25.7):  39%|      | 782/2000 [1:10:30<1:51:27,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 783  (25.7):  39%|      | 783/2000 [1:10:36<1:50:53,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 784  (25.6):  39%|      | 784/2000 [1:10:41<1:50:16,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 201 / 785  (25.6):  39%|      | 785/2000 [1:10:46<1:49:58,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 202 / 786  (25.7):  39%|      | 786/2000 [1:10:52<1:49:36,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 202 / 787  (25.7):  39%|      | 787/2000 [1:10:57<1:49:26,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 202 / 788  (25.6):  39%|      | 788/2000 [1:11:03<1:49:14,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 203 / 789  (25.7):  39%|      | 789/2000 [1:11:08<1:49:06,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 790  (25.8):  40%|      | 790/2000 [1:11:13<1:49:00,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 791  (25.8):  40%|      | 791/2000 [1:11:19<1:48:55,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 792  (25.8):  40%|      | 792/2000 [1:11:24<1:48:51,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 793  (25.7):  40%|      | 793/2000 [1:11:30<1:48:41,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 794  (25.7):  40%|      | 794/2000 [1:11:35<1:48:36,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 795  (25.7):  40%|      | 795/2000 [1:11:40<1:48:26,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 796  (25.6):  40%|      | 796/2000 [1:11:46<1:48:22,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 797  (25.6):  40%|      | 797/2000 [1:11:51<1:48:17,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 798  (25.6):  40%|      | 798/2000 [1:11:57<1:48:08,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 799  (25.5):  40%|      | 799/2000 [1:12:02<1:48:08,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 800  (25.5):  40%|      | 800/2000 [1:12:07<1:48:09,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 801  (25.5):  40%|      | 801/2000 [1:12:13<1:48:01,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 802  (25.4):  40%|      | 802/2000 [1:12:18<1:47:52,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 803  (25.4):  40%|      | 803/2000 [1:12:24<1:47:44,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 804  (25.4):  40%|      | 804/2000 [1:12:29<1:47:35,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 805  (25.3):  40%|      | 805/2000 [1:12:34<1:47:31,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 806  (25.3):  40%|      | 806/2000 [1:12:40<1:47:26,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 807  (25.3):  40%|      | 807/2000 [1:12:45<1:47:25,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 808  (25.2):  40%|      | 808/2000 [1:12:51<1:47:20,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 809  (25.2):  40%|      | 809/2000 [1:12:56<1:47:15,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 810  (25.2):  40%|      | 810/2000 [1:13:01<1:47:07,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 204 / 811  (25.2):  41%|      | 811/2000 [1:13:07<1:47:07,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 812  (25.2):  41%|      | 812/2000 [1:13:12<1:47:05,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 813  (25.2):  41%|      | 813/2000 [1:13:18<1:47:00,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 814  (25.2):  41%|      | 814/2000 [1:13:23<1:46:56,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 815  (25.2):  41%|      | 815/2000 [1:13:28<1:46:51,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 816  (25.1):  41%|      | 816/2000 [1:13:34<1:46:42,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 817  (25.1):  41%|      | 817/2000 [1:13:39<1:46:32,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 205 / 818  (25.1):  41%|      | 818/2000 [1:13:45<1:46:28,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 819  (25.2):  41%|      | 819/2000 [1:13:50<1:46:24,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 820  (25.1):  41%|      | 820/2000 [1:13:55<1:46:21,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 821  (25.1):  41%|      | 821/2000 [1:14:01<1:46:16,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 206 / 822  (25.1):  41%|      | 822/2000 [1:14:06<1:46:09,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 207 / 823  (25.2):  41%|      | 823/2000 [1:14:12<1:46:08,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 207 / 824  (25.1):  41%|      | 824/2000 [1:14:17<1:45:59,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 207 / 825  (25.1):  41%|     | 825/2000 [1:14:22<1:45:50,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 826  (25.2):  41%|     | 826/2000 [1:14:28<1:45:39,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 208 / 827  (25.2):  41%|     | 827/2000 [1:14:33<1:45:30,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 828  (25.2):  41%|     | 828/2000 [1:14:39<1:45:25,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 829  (25.2):  41%|     | 829/2000 [1:14:44<1:45:31,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 209 / 830  (25.2):  42%|     | 830/2000 [1:14:50<1:45:22,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 831  (25.3):  42%|     | 831/2000 [1:14:55<1:45:24,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 832  (25.2):  42%|     | 832/2000 [1:15:00<1:45:17,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 833  (25.2):  42%|     | 833/2000 [1:15:06<1:45:15,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 834  (25.2):  42%|     | 834/2000 [1:15:11<1:45:04,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 835  (25.1):  42%|     | 835/2000 [1:15:17<1:45:05,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 836  (25.1):  42%|     | 836/2000 [1:15:22<1:44:54,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 210 / 837  (25.1):  42%|     | 837/2000 [1:15:27<1:44:51,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 838  (25.2):  42%|     | 838/2000 [1:15:33<1:44:53,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 839  (25.1):  42%|     | 839/2000 [1:15:38<1:44:48,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 840  (25.1):  42%|     | 840/2000 [1:15:44<1:44:43,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 841  (25.1):  42%|     | 841/2000 [1:15:49<1:44:40,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 211 / 842  (25.1):  42%|     | 842/2000 [1:15:54<1:44:33,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 843  (25.1):  42%|     | 843/2000 [1:16:00<1:44:19,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 844  (25.1):  42%|     | 844/2000 [1:16:05<1:44:14,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 845  (25.1):  42%|     | 845/2000 [1:16:11<1:44:11,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 846  (25.1):  42%|     | 846/2000 [1:16:16<1:44:03,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 847  (25.0):  42%|     | 847/2000 [1:16:22<1:44:01,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 848  (25.0):  42%|     | 848/2000 [1:16:27<1:43:52,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 849  (25.0):  42%|     | 849/2000 [1:16:32<1:43:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 850  (24.9):  42%|     | 850/2000 [1:16:38<1:43:43,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 851  (24.9):  43%|     | 851/2000 [1:16:43<1:43:41,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 212 / 852  (24.9):  43%|     | 852/2000 [1:16:49<1:43:29,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 213 / 853  (25.0):  43%|     | 853/2000 [1:16:54<1:43:28,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 214 / 854  (25.1):  43%|     | 854/2000 [1:16:59<1:43:28,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 855  (25.1):  43%|     | 855/2000 [1:17:05<1:43:24,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 856  (25.1):  43%|     | 856/2000 [1:17:10<1:43:16,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 857  (25.1):  43%|     | 857/2000 [1:17:16<1:43:08,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 858  (25.1):  43%|     | 858/2000 [1:17:21<1:42:59,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 859  (25.0):  43%|     | 859/2000 [1:17:26<1:42:49,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 215 / 860  (25.0):  43%|     | 860/2000 [1:17:32<1:42:48,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 216 / 861  (25.1):  43%|     | 861/2000 [1:17:37<1:42:46,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 217 / 862  (25.2):  43%|     | 862/2000 [1:17:43<1:42:40,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 217 / 863  (25.1):  43%|     | 863/2000 [1:17:48<1:42:38,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 217 / 864  (25.1):  43%|     | 864/2000 [1:17:54<1:42:22,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 217 / 865  (25.1):  43%|     | 865/2000 [1:17:59<1:42:11,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 218 / 866  (25.2):  43%|     | 866/2000 [1:18:04<1:42:04,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 218 / 867  (25.1):  43%|     | 867/2000 [1:18:10<1:42:02,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 219 / 868  (25.2):  43%|     | 868/2000 [1:18:15<1:41:49,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 869  (25.3):  43%|     | 869/2000 [1:18:21<1:41:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 870  (25.3):  44%|     | 870/2000 [1:18:26<1:41:07,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 871  (25.3):  44%|     | 871/2000 [1:18:31<1:40:32,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 872  (25.2):  44%|     | 872/2000 [1:18:36<1:40:13,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 873  (25.2):  44%|     | 873/2000 [1:18:42<1:39:54,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 220 / 874  (25.2):  44%|     | 874/2000 [1:18:47<1:39:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 221 / 875  (25.3):  44%|     | 875/2000 [1:18:52<1:39:27,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 221 / 876  (25.2):  44%|     | 876/2000 [1:18:58<1:39:16,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 877  (25.3):  44%|     | 877/2000 [1:19:03<1:39:13,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 878  (25.3):  44%|     | 878/2000 [1:19:08<1:39:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 879  (25.3):  44%|     | 879/2000 [1:19:14<1:39:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 880  (25.2):  44%|     | 880/2000 [1:19:19<1:39:11,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 881  (25.2):  44%|     | 881/2000 [1:19:24<1:39:13,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 222 / 882  (25.2):  44%|     | 882/2000 [1:19:29<1:39:04,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 223 / 883  (25.3):  44%|     | 883/2000 [1:19:35<1:39:00,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 223 / 884  (25.2):  44%|     | 884/2000 [1:19:40<1:38:56,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 223 / 885  (25.2):  44%|     | 885/2000 [1:19:45<1:38:51,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 223 / 886  (25.2):  44%|     | 886/2000 [1:19:51<1:38:41,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 887  (25.3):  44%|     | 887/2000 [1:19:56<1:38:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 888  (25.2):  44%|     | 888/2000 [1:20:01<1:38:32,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 889  (25.2):  44%|     | 889/2000 [1:20:07<1:38:27,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 890  (25.2):  44%|     | 890/2000 [1:20:12<1:38:26,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 891  (25.1):  45%|     | 891/2000 [1:20:17<1:38:19,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 892  (25.1):  45%|     | 892/2000 [1:20:23<1:38:14,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 224 / 893  (25.1):  45%|     | 893/2000 [1:20:28<1:38:06,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 225 / 894  (25.2):  45%|     | 894/2000 [1:20:33<1:37:59,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 895  (25.3):  45%|     | 895/2000 [1:20:39<1:37:53,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 896  (25.2):  45%|     | 896/2000 [1:20:44<1:37:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 897  (25.2):  45%|     | 897/2000 [1:20:49<1:37:43,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 898  (25.2):  45%|     | 898/2000 [1:20:55<1:37:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 899  (25.1):  45%|     | 899/2000 [1:21:00<1:37:31,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 900  (25.1):  45%|     | 900/2000 [1:21:05<1:37:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 901  (25.1):  45%|     | 901/2000 [1:21:10<1:37:20,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 226 / 902  (25.1):  45%|     | 902/2000 [1:21:16<1:37:20,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 227 / 903  (25.1):  45%|     | 903/2000 [1:21:21<1:37:16,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 227 / 904  (25.1):  45%|     | 904/2000 [1:21:26<1:37:06,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 227 / 905  (25.1):  45%|     | 905/2000 [1:21:32<1:37:00,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 227 / 906  (25.1):  45%|     | 906/2000 [1:21:37<1:36:54,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 227 / 907  (25.0):  45%|     | 907/2000 [1:21:42<1:36:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 908  (25.1):  45%|     | 908/2000 [1:21:48<1:36:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 909  (25.1):  45%|     | 909/2000 [1:21:53<1:36:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 910  (25.1):  46%|     | 910/2000 [1:21:58<1:36:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 911  (25.0):  46%|     | 911/2000 [1:22:04<1:36:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 912  (25.0):  46%|     | 912/2000 [1:22:09<1:36:23,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 913  (25.0):  46%|     | 913/2000 [1:22:14<1:36:16,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 914  (24.9):  46%|     | 914/2000 [1:22:20<1:36:12,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 915  (24.9):  46%|     | 915/2000 [1:22:25<1:36:08,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 916  (24.9):  46%|     | 916/2000 [1:22:30<1:36:02,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 917  (24.9):  46%|     | 917/2000 [1:22:36<1:36:01,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 918  (24.8):  46%|     | 918/2000 [1:22:41<1:35:57,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 919  (24.8):  46%|     | 919/2000 [1:22:46<1:35:47,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 920  (24.8):  46%|     | 920/2000 [1:22:51<1:35:40,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 921  (24.8):  46%|     | 921/2000 [1:22:57<1:35:35,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 922  (24.7):  46%|     | 922/2000 [1:23:02<1:35:40,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 228 / 923  (24.7):  46%|     | 923/2000 [1:23:08<1:36:00,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 924  (24.8):  46%|     | 924/2000 [1:23:13<1:36:08,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 925  (24.8):  46%|     | 925/2000 [1:23:18<1:36:10,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 926  (24.7):  46%|     | 926/2000 [1:23:24<1:36:17,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 927  (24.7):  46%|     | 927/2000 [1:23:29<1:36:20,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 229 / 928  (24.7):  46%|     | 928/2000 [1:23:35<1:36:17,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 929  (24.8):  46%|     | 929/2000 [1:23:40<1:36:20,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 930  (24.7):  46%|     | 930/2000 [1:23:45<1:36:16,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 931  (24.7):  47%|     | 931/2000 [1:23:51<1:35:59,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 932  (24.7):  47%|     | 932/2000 [1:23:56<1:35:35,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 933  (24.7):  47%|     | 933/2000 [1:24:01<1:35:16,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 230 / 934  (24.6):  47%|     | 934/2000 [1:24:07<1:35:01,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 231 / 935  (24.7):  47%|     | 935/2000 [1:24:12<1:34:42,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 231 / 936  (24.7):  47%|     | 936/2000 [1:24:17<1:34:28,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 231 / 937  (24.7):  47%|     | 937/2000 [1:24:23<1:34:18,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 232 / 938  (24.7):  47%|     | 938/2000 [1:24:28<1:34:12,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 232 / 939  (24.7):  47%|     | 939/2000 [1:24:33<1:34:03,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 233 / 940  (24.8):  47%|     | 940/2000 [1:24:39<1:33:55,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 233 / 941  (24.8):  47%|     | 941/2000 [1:24:44<1:33:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 233 / 942  (24.7):  47%|     | 942/2000 [1:24:49<1:33:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 233 / 943  (24.7):  47%|     | 943/2000 [1:24:54<1:33:33,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 944  (24.8):  47%|     | 944/2000 [1:25:00<1:33:34,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 945  (24.8):  47%|     | 945/2000 [1:25:05<1:33:27,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 946  (24.7):  47%|     | 946/2000 [1:25:10<1:33:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 947  (24.7):  47%|     | 947/2000 [1:25:16<1:33:16,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 948  (24.7):  47%|     | 948/2000 [1:25:21<1:33:12,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 234 / 949  (24.7):  47%|     | 949/2000 [1:25:26<1:33:09,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 235 / 950  (24.7):  48%|     | 950/2000 [1:25:32<1:33:09,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 951  (24.8):  48%|     | 951/2000 [1:25:37<1:32:58,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 952  (24.8):  48%|     | 952/2000 [1:25:42<1:32:48,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 953  (24.8):  48%|     | 953/2000 [1:25:48<1:32:43,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 236 / 954  (24.7):  48%|     | 954/2000 [1:25:53<1:32:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 955  (24.8):  48%|     | 955/2000 [1:25:58<1:32:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 956  (24.8):  48%|     | 956/2000 [1:26:04<1:32:26,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 957  (24.8):  48%|     | 957/2000 [1:26:09<1:32:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 237 / 958  (24.7):  48%|     | 958/2000 [1:26:14<1:32:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 238 / 959  (24.8):  48%|     | 959/2000 [1:26:20<1:32:11,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 238 / 960  (24.8):  48%|     | 960/2000 [1:26:25<1:32:06,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 239 / 961  (24.9):  48%|     | 961/2000 [1:26:30<1:32:01,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 239 / 962  (24.8):  48%|     | 962/2000 [1:26:35<1:31:56,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 963  (24.9):  48%|     | 963/2000 [1:26:41<1:31:50,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 240 / 964  (24.9):  48%|     | 964/2000 [1:26:46<1:31:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 965  (25.0):  48%|     | 965/2000 [1:26:51<1:31:37,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 966  (24.9):  48%|     | 966/2000 [1:26:57<1:31:26,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 967  (24.9):  48%|     | 967/2000 [1:27:02<1:31:18,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 968  (24.9):  48%|     | 968/2000 [1:27:07<1:31:14,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 969  (24.9):  48%|     | 969/2000 [1:27:13<1:31:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 970  (24.8):  48%|     | 970/2000 [1:27:18<1:31:04,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 971  (24.8):  49%|     | 971/2000 [1:27:23<1:30:59,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 241 / 972  (24.8):  49%|     | 972/2000 [1:27:29<1:30:54,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 242 / 973  (24.9):  49%|     | 973/2000 [1:27:34<1:30:51,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 243 / 974  (24.9):  49%|     | 974/2000 [1:27:39<1:30:45,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 243 / 975  (24.9):  49%|     | 975/2000 [1:27:44<1:30:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 243 / 976  (24.9):  49%|     | 976/2000 [1:27:50<1:30:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 243 / 977  (24.9):  49%|     | 977/2000 [1:27:55<1:30:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 243 / 978  (24.8):  49%|     | 978/2000 [1:28:00<1:30:27,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 243 / 979  (24.8):  49%|     | 979/2000 [1:28:06<1:30:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 244 / 980  (24.9):  49%|     | 980/2000 [1:28:11<1:30:18,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 244 / 981  (24.9):  49%|     | 981/2000 [1:28:16<1:30:15,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 982  (24.9):  49%|     | 982/2000 [1:28:22<1:30:12,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 983  (24.9):  49%|     | 983/2000 [1:28:27<1:30:06,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 984  (24.9):  49%|     | 984/2000 [1:28:32<1:29:56,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 985  (24.9):  49%|     | 985/2000 [1:28:38<1:29:46,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 986  (24.8):  49%|     | 986/2000 [1:28:43<1:29:48,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 987  (24.8):  49%|     | 987/2000 [1:28:48<1:29:46,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 988  (24.8):  49%|     | 988/2000 [1:28:54<1:29:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 245 / 989  (24.8):  49%|     | 989/2000 [1:28:59<1:29:30,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 990  (24.8):  50%|     | 990/2000 [1:29:04<1:29:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 991  (24.8):  50%|     | 991/2000 [1:29:09<1:29:17,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 992  (24.8):  50%|     | 992/2000 [1:29:15<1:29:12,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 993  (24.8):  50%|     | 993/2000 [1:29:20<1:29:06,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 246 / 994  (24.7):  50%|     | 994/2000 [1:29:25<1:28:59,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 995  (24.8):  50%|     | 995/2000 [1:29:31<1:28:56,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 996  (24.8):  50%|     | 996/2000 [1:29:36<1:28:54,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 997  (24.8):  50%|     | 997/2000 [1:29:41<1:28:49,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 998  (24.7):  50%|     | 998/2000 [1:29:47<1:28:53,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 999  (24.7):  50%|     | 999/2000 [1:29:52<1:28:46,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 1000  (24.7):  50%|     | 1000/2000 [1:29:57<1:28:39,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 1001  (24.7):  50%|     | 1001/2000 [1:30:03<1:28:31,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 1002  (24.7):  50%|     | 1002/2000 [1:30:08<1:28:24,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 1003  (24.6):  50%|     | 1003/2000 [1:30:13<1:28:17,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 1004  (24.6):  50%|     | 1004/2000 [1:30:19<1:28:16,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 247 / 1005  (24.6):  50%|     | 1005/2000 [1:30:24<1:28:07,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 1006  (24.7):  50%|     | 1006/2000 [1:30:29<1:28:01,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 1007  (24.6):  50%|     | 1007/2000 [1:30:34<1:27:52,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 1008  (24.6):  50%|     | 1008/2000 [1:30:40<1:27:43,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 1009  (24.6):  50%|     | 1009/2000 [1:30:45<1:27:36,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 1010  (24.6):  50%|     | 1010/2000 [1:30:50<1:27:30,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 248 / 1011  (24.5):  51%|     | 1011/2000 [1:30:56<1:27:29,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 249 / 1012  (24.6):  51%|     | 1012/2000 [1:31:01<1:27:29,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 249 / 1013  (24.6):  51%|     | 1013/2000 [1:31:06<1:27:27,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 249 / 1014  (24.6):  51%|     | 1014/2000 [1:31:12<1:27:21,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 249 / 1015  (24.5):  51%|     | 1015/2000 [1:31:17<1:27:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 250 / 1016  (24.6):  51%|     | 1016/2000 [1:31:22<1:27:07,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 1017  (24.7):  51%|     | 1017/2000 [1:31:28<1:27:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 1018  (24.7):  51%|     | 1018/2000 [1:31:33<1:26:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 251 / 1019  (24.6):  51%|     | 1019/2000 [1:31:38<1:26:54,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 252 / 1020  (24.7):  51%|     | 1020/2000 [1:31:44<1:26:48,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 253 / 1021  (24.8):  51%|     | 1021/2000 [1:31:49<1:26:44,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 254 / 1022  (24.9):  51%|     | 1022/2000 [1:31:54<1:26:43,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 254 / 1023  (24.8):  51%|     | 1023/2000 [1:31:59<1:26:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 1024  (24.9):  51%|     | 1024/2000 [1:32:05<1:26:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 1025  (24.9):  51%|    | 1025/2000 [1:32:10<1:26:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 255 / 1026  (24.9):  51%|    | 1026/2000 [1:32:15<1:26:07,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 256 / 1027  (24.9):  51%|    | 1027/2000 [1:32:21<1:26:01,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 256 / 1028  (24.9):  51%|    | 1028/2000 [1:32:26<1:26:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 256 / 1029  (24.9):  51%|    | 1029/2000 [1:32:31<1:26:01,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 1030  (25.0):  52%|    | 1030/2000 [1:32:37<1:25:55,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 1031  (24.9):  52%|    | 1031/2000 [1:32:42<1:25:50,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 1032  (24.9):  52%|    | 1032/2000 [1:32:47<1:25:42,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 257 / 1033  (24.9):  52%|    | 1033/2000 [1:32:53<1:25:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 1034  (25.0):  52%|    | 1034/2000 [1:32:58<1:25:26,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 1035  (24.9):  52%|    | 1035/2000 [1:33:03<1:25:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 258 / 1036  (24.9):  52%|    | 1036/2000 [1:33:08<1:25:13,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 259 / 1037  (25.0):  52%|    | 1037/2000 [1:33:14<1:25:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 259 / 1038  (25.0):  52%|    | 1038/2000 [1:33:19<1:25:01,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 259 / 1039  (24.9):  52%|    | 1039/2000 [1:33:24<1:24:53,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 259 / 1040  (24.9):  52%|    | 1040/2000 [1:33:30<1:24:49,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 259 / 1041  (24.9):  52%|    | 1041/2000 [1:33:35<1:24:43,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 259 / 1042  (24.9):  52%|    | 1042/2000 [1:33:40<1:24:39,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 1043  (24.9):  52%|    | 1043/2000 [1:33:46<1:24:32,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 1044  (24.9):  52%|    | 1044/2000 [1:33:51<1:24:31,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 1045  (24.9):  52%|    | 1045/2000 [1:33:56<1:24:25,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 1046  (24.9):  52%|    | 1046/2000 [1:34:02<1:24:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 1047  (24.8):  52%|    | 1047/2000 [1:34:07<1:24:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 1048  (24.8):  52%|    | 1048/2000 [1:34:12<1:24:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 260 / 1049  (24.8):  52%|    | 1049/2000 [1:34:17<1:24:06,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 261 / 1050  (24.9):  52%|    | 1050/2000 [1:34:23<1:24:00,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 262 / 1051  (24.9):  53%|    | 1051/2000 [1:34:28<1:23:50,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 262 / 1052  (24.9):  53%|    | 1052/2000 [1:34:33<1:23:47,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 262 / 1053  (24.9):  53%|    | 1053/2000 [1:34:39<1:23:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 262 / 1054  (24.9):  53%|    | 1054/2000 [1:34:44<1:23:37,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 1055  (24.9):  53%|    | 1055/2000 [1:34:49<1:23:29,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 1056  (24.9):  53%|    | 1056/2000 [1:34:55<1:23:27,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 263 / 1057  (24.9):  53%|    | 1057/2000 [1:35:00<1:23:29,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1058  (25.0):  53%|    | 1058/2000 [1:35:05<1:23:20,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1059  (24.9):  53%|    | 1059/2000 [1:35:11<1:23:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1060  (24.9):  53%|    | 1060/2000 [1:35:16<1:23:15,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1061  (24.9):  53%|    | 1061/2000 [1:35:21<1:23:11,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1062  (24.9):  53%|    | 1062/2000 [1:35:26<1:23:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1063  (24.8):  53%|    | 1063/2000 [1:35:32<1:22:52,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1064  (24.8):  53%|    | 1064/2000 [1:35:37<1:22:46,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1065  (24.8):  53%|    | 1065/2000 [1:35:42<1:22:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 264 / 1066  (24.8):  53%|    | 1066/2000 [1:35:48<1:22:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 265 / 1067  (24.8):  53%|    | 1067/2000 [1:35:53<1:22:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 266 / 1068  (24.9):  53%|    | 1068/2000 [1:35:58<1:22:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 266 / 1069  (24.9):  53%|    | 1069/2000 [1:36:04<1:22:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 266 / 1070  (24.9):  54%|    | 1070/2000 [1:36:09<1:22:15,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 266 / 1071  (24.8):  54%|    | 1071/2000 [1:36:14<1:22:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 1072  (24.9):  54%|    | 1072/2000 [1:36:20<1:22:04,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 1073  (24.9):  54%|    | 1073/2000 [1:36:25<1:21:57,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 1074  (24.9):  54%|    | 1074/2000 [1:36:30<1:21:51,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 1075  (24.8):  54%|    | 1075/2000 [1:36:35<1:21:44,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 267 / 1076  (24.8):  54%|    | 1076/2000 [1:36:41<1:21:42,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 268 / 1077  (24.9):  54%|    | 1077/2000 [1:36:46<1:21:37,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 268 / 1078  (24.9):  54%|    | 1078/2000 [1:36:51<1:21:31,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 268 / 1079  (24.8):  54%|    | 1079/2000 [1:36:57<1:21:25,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 268 / 1080  (24.8):  54%|    | 1080/2000 [1:37:02<1:21:20,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 269 / 1081  (24.9):  54%|    | 1081/2000 [1:37:07<1:21:20,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 269 / 1082  (24.9):  54%|    | 1082/2000 [1:37:13<1:21:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 269 / 1083  (24.8):  54%|    | 1083/2000 [1:37:18<1:21:07,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 269 / 1084  (24.8):  54%|    | 1084/2000 [1:37:23<1:21:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 269 / 1085  (24.8):  54%|    | 1085/2000 [1:37:29<1:20:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 269 / 1086  (24.8):  54%|    | 1086/2000 [1:37:34<1:20:49,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 1087  (24.8):  54%|    | 1087/2000 [1:37:39<1:20:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 1088  (24.8):  54%|    | 1088/2000 [1:37:44<1:20:45,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 1089  (24.8):  54%|    | 1089/2000 [1:37:50<1:20:40,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 1090  (24.8):  55%|    | 1090/2000 [1:37:55<1:20:33,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 270 / 1091  (24.7):  55%|    | 1091/2000 [1:38:00<1:20:25,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 1092  (24.8):  55%|    | 1092/2000 [1:38:06<1:20:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 1093  (24.8):  55%|    | 1093/2000 [1:38:11<1:20:17,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 1094  (24.8):  55%|    | 1094/2000 [1:38:16<1:20:12,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 1095  (24.7):  55%|    | 1095/2000 [1:38:22<1:20:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 1096  (24.7):  55%|    | 1096/2000 [1:38:27<1:19:53,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 1097  (24.7):  55%|    | 1097/2000 [1:38:32<1:19:51,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 271 / 1098  (24.7):  55%|    | 1098/2000 [1:38:38<1:19:42,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 272 / 1099  (24.7):  55%|    | 1099/2000 [1:38:43<1:19:34,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 1100  (24.8):  55%|    | 1100/2000 [1:38:48<1:19:28,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 1101  (24.8):  55%|    | 1101/2000 [1:38:53<1:19:25,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 1102  (24.8):  55%|    | 1102/2000 [1:38:59<1:19:25,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 1103  (24.8):  55%|    | 1103/2000 [1:39:04<1:19:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 273 / 1104  (24.7):  55%|    | 1104/2000 [1:39:09<1:19:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1105  (24.8):  55%|    | 1105/2000 [1:39:15<1:19:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1106  (24.8):  55%|    | 1106/2000 [1:39:20<1:19:01,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1107  (24.8):  55%|    | 1107/2000 [1:39:25<1:18:52,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1108  (24.7):  55%|    | 1108/2000 [1:39:31<1:18:46,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1109  (24.7):  55%|    | 1109/2000 [1:39:36<1:18:42,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1110  (24.7):  56%|    | 1110/2000 [1:39:41<1:18:35,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1111  (24.7):  56%|    | 1111/2000 [1:39:46<1:18:34,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1112  (24.6):  56%|    | 1112/2000 [1:39:52<1:18:31,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1113  (24.6):  56%|    | 1113/2000 [1:39:57<1:18:30,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 274 / 1114  (24.6):  56%|    | 1114/2000 [1:40:02<1:18:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 1115  (24.7):  56%|    | 1115/2000 [1:40:08<1:18:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 1116  (24.6):  56%|    | 1116/2000 [1:40:13<1:18:11,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 275 / 1117  (24.6):  56%|    | 1117/2000 [1:40:18<1:18:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 1118  (24.7):  56%|    | 1118/2000 [1:40:24<1:18:07,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 276 / 1119  (24.7):  56%|    | 1119/2000 [1:40:29<1:18:01,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 1120  (24.7):  56%|    | 1120/2000 [1:40:34<1:17:54,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 1121  (24.7):  56%|    | 1121/2000 [1:40:40<1:17:46,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 1122  (24.7):  56%|    | 1122/2000 [1:40:45<1:17:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 1123  (24.7):  56%|    | 1123/2000 [1:40:50<1:17:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 277 / 1124  (24.6):  56%|    | 1124/2000 [1:40:55<1:17:26,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1125  (24.7):  56%|    | 1125/2000 [1:41:01<1:17:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1126  (24.7):  56%|    | 1126/2000 [1:41:06<1:17:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1127  (24.7):  56%|    | 1127/2000 [1:41:11<1:17:12,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1128  (24.6):  56%|    | 1128/2000 [1:41:17<1:17:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1129  (24.6):  56%|    | 1129/2000 [1:41:22<1:17:05,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1130  (24.6):  56%|    | 1130/2000 [1:41:27<1:17:00,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1131  (24.6):  57%|    | 1131/2000 [1:41:33<1:16:53,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 278 / 1132  (24.6):  57%|    | 1132/2000 [1:41:38<1:16:46,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 279 / 1133  (24.6):  57%|    | 1133/2000 [1:41:43<1:16:40,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 1134  (24.7):  57%|    | 1134/2000 [1:41:49<1:16:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 1135  (24.7):  57%|    | 1135/2000 [1:41:54<1:16:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 280 / 1136  (24.6):  57%|    | 1136/2000 [1:41:59<1:16:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 281 / 1137  (24.7):  57%|    | 1137/2000 [1:42:04<1:16:18,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 282 / 1138  (24.8):  57%|    | 1138/2000 [1:42:10<1:16:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 283 / 1139  (24.8):  57%|    | 1139/2000 [1:42:15<1:16:12,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 283 / 1140  (24.8):  57%|    | 1140/2000 [1:42:20<1:16:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 1141  (24.9):  57%|    | 1141/2000 [1:42:26<1:15:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 1142  (24.9):  57%|    | 1142/2000 [1:42:31<1:15:55,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 1143  (24.8):  57%|    | 1143/2000 [1:42:36<1:15:49,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 284 / 1144  (24.8):  57%|    | 1144/2000 [1:42:42<1:15:43,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1145  (24.9):  57%|    | 1145/2000 [1:42:47<1:15:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1146  (24.9):  57%|    | 1146/2000 [1:42:52<1:15:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1147  (24.8):  57%|    | 1147/2000 [1:42:58<1:15:34,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1148  (24.8):  57%|    | 1148/2000 [1:43:03<1:15:28,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1149  (24.8):  57%|    | 1149/2000 [1:43:08<1:15:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1150  (24.8):  57%|    | 1150/2000 [1:43:14<1:15:12,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1151  (24.8):  58%|    | 1151/2000 [1:43:19<1:15:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 285 / 1152  (24.7):  58%|    | 1152/2000 [1:43:24<1:15:05,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 286 / 1153  (24.8):  58%|    | 1153/2000 [1:43:29<1:14:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 286 / 1154  (24.8):  58%|    | 1154/2000 [1:43:35<1:14:53,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 286 / 1155  (24.8):  58%|    | 1155/2000 [1:43:40<1:14:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 286 / 1156  (24.7):  58%|    | 1156/2000 [1:43:45<1:14:40,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 1157  (24.8):  58%|    | 1157/2000 [1:43:51<1:14:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 1158  (24.8):  58%|    | 1158/2000 [1:43:56<1:14:27,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 1159  (24.8):  58%|    | 1159/2000 [1:44:01<1:14:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 287 / 1160  (24.7):  58%|    | 1160/2000 [1:44:07<1:14:17,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1161  (24.8):  58%|    | 1161/2000 [1:44:12<1:14:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1162  (24.8):  58%|    | 1162/2000 [1:44:17<1:14:04,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1163  (24.8):  58%|    | 1163/2000 [1:44:23<1:13:58,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1164  (24.7):  58%|    | 1164/2000 [1:44:28<1:13:54,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1165  (24.7):  58%|    | 1165/2000 [1:44:33<1:13:48,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1166  (24.7):  58%|    | 1166/2000 [1:44:38<1:13:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1167  (24.7):  58%|    | 1167/2000 [1:44:44<1:13:39,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1168  (24.7):  58%|    | 1168/2000 [1:44:49<1:13:32,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1169  (24.6):  58%|    | 1169/2000 [1:44:54<1:13:25,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 288 / 1170  (24.6):  58%|    | 1170/2000 [1:45:00<1:13:25,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 289 / 1171  (24.7):  59%|    | 1171/2000 [1:45:05<1:13:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 289 / 1172  (24.7):  59%|    | 1172/2000 [1:45:10<1:13:17,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 290 / 1173  (24.7):  59%|    | 1173/2000 [1:45:16<1:13:09,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 290 / 1174  (24.7):  59%|    | 1174/2000 [1:45:21<1:13:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 290 / 1175  (24.7):  59%|    | 1175/2000 [1:45:26<1:12:55,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 1176  (24.7):  59%|    | 1176/2000 [1:45:31<1:12:51,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 1177  (24.7):  59%|    | 1177/2000 [1:45:37<1:12:49,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 291 / 1178  (24.7):  59%|    | 1178/2000 [1:45:42<1:12:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 292 / 1179  (24.8):  59%|    | 1179/2000 [1:45:47<1:12:42,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 292 / 1180  (24.7):  59%|    | 1180/2000 [1:45:53<1:12:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 292 / 1181  (24.7):  59%|    | 1181/2000 [1:45:58<1:12:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 292 / 1182  (24.7):  59%|    | 1182/2000 [1:46:03<1:12:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 293 / 1183  (24.8):  59%|    | 1183/2000 [1:46:09<1:12:17,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 293 / 1184  (24.7):  59%|    | 1184/2000 [1:46:14<1:12:09,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 294 / 1185  (24.8):  59%|    | 1185/2000 [1:46:19<1:12:02,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 295 / 1186  (24.9):  59%|    | 1186/2000 [1:46:25<1:11:54,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 1187  (24.9):  59%|    | 1187/2000 [1:46:30<1:11:52,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 1188  (24.9):  59%|    | 1188/2000 [1:46:35<1:11:48,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 1189  (24.9):  59%|    | 1189/2000 [1:46:40<1:11:40,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 1190  (24.9):  60%|    | 1190/2000 [1:46:46<1:11:35,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 1191  (24.9):  60%|    | 1191/2000 [1:46:51<1:11:27,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 296 / 1192  (24.8):  60%|    | 1192/2000 [1:46:56<1:11:25,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 297 / 1193  (24.9):  60%|    | 1193/2000 [1:47:02<1:11:17,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 298 / 1194  (25.0):  60%|    | 1194/2000 [1:47:07<1:11:15,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 1195  (25.0):  60%|    | 1195/2000 [1:47:12<1:11:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 1196  (25.0):  60%|    | 1196/2000 [1:47:18<1:11:14,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 1197  (25.0):  60%|    | 1197/2000 [1:47:23<1:11:09,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 1198  (25.0):  60%|    | 1198/2000 [1:47:28<1:11:00,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 1199  (24.9):  60%|    | 1199/2000 [1:47:34<1:10:54,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 299 / 1200  (24.9):  60%|    | 1200/2000 [1:47:39<1:10:52,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 300 / 1201  (25.0):  60%|    | 1201/2000 [1:47:44<1:10:46,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 300 / 1202  (25.0):  60%|    | 1202/2000 [1:47:50<1:10:40,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 300 / 1203  (24.9):  60%|    | 1203/2000 [1:47:55<1:10:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 301 / 1204  (25.0):  60%|    | 1204/2000 [1:48:00<1:10:27,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 301 / 1205  (25.0):  60%|    | 1205/2000 [1:48:05<1:10:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 302 / 1206  (25.0):  60%|    | 1206/2000 [1:48:11<1:10:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 302 / 1207  (25.0):  60%|    | 1207/2000 [1:48:16<1:10:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 303 / 1208  (25.1):  60%|    | 1208/2000 [1:48:21<1:10:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 304 / 1209  (25.1):  60%|    | 1209/2000 [1:48:27<1:10:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 304 / 1210  (25.1):  60%|    | 1210/2000 [1:48:32<1:09:53,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 304 / 1211  (25.1):  61%|    | 1211/2000 [1:48:37<1:09:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 1212  (25.2):  61%|    | 1212/2000 [1:48:43<1:09:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 305 / 1213  (25.1):  61%|    | 1213/2000 [1:48:48<1:09:34,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 306 / 1214  (25.2):  61%|    | 1214/2000 [1:48:53<1:09:28,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 1215  (25.3):  61%|    | 1215/2000 [1:48:59<1:09:21,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 1216  (25.2):  61%|    | 1216/2000 [1:49:04<1:09:19,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 1217  (25.2):  61%|    | 1217/2000 [1:49:09<1:09:12,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 1218  (25.2):  61%|    | 1218/2000 [1:49:14<1:09:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 1219  (25.2):  61%|    | 1219/2000 [1:49:20<1:09:04,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 307 / 1220  (25.2):  61%|    | 1220/2000 [1:49:25<1:09:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 308 / 1221  (25.2):  61%|    | 1221/2000 [1:49:30<1:08:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 308 / 1222  (25.2):  61%|    | 1222/2000 [1:49:36<1:08:51,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 1223  (25.3):  61%|    | 1223/2000 [1:49:41<1:08:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 1224  (25.2):  61%|    | 1224/2000 [1:49:46<1:08:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 1225  (25.2):  61%|   | 1225/2000 [1:49:52<1:08:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 1226  (25.2):  61%|   | 1226/2000 [1:49:57<1:08:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 1227  (25.2):  61%|   | 1227/2000 [1:50:02<1:08:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 309 / 1228  (25.2):  61%|   | 1228/2000 [1:50:08<1:08:14,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1229  (25.2):  61%|   | 1229/2000 [1:50:13<1:08:10,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1230  (25.2):  62%|   | 1230/2000 [1:50:18<1:08:03,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1231  (25.2):  62%|   | 1231/2000 [1:50:23<1:07:58,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1232  (25.2):  62%|   | 1232/2000 [1:50:29<1:07:55,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1233  (25.1):  62%|   | 1233/2000 [1:50:34<1:07:51,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1234  (25.1):  62%|   | 1234/2000 [1:50:39<1:07:42,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1235  (25.1):  62%|   | 1235/2000 [1:50:45<1:07:35,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 310 / 1236  (25.1):  62%|   | 1236/2000 [1:50:50<1:07:32,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 1237  (25.1):  62%|   | 1237/2000 [1:50:55<1:07:29,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 1238  (25.1):  62%|   | 1238/2000 [1:51:01<1:07:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 1239  (25.1):  62%|   | 1239/2000 [1:51:06<1:07:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 1240  (25.1):  62%|   | 1240/2000 [1:51:11<1:07:16,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 311 / 1241  (25.1):  62%|   | 1241/2000 [1:51:17<1:07:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 1242  (25.1):  62%|   | 1242/2000 [1:51:22<1:07:09,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 312 / 1243  (25.1):  62%|   | 1243/2000 [1:51:27<1:07:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 1244  (25.2):  62%|   | 1244/2000 [1:51:32<1:06:57,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 1245  (25.1):  62%|   | 1245/2000 [1:51:38<1:06:49,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 1246  (25.1):  62%|   | 1246/2000 [1:51:43<1:06:46,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 1247  (25.1):  62%|   | 1247/2000 [1:51:48<1:06:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 1248  (25.1):  62%|   | 1248/2000 [1:51:54<1:06:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 1249  (25.1):  62%|   | 1249/2000 [1:51:59<1:06:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 313 / 1250  (25.0):  62%|   | 1250/2000 [1:52:04<1:06:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 1251  (25.1):  63%|   | 1251/2000 [1:52:10<1:06:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 1252  (25.1):  63%|   | 1252/2000 [1:52:15<1:06:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 1253  (25.1):  63%|   | 1253/2000 [1:52:20<1:06:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 1254  (25.0):  63%|   | 1254/2000 [1:52:26<1:06:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 314 / 1255  (25.0):  63%|   | 1255/2000 [1:52:31<1:05:59,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 1256  (25.1):  63%|   | 1256/2000 [1:52:36<1:05:53,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 1257  (25.1):  63%|   | 1257/2000 [1:52:42<1:05:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 1258  (25.0):  63%|   | 1258/2000 [1:52:47<1:05:40,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 315 / 1259  (25.0):  63%|   | 1259/2000 [1:52:52<1:05:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 1260  (25.1):  63%|   | 1260/2000 [1:52:57<1:05:31,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 316 / 1261  (25.1):  63%|   | 1261/2000 [1:53:03<1:05:25,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 1262  (25.1):  63%|   | 1262/2000 [1:53:08<1:05:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 1263  (25.1):  63%|   | 1263/2000 [1:53:13<1:05:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 317 / 1264  (25.1):  63%|   | 1264/2000 [1:53:19<1:05:06,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 318 / 1265  (25.1):  63%|   | 1265/2000 [1:53:24<1:05:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 1266  (25.2):  63%|   | 1266/2000 [1:53:29<1:04:57,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 1267  (25.2):  63%|   | 1267/2000 [1:53:35<1:04:50,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 319 / 1268  (25.2):  63%|   | 1268/2000 [1:53:40<1:04:46,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 1269  (25.2):  63%|   | 1269/2000 [1:53:45<1:04:37,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 1270  (25.2):  64%|   | 1270/2000 [1:53:51<1:04:32,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 1271  (25.2):  64%|   | 1271/2000 [1:53:56<1:04:30,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 320 / 1272  (25.2):  64%|   | 1272/2000 [1:54:01<1:04:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 321 / 1273  (25.2):  64%|   | 1273/2000 [1:54:06<1:04:18,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 321 / 1274  (25.2):  64%|   | 1274/2000 [1:54:12<1:04:15,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 322 / 1275  (25.3):  64%|   | 1275/2000 [1:54:17<1:04:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 322 / 1276  (25.2):  64%|   | 1276/2000 [1:54:22<1:03:59,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 322 / 1277  (25.2):  64%|   | 1277/2000 [1:54:28<1:03:51,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 1278  (25.3):  64%|   | 1278/2000 [1:54:33<1:03:46,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 1279  (25.3):  64%|   | 1279/2000 [1:54:38<1:03:40,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 323 / 1280  (25.2):  64%|   | 1280/2000 [1:54:44<1:03:36,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 1281  (25.3):  64%|   | 1281/2000 [1:54:49<1:03:31,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 324 / 1282  (25.3):  64%|   | 1282/2000 [1:54:54<1:03:23,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 1283  (25.3):  64%|   | 1283/2000 [1:54:59<1:03:20,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 1284  (25.3):  64%|   | 1284/2000 [1:55:05<1:03:13,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 325 / 1285  (25.3):  64%|   | 1285/2000 [1:55:10<1:03:09,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 326 / 1286  (25.3):  64%|   | 1286/2000 [1:55:15<1:03:03,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 326 / 1287  (25.3):  64%|   | 1287/2000 [1:55:21<1:02:58,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 327 / 1288  (25.4):  64%|   | 1288/2000 [1:55:26<1:02:53,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 327 / 1289  (25.4):  64%|   | 1289/2000 [1:55:31<1:02:45,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 328 / 1290  (25.4):  64%|   | 1290/2000 [1:55:37<1:02:40,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 328 / 1291  (25.4):  65%|   | 1291/2000 [1:55:42<1:02:36,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 329 / 1292  (25.5):  65%|   | 1292/2000 [1:55:47<1:02:34,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 329 / 1293  (25.4):  65%|   | 1293/2000 [1:55:52<1:02:29,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 329 / 1294  (25.4):  65%|   | 1294/2000 [1:55:58<1:02:20,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 329 / 1295  (25.4):  65%|   | 1295/2000 [1:56:03<1:02:17,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 1296  (25.5):  65%|   | 1296/2000 [1:56:08<1:02:12,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 1297  (25.4):  65%|   | 1297/2000 [1:56:14<1:02:06,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 1298  (25.4):  65%|   | 1298/2000 [1:56:19<1:02:06,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 1299  (25.4):  65%|   | 1299/2000 [1:56:24<1:01:59,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 330 / 1300  (25.4):  65%|   | 1300/2000 [1:56:30<1:01:50,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 1301  (25.4):  65%|   | 1301/2000 [1:56:35<1:01:48,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 1302  (25.4):  65%|   | 1302/2000 [1:56:40<1:01:41,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 331 / 1303  (25.4):  65%|   | 1303/2000 [1:56:46<1:01:37,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 332 / 1304  (25.5):  65%|   | 1304/2000 [1:56:51<1:01:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 1305  (25.5):  65%|   | 1305/2000 [1:56:56<1:01:30,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 1306  (25.5):  65%|   | 1306/2000 [1:57:01<1:01:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 1307  (25.5):  65%|   | 1307/2000 [1:57:07<1:01:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 1308  (25.5):  65%|   | 1308/2000 [1:57:12<1:01:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 333 / 1309  (25.4):  65%|   | 1309/2000 [1:57:17<1:01:06,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 1310  (25.5):  66%|   | 1310/2000 [1:57:23<1:00:59,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 1311  (25.5):  66%|   | 1311/2000 [1:57:28<1:00:53,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 1312  (25.5):  66%|   | 1312/2000 [1:57:33<1:00:46,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 1313  (25.4):  66%|   | 1313/2000 [1:57:39<1:00:41,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 1314  (25.4):  66%|   | 1314/2000 [1:57:44<1:00:35,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 1315  (25.4):  66%|   | 1315/2000 [1:57:49<1:00:32,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 334 / 1316  (25.4):  66%|   | 1316/2000 [1:57:55<1:00:31,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 1317  (25.4):  66%|   | 1317/2000 [1:58:00<1:00:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 1318  (25.4):  66%|   | 1318/2000 [1:58:05<1:00:18,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 335 / 1319  (25.4):  66%|   | 1319/2000 [1:58:10<1:00:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 336 / 1320  (25.5):  66%|   | 1320/2000 [1:58:16<1:00:04,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 337 / 1321  (25.5):  66%|   | 1321/2000 [1:58:21<59:58,  5.30s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 338 / 1322  (25.6):  66%|   | 1322/2000 [1:58:26<59:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 339 / 1323  (25.6):  66%|   | 1323/2000 [1:58:32<59:50,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 1324  (25.7):  66%|   | 1324/2000 [1:58:37<59:41,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 1325  (25.7):  66%|   | 1325/2000 [1:58:42<59:36,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 1326  (25.6):  66%|   | 1326/2000 [1:58:48<59:30,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 1327  (25.6):  66%|   | 1327/2000 [1:58:53<59:24,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 1328  (25.6):  66%|   | 1328/2000 [1:58:58<59:21,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 340 / 1329  (25.6):  66%|   | 1329/2000 [1:59:03<59:16,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 1330  (25.6):  66%|   | 1330/2000 [1:59:09<59:11,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 1331  (25.6):  67%|   | 1331/2000 [1:59:14<59:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 1332  (25.6):  67%|   | 1332/2000 [1:59:19<59:08,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 1333  (25.6):  67%|   | 1333/2000 [1:59:25<59:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 1334  (25.6):  67%|   | 1334/2000 [1:59:30<58:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 1335  (25.5):  67%|   | 1335/2000 [1:59:35<58:52,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 341 / 1336  (25.5):  67%|   | 1336/2000 [1:59:41<58:45,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 342 / 1337  (25.6):  67%|   | 1337/2000 [1:59:46<58:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 343 / 1338  (25.6):  67%|   | 1338/2000 [1:59:51<58:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 343 / 1339  (25.6):  67%|   | 1339/2000 [1:59:57<58:33,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 1340  (25.7):  67%|   | 1340/2000 [2:00:02<58:29,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 344 / 1341  (25.7):  67%|   | 1341/2000 [2:00:07<58:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 345 / 1342  (25.7):  67%|   | 1342/2000 [2:00:12<58:11,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 345 / 1343  (25.7):  67%|   | 1343/2000 [2:00:18<58:07,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 346 / 1344  (25.7):  67%|   | 1344/2000 [2:00:23<58:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 346 / 1345  (25.7):  67%|   | 1345/2000 [2:00:28<57:54,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 347 / 1346  (25.8):  67%|   | 1346/2000 [2:00:34<57:47,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 347 / 1347  (25.8):  67%|   | 1347/2000 [2:00:39<57:40,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 347 / 1348  (25.7):  67%|   | 1348/2000 [2:00:44<57:39,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 347 / 1349  (25.7):  67%|   | 1349/2000 [2:00:50<57:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 347 / 1350  (25.7):  68%|   | 1350/2000 [2:00:55<57:29,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 347 / 1351  (25.7):  68%|   | 1351/2000 [2:01:00<57:22,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 348 / 1352  (25.7):  68%|   | 1352/2000 [2:01:05<57:15,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 349 / 1353  (25.8):  68%|   | 1353/2000 [2:01:11<57:07,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 350 / 1354  (25.8):  68%|   | 1354/2000 [2:01:16<57:03,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 350 / 1355  (25.8):  68%|   | 1355/2000 [2:01:21<56:59,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 1356  (25.9):  68%|   | 1356/2000 [2:01:27<56:57,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 351 / 1357  (25.9):  68%|   | 1357/2000 [2:01:32<56:53,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 352 / 1358  (25.9):  68%|   | 1358/2000 [2:01:37<56:48,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 353 / 1359  (26.0):  68%|   | 1359/2000 [2:01:43<56:42,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 1360  (26.0):  68%|   | 1360/2000 [2:01:48<56:37,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 1361  (26.0):  68%|   | 1361/2000 [2:01:53<56:31,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 354 / 1362  (26.0):  68%|   | 1362/2000 [2:01:59<56:25,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 1363  (26.0):  68%|   | 1363/2000 [2:02:04<56:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 1364  (26.0):  68%|   | 1364/2000 [2:02:09<56:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 1365  (26.0):  68%|   | 1365/2000 [2:02:15<56:15,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 1366  (26.0):  68%|   | 1366/2000 [2:02:20<56:09,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 1367  (26.0):  68%|   | 1367/2000 [2:02:25<56:00,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 355 / 1368  (26.0):  68%|   | 1368/2000 [2:02:30<55:54,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 1369  (26.0):  68%|   | 1369/2000 [2:02:36<55:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 1370  (26.0):  68%|   | 1370/2000 [2:02:41<55:39,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 356 / 1371  (26.0):  69%|   | 1371/2000 [2:02:46<55:35,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 1372  (26.0):  69%|   | 1372/2000 [2:02:52<55:30,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 1373  (26.0):  69%|   | 1373/2000 [2:02:57<55:25,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 1374  (26.0):  69%|   | 1374/2000 [2:03:02<55:18,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 1375  (26.0):  69%|   | 1375/2000 [2:03:08<55:11,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 357 / 1376  (25.9):  69%|   | 1376/2000 [2:03:13<55:06,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 358 / 1377  (26.0):  69%|   | 1377/2000 [2:03:18<55:02,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 1378  (26.1):  69%|   | 1378/2000 [2:03:23<54:55,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 1379  (26.0):  69%|   | 1379/2000 [2:03:29<54:50,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 1380  (26.0):  69%|   | 1380/2000 [2:03:34<54:45,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 1381  (26.0):  69%|   | 1381/2000 [2:03:39<54:43,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 1382  (26.0):  69%|   | 1382/2000 [2:03:45<54:37,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 1383  (26.0):  69%|   | 1383/2000 [2:03:50<54:34,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 359 / 1384  (25.9):  69%|   | 1384/2000 [2:03:55<54:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 1385  (26.0):  69%|   | 1385/2000 [2:04:01<54:25,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 1386  (26.0):  69%|   | 1386/2000 [2:04:06<54:16,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 360 / 1387  (26.0):  69%|   | 1387/2000 [2:04:11<54:12,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 361 / 1388  (26.0):  69%|   | 1388/2000 [2:04:16<54:04,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 361 / 1389  (26.0):  69%|   | 1389/2000 [2:04:22<53:57,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 361 / 1390  (26.0):  70%|   | 1390/2000 [2:04:27<53:54,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 1391  (26.0):  70%|   | 1391/2000 [2:04:32<53:50,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 1392  (26.0):  70%|   | 1392/2000 [2:04:38<53:42,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 1393  (26.0):  70%|   | 1393/2000 [2:04:43<53:36,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 1394  (26.0):  70%|   | 1394/2000 [2:04:48<53:33,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 1395  (25.9):  70%|   | 1395/2000 [2:04:54<53:27,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 362 / 1396  (25.9):  70%|   | 1396/2000 [2:04:59<53:24,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 363 / 1397  (26.0):  70%|   | 1397/2000 [2:05:04<53:21,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 364 / 1398  (26.0):  70%|   | 1398/2000 [2:05:10<53:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 364 / 1399  (26.0):  70%|   | 1399/2000 [2:05:15<53:09,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1400  (26.1):  70%|   | 1400/2000 [2:05:20<53:01,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1401  (26.1):  70%|   | 1401/2000 [2:05:25<52:53,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1402  (26.0):  70%|   | 1402/2000 [2:05:31<52:48,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1403  (26.0):  70%|   | 1403/2000 [2:05:36<52:44,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1404  (26.0):  70%|   | 1404/2000 [2:05:41<52:38,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1405  (26.0):  70%|   | 1405/2000 [2:05:47<52:34,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1406  (26.0):  70%|   | 1406/2000 [2:05:52<52:27,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1407  (25.9):  70%|   | 1407/2000 [2:05:57<52:22,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1408  (25.9):  70%|   | 1408/2000 [2:06:03<52:20,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 365 / 1409  (25.9):  70%|   | 1409/2000 [2:06:08<52:16,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 366 / 1410  (26.0):  70%|   | 1410/2000 [2:06:13<52:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 366 / 1411  (25.9):  71%|   | 1411/2000 [2:06:18<52:06,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 366 / 1412  (25.9):  71%|   | 1412/2000 [2:06:24<52:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 366 / 1413  (25.9):  71%|   | 1413/2000 [2:06:29<51:57,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1414  (26.0):  71%|   | 1414/2000 [2:06:34<51:54,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1415  (25.9):  71%|   | 1415/2000 [2:06:40<51:50,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1416  (25.9):  71%|   | 1416/2000 [2:06:45<51:44,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1417  (25.9):  71%|   | 1417/2000 [2:06:50<51:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1418  (25.9):  71%|   | 1418/2000 [2:06:56<51:29,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1419  (25.9):  71%|   | 1419/2000 [2:07:01<51:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1420  (25.8):  71%|   | 1420/2000 [2:07:06<51:18,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1421  (25.8):  71%|   | 1421/2000 [2:07:12<51:12,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 367 / 1422  (25.8):  71%|   | 1422/2000 [2:07:17<51:06,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 1423  (25.9):  71%|   | 1423/2000 [2:07:22<51:04,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 1424  (25.8):  71%|   | 1424/2000 [2:07:28<50:58,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 1425  (25.8):  71%|  | 1425/2000 [2:07:33<50:50,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 1426  (25.8):  71%|  | 1426/2000 [2:07:38<50:45,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 368 / 1427  (25.8):  71%|  | 1427/2000 [2:07:43<50:41,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1428  (25.8):  71%|  | 1428/2000 [2:07:49<50:37,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1429  (25.8):  71%|  | 1429/2000 [2:07:54<50:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1430  (25.8):  72%|  | 1430/2000 [2:07:59<50:26,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1431  (25.8):  72%|  | 1431/2000 [2:08:05<50:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1432  (25.8):  72%|  | 1432/2000 [2:08:10<50:16,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1433  (25.8):  72%|  | 1433/2000 [2:08:15<50:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1434  (25.7):  72%|  | 1434/2000 [2:08:21<50:04,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1435  (25.7):  72%|  | 1435/2000 [2:08:26<49:59,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1436  (25.7):  72%|  | 1436/2000 [2:08:31<49:53,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 369 / 1437  (25.7):  72%|  | 1437/2000 [2:08:37<49:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 1438  (25.7):  72%|  | 1438/2000 [2:08:42<49:43,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 1439  (25.7):  72%|  | 1439/2000 [2:08:47<49:37,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 1440  (25.7):  72%|  | 1440/2000 [2:08:52<49:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 1441  (25.7):  72%|  | 1441/2000 [2:08:58<49:26,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 370 / 1442  (25.7):  72%|  | 1442/2000 [2:09:03<49:20,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 371 / 1443  (25.7):  72%|  | 1443/2000 [2:09:08<49:15,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 371 / 1444  (25.7):  72%|  | 1444/2000 [2:09:14<49:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 1445  (25.7):  72%|  | 1445/2000 [2:09:19<49:04,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 372 / 1446  (25.7):  72%|  | 1446/2000 [2:09:24<48:59,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1447  (25.8):  72%|  | 1447/2000 [2:09:30<48:51,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1448  (25.8):  72%|  | 1448/2000 [2:09:35<48:46,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1449  (25.7):  72%|  | 1449/2000 [2:09:40<48:39,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1450  (25.7):  72%|  | 1450/2000 [2:09:45<48:35,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1451  (25.7):  73%|  | 1451/2000 [2:09:51<48:30,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1452  (25.7):  73%|  | 1452/2000 [2:09:56<48:27,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1453  (25.7):  73%|  | 1453/2000 [2:10:01<48:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1454  (25.7):  73%|  | 1454/2000 [2:10:07<48:18,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1455  (25.6):  73%|  | 1455/2000 [2:10:12<48:15,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 373 / 1456  (25.6):  73%|  | 1456/2000 [2:10:17<48:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1457  (25.7):  73%|  | 1457/2000 [2:10:23<48:03,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1458  (25.7):  73%|  | 1458/2000 [2:10:28<47:56,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1459  (25.6):  73%|  | 1459/2000 [2:10:33<47:50,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1460  (25.6):  73%|  | 1460/2000 [2:10:39<47:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1461  (25.6):  73%|  | 1461/2000 [2:10:44<47:39,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1462  (25.6):  73%|  | 1462/2000 [2:10:49<47:36,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1463  (25.6):  73%|  | 1463/2000 [2:10:54<47:33,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1464  (25.5):  73%|  | 1464/2000 [2:11:00<47:30,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1465  (25.5):  73%|  | 1465/2000 [2:11:05<47:24,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 374 / 1466  (25.5):  73%|  | 1466/2000 [2:11:10<47:18,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 375 / 1467  (25.6):  73%|  | 1467/2000 [2:11:16<47:10,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 376 / 1468  (25.6):  73%|  | 1468/2000 [2:11:21<47:05,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 1469  (25.7):  73%|  | 1469/2000 [2:11:26<47:00,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 377 / 1470  (25.6):  74%|  | 1470/2000 [2:11:32<46:57,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 378 / 1471  (25.7):  74%|  | 1471/2000 [2:11:37<46:49,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 378 / 1472  (25.7):  74%|  | 1472/2000 [2:11:42<46:45,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 378 / 1473  (25.7):  74%|  | 1473/2000 [2:11:48<46:41,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 1474  (25.7):  74%|  | 1474/2000 [2:11:53<46:36,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 379 / 1475  (25.7):  74%|  | 1475/2000 [2:11:58<46:33,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1476  (25.7):  74%|  | 1476/2000 [2:12:04<46:25,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1477  (25.7):  74%|  | 1477/2000 [2:12:09<46:19,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1478  (25.7):  74%|  | 1478/2000 [2:12:14<46:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1479  (25.7):  74%|  | 1479/2000 [2:12:20<46:10,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1480  (25.7):  74%|  | 1480/2000 [2:12:25<46:04,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1481  (25.7):  74%|  | 1481/2000 [2:12:30<45:58,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1482  (25.6):  74%|  | 1482/2000 [2:12:35<45:52,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 380 / 1483  (25.6):  74%|  | 1483/2000 [2:12:41<45:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 381 / 1484  (25.7):  74%|  | 1484/2000 [2:12:46<45:40,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 382 / 1485  (25.7):  74%|  | 1485/2000 [2:12:51<45:35,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 1486  (25.8):  74%|  | 1486/2000 [2:12:57<45:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 383 / 1487  (25.8):  74%|  | 1487/2000 [2:13:02<45:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 1488  (25.8):  74%|  | 1488/2000 [2:13:07<45:16,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 1489  (25.8):  74%|  | 1489/2000 [2:13:13<45:09,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 384 / 1490  (25.8):  74%|  | 1490/2000 [2:13:18<45:03,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1491  (25.8):  75%|  | 1491/2000 [2:13:23<44:59,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1492  (25.8):  75%|  | 1492/2000 [2:13:29<44:56,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1493  (25.8):  75%|  | 1493/2000 [2:13:34<44:55,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1494  (25.8):  75%|  | 1494/2000 [2:13:39<44:50,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1495  (25.8):  75%|  | 1495/2000 [2:13:45<44:44,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1496  (25.7):  75%|  | 1496/2000 [2:13:50<44:37,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1497  (25.7):  75%|  | 1497/2000 [2:13:55<44:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1498  (25.7):  75%|  | 1498/2000 [2:14:00<44:29,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 385 / 1499  (25.7):  75%|  | 1499/2000 [2:14:06<44:22,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 1500  (25.7):  75%|  | 1500/2000 [2:14:11<44:14,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 1501  (25.7):  75%|  | 1501/2000 [2:14:16<44:07,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 1502  (25.7):  75%|  | 1502/2000 [2:14:22<44:02,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 1503  (25.7):  75%|  | 1503/2000 [2:14:27<43:57,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 386 / 1504  (25.7):  75%|  | 1504/2000 [2:14:32<43:51,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 387 / 1505  (25.7):  75%|  | 1505/2000 [2:14:38<43:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 388 / 1506  (25.8):  75%|  | 1506/2000 [2:14:43<43:44,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 388 / 1507  (25.7):  75%|  | 1507/2000 [2:14:48<43:38,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 388 / 1508  (25.7):  75%|  | 1508/2000 [2:14:54<43:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 389 / 1509  (25.8):  75%|  | 1509/2000 [2:14:59<43:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 390 / 1510  (25.8):  76%|  | 1510/2000 [2:15:04<43:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 390 / 1511  (25.8):  76%|  | 1511/2000 [2:15:09<43:19,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 391 / 1512  (25.9):  76%|  | 1512/2000 [2:15:15<43:13,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 391 / 1513  (25.8):  76%|  | 1513/2000 [2:15:20<43:10,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 1514  (25.9):  76%|  | 1514/2000 [2:15:25<43:05,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 1515  (25.9):  76%|  | 1515/2000 [2:15:31<42:56,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 392 / 1516  (25.9):  76%|  | 1516/2000 [2:15:36<42:49,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 1517  (25.9):  76%|  | 1517/2000 [2:15:41<42:43,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 1518  (25.9):  76%|  | 1518/2000 [2:15:47<42:38,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 1519  (25.9):  76%|  | 1519/2000 [2:15:52<42:32,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 1520  (25.9):  76%|  | 1520/2000 [2:15:57<42:27,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 393 / 1521  (25.8):  76%|  | 1521/2000 [2:16:03<43:34,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1522  (25.9):  76%|  | 1522/2000 [2:16:08<43:21,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1523  (25.9):  76%|  | 1523/2000 [2:16:14<43:05,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1524  (25.9):  76%|  | 1524/2000 [2:16:19<42:50,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1525  (25.8):  76%|  | 1525/2000 [2:16:25<42:36,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1526  (25.8):  76%|  | 1526/2000 [2:16:30<42:27,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1527  (25.8):  76%|  | 1527/2000 [2:16:35<42:18,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1528  (25.8):  76%|  | 1528/2000 [2:16:41<42:10,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1529  (25.8):  76%|  | 1529/2000 [2:16:46<42:04,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 394 / 1530  (25.8):  76%|  | 1530/2000 [2:16:51<41:55,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 395 / 1531  (25.8):  77%|  | 1531/2000 [2:16:57<41:47,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 1532  (25.8):  77%|  | 1532/2000 [2:17:02<41:40,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 1533  (25.8):  77%|  | 1533/2000 [2:17:07<41:36,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 1534  (25.8):  77%|  | 1534/2000 [2:17:13<41:30,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 1535  (25.8):  77%|  | 1535/2000 [2:17:18<41:24,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 396 / 1536  (25.8):  77%|  | 1536/2000 [2:17:23<41:17,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 397 / 1537  (25.8):  77%|  | 1537/2000 [2:17:29<41:13,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 398 / 1538  (25.9):  77%|  | 1538/2000 [2:17:34<41:08,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 398 / 1539  (25.9):  77%|  | 1539/2000 [2:17:39<41:01,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 398 / 1540  (25.8):  77%|  | 1540/2000 [2:17:45<40:55,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 1541  (25.9):  77%|  | 1541/2000 [2:17:50<40:49,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 1542  (25.9):  77%|  | 1542/2000 [2:17:55<40:43,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 399 / 1543  (25.9):  77%|  | 1543/2000 [2:18:01<40:37,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 400 / 1544  (25.9):  77%|  | 1544/2000 [2:18:06<40:34,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 400 / 1545  (25.9):  77%|  | 1545/2000 [2:18:11<40:29,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 1546  (25.9):  77%|  | 1546/2000 [2:18:17<40:22,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 1547  (25.9):  77%|  | 1547/2000 [2:18:22<40:18,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 401 / 1548  (25.9):  77%|  | 1548/2000 [2:18:27<40:11,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 402 / 1549  (26.0):  77%|  | 1549/2000 [2:18:33<40:06,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 403 / 1550  (26.0):  78%|  | 1550/2000 [2:18:38<40:01,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 403 / 1551  (26.0):  78%|  | 1551/2000 [2:18:43<39:56,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 404 / 1552  (26.0):  78%|  | 1552/2000 [2:18:49<39:51,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 404 / 1553  (26.0):  78%|  | 1553/2000 [2:18:54<39:46,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 404 / 1554  (26.0):  78%|  | 1554/2000 [2:18:59<39:42,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1555  (26.0):  78%|  | 1555/2000 [2:19:05<39:36,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1556  (26.0):  78%|  | 1556/2000 [2:19:10<39:32,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1557  (26.0):  78%|  | 1557/2000 [2:19:15<39:26,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1558  (26.0):  78%|  | 1558/2000 [2:19:21<39:18,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1559  (26.0):  78%|  | 1559/2000 [2:19:26<39:13,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1560  (26.0):  78%|  | 1560/2000 [2:19:31<39:06,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1561  (25.9):  78%|  | 1561/2000 [2:19:37<39:02,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1562  (25.9):  78%|  | 1562/2000 [2:19:42<38:56,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1563  (25.9):  78%|  | 1563/2000 [2:19:47<38:50,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1564  (25.9):  78%|  | 1564/2000 [2:19:53<38:44,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1565  (25.9):  78%|  | 1565/2000 [2:19:58<38:40,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1566  (25.9):  78%|  | 1566/2000 [2:20:03<38:34,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1567  (25.8):  78%|  | 1567/2000 [2:20:09<38:29,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1568  (25.8):  78%|  | 1568/2000 [2:20:14<38:23,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1569  (25.8):  78%|  | 1569/2000 [2:20:19<38:18,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1570  (25.8):  78%|  | 1570/2000 [2:20:25<38:13,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1571  (25.8):  79%|  | 1571/2000 [2:20:30<38:08,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1572  (25.8):  79%|  | 1572/2000 [2:20:35<38:03,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1573  (25.7):  79%|  | 1573/2000 [2:20:41<37:59,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1574  (25.7):  79%|  | 1574/2000 [2:20:46<37:52,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 405 / 1575  (25.7):  79%|  | 1575/2000 [2:20:51<37:46,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 406 / 1576  (25.8):  79%|  | 1576/2000 [2:20:57<37:44,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 406 / 1577  (25.7):  79%|  | 1577/2000 [2:21:02<37:39,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 1578  (25.8):  79%|  | 1578/2000 [2:21:07<37:35,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 1579  (25.8):  79%|  | 1579/2000 [2:21:13<37:29,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 1580  (25.8):  79%|  | 1580/2000 [2:21:18<37:22,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 1581  (25.7):  79%|  | 1581/2000 [2:21:23<37:16,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 1582  (25.7):  79%|  | 1582/2000 [2:21:29<37:10,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 1583  (25.7):  79%|  | 1583/2000 [2:21:34<37:05,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 407 / 1584  (25.7):  79%|  | 1584/2000 [2:21:39<36:58,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1585  (25.7):  79%|  | 1585/2000 [2:21:45<36:52,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1586  (25.7):  79%|  | 1586/2000 [2:21:50<36:46,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1587  (25.7):  79%|  | 1587/2000 [2:21:55<36:41,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1588  (25.7):  79%|  | 1588/2000 [2:22:01<36:35,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1589  (25.7):  79%|  | 1589/2000 [2:22:06<36:30,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1590  (25.7):  80%|  | 1590/2000 [2:22:11<36:26,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1591  (25.6):  80%|  | 1591/2000 [2:22:17<36:19,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1592  (25.6):  80%|  | 1592/2000 [2:22:22<36:14,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1593  (25.6):  80%|  | 1593/2000 [2:22:27<36:07,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1594  (25.6):  80%|  | 1594/2000 [2:22:33<36:02,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1595  (25.6):  80%|  | 1595/2000 [2:22:38<35:58,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 408 / 1596  (25.6):  80%|  | 1596/2000 [2:22:43<35:54,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 409 / 1597  (25.6):  80%|  | 1597/2000 [2:22:49<35:48,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 409 / 1598  (25.6):  80%|  | 1598/2000 [2:22:54<35:43,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 410 / 1599  (25.6):  80%|  | 1599/2000 [2:22:59<35:37,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 410 / 1600  (25.6):  80%|  | 1600/2000 [2:23:05<35:29,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 410 / 1601  (25.6):  80%|  | 1601/2000 [2:23:10<35:25,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 411 / 1602  (25.7):  80%|  | 1602/2000 [2:23:15<35:20,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 411 / 1603  (25.6):  80%|  | 1603/2000 [2:23:21<35:16,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 411 / 1604  (25.6):  80%|  | 1604/2000 [2:23:26<35:12,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 412 / 1605  (25.7):  80%|  | 1605/2000 [2:23:31<35:05,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 413 / 1606  (25.7):  80%|  | 1606/2000 [2:23:37<34:59,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 414 / 1607  (25.8):  80%|  | 1607/2000 [2:23:42<34:55,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 414 / 1608  (25.7):  80%|  | 1608/2000 [2:23:47<34:49,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 414 / 1609  (25.7):  80%|  | 1609/2000 [2:23:53<34:44,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 415 / 1610  (25.8):  80%|  | 1610/2000 [2:23:58<34:40,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 415 / 1611  (25.8):  81%|  | 1611/2000 [2:24:03<34:36,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 415 / 1612  (25.7):  81%|  | 1612/2000 [2:24:09<34:31,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 416 / 1613  (25.8):  81%|  | 1613/2000 [2:24:14<34:26,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 417 / 1614  (25.8):  81%|  | 1614/2000 [2:24:19<34:21,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 417 / 1615  (25.8):  81%|  | 1615/2000 [2:24:25<34:16,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 418 / 1616  (25.9):  81%|  | 1616/2000 [2:24:30<34:10,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 1617  (25.9):  81%|  | 1617/2000 [2:24:35<34:04,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 419 / 1618  (25.9):  81%|  | 1618/2000 [2:24:41<33:57,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 420 / 1619  (25.9):  81%|  | 1619/2000 [2:24:46<33:53,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 420 / 1620  (25.9):  81%|  | 1620/2000 [2:24:51<33:48,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 420 / 1621  (25.9):  81%|  | 1621/2000 [2:24:57<33:43,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1622  (26.0):  81%|  | 1622/2000 [2:25:02<33:38,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1623  (25.9):  81%|  | 1623/2000 [2:25:07<33:34,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1624  (25.9):  81%|  | 1624/2000 [2:25:13<33:29,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1625  (25.9):  81%| | 1625/2000 [2:25:18<33:22,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1626  (25.9):  81%| | 1626/2000 [2:25:24<33:17,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1627  (25.9):  81%| | 1627/2000 [2:25:29<33:10,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1628  (25.9):  81%| | 1628/2000 [2:25:34<33:05,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 421 / 1629  (25.8):  81%| | 1629/2000 [2:25:40<33:00,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 1630  (25.9):  82%| | 1630/2000 [2:25:45<32:55,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 422 / 1631  (25.9):  82%| | 1631/2000 [2:25:50<32:50,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 423 / 1632  (25.9):  82%| | 1632/2000 [2:25:56<32:43,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 423 / 1633  (25.9):  82%| | 1633/2000 [2:26:01<32:36,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1634  (25.9):  82%| | 1634/2000 [2:26:06<32:31,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 424 / 1635  (25.9):  82%| | 1635/2000 [2:26:12<32:26,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 425 / 1636  (26.0):  82%| | 1636/2000 [2:26:17<32:19,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 425 / 1637  (26.0):  82%| | 1637/2000 [2:26:22<32:13,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 425 / 1638  (25.9):  82%| | 1638/2000 [2:26:27<32:08,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 426 / 1639  (26.0):  82%| | 1639/2000 [2:26:33<32:02,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1640  (26.0):  82%| | 1640/2000 [2:26:38<31:57,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 427 / 1641  (26.0):  82%| | 1641/2000 [2:26:43<31:52,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1642  (26.1):  82%| | 1642/2000 [2:26:49<31:47,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1643  (26.0):  82%| | 1643/2000 [2:26:54<31:42,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 428 / 1644  (26.0):  82%| | 1644/2000 [2:26:59<31:36,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1645  (26.1):  82%| | 1645/2000 [2:27:05<31:31,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 429 / 1646  (26.1):  82%| | 1646/2000 [2:27:10<31:27,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 430 / 1647  (26.1):  82%| | 1647/2000 [2:27:15<31:22,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1648  (26.2):  82%| | 1648/2000 [2:27:21<31:15,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1649  (26.1):  82%| | 1649/2000 [2:27:26<31:11,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1650  (26.1):  82%| | 1650/2000 [2:27:31<31:06,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1651  (26.1):  83%| | 1651/2000 [2:27:37<31:00,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1652  (26.1):  83%| | 1652/2000 [2:27:42<30:54,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 431 / 1653  (26.1):  83%| | 1653/2000 [2:27:47<30:49,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1654  (26.1):  83%| | 1654/2000 [2:27:53<30:43,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1655  (26.1):  83%| | 1655/2000 [2:27:58<30:39,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1656  (26.1):  83%| | 1656/2000 [2:28:03<30:34,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1657  (26.1):  83%| | 1657/2000 [2:28:09<30:27,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1658  (26.1):  83%| | 1658/2000 [2:28:14<30:24,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1659  (26.0):  83%| | 1659/2000 [2:28:19<30:19,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 432 / 1660  (26.0):  83%| | 1660/2000 [2:28:25<30:14,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 433 / 1661  (26.1):  83%| | 1661/2000 [2:28:30<30:08,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 434 / 1662  (26.1):  83%| | 1662/2000 [2:28:35<30:03,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1663  (26.2):  83%| | 1663/2000 [2:28:41<29:57,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1664  (26.1):  83%| | 1664/2000 [2:28:46<29:52,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1665  (26.1):  83%| | 1665/2000 [2:28:51<29:48,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1666  (26.1):  83%| | 1666/2000 [2:28:57<29:43,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1667  (26.1):  83%| | 1667/2000 [2:29:02<29:36,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1668  (26.1):  83%| | 1668/2000 [2:29:07<29:31,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 435 / 1669  (26.1):  83%| | 1669/2000 [2:29:13<29:26,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 436 / 1670  (26.1):  84%| | 1670/2000 [2:29:18<29:21,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1671  (26.2):  84%| | 1671/2000 [2:29:23<29:16,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1672  (26.1):  84%| | 1672/2000 [2:29:29<29:10,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1673  (26.1):  84%| | 1673/2000 [2:29:34<29:04,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 437 / 1674  (26.1):  84%| | 1674/2000 [2:29:39<28:59,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 438 / 1675  (26.1):  84%| | 1675/2000 [2:29:45<28:54,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 438 / 1676  (26.1):  84%| | 1676/2000 [2:29:50<28:49,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1677  (26.2):  84%| | 1677/2000 [2:29:55<28:43,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1678  (26.2):  84%| | 1678/2000 [2:30:01<28:39,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1679  (26.1):  84%| | 1679/2000 [2:30:06<28:34,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1680  (26.1):  84%| | 1680/2000 [2:30:12<28:27,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1681  (26.1):  84%| | 1681/2000 [2:30:17<28:20,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1682  (26.1):  84%| | 1682/2000 [2:30:22<28:13,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 439 / 1683  (26.1):  84%| | 1683/2000 [2:30:27<28:08,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1684  (26.1):  84%| | 1684/2000 [2:30:33<28:02,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1685  (26.1):  84%| | 1685/2000 [2:30:38<27:59,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 440 / 1686  (26.1):  84%| | 1686/2000 [2:30:43<27:53,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 441 / 1687  (26.1):  84%| | 1687/2000 [2:30:49<27:49,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 441 / 1688  (26.1):  84%| | 1688/2000 [2:30:54<27:43,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 441 / 1689  (26.1):  84%| | 1689/2000 [2:30:59<27:38,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 442 / 1690  (26.2):  84%| | 1690/2000 [2:31:05<27:35,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 442 / 1691  (26.1):  85%| | 1691/2000 [2:31:10<27:29,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 1692  (26.2):  85%| | 1692/2000 [2:31:15<27:23,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 1693  (26.2):  85%| | 1693/2000 [2:31:21<27:16,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 1694  (26.2):  85%| | 1694/2000 [2:31:26<27:09,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 1695  (26.1):  85%| | 1695/2000 [2:31:31<27:04,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 443 / 1696  (26.1):  85%| | 1696/2000 [2:31:37<26:59,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1697  (26.2):  85%| | 1697/2000 [2:31:42<26:54,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1698  (26.1):  85%| | 1698/2000 [2:31:47<26:48,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1699  (26.1):  85%| | 1699/2000 [2:31:53<26:41,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1700  (26.1):  85%| | 1700/2000 [2:31:58<26:37,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1701  (26.1):  85%| | 1701/2000 [2:32:03<26:31,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1702  (26.1):  85%| | 1702/2000 [2:32:09<26:27,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 444 / 1703  (26.1):  85%| | 1703/2000 [2:32:14<26:22,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1704  (26.1):  85%| | 1704/2000 [2:32:19<26:16,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 445 / 1705  (26.1):  85%| | 1705/2000 [2:32:25<26:11,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 446 / 1706  (26.1):  85%| | 1706/2000 [2:32:30<26:06,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 446 / 1707  (26.1):  85%| | 1707/2000 [2:32:35<26:00,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 446 / 1708  (26.1):  85%| | 1708/2000 [2:32:41<25:55,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 446 / 1709  (26.1):  85%| | 1709/2000 [2:32:46<25:49,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1710  (26.1):  86%| | 1710/2000 [2:32:51<25:42,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1711  (26.1):  86%| | 1711/2000 [2:32:57<25:38,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1712  (26.1):  86%| | 1712/2000 [2:33:02<25:33,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1713  (26.1):  86%| | 1713/2000 [2:33:07<25:28,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1714  (26.1):  86%| | 1714/2000 [2:33:13<25:22,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1715  (26.1):  86%| | 1715/2000 [2:33:18<25:17,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1716  (26.0):  86%| | 1716/2000 [2:33:23<25:12,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1717  (26.0):  86%| | 1717/2000 [2:33:29<25:07,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1718  (26.0):  86%| | 1718/2000 [2:33:34<25:02,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 447 / 1719  (26.0):  86%| | 1719/2000 [2:33:39<24:56,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 448 / 1720  (26.0):  86%| | 1720/2000 [2:33:45<24:50,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 448 / 1721  (26.0):  86%| | 1721/2000 [2:33:50<24:45,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 449 / 1722  (26.1):  86%| | 1722/2000 [2:33:55<24:40,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 449 / 1723  (26.1):  86%| | 1723/2000 [2:34:01<24:36,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 449 / 1724  (26.0):  86%| | 1724/2000 [2:34:06<24:31,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 449 / 1725  (26.0):  86%| | 1725/2000 [2:34:11<24:25,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 449 / 1726  (26.0):  86%| | 1726/2000 [2:34:17<24:19,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 449 / 1727  (26.0):  86%| | 1727/2000 [2:34:22<24:13,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1728  (26.0):  86%| | 1728/2000 [2:34:27<24:08,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1729  (26.0):  86%| | 1729/2000 [2:34:33<24:02,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1730  (26.0):  86%| | 1730/2000 [2:34:38<23:57,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 450 / 1731  (26.0):  87%| | 1731/2000 [2:34:43<23:51,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 1732  (26.0):  87%| | 1732/2000 [2:34:48<23:46,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 1733  (26.0):  87%| | 1733/2000 [2:34:54<23:41,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 1734  (26.0):  87%| | 1734/2000 [2:34:59<23:38,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 1735  (26.0):  87%| | 1735/2000 [2:35:04<23:31,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 451 / 1736  (26.0):  87%| | 1736/2000 [2:35:10<23:24,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1737  (26.0):  87%| | 1737/2000 [2:35:15<23:19,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1738  (26.0):  87%| | 1738/2000 [2:35:20<23:13,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1739  (26.0):  87%| | 1739/2000 [2:35:26<23:08,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 452 / 1740  (26.0):  87%| | 1740/2000 [2:35:31<23:03,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 453 / 1741  (26.0):  87%| | 1741/2000 [2:35:36<22:59,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 454 / 1742  (26.1):  87%| | 1742/2000 [2:35:42<22:53,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 454 / 1743  (26.0):  87%| | 1743/2000 [2:35:47<22:48,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1744  (26.1):  87%| | 1744/2000 [2:35:52<22:42,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1745  (26.1):  87%| | 1745/2000 [2:35:58<22:36,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1746  (26.1):  87%| | 1746/2000 [2:36:03<22:30,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1747  (26.0):  87%| | 1747/2000 [2:36:08<22:25,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1748  (26.0):  87%| | 1748/2000 [2:36:14<22:20,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 455 / 1749  (26.0):  87%| | 1749/2000 [2:36:19<22:15,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 456 / 1750  (26.1):  88%| | 1750/2000 [2:36:24<22:10,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 456 / 1751  (26.0):  88%| | 1751/2000 [2:36:30<22:06,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 457 / 1752  (26.1):  88%| | 1752/2000 [2:36:35<22:00,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 457 / 1753  (26.1):  88%| | 1753/2000 [2:36:40<21:54,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 457 / 1754  (26.1):  88%| | 1754/2000 [2:36:46<21:50,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 457 / 1755  (26.0):  88%| | 1755/2000 [2:36:51<21:44,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 457 / 1756  (26.0):  88%| | 1756/2000 [2:36:56<21:39,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1757  (26.1):  88%| | 1757/2000 [2:37:02<21:34,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 458 / 1758  (26.1):  88%| | 1758/2000 [2:37:07<21:28,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 459 / 1759  (26.1):  88%| | 1759/2000 [2:37:12<21:22,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 459 / 1760  (26.1):  88%| | 1760/2000 [2:37:18<21:17,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1761  (26.1):  88%| | 1761/2000 [2:37:23<21:12,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1762  (26.1):  88%| | 1762/2000 [2:37:28<21:08,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 460 / 1763  (26.1):  88%| | 1763/2000 [2:37:34<21:03,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 461 / 1764  (26.1):  88%| | 1764/2000 [2:37:39<20:58,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 461 / 1765  (26.1):  88%| | 1765/2000 [2:37:44<20:52,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 461 / 1766  (26.1):  88%| | 1766/2000 [2:37:50<20:46,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 462 / 1767  (26.1):  88%| | 1767/2000 [2:37:55<20:40,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 462 / 1768  (26.1):  88%| | 1768/2000 [2:38:00<20:35,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 463 / 1769  (26.2):  88%| | 1769/2000 [2:38:05<20:29,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 463 / 1770  (26.2):  88%| | 1770/2000 [2:38:11<20:23,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 463 / 1771  (26.1):  89%| | 1771/2000 [2:38:16<20:18,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 463 / 1772  (26.1):  89%| | 1772/2000 [2:38:21<20:13,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 463 / 1773  (26.1):  89%| | 1773/2000 [2:38:27<20:07,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1774  (26.2):  89%| | 1774/2000 [2:38:32<20:03,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1775  (26.1):  89%| | 1775/2000 [2:38:37<19:59,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1776  (26.1):  89%| | 1776/2000 [2:38:43<19:53,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1777  (26.1):  89%| | 1777/2000 [2:38:48<19:49,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1778  (26.1):  89%| | 1778/2000 [2:38:53<19:44,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1779  (26.1):  89%| | 1779/2000 [2:38:59<19:39,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 464 / 1780  (26.1):  89%| | 1780/2000 [2:39:04<19:33,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1781  (26.1):  89%| | 1781/2000 [2:39:09<19:28,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1782  (26.1):  89%| | 1782/2000 [2:39:15<19:22,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1783  (26.1):  89%| | 1783/2000 [2:39:20<19:17,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 465 / 1784  (26.1):  89%| | 1784/2000 [2:39:25<19:11,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 466 / 1785  (26.1):  89%| | 1785/2000 [2:39:31<19:07,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 466 / 1786  (26.1):  89%| | 1786/2000 [2:39:36<19:01,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 466 / 1787  (26.1):  89%| | 1787/2000 [2:39:41<18:56,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 466 / 1788  (26.1):  89%| | 1788/2000 [2:39:47<18:51,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 467 / 1789  (26.1):  89%| | 1789/2000 [2:39:52<18:46,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1790  (26.1):  90%| | 1790/2000 [2:39:57<18:41,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1791  (26.1):  90%| | 1791/2000 [2:40:03<18:36,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1792  (26.1):  90%| | 1792/2000 [2:40:08<18:29,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1793  (26.1):  90%| | 1793/2000 [2:40:13<18:24,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1794  (26.1):  90%| | 1794/2000 [2:40:19<18:19,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1795  (26.1):  90%| | 1795/2000 [2:40:24<18:13,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1796  (26.1):  90%| | 1796/2000 [2:40:30<18:09,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1797  (26.0):  90%| | 1797/2000 [2:40:35<18:09,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1798  (26.0):  90%| | 1798/2000 [2:40:40<18:07,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1799  (26.0):  90%| | 1799/2000 [2:40:46<18:03,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1800  (26.0):  90%| | 1800/2000 [2:40:51<17:59,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1801  (26.0):  90%| | 1801/2000 [2:40:57<17:55,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1802  (26.0):  90%| | 1802/2000 [2:41:02<17:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1803  (26.0):  90%| | 1803/2000 [2:41:07<17:45,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1804  (25.9):  90%| | 1804/2000 [2:41:13<17:41,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1805  (25.9):  90%| | 1805/2000 [2:41:18<17:36,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1806  (25.9):  90%| | 1806/2000 [2:41:24<17:30,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1807  (25.9):  90%| | 1807/2000 [2:41:29<17:20,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1808  (25.9):  90%| | 1808/2000 [2:41:34<17:10,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 468 / 1809  (25.9):  90%| | 1809/2000 [2:41:40<17:02,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 469 / 1810  (25.9):  90%| | 1810/2000 [2:41:45<16:56,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1811  (26.0):  91%| | 1811/2000 [2:41:50<16:50,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1812  (25.9):  91%| | 1812/2000 [2:41:56<16:44,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1813  (25.9):  91%| | 1813/2000 [2:42:01<16:38,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1814  (25.9):  91%| | 1814/2000 [2:42:06<16:33,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1815  (25.9):  91%| | 1815/2000 [2:42:12<16:28,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1816  (25.9):  91%| | 1816/2000 [2:42:17<16:22,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1817  (25.9):  91%| | 1817/2000 [2:42:22<16:17,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1818  (25.9):  91%| | 1818/2000 [2:42:28<16:11,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1819  (25.8):  91%| | 1819/2000 [2:42:33<16:06,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1820  (25.8):  91%| | 1820/2000 [2:42:38<16:01,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 470 / 1821  (25.8):  91%| | 1821/2000 [2:42:44<15:55,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1822  (25.9):  91%| | 1822/2000 [2:42:49<15:51,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1823  (25.8):  91%| | 1823/2000 [2:42:54<15:46,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1824  (25.8):  91%| | 1824/2000 [2:43:00<15:40,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1825  (25.8):  91%|| 1825/2000 [2:43:05<15:34,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1826  (25.8):  91%|| 1826/2000 [2:43:10<15:28,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1827  (25.8):  91%|| 1827/2000 [2:43:16<15:22,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 471 / 1828  (25.8):  91%|| 1828/2000 [2:43:21<15:17,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 472 / 1829  (25.8):  91%|| 1829/2000 [2:43:26<15:13,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 472 / 1830  (25.8):  92%|| 1830/2000 [2:43:32<15:08,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 472 / 1831  (25.8):  92%|| 1831/2000 [2:43:37<15:02,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1832  (25.8):  92%|| 1832/2000 [2:43:42<14:56,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1833  (25.8):  92%|| 1833/2000 [2:43:48<14:50,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1834  (25.8):  92%|| 1834/2000 [2:43:53<14:45,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1835  (25.8):  92%|| 1835/2000 [2:43:58<14:40,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1836  (25.8):  92%|| 1836/2000 [2:44:04<14:35,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 473 / 1837  (25.7):  92%|| 1837/2000 [2:44:09<14:29,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 474 / 1838  (25.8):  92%|| 1838/2000 [2:44:14<14:23,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 474 / 1839  (25.8):  92%|| 1839/2000 [2:44:20<14:19,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 1840  (25.8):  92%|| 1840/2000 [2:44:25<14:13,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 1841  (25.8):  92%|| 1841/2000 [2:44:30<14:07,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 1842  (25.8):  92%|| 1842/2000 [2:44:36<14:02,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 1843  (25.8):  92%|| 1843/2000 [2:44:41<13:57,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 1844  (25.8):  92%|| 1844/2000 [2:44:46<13:52,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 1845  (25.7):  92%|| 1845/2000 [2:44:52<13:46,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 475 / 1846  (25.7):  92%|| 1846/2000 [2:44:57<13:41,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 476 / 1847  (25.8):  92%|| 1847/2000 [2:45:02<13:36,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 476 / 1848  (25.8):  92%|| 1848/2000 [2:45:08<13:31,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1849  (25.8):  92%|| 1849/2000 [2:45:13<13:26,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1850  (25.8):  92%|| 1850/2000 [2:45:19<13:21,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1851  (25.8):  93%|| 1851/2000 [2:45:24<13:16,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1852  (25.8):  93%|| 1852/2000 [2:45:29<13:10,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1853  (25.7):  93%|| 1853/2000 [2:45:35<13:04,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1854  (25.7):  93%|| 1854/2000 [2:45:40<12:59,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 477 / 1855  (25.7):  93%|| 1855/2000 [2:45:45<12:54,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 478 / 1856  (25.8):  93%|| 1856/2000 [2:45:51<12:48,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 478 / 1857  (25.7):  93%|| 1857/2000 [2:45:56<12:43,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 478 / 1858  (25.7):  93%|| 1858/2000 [2:46:01<12:38,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 478 / 1859  (25.7):  93%|| 1859/2000 [2:46:07<12:33,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1860  (25.8):  93%|| 1860/2000 [2:46:12<12:28,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1861  (25.7):  93%|| 1861/2000 [2:46:17<12:22,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1862  (25.7):  93%|| 1862/2000 [2:46:23<12:17,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1863  (25.7):  93%|| 1863/2000 [2:46:28<12:11,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1864  (25.7):  93%|| 1864/2000 [2:46:33<12:06,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1865  (25.7):  93%|| 1865/2000 [2:46:39<12:01,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1866  (25.7):  93%|| 1866/2000 [2:46:44<11:55,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1867  (25.7):  93%|| 1867/2000 [2:46:49<11:50,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1868  (25.6):  93%|| 1868/2000 [2:46:55<11:44,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1869  (25.6):  93%|| 1869/2000 [2:47:00<11:39,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 479 / 1870  (25.6):  94%|| 1870/2000 [2:47:05<11:33,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1871  (25.7):  94%|| 1871/2000 [2:47:11<11:28,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1872  (25.6):  94%|| 1872/2000 [2:47:16<11:23,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1873  (25.6):  94%|| 1873/2000 [2:47:21<11:17,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1874  (25.6):  94%|| 1874/2000 [2:47:27<11:12,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1875  (25.6):  94%|| 1875/2000 [2:47:32<11:07,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1876  (25.6):  94%|| 1876/2000 [2:47:37<11:01,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 480 / 1877  (25.6):  94%|| 1877/2000 [2:47:43<10:57,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 1878  (25.6):  94%|| 1878/2000 [2:47:48<10:52,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 481 / 1879  (25.6):  94%|| 1879/2000 [2:47:53<10:47,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 482 / 1880  (25.6):  94%|| 1880/2000 [2:47:59<10:42,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 482 / 1881  (25.6):  94%|| 1881/2000 [2:48:04<10:37,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 483 / 1882  (25.7):  94%|| 1882/2000 [2:48:09<10:31,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 484 / 1883  (25.7):  94%|| 1883/2000 [2:48:15<10:26,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 484 / 1884  (25.7):  94%|| 1884/2000 [2:48:20<10:21,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1885  (25.7):  94%|| 1885/2000 [2:48:26<10:14,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1886  (25.7):  94%|| 1886/2000 [2:48:31<10:10,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1887  (25.7):  94%|| 1887/2000 [2:48:36<10:05,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1888  (25.7):  94%|| 1888/2000 [2:48:42<09:59,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1889  (25.7):  94%|| 1889/2000 [2:48:47<09:54,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1890  (25.7):  94%|| 1890/2000 [2:48:52<09:49,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1891  (25.6):  95%|| 1891/2000 [2:48:58<09:43,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1892  (25.6):  95%|| 1892/2000 [2:49:03<09:38,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1893  (25.6):  95%|| 1893/2000 [2:49:08<09:32,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1894  (25.6):  95%|| 1894/2000 [2:49:14<09:27,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1895  (25.6):  95%|| 1895/2000 [2:49:19<09:22,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1896  (25.6):  95%|| 1896/2000 [2:49:24<09:16,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 485 / 1897  (25.6):  95%|| 1897/2000 [2:49:30<09:11,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 486 / 1898  (25.6):  95%|| 1898/2000 [2:49:35<09:05,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 486 / 1899  (25.6):  95%|| 1899/2000 [2:49:40<09:00,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 487 / 1900  (25.6):  95%|| 1900/2000 [2:49:46<08:55,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 487 / 1901  (25.6):  95%|| 1901/2000 [2:49:51<08:50,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 487 / 1902  (25.6):  95%|| 1902/2000 [2:49:57<08:45,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 487 / 1903  (25.6):  95%|| 1903/2000 [2:50:02<08:39,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1904  (25.6):  95%|| 1904/2000 [2:50:07<08:34,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1905  (25.6):  95%|| 1905/2000 [2:50:13<08:28,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1906  (25.6):  95%|| 1906/2000 [2:50:18<08:23,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1907  (25.6):  95%|| 1907/2000 [2:50:23<08:18,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1908  (25.6):  95%|| 1908/2000 [2:50:29<08:12,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1909  (25.6):  95%|| 1909/2000 [2:50:34<08:07,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1910  (25.5):  96%|| 1910/2000 [2:50:39<08:02,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 488 / 1911  (25.5):  96%|| 1911/2000 [2:50:45<07:57,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 489 / 1912  (25.6):  96%|| 1912/2000 [2:50:50<07:51,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 489 / 1913  (25.6):  96%|| 1913/2000 [2:50:56<07:45,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1914  (25.6):  96%|| 1914/2000 [2:51:01<07:40,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1915  (25.6):  96%|| 1915/2000 [2:51:06<07:35,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1916  (25.6):  96%|| 1916/2000 [2:51:12<07:29,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1917  (25.6):  96%|| 1917/2000 [2:51:17<07:24,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1918  (25.5):  96%|| 1918/2000 [2:51:22<07:19,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1919  (25.5):  96%|| 1919/2000 [2:51:28<07:13,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1920  (25.5):  96%|| 1920/2000 [2:51:33<07:08,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1921  (25.5):  96%|| 1921/2000 [2:51:38<07:02,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1922  (25.5):  96%|| 1922/2000 [2:51:44<06:57,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1923  (25.5):  96%|| 1923/2000 [2:51:49<06:52,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1924  (25.5):  96%|| 1924/2000 [2:51:54<06:47,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1925  (25.5):  96%|| 1925/2000 [2:52:00<06:41,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1926  (25.4):  96%|| 1926/2000 [2:52:05<06:36,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1927  (25.4):  96%|| 1927/2000 [2:52:10<06:30,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 490 / 1928  (25.4):  96%|| 1928/2000 [2:52:16<06:25,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 491 / 1929  (25.5):  96%|| 1929/2000 [2:52:21<06:20,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 491 / 1930  (25.4):  96%|| 1930/2000 [2:52:27<06:14,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 492 / 1931  (25.5):  97%|| 1931/2000 [2:52:32<06:09,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 1932  (25.5):  97%|| 1932/2000 [2:52:37<06:04,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 1933  (25.5):  97%|| 1933/2000 [2:52:43<05:58,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 1934  (25.5):  97%|| 1934/2000 [2:52:48<05:53,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 1935  (25.5):  97%|| 1935/2000 [2:52:53<05:48,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 1936  (25.5):  97%|| 1936/2000 [2:52:59<05:42,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 1937  (25.5):  97%|| 1937/2000 [2:53:04<05:37,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 493 / 1938  (25.4):  97%|| 1938/2000 [2:53:09<05:32,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 494 / 1939  (25.5):  97%|| 1939/2000 [2:53:15<05:26,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 494 / 1940  (25.5):  97%|| 1940/2000 [2:53:20<05:21,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1941  (25.5):  97%|| 1941/2000 [2:53:25<05:15,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1942  (25.5):  97%|| 1942/2000 [2:53:31<05:10,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1943  (25.5):  97%|| 1943/2000 [2:53:36<05:05,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1944  (25.5):  97%|| 1944/2000 [2:53:42<04:59,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1945  (25.4):  97%|| 1945/2000 [2:53:47<04:54,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1946  (25.4):  97%|| 1946/2000 [2:53:52<04:48,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1947  (25.4):  97%|| 1947/2000 [2:53:58<04:43,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1948  (25.4):  97%|| 1948/2000 [2:54:03<04:38,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 495 / 1949  (25.4):  97%|| 1949/2000 [2:54:08<04:32,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1950  (25.4):  98%|| 1950/2000 [2:54:14<04:27,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1951  (25.4):  98%|| 1951/2000 [2:54:19<04:22,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1952  (25.4):  98%|| 1952/2000 [2:54:24<04:16,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1953  (25.4):  98%|| 1953/2000 [2:54:30<04:11,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1954  (25.4):  98%|| 1954/2000 [2:54:35<04:06,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1955  (25.4):  98%|| 1955/2000 [2:54:40<04:00,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1956  (25.4):  98%|| 1956/2000 [2:54:46<03:55,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1957  (25.3):  98%|| 1957/2000 [2:54:51<03:50,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1958  (25.3):  98%|| 1958/2000 [2:54:56<03:44,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1959  (25.3):  98%|| 1959/2000 [2:55:02<03:39,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1960  (25.3):  98%|| 1960/2000 [2:55:07<03:34,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1961  (25.3):  98%|| 1961/2000 [2:55:13<03:28,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 496 / 1962  (25.3):  98%|| 1962/2000 [2:55:18<03:23,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1963  (25.3):  98%|| 1963/2000 [2:55:23<03:18,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1964  (25.3):  98%|| 1964/2000 [2:55:29<03:12,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1965  (25.3):  98%|| 1965/2000 [2:55:34<03:07,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1966  (25.3):  98%|| 1966/2000 [2:55:39<03:02,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1967  (25.3):  98%|| 1967/2000 [2:55:45<02:56,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 497 / 1968  (25.3):  98%|| 1968/2000 [2:55:50<02:51,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 498 / 1969  (25.3):  98%|| 1969/2000 [2:55:55<02:45,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 499 / 1970  (25.3):  98%|| 1970/2000 [2:56:01<02:40,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 499 / 1971  (25.3):  99%|| 1971/2000 [2:56:06<02:35,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1972  (25.4):  99%|| 1972/2000 [2:56:11<02:29,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1973  (25.3):  99%|| 1973/2000 [2:56:17<02:24,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1974  (25.3):  99%|| 1974/2000 [2:56:22<02:19,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1975  (25.3):  99%|| 1975/2000 [2:56:27<02:13,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 500 / 1976  (25.3):  99%|| 1976/2000 [2:56:33<02:08,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 501 / 1977  (25.3):  99%|| 1977/2000 [2:56:38<02:03,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 501 / 1978  (25.3):  99%|| 1978/2000 [2:56:44<01:57,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 501 / 1979  (25.3):  99%|| 1979/2000 [2:56:49<01:52,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 502 / 1980  (25.4):  99%|| 1980/2000 [2:56:54<01:47,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1981  (25.4):  99%|| 1981/2000 [2:57:00<01:41,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 503 / 1982  (25.4):  99%|| 1982/2000 [2:57:05<01:36,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1983  (25.4):  99%|| 1983/2000 [2:57:10<01:31,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1984  (25.4):  99%|| 1984/2000 [2:57:16<01:25,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1985  (25.4):  99%|| 1985/2000 [2:57:21<01:20,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1986  (25.4):  99%|| 1986/2000 [2:57:26<01:14,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1987  (25.4):  99%|| 1987/2000 [2:57:32<01:09,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1988  (25.4):  99%|| 1988/2000 [2:57:37<01:04,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1989  (25.3):  99%|| 1989/2000 [2:57:42<00:58,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1990  (25.3): 100%|| 1990/2000 [2:57:48<00:53,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 504 / 1991  (25.3): 100%|| 1991/2000 [2:57:53<00:48,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 505 / 1992  (25.4): 100%|| 1992/2000 [2:57:59<00:42,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1993  (25.4): 100%|| 1993/2000 [2:58:04<00:37,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1994  (25.4): 100%|| 1994/2000 [2:58:09<00:32,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1995  (25.4): 100%|| 1995/2000 [2:58:15<00:26,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 506 / 1996  (25.4): 100%|| 1996/2000 [2:58:20<00:21,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 507 / 1997  (25.4): 100%|| 1997/2000 [2:58:25<00:16,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 507 / 1998  (25.4): 100%|| 1998/2000 [2:58:31<00:10,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 508 / 1999  (25.4): 100%|| 1999/2000 [2:58:36<00:05,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Average Metric: 508 / 2000  (25.4): 100%|| 2000/2000 [2:58:41<00:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 508 / 2000  (25.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:126: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6d4ef th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6d4ef td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6d4ef_row0_col0, #T_6d4ef_row0_col1, #T_6d4ef_row0_col2, #T_6d4ef_row0_col3, #T_6d4ef_row0_col4, #T_6d4ef_row0_col5, #T_6d4ef_row1_col0, #T_6d4ef_row1_col1, #T_6d4ef_row1_col2, #T_6d4ef_row1_col3, #T_6d4ef_row1_col4, #T_6d4ef_row1_col5, #T_6d4ef_row2_col0, #T_6d4ef_row2_col1, #T_6d4ef_row2_col2, #T_6d4ef_row2_col3, #T_6d4ef_row2_col4, #T_6d4ef_row2_col5, #T_6d4ef_row3_col0, #T_6d4ef_row3_col1, #T_6d4ef_row3_col2, #T_6d4ef_row3_col3, #T_6d4ef_row3_col4, #T_6d4ef_row3_col5, #T_6d4ef_row4_col0, #T_6d4ef_row4_col1, #T_6d4ef_row4_col2, #T_6d4ef_row4_col3, #T_6d4ef_row4_col4, #T_6d4ef_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6d4ef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6d4ef_level0_col0\" class=\"col_heading level0 col0\" >example_answer</th>\n",
       "      <th id=\"T_6d4ef_level0_col1\" class=\"col_heading level0 col1\" >word</th>\n",
       "      <th id=\"T_6d4ef_level0_col2\" class=\"col_heading level0 col2\" >scrambled</th>\n",
       "      <th id=\"T_6d4ef_level0_col3\" class=\"col_heading level0 col3\" >question</th>\n",
       "      <th id=\"T_6d4ef_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_6d4ef_level0_col5\" class=\"col_heading level0 col5\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6d4ef_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6d4ef_row0_col0\" class=\"data row0 col0\" >B</td>\n",
       "      <td id=\"T_6d4ef_row0_col1\" class=\"data row0 col1\" >knee</td>\n",
       "      <td id=\"T_6d4ef_row0_col2\" class=\"data row0 col2\" >kene</td>\n",
       "      <td id=\"T_6d4ef_row0_col3\" class=\"data row0 col3\" >Can you unscramble 'kene'?\n",
       "A: raymond\n",
       "B: knee\n",
       "C: take\n",
       "D: consumption</td>\n",
       "      <td id=\"T_6d4ef_row0_col4\" class=\"data row0 col4\" >D</td>\n",
       "      <td id=\"T_6d4ef_row0_col5\" class=\"data row0 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d4ef_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6d4ef_row1_col0\" class=\"data row1 col0\" >D</td>\n",
       "      <td id=\"T_6d4ef_row1_col1\" class=\"data row1 col1\" >camcorders</td>\n",
       "      <td id=\"T_6d4ef_row1_col2\" class=\"data row1 col2\" >cmorarecds</td>\n",
       "      <td id=\"T_6d4ef_row1_col3\" class=\"data row1 col3\" >Decode the word 'cmorarecds'.\n",
       "A: charitable\n",
       "B: thats\n",
       "C: univ\n",
       "D: camcorders</td>\n",
       "      <td id=\"T_6d4ef_row1_col4\" class=\"data row1 col4\" >D</td>\n",
       "      <td id=\"T_6d4ef_row1_col5\" class=\"data row1 col5\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d4ef_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6d4ef_row2_col0\" class=\"data row2 col0\" >C</td>\n",
       "      <td id=\"T_6d4ef_row2_col1\" class=\"data row2 col1\" >heat</td>\n",
       "      <td id=\"T_6d4ef_row2_col2\" class=\"data row2 col2\" >haet</td>\n",
       "      <td id=\"T_6d4ef_row2_col3\" class=\"data row2 col3\" >Decode the word 'haet'.\n",
       "A: babes\n",
       "B: competent\n",
       "C: heat\n",
       "D: dogs</td>\n",
       "      <td id=\"T_6d4ef_row2_col4\" class=\"data row2 col4\" >D</td>\n",
       "      <td id=\"T_6d4ef_row2_col5\" class=\"data row2 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d4ef_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6d4ef_row3_col0\" class=\"data row3 col0\" >C</td>\n",
       "      <td id=\"T_6d4ef_row3_col1\" class=\"data row3 col1\" >brochure</td>\n",
       "      <td id=\"T_6d4ef_row3_col2\" class=\"data row3 col2\" >bruchore</td>\n",
       "      <td id=\"T_6d4ef_row3_col3\" class=\"data row3 col3\" >Can you unscramble 'bruchore'?\n",
       "A: acrylic\n",
       "B: monroe\n",
       "C: brochure\n",
       "D: products</td>\n",
       "      <td id=\"T_6d4ef_row3_col4\" class=\"data row3 col4\" >D</td>\n",
       "      <td id=\"T_6d4ef_row3_col5\" class=\"data row3 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d4ef_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6d4ef_row4_col0\" class=\"data row4 col0\" >B</td>\n",
       "      <td id=\"T_6d4ef_row4_col1\" class=\"data row4 col1\" >grass</td>\n",
       "      <td id=\"T_6d4ef_row4_col2\" class=\"data row4 col2\" >gasrs</td>\n",
       "      <td id=\"T_6d4ef_row4_col3\" class=\"data row4 col3\" >Rearrange the letters in 'gasrs' to form the correct word.\n",
       "A: valuable\n",
       "B: grass\n",
       "C: fresno\n",
       "D: dept</td>\n",
       "      <td id=\"T_6d4ef_row4_col4\" class=\"data row4 col4\" >D</td>\n",
       "      <td id=\"T_6d4ef_row4_col5\" class=\"data row4 col5\" > [False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f18643ef6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1995 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=test_set, num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(compiled_cot, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smHnvL6uePAl"
   },
   "source": [
    "## Finetune T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHRQWguG9Uy_",
    "outputId": "e36cd2bb-bc58-4c73-f1ae-f26cf4176d0c"
   },
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_scramble = Evaluate(devset=test_set, num_threads=2, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loS_39JFb7hG",
    "outputId": "0e8a9933-0146-492a-fa57-b1b159774696"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 4/50 [00:00<00:00, 1407.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tp = BootstrapFewShotWithRandomSearch(metric=validate_answer, max_bootstrapped_demos=2, num_threads=2)\n",
    "tp = BootstrapFewShot(metric=validate_answer, max_bootstrapped_demos=4)\n",
    "\n",
    "cot_bs = tp.compile(CoT(), trainset=train_set[:50], valset=validation_set[50:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_LZegl4-lSEC"
   },
   "outputs": [],
   "source": [
    "cot_bs.save(f'cot_gpt35.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lpo0iNekeCoR"
   },
   "outputs": [],
   "source": [
    "prog = CoT()\n",
    "prog.load(f'cot_gpt35.json')\n",
    "ensemble = [prog]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BpYYviEOek__"
   },
   "outputs": [],
   "source": [
    "always_true = lambda g, p, trace=None: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rsg29jXftl3i",
    "outputId": "ecc80090-2a13-40d3-a569-16a5d670ce50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (1.24.1)\n",
      "Requirement already satisfied: dill in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: packaging in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: rouge_score in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (2.0.0)\n",
      "Requirement already satisfied: nltk in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from nltk->rouge_score) (4.66.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: accelerate in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (2.0.1+cu117)\n",
      "Requirement already satisfied: huggingface-hub in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (0.18.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorboardX in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from tensorboardX) (1.24.1)\n",
      "Requirement already satisfied: packaging in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from tensorboardX) (23.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/muaz/anaconda3/envs/fastrag_new/lib/python3.10/site-packages (from tensorboardX) (3.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d5869c5b82e9415c8b9c22ab8b2d9d02",
      "cb3bc20c19f54663a1b420c2b06365ba",
      "c13234152b4c477d88dd85844b5e712e",
      "c95483cbfca84905b44b1aaa32480615",
      "4571611d877e4d03a2aa0ffa364d635d",
      "9007cb683c264fa599648b008871d9a8",
      "88827a69dace443e9db9aaee06730ee0",
      "17156cb5ed9d4b4f9fe52b4286016752",
      "c328a618bad746c6855ca796b076ae0c",
      "25fe02c768e54238bf20540dbf311fa7",
      "2e21bc0c967f40148fb882c8692d3278",
      "77fd1da3e56a48ddb679433ed04fd954",
      "4fbe9e916c58498f94d1dbc39030736d",
      "8e2c8030ad78492ba390202aa7ef0d93",
      "1e374f032d0a44e0bcd20e3f06c78c83",
      "cb20de4cee8f4f74a92e3251a0202ea9",
      "9438276614d94569b36a1ccd8903927e",
      "9c8f103f3e92424e87ec527f06ce3783",
      "acfd7180cd984b2089632238c0cf080e",
      "8e1a494621894bfcad9418e6da0dff41",
      "1c5bde4646194721a2a30f2cc07335a5",
      "f4dd0c0980fc4c19bdeef3c1630c5312",
      "691b812bbacc46d3b9d8413d5ee8cbaa",
      "a905eb31b29343408c2923898845ac82",
      "45745800f73046a2b27efada4f8eb3e6",
      "f5a908ff6a5141e29c0f2adf1e4eb6f3",
      "714f7dc65d0b4f5f96c23326732bb1cb",
      "7f40feca3d4c41bf8bc62627ed1dc958",
      "35df6a1f32524ab1a0cb9dedcda968d9",
      "15a82a5784914ac08630e2f4071ba3bc",
      "b0752f1be3c2478c9464438fcadd0127",
      "9be50fdd5ace4151b9033fc53de6856b",
      "d7aadac4406b43d99549d088f9b6d24f",
      "d6d3f9489f62473a935de8e4f7ad5146",
      "0d8372e00adc4573914cd14a7435f9be",
      "deebf2522b3246b193bd00a8eb613807",
      "46eea712001e449b806537819ff208f8",
      "93558e5be6694ff1a3bfab6f0aea7d97",
      "c2f7cd716de84319be6b2fc47596e83b",
      "f756ff4c6a234b81aeffdbca9740120e",
      "8ec864e098ae4c09b41f74e37d011d40",
      "8645eb09632f4a3eb9660a18b7a22f3f",
      "7541ec8e9bc446a297e35442bc8cd2a9",
      "c7d92f41c2564ce9909d2fbb1ded4c24",
      "f5568b990cb8474d8ea7d880486a207b",
      "99919dbc154f4d289d2ae34f9bbecf54",
      "38f0319edfed473d8100d6ad3504ed75",
      "c34bead716714285833a9ab9328b2b52",
      "a00da28977b44a549906c98c14f7f97a",
      "c24d002c4d5d488c8ae49d158d3017af",
      "9d28d336e00d446bb7f7629b99c9b53d",
      "2645512b9ade44f6a74576ff0d6fa447",
      "a8167d6e1e3945e8993fb038c4ecc9ea",
      "1698a2b8f6e448e49e36c9c9962c7c95",
      "7e02b08cb22c4674acdb19ca61794894"
     ]
    },
    "id": "gEVotJX7e9Qo",
    "outputId": "d4e180ec-adf8-419c-d1d0-b576046160e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:00<00:00, 3776.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 100 full traces after 100 examples in round 0.\n",
      "all 100\n",
      "local_cache/compiler/all.cfeec7cbd49cfd3e.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f31252230e4015b8024f75f732025b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991cadbdb7924c86846b095ddf9ae586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35b81bec1a64515b6ffef5a322a6886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b1a1698cf8488d8d35beb21e83969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d75b89bc6a48b18aa11cc7a43745d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26e1dbfea0b4e21b2feee4469568b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9780f87859e84aae9d6a4ce55842e08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e73a6ed945c4cfb99d75a36e094f1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# examples skipped due to parsing error: 0 / 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ba1d0f7963435eb1be6ee47a8a590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5619fd72ebe4aca8fcc220519b19867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f20c07b6994a028069d2aae0835f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f6e37e68d4910b7da05b4d6767048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics: {'max_source_length': 44, 'max_target_length': 2}\n",
      "Keys of tokenized dataset: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels']\n",
      "Finetuning dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 90\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 10\n",
      "    })\n",
      "})\n",
      "{'eval_loss': 0.6288124322891235, 'eval_rouge1': 30.0, 'eval_rouge2': 0.0, 'eval_rougeL': 30.0, 'eval_rougeLsum': 30.0, 'eval_gen_len': 2.0, 'eval_runtime': 0.1223, 'eval_samples_per_second': 81.734, 'eval_steps_per_second': 16.347, 'epoch': 0.93}\n",
      "{'eval_loss': 0.6246126890182495, 'eval_rouge1': 30.0, 'eval_rouge2': 0.0, 'eval_rougeL': 30.0, 'eval_rougeLsum': 30.0, 'eval_gen_len': 2.0, 'eval_runtime': 0.1443, 'eval_samples_per_second': 69.281, 'eval_steps_per_second': 13.856, 'epoch': 1.87}\n",
      "{'train_runtime': 3.4201, 'train_samples_per_second': 52.63, 'train_steps_per_second': 4.093, 'train_loss': 0.6946390015738351, 'epoch': 1.87}\n",
      "Best checkpoint of model: ../finetuning_ckpts/S32P3WSDB9KH7.all/checkpoint-14\n",
      "#> Best checkpoint path: ../finetuning_ckpts/S32P3WSDB9KH7.all/checkpoint-14 for all\n",
      "Assigning the LM of predictor all.\n"
     ]
    }
   ],
   "source": [
    "config = dict(target='google/flan-t5-small', epochs=2, bf16=True, bsize=6, accumsteps=2, lr=5e-5)\n",
    "\n",
    "tp = BootstrapFinetune(metric=None)\n",
    "t5_program = tp.compile(CoT(), teacher=ensemble, trainset=test_set[:100], **config)\n",
    "\n",
    "# Deactivate chain of thought prompting. Let's use T5 to directly predict outputs. (Faster and similar quality.)\n",
    "for p in t5_program.predictors(): p.activated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "BoGeTm5xe_ZL"
   },
   "outputs": [],
   "source": [
    "t5_program_load = CoT()\n",
    "ckpt_path = '../finetuning_ckpts/S32P3WSDB9KH7.all/checkpoint-14'\n",
    "# ckpt_path = \"colbert-ir/dspy-Oct11-T5-Large-MH-3k-v1\"\n",
    "LM = dspy.HFModel(checkpoint=ckpt_path, model='google/flan-t5-small')\n",
    "\n",
    "for p in t5_program_load.predictors():\n",
    "    p.lm = LM\n",
    "    p.activated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dAoVLOSqm8nR"
   },
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_scramble = Evaluate(devset=test_set, num_threads=2, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yB3L0CNtfBj5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 916 / 2000  (45.8): 100%|| 2000/2000 [00:22<00:00, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 916 / 2000  (45.8%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aae0a th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aae0a td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aae0a_row0_col0, #T_aae0a_row0_col1, #T_aae0a_row0_col2, #T_aae0a_row0_col3, #T_aae0a_row0_col4, #T_aae0a_row0_col5, #T_aae0a_row1_col0, #T_aae0a_row1_col1, #T_aae0a_row1_col2, #T_aae0a_row1_col3, #T_aae0a_row1_col4, #T_aae0a_row1_col5, #T_aae0a_row2_col0, #T_aae0a_row2_col1, #T_aae0a_row2_col2, #T_aae0a_row2_col3, #T_aae0a_row2_col4, #T_aae0a_row2_col5, #T_aae0a_row3_col0, #T_aae0a_row3_col1, #T_aae0a_row3_col2, #T_aae0a_row3_col3, #T_aae0a_row3_col4, #T_aae0a_row3_col5, #T_aae0a_row4_col0, #T_aae0a_row4_col1, #T_aae0a_row4_col2, #T_aae0a_row4_col3, #T_aae0a_row4_col4, #T_aae0a_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aae0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aae0a_level0_col0\" class=\"col_heading level0 col0\" >example_answer</th>\n",
       "      <th id=\"T_aae0a_level0_col1\" class=\"col_heading level0 col1\" >word</th>\n",
       "      <th id=\"T_aae0a_level0_col2\" class=\"col_heading level0 col2\" >scrambled</th>\n",
       "      <th id=\"T_aae0a_level0_col3\" class=\"col_heading level0 col3\" >question</th>\n",
       "      <th id=\"T_aae0a_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_aae0a_level0_col5\" class=\"col_heading level0 col5\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aae0a_row0_col0\" class=\"data row0 col0\" >B</td>\n",
       "      <td id=\"T_aae0a_row0_col1\" class=\"data row0 col1\" >knee</td>\n",
       "      <td id=\"T_aae0a_row0_col2\" class=\"data row0 col2\" >kene</td>\n",
       "      <td id=\"T_aae0a_row0_col3\" class=\"data row0 col3\" >Can you unscramble 'kene'?\n",
       "A: raymond\n",
       "B: knee\n",
       "C: take\n",
       "D: consumption</td>\n",
       "      <td id=\"T_aae0a_row0_col4\" class=\"data row0 col4\" >C</td>\n",
       "      <td id=\"T_aae0a_row0_col5\" class=\"data row0 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aae0a_row1_col0\" class=\"data row1 col0\" >D</td>\n",
       "      <td id=\"T_aae0a_row1_col1\" class=\"data row1 col1\" >camcorders</td>\n",
       "      <td id=\"T_aae0a_row1_col2\" class=\"data row1 col2\" >cmorarecds</td>\n",
       "      <td id=\"T_aae0a_row1_col3\" class=\"data row1 col3\" >Decode the word 'cmorarecds'.\n",
       "A: charitable\n",
       "B: thats\n",
       "C: univ\n",
       "D: camcorders</td>\n",
       "      <td id=\"T_aae0a_row1_col4\" class=\"data row1 col4\" >A</td>\n",
       "      <td id=\"T_aae0a_row1_col5\" class=\"data row1 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aae0a_row2_col0\" class=\"data row2 col0\" >C</td>\n",
       "      <td id=\"T_aae0a_row2_col1\" class=\"data row2 col1\" >heat</td>\n",
       "      <td id=\"T_aae0a_row2_col2\" class=\"data row2 col2\" >haet</td>\n",
       "      <td id=\"T_aae0a_row2_col3\" class=\"data row2 col3\" >Decode the word 'haet'.\n",
       "A: babes\n",
       "B: competent\n",
       "C: heat\n",
       "D: dogs</td>\n",
       "      <td id=\"T_aae0a_row2_col4\" class=\"data row2 col4\" >B</td>\n",
       "      <td id=\"T_aae0a_row2_col5\" class=\"data row2 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aae0a_row3_col0\" class=\"data row3 col0\" >C</td>\n",
       "      <td id=\"T_aae0a_row3_col1\" class=\"data row3 col1\" >brochure</td>\n",
       "      <td id=\"T_aae0a_row3_col2\" class=\"data row3 col2\" >bruchore</td>\n",
       "      <td id=\"T_aae0a_row3_col3\" class=\"data row3 col3\" >Can you unscramble 'bruchore'?\n",
       "A: acrylic\n",
       "B: monroe\n",
       "C: brochure\n",
       "D: products</td>\n",
       "      <td id=\"T_aae0a_row3_col4\" class=\"data row3 col4\" >D</td>\n",
       "      <td id=\"T_aae0a_row3_col5\" class=\"data row3 col5\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae0a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aae0a_row4_col0\" class=\"data row4 col0\" >B</td>\n",
       "      <td id=\"T_aae0a_row4_col1\" class=\"data row4 col1\" >grass</td>\n",
       "      <td id=\"T_aae0a_row4_col2\" class=\"data row4 col2\" >gasrs</td>\n",
       "      <td id=\"T_aae0a_row4_col3\" class=\"data row4 col3\" >Rearrange the letters in 'gasrs' to form the correct word.\n",
       "A: valuable\n",
       "B: grass\n",
       "C: fresno\n",
       "D: dept</td>\n",
       "      <td id=\"T_aae0a_row4_col4\" class=\"data row4 col4\" >A</td>\n",
       "      <td id=\"T_aae0a_row4_col5\" class=\"data row4 col5\" > [False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e79ac4af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1995 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = evaluate_on_scramble(t5_program_load, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Rearrange the letters in 'prohept' to form the correct word.\n",
      "A: prophet\n",
      "B: jessica\n",
      "C: child\n",
      "D: respected\n",
      "Predicted Answer: D\n"
     ]
    }
   ],
   "source": [
    "# Call the predictor on a particular input.\n",
    "pred = t5_program(question=example.question)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZS02QmYfDQK"
   },
   "outputs": [],
   "source": [
    "t5_program.predictors()[0].lm.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model_Wranglers_DSPy (1).ipynb'   RACE.zip   local_cache\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-25ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 111 not upgraded.\n",
      "'Model_Wranglers_DSPy (1).ipynb'   RACE   RACE.zip   __MACOSX   local_cache\n"
     ]
    }
   ],
   "source": [
    "! ls\n",
    "! rm -rf RACE\n",
    "! apt install unzip\n",
    "! unzip -q RACE.zip\n",
    "! rm -rf __MACOSX\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmHc8qMkrSmv"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high  middle\n"
     ]
    }
   ],
   "source": [
    "! ls RACE/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle School Example:\n",
      "Example({'context': \"Do you know HFMD? It's short for Hand-Foot-Mouth Disease. This year, in China, thousands of children were suffering from it. What's HFMD? How to prevent it? Now, read the passage please.\\nHFMD usually affects babies who are 1~4 years old, but adults can also be infected. Both EV71 and Cox A16 can cause HFMD, which usually starts with a slight fever followed by blisters   and ulcers   in the mouth and rashes   on the hands and feet.\\nIt can be spread through people with the mucus   or feces   of an _ person. It usually appears during the summer and autumn months. HFMD isn't Bird Flu, SARS or Mad Cow Disease, but it's not a new one, either. It first appeared in New Zealand in 1957. About forty years later, it appears in Asia. It's reported that it breaks out every 2 or 3 years.\\nHFMD is very terrible and there is no vaccine   now, but we can do something helpful to prevent it. 'Children with HFMD should seek medical treatment as early as possible', experts say. They also suggest that parents keep the air fresh in a child's room, which should be kept clean, tidy and dry. Children should be taught to wash their hands regularly. Staying away from crowded public places is also basic.\", 'question': 'HFMD is usually spread with   _  .', 'options': \"['feces', 'feces of an infected person', 'water', 'mucus']\", 'answer_option': 'B', 'answer': 'feces of an infected person'}) (input_keys={'context', 'options', 'question'})\n",
      "\n",
      "High School Example:\n",
      "Example({'context': 'It\\'s cool, and it\\'s hot, and everyone is doing it. People talk about it often, and friends tell other friends how good they look. Sound like a fashion? It\\'s actually another trend : \"blog\". What\\'s a blog? A blog is a personal online diary. The word \"blogger\" means a person who writes diaries online.\\nMany bloggers are teens who\\'ve been logging  onto sites to discuss anything in their lives. Many of today\\'s teenagers are not afraid to openly discuss everything in their lives. Teens complain  about parents and homework. They share diaries, post songs from the latest bands and show pictures of theirs. They write their own poems, say something about their girlfriends or boyfriends and complain to each other or offer support. But mostly they just write down what they do every day.\\nHowever, many parents are afraid of these young bloggers. Parents see the kids talking about how they got drunk last weekend and how they don\\'t like studying. They are using language that is surprising to their parents. Besides hearing from their friends, teen bloggers also get message from strangers. Most of the time, it\\'s older men asking to meet teenage girls. \"These strange men are dangerous for my kids. They sometimes teach my kids bad words, \" said Cara Cabral, a mother of two.\\nMany teens and young adults know it\\'s not safe to use blogs on the Internet. They know they are putting information about themselves in a place they can be seen by anyone. But teens are unlikely to give up these new communication tools that have becomes a way of life for many of them.\\nAre you a bloggers? What do you think of the blog?', 'question': 'A blogger is a person   _  .', 'options': \"['who teaches kids bad words', 'who posts songs from the latest bands', 'who got drunk last weekend', 'who writes diaries online']\", 'answer_option': 'D', 'answer': 'who writes diaries online'}) (input_keys={'context', 'options', 'question'})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import dspy\n",
    "\n",
    "# Function to convert a RACE dataset row to DSPy format\n",
    "def convert_race_to_dspy_format(item):\n",
    "    context = item[\"article\"]\n",
    "    options = item[\"options\"]\n",
    "    questions = item[\"questions\"]\n",
    "    answers = item[\"answers\"]\n",
    "\n",
    "    # Assuming options, questions, and answers have the same length\n",
    "    examples = []\n",
    "    answer_to_index = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "    for i in range(len(options)):\n",
    "        example = dspy.Example(\n",
    "            context=context,\n",
    "            question=questions[i],\n",
    "            options=str(options[i]),\n",
    "            answer_option=answers[i],\n",
    "            answer = options[i][answer_to_index[answers[i]]]\n",
    "        )\n",
    "        examples.append(example)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Convert and combine all splits for middle and high school\n",
    "dspy_dataset = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for level in ['middle', 'high']:\n",
    "    for split in ['dev', 'test', 'train']:\n",
    "        folder_path = os.path.join(\"RACE\", split, level)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                dspy_examples = convert_race_to_dspy_format(data)\n",
    "                dspy_dataset[level][split].extend(dspy_examples)\n",
    "\n",
    "# Add inputs to the datasets\n",
    "for level in ['middle', 'high']:\n",
    "    for split in ['dev', 'test', 'train']:\n",
    "        dspy_dataset[level][split] = [x.with_inputs('context', 'question', 'options') for x in dspy_dataset[level][split]]\n",
    "\n",
    "# Check the first element of the datasets\n",
    "example_middle_school = dspy_dataset[\"middle\"][\"dev\"][0]\n",
    "example_high_school = dspy_dataset[\"high\"][\"dev\"][0]\n",
    "\n",
    "print(\"middle School Example:\")\n",
    "print(example_middle_school)\n",
    "print(\"\\nHigh School Example:\")\n",
    "print(example_high_school)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSPy Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Given the context, fill in the  _ by choosing from given options. Give one letter answer. A,B,C,D\"\"\"\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Given the context, answer the question by choosing from given options.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    question = dspy.InputField()\n",
    "    options = dspy.InputField(desc=\"4 options to select from\")\n",
    "    answer = dspy.OutputField()\n",
    "    \n",
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(BasicQA)\n",
    "    def postprocess(self, prediction):\n",
    "        # print(\"_______\")\n",
    "        # print(prediction)\n",
    "        # print(\"_______\")\n",
    "        return prediction.split(\"Answer: \")[-1].split('\\n')[0]\n",
    "\n",
    "    def forward(self, context, question, options):\n",
    "        prediction = self.generate_answer(context=context, question=question, options=options, kwargs={\"max_tokens\":2000})\n",
    "        prediction.answer = self.postprocess(prediction.answer)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which of these is not right?\n",
      "Correct Answer: John exercises on Sundays.\n",
      "Predicted Answer: ${answer}\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\n",
    "generate_answer_with_chain_of_thought = CoT()\n",
    "\n",
    "example = example_high_school\n",
    "for example in dspy_dataset[\"middle\"][\"test\"][9:10]:\n",
    "    # Call the predictor on the same input.\n",
    "    pred = generate_answer_with_chain_of_thought(\n",
    "        context=example.context,\n",
    "        question=example.question,\n",
    "        options=example.options\n",
    "    )\n",
    "    \n",
    "    # Print the input, the chain of thought, and the prediction.\n",
    "    print(f\"Question: {example.question}\")\n",
    "    print(f\"Correct Answer: {example.answer}\")\n",
    "    # print(f\"Thought: {pred.rationale}\") #.split('.', 1)[1].strip()}\")\n",
    "    print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the context, answer the question by choosing from given options.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Options: 4 options to select from\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "John gets up early from Monday to Saturday, because he must go to school before 7:30 on weekdays  and go to Drawing Club at 8:00 on Saturday mornings. He usually goes to the bookshop on Saturday afternoon, and after dinner he watches TV until  midnight .\n",
      "He doesn't get up early on Sundays. John's parents both work on Sundays. John always watches TV after he gets up. Then he usually goes to KFC to have a hamburger and some juice for lunch. After that, he goes back home and starts to play computer games until his parents come back. He does his homework after dinner. He usually has lots of weekend homework, so he must spend three hours on it. He usually goes to bed at about 11:00 p.m. on Sundays. He often complains  he has too much homework to do.\n",
      ",.\n",
      "\n",
      "Question: Which of these is not right?\n",
      "\n",
      "Options: ['John watches TV after dinner on Saturdays.', 'John exercises on Sundays.', 'John plays computer games on Sunday afternoon.', 'John finishes his homework very late on Sundays.']\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32mGiven the context, answer the question by choosing from given options.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Options: 4 options to select from\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "John gets up early from Monday to Saturday, because he must go to school before 7:30 on weekdays  and go to Drawing Club at 8:00 on Saturday mornings. He usually goes to the bookshop on Saturday afternoon, and after dinner he watches TV until  midnight .\n",
      "He doesn't get up early on Sundays. John's parents both work on Sundays. John always watches TV after he gets up. Then he usually goes to KFC to have a hamburger and some juice for lunch. After that, he goes back home and starts to play computer games until his parents come back. He does his homework after dinner. He usually has lots of weekend homework, so he must spend three hours on it. He usually goes to bed at about 11:00 p.m. on Sundays. He often complains  he has too much homework to do.\n",
      ",.\n",
      "\n",
      "Question: Which of these is not right?\n",
      "\n",
      "Options: ['John watches TV after dinner on Saturdays.', 'John exercises on Sundays.', 'John plays computer games on Sunday afternoon.', 'John finishes his homework very late on Sundays.']\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the answer. We know that John gets up early from Monday to Saturday, because he must go to school before 7:30 on weekdays and go to Drawing Club at 8:00 on Saturday mornings. He usually goes to the bookshop on Saturday afternoon, and after dinner he watches TV until midnight. He doesn't get up early on Sundays. John's parents both work on Sundays. John always watches TV after he gets up. Then he usually goes to KFC to have a hamburger and some juice for lunch. After that, he goes back home and starts to play computer games until his parents come back. He does his homework after dinner. He usually has lots of\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 0/1436 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 1/1436 [00:01<31:07,  1.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 2  (100.0):   0%|          | 1/1436 [00:02<31:07,  1.30s/it]\u001b[A\n",
      "Average Metric: 2 / 2  (100.0):   0%|          | 2/1436 [00:02<31:52,  1.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 3  (66.7):   0%|          | 2/1436 [00:06<31:52,  1.33s/it] \u001b[A\n",
      "Average Metric: 2 / 3  (66.7):   0%|          | 3/1436 [00:06<1:02:55,  2.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 4  (50.0):   0%|          | 3/1436 [00:10<1:02:55,  2.63s/it]\u001b[A\n",
      "Average Metric: 2 / 4  (50.0):   0%|          | 4/1436 [00:10<1:13:31,  3.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 3 / 5  (60.0):   0%|          | 4/1436 [00:15<1:13:31,  3.08s/it]\u001b[A\n",
      "Average Metric: 3 / 5  (60.0):   0%|          | 5/1436 [00:15<1:25:25,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 3 / 6  (50.0):   0%|          | 5/1436 [00:17<1:25:25,  3.58s/it]\u001b[A\n",
      "Average Metric: 3 / 6  (50.0):   0%|          | 6/1436 [00:17<1:19:59,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 7  (57.1):   0%|          | 6/1436 [00:21<1:19:59,  3.36s/it]\u001b[A\n",
      "Average Metric: 4 / 7  (57.1):   0%|          | 7/1436 [00:21<1:21:52,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 8  (50.0):   0%|          | 7/1436 [00:25<1:21:52,  3.44s/it]\u001b[A\n",
      "Average Metric: 4 / 8  (50.0):   1%|          | 8/1436 [00:25<1:27:54,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 9  (44.4):   1%|          | 8/1436 [00:29<1:27:54,  3.69s/it]\u001b[A\n",
      "Average Metric: 4 / 9  (44.4):   1%|          | 9/1436 [00:29<1:24:35,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 10  (40.0):   1%|          | 9/1436 [00:34<1:24:35,  3.56s/it]\u001b[A\n",
      "Average Metric: 4 / 10  (40.0):   1%|          | 10/1436 [00:34<1:35:58,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 5 / 11  (45.5):   1%|          | 10/1436 [00:35<1:35:58,  4.04s/it]\u001b[A\n",
      "Average Metric: 5 / 11  (45.5):   1%|          | 11/1436 [00:35<1:17:24,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 5 / 12  (41.7):   1%|          | 11/1436 [00:40<1:17:24,  3.26s/it]\u001b[A\n",
      "Average Metric: 5 / 12  (41.7):   1%|          | 12/1436 [00:40<1:30:42,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 5 / 13  (38.5):   1%|          | 12/1436 [00:45<1:30:42,  3.82s/it]\u001b[A\n",
      "Average Metric: 5 / 13  (38.5):   1%|          | 13/1436 [00:45<1:39:52,  4.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 5 / 14  (35.7):   1%|          | 13/1436 [00:48<1:39:52,  4.21s/it]\u001b[A\n",
      "Average Metric: 5 / 14  (35.7):   1%|          | 14/1436 [00:48<1:29:58,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 6 / 15  (40.0):   1%|          | 14/1436 [00:53<1:29:58,  3.80s/it]\u001b[A\n",
      "Average Metric: 6 / 15  (40.0):   1%|          | 15/1436 [00:53<1:35:13,  4.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 6 / 16  (37.5):   1%|          | 15/1436 [00:58<1:35:13,  4.02s/it]\u001b[A\n",
      "Average Metric: 6 / 16  (37.5):   1%|          | 16/1436 [00:58<1:43:40,  4.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 7 / 17  (41.2):   1%|          | 16/1436 [01:02<1:43:40,  4.38s/it]\u001b[A\n",
      "Average Metric: 7 / 17  (41.2):   1%|          | 17/1436 [01:02<1:39:56,  4.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 7 / 18  (38.9):   1%|          | 17/1436 [01:05<1:39:56,  4.23s/it]\u001b[A\n",
      "Average Metric: 7 / 18  (38.9):   1%|         | 18/1436 [01:05<1:33:58,  3.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 7 / 19  (36.8):   1%|         | 18/1436 [01:09<1:33:58,  3.98s/it]\u001b[A\n",
      "Average Metric: 7 / 19  (36.8):   1%|         | 19/1436 [01:09<1:32:50,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 7 / 20  (35.0):   1%|         | 19/1436 [01:13<1:32:50,  3.93s/it]\u001b[A\n",
      "Average Metric: 7 / 20  (35.0):   1%|         | 20/1436 [01:13<1:33:12,  3.95s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 21  (38.1):   1%|         | 20/1436 [01:16<1:33:12,  3.95s/it]\u001b[A\n",
      "Average Metric: 8 / 21  (38.1):   1%|         | 21/1436 [01:16<1:23:17,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 22  (36.4):   1%|         | 21/1436 [01:19<1:23:17,  3.53s/it]\u001b[A\n",
      "Average Metric: 8 / 22  (36.4):   2%|         | 22/1436 [01:19<1:19:02,  3.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 23  (34.8):   2%|         | 22/1436 [01:21<1:19:02,  3.35s/it]\u001b[A\n",
      "Average Metric: 8 / 23  (34.8):   2%|         | 23/1436 [01:21<1:14:31,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 9 / 24  (37.5):   2%|         | 23/1436 [01:25<1:14:31,  3.16s/it]\u001b[A\n",
      "Average Metric: 9 / 24  (37.5):   2%|         | 24/1436 [01:25<1:15:39,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 9 / 25  (36.0):   2%|         | 24/1436 [01:30<1:15:39,  3.21s/it]\u001b[A\n",
      "Average Metric: 9 / 25  (36.0):   2%|         | 25/1436 [01:30<1:28:44,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 9 / 26  (34.6):   2%|         | 25/1436 [01:34<1:28:44,  3.77s/it]\u001b[A\n",
      "Average Metric: 9 / 26  (34.6):   2%|         | 26/1436 [01:34<1:29:41,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 9 / 27  (33.3):   2%|         | 26/1436 [01:36<1:29:41,  3.82s/it]\u001b[A\n",
      "Average Metric: 9 / 27  (33.3):   2%|         | 27/1436 [01:36<1:20:00,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 9 / 28  (32.1):   2%|         | 27/1436 [01:41<1:20:00,  3.41s/it]\u001b[A\n",
      "Average Metric: 9 / 28  (32.1):   2%|         | 28/1436 [01:41<1:31:36,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 9 / 29  (31.0):   2%|         | 28/1436 [01:45<1:31:36,  3.90s/it]\u001b[A\n",
      "Average Metric: 9 / 29  (31.0):   2%|         | 29/1436 [01:45<1:29:07,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 9 / 30  (30.0):   2%|         | 29/1436 [01:48<1:29:07,  3.80s/it]\u001b[A\n",
      "Average Metric: 9 / 30  (30.0):   2%|         | 30/1436 [01:48<1:21:57,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 10 / 31  (32.3):   2%|         | 30/1436 [01:49<1:21:57,  3.50s/it]\u001b[A\n",
      "Average Metric: 10 / 31  (32.3):   2%|         | 31/1436 [01:49<1:06:35,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 11 / 32  (34.4):   2%|         | 31/1436 [01:51<1:06:35,  2.84s/it]\u001b[A\n",
      "Average Metric: 11 / 32  (34.4):   2%|         | 32/1436 [01:51<1:00:45,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 11 / 33  (33.3):   2%|         | 32/1436 [01:56<1:00:45,  2.60s/it]\u001b[A\n",
      "Average Metric: 11 / 33  (33.3):   2%|         | 33/1436 [01:56<1:15:46,  3.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 12 / 34  (35.3):   2%|         | 33/1436 [01:58<1:15:46,  3.24s/it]\u001b[A\n",
      "Average Metric: 12 / 34  (35.3):   2%|         | 34/1436 [01:58<1:12:17,  3.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 13 / 35  (37.1):   2%|         | 34/1436 [02:03<1:12:17,  3.09s/it]\u001b[A\n",
      "Average Metric: 13 / 35  (37.1):   2%|         | 35/1436 [02:03<1:21:40,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 14 / 36  (38.9):   2%|         | 35/1436 [02:05<1:21:40,  3.50s/it]\u001b[A\n",
      "Average Metric: 14 / 36  (38.9):   3%|         | 36/1436 [02:05<1:14:53,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 14 / 37  (37.8):   3%|         | 36/1436 [02:08<1:14:53,  3.21s/it]\u001b[A\n",
      "Average Metric: 14 / 37  (37.8):   3%|         | 37/1436 [02:08<1:11:18,  3.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 15 / 38  (39.5):   3%|         | 37/1436 [02:11<1:11:18,  3.06s/it]\u001b[A\n",
      "Average Metric: 15 / 38  (39.5):   3%|         | 38/1436 [02:11<1:13:42,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 15 / 39  (38.5):   3%|         | 38/1436 [02:17<1:13:42,  3.16s/it]\u001b[A\n",
      "Average Metric: 15 / 39  (38.5):   3%|         | 39/1436 [02:17<1:27:18,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 15 / 40  (37.5):   3%|         | 39/1436 [02:22<1:27:18,  3.75s/it]\u001b[A\n",
      "Average Metric: 15 / 40  (37.5):   3%|         | 40/1436 [02:22<1:36:42,  4.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 16 / 41  (39.0):   3%|         | 40/1436 [02:26<1:36:42,  4.16s/it]\u001b[A\n",
      "Average Metric: 16 / 41  (39.0):   3%|         | 41/1436 [02:26<1:37:07,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 17 / 42  (40.5):   3%|         | 41/1436 [02:29<1:37:07,  4.18s/it]\u001b[A\n",
      "Average Metric: 17 / 42  (40.5):   3%|         | 42/1436 [02:29<1:27:16,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 17 / 43  (39.5):   3%|         | 42/1436 [02:32<1:27:16,  3.76s/it]\u001b[A\n",
      "Average Metric: 17 / 43  (39.5):   3%|         | 43/1436 [02:32<1:27:46,  3.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 18 / 44  (40.9):   3%|         | 43/1436 [02:36<1:27:46,  3.78s/it]\u001b[A\n",
      "Average Metric: 18 / 44  (40.9):   3%|         | 44/1436 [02:36<1:25:30,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 18 / 45  (40.0):   3%|         | 44/1436 [02:38<1:25:30,  3.69s/it]\u001b[A\n",
      "Average Metric: 18 / 45  (40.0):   3%|         | 45/1436 [02:38<1:11:57,  3.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 19 / 46  (41.3):   3%|         | 45/1436 [02:39<1:11:57,  3.10s/it]\u001b[A\n",
      "Average Metric: 19 / 46  (41.3):   3%|         | 46/1436 [02:39<1:00:14,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 19 / 47  (40.4):   3%|         | 46/1436 [02:43<1:00:14,  2.60s/it]\u001b[A\n",
      "Average Metric: 19 / 47  (40.4):   3%|         | 47/1436 [02:43<1:06:11,  2.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 19 / 48  (39.6):   3%|         | 47/1436 [02:45<1:06:11,  2.86s/it]\u001b[A\n",
      "Average Metric: 19 / 48  (39.6):   3%|         | 48/1436 [02:45<1:05:18,  2.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 20 / 49  (40.8):   3%|         | 48/1436 [02:47<1:05:18,  2.82s/it]\u001b[A\n",
      "Average Metric: 20 / 49  (40.8):   3%|         | 49/1436 [02:47<55:57,  2.42s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 20 / 50  (40.0):   3%|         | 49/1436 [02:51<55:57,  2.42s/it]\u001b[A\n",
      "Average Metric: 20 / 50  (40.0):   3%|         | 50/1436 [02:51<1:05:38,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 20 / 51  (39.2):   3%|         | 50/1436 [02:55<1:05:38,  2.84s/it]\u001b[A\n",
      "Average Metric: 20 / 51  (39.2):   4%|         | 51/1436 [02:55<1:16:21,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 20 / 52  (38.5):   4%|         | 51/1436 [03:00<1:16:21,  3.31s/it]\u001b[A\n",
      "Average Metric: 20 / 52  (38.5):   4%|         | 52/1436 [03:00<1:28:40,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 20 / 53  (37.7):   4%|         | 52/1436 [03:05<1:28:40,  3.84s/it]\u001b[A\n",
      "Average Metric: 20 / 53  (37.7):   4%|         | 53/1436 [03:05<1:37:18,  4.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 21 / 54  (38.9):   4%|         | 53/1436 [03:07<1:37:18,  4.22s/it]\u001b[A\n",
      "Average Metric: 21 / 54  (38.9):   4%|         | 54/1436 [03:07<1:22:36,  3.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 21 / 55  (38.2):   4%|         | 54/1436 [03:12<1:22:36,  3.59s/it]\u001b[A\n",
      "Average Metric: 21 / 55  (38.2):   4%|         | 55/1436 [03:12<1:27:51,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 21 / 56  (37.5):   4%|         | 55/1436 [03:15<1:27:51,  3.82s/it]\u001b[A\n",
      "Average Metric: 21 / 56  (37.5):   4%|         | 56/1436 [03:15<1:24:47,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 22 / 57  (38.6):   4%|         | 56/1436 [03:19<1:24:47,  3.69s/it]\u001b[A\n",
      "Average Metric: 22 / 57  (38.6):   4%|         | 57/1436 [03:19<1:23:42,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 58  (39.7):   4%|         | 57/1436 [03:21<1:23:42,  3.64s/it]\u001b[A\n",
      "Average Metric: 23 / 58  (39.7):   4%|         | 58/1436 [03:21<1:11:35,  3.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 59  (39.0):   4%|         | 58/1436 [03:26<1:11:35,  3.12s/it]\u001b[A\n",
      "Average Metric: 23 / 59  (39.0):   4%|         | 59/1436 [03:26<1:25:11,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 60  (38.3):   4%|         | 59/1436 [03:28<1:25:11,  3.71s/it]\u001b[A\n",
      "Average Metric: 23 / 60  (38.3):   4%|         | 60/1436 [03:28<1:15:10,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 61  (37.7):   4%|         | 60/1436 [03:33<1:15:10,  3.28s/it]\u001b[A\n",
      "Average Metric: 23 / 61  (37.7):   4%|         | 61/1436 [03:33<1:28:32,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 62  (37.1):   4%|         | 61/1436 [03:38<1:28:32,  3.86s/it]\u001b[A\n",
      "Average Metric: 23 / 62  (37.1):   4%|         | 62/1436 [03:38<1:38:14,  4.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 63  (36.5):   4%|         | 62/1436 [03:43<1:38:14,  4.29s/it]\u001b[A\n",
      "Average Metric: 23 / 63  (36.5):   4%|         | 63/1436 [03:43<1:39:49,  4.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 64  (35.9):   4%|         | 63/1436 [03:48<1:39:49,  4.36s/it]\u001b[A\n",
      "Average Metric: 23 / 64  (35.9):   4%|         | 64/1436 [03:48<1:46:03,  4.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 23 / 65  (35.4):   4%|         | 64/1436 [03:50<1:46:03,  4.64s/it]\u001b[A\n",
      "Average Metric: 23 / 65  (35.4):   5%|         | 65/1436 [03:50<1:25:10,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 24 / 66  (36.4):   5%|         | 65/1436 [03:51<1:25:10,  3.73s/it]\u001b[A\n",
      "Average Metric: 24 / 66  (36.4):   5%|         | 66/1436 [03:51<1:07:43,  2.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 24 / 67  (35.8):   5%|         | 66/1436 [03:54<1:07:43,  2.97s/it]\u001b[A\n",
      "Average Metric: 24 / 67  (35.8):   5%|         | 67/1436 [03:54<1:08:22,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 25 / 68  (36.8):   5%|         | 67/1436 [03:57<1:08:22,  3.00s/it]\u001b[A\n",
      "Average Metric: 25 / 68  (36.8):   5%|         | 68/1436 [03:57<1:04:58,  2.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 26 / 69  (37.7):   5%|         | 68/1436 [04:00<1:04:58,  2.85s/it]\u001b[A\n",
      "Average Metric: 26 / 69  (37.7):   5%|         | 69/1436 [04:00<1:06:46,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 26 / 70  (37.1):   5%|         | 69/1436 [04:03<1:06:46,  2.93s/it]\u001b[A\n",
      "Average Metric: 26 / 70  (37.1):   5%|         | 70/1436 [04:03<1:06:45,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 26 / 71  (36.6):   5%|         | 70/1436 [04:07<1:06:45,  2.93s/it]\u001b[A\n",
      "Average Metric: 26 / 71  (36.6):   5%|         | 71/1436 [04:07<1:13:40,  3.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 26 / 72  (36.1):   5%|         | 71/1436 [04:10<1:13:40,  3.24s/it]\u001b[A\n",
      "Average Metric: 26 / 72  (36.1):   5%|         | 72/1436 [04:10<1:17:24,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 26 / 73  (35.6):   5%|         | 72/1436 [04:12<1:17:24,  3.41s/it]\u001b[A\n",
      "Average Metric: 26 / 73  (35.6):   5%|         | 73/1436 [04:12<1:08:26,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 27 / 74  (36.5):   5%|         | 73/1436 [04:14<1:08:26,  3.01s/it]\u001b[A\n",
      "Average Metric: 27 / 74  (36.5):   5%|         | 74/1436 [04:14<56:55,  2.51s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 27 / 75  (36.0):   5%|         | 74/1436 [04:16<56:55,  2.51s/it]\u001b[A\n",
      "Average Metric: 27 / 75  (36.0):   5%|         | 75/1436 [04:16<54:44,  2.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 27 / 76  (35.5):   5%|         | 75/1436 [04:21<54:44,  2.41s/it]\u001b[A\n",
      "Average Metric: 27 / 76  (35.5):   5%|         | 76/1436 [04:21<1:12:36,  3.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 27 / 77  (35.1):   5%|         | 76/1436 [04:26<1:12:36,  3.20s/it]\u001b[A\n",
      "Average Metric: 27 / 77  (35.1):   5%|         | 77/1436 [04:26<1:26:52,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 28 / 78  (35.9):   5%|         | 77/1436 [04:30<1:26:52,  3.84s/it]\u001b[A\n",
      "Average Metric: 28 / 78  (35.9):   5%|         | 78/1436 [04:30<1:26:05,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 28 / 79  (35.4):   5%|         | 78/1436 [04:35<1:26:05,  3.80s/it]\u001b[A\n",
      "Average Metric: 28 / 79  (35.4):   6%|         | 79/1436 [04:35<1:36:23,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 29 / 80  (36.2):   6%|         | 79/1436 [04:39<1:36:23,  4.26s/it]\u001b[A\n",
      "Average Metric: 29 / 80  (36.2):   6%|         | 80/1436 [04:39<1:31:51,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 30 / 81  (37.0):   6%|         | 80/1436 [04:41<1:31:51,  4.06s/it]\u001b[A\n",
      "Average Metric: 30 / 81  (37.0):   6%|         | 81/1436 [04:41<1:19:30,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 30 / 82  (36.6):   6%|         | 81/1436 [04:46<1:19:30,  3.52s/it]\u001b[A\n",
      "Average Metric: 30 / 82  (36.6):   6%|         | 82/1436 [04:46<1:31:02,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 30 / 83  (36.1):   6%|         | 82/1436 [04:52<1:31:02,  4.03s/it]\u001b[A\n",
      "Average Metric: 30 / 83  (36.1):   6%|         | 83/1436 [04:52<1:38:57,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 30 / 84  (35.7):   6%|         | 83/1436 [04:55<1:38:57,  4.39s/it]\u001b[A\n",
      "Average Metric: 30 / 84  (35.7):   6%|         | 84/1436 [04:55<1:31:29,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 30 / 85  (35.3):   6%|         | 84/1436 [04:58<1:31:29,  4.06s/it]\u001b[A\n",
      "Average Metric: 30 / 85  (35.3):   6%|         | 85/1436 [04:58<1:24:14,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 30 / 86  (34.9):   6%|         | 85/1436 [05:02<1:24:14,  3.74s/it]\u001b[A\n",
      "Average Metric: 30 / 86  (34.9):   6%|         | 86/1436 [05:02<1:27:22,  3.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 30 / 87  (34.5):   6%|         | 86/1436 [05:07<1:27:22,  3.88s/it]\u001b[A\n",
      "Average Metric: 30 / 87  (34.5):   6%|         | 87/1436 [05:07<1:32:05,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 31 / 88  (35.2):   6%|         | 87/1436 [05:10<1:32:05,  4.10s/it]\u001b[A\n",
      "Average Metric: 31 / 88  (35.2):   6%|         | 88/1436 [05:10<1:25:32,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 32 / 89  (36.0):   6%|         | 88/1436 [05:12<1:25:32,  3.81s/it]\u001b[A\n",
      "Average Metric: 32 / 89  (36.0):   6%|         | 89/1436 [05:12<1:10:28,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 32 / 90  (35.6):   6%|         | 89/1436 [05:15<1:10:28,  3.14s/it]\u001b[A\n",
      "Average Metric: 32 / 90  (35.6):   6%|         | 90/1436 [05:15<1:10:25,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 32 / 91  (35.2):   6%|         | 90/1436 [05:19<1:10:25,  3.14s/it]\u001b[A\n",
      "Average Metric: 32 / 91  (35.2):   6%|         | 91/1436 [05:19<1:19:42,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 33 / 92  (35.9):   6%|         | 91/1436 [05:22<1:19:42,  3.56s/it]\u001b[A\n",
      "Average Metric: 33 / 92  (35.9):   6%|         | 92/1436 [05:22<1:14:58,  3.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 33 / 93  (35.5):   6%|         | 92/1436 [05:27<1:14:58,  3.35s/it]\u001b[A\n",
      "Average Metric: 33 / 93  (35.5):   6%|         | 93/1436 [05:27<1:26:27,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 33 / 94  (35.1):   6%|         | 93/1436 [05:31<1:26:27,  3.86s/it]\u001b[A\n",
      "Average Metric: 33 / 94  (35.1):   7%|         | 94/1436 [05:31<1:25:25,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 33 / 95  (34.7):   7%|         | 94/1436 [05:36<1:25:25,  3.82s/it]\u001b[A\n",
      "Average Metric: 33 / 95  (34.7):   7%|         | 95/1436 [05:36<1:32:09,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 34 / 96  (35.4):   7%|         | 95/1436 [05:40<1:32:09,  4.12s/it]\u001b[A\n",
      "Average Metric: 34 / 96  (35.4):   7%|         | 96/1436 [05:40<1:36:22,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 34 / 97  (35.1):   7%|         | 96/1436 [05:46<1:36:22,  4.32s/it]\u001b[A\n",
      "Average Metric: 34 / 97  (35.1):   7%|         | 97/1436 [05:46<1:42:12,  4.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 35 / 98  (35.7):   7%|         | 97/1436 [05:49<1:42:12,  4.58s/it]\u001b[A\n",
      "Average Metric: 35 / 98  (35.7):   7%|         | 98/1436 [05:49<1:35:58,  4.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 35 / 99  (35.4):   7%|         | 98/1436 [05:53<1:35:58,  4.30s/it]\u001b[A\n",
      "Average Metric: 35 / 99  (35.4):   7%|         | 99/1436 [05:53<1:35:12,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 35 / 100  (35.0):   7%|         | 99/1436 [05:55<1:35:12,  4.27s/it]\u001b[A\n",
      "Average Metric: 35 / 100  (35.0):   7%|         | 100/1436 [05:55<1:19:28,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 35 / 101  (34.7):   7%|         | 100/1436 [05:59<1:19:28,  3.57s/it]\u001b[A\n",
      "Average Metric: 35 / 101  (34.7):   7%|         | 101/1436 [05:59<1:19:33,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 35 / 102  (34.3):   7%|         | 101/1436 [06:02<1:19:33,  3.58s/it]\u001b[A\n",
      "Average Metric: 35 / 102  (34.3):   7%|         | 102/1436 [06:02<1:14:37,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 36 / 103  (35.0):   7%|         | 102/1436 [06:05<1:14:37,  3.36s/it]\u001b[A\n",
      "Average Metric: 36 / 103  (35.0):   7%|         | 103/1436 [06:05<1:12:46,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 36 / 104  (34.6):   7%|         | 103/1436 [06:10<1:12:46,  3.28s/it]\u001b[A\n",
      "Average Metric: 36 / 104  (34.6):   7%|         | 104/1436 [06:10<1:25:27,  3.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 36 / 105  (34.3):   7%|         | 104/1436 [06:15<1:25:27,  3.85s/it]\u001b[A\n",
      "Average Metric: 36 / 105  (34.3):   7%|         | 105/1436 [06:15<1:29:40,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 36 / 106  (34.0):   7%|         | 105/1436 [06:19<1:29:40,  4.04s/it]\u001b[A\n",
      "Average Metric: 36 / 106  (34.0):   7%|         | 106/1436 [06:19<1:31:40,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 37 / 107  (34.6):   7%|         | 106/1436 [06:23<1:31:40,  4.14s/it]\u001b[A\n",
      "Average Metric: 37 / 107  (34.6):   7%|         | 107/1436 [06:23<1:27:47,  3.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 37 / 108  (34.3):   7%|         | 107/1436 [06:26<1:27:47,  3.96s/it]\u001b[A\n",
      "Average Metric: 37 / 108  (34.3):   8%|         | 108/1436 [06:26<1:25:27,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 38 / 109  (34.9):   8%|         | 108/1436 [06:30<1:25:27,  3.86s/it]\u001b[A\n",
      "Average Metric: 38 / 109  (34.9):   8%|         | 109/1436 [06:30<1:22:09,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 110  (35.5):   8%|         | 109/1436 [06:32<1:22:09,  3.71s/it]\u001b[A\n",
      "Average Metric: 39 / 110  (35.5):   8%|         | 110/1436 [06:32<1:13:26,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 111  (35.1):   8%|         | 110/1436 [06:37<1:13:26,  3.32s/it]\u001b[A\n",
      "Average Metric: 39 / 111  (35.1):   8%|         | 111/1436 [06:37<1:26:52,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 112  (34.8):   8%|         | 111/1436 [06:42<1:26:52,  3.93s/it]\u001b[A\n",
      "Average Metric: 39 / 112  (34.8):   8%|         | 112/1436 [06:42<1:29:33,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 113  (34.5):   8%|         | 112/1436 [06:45<1:29:33,  4.06s/it]\u001b[A\n",
      "Average Metric: 39 / 113  (34.5):   8%|         | 113/1436 [06:45<1:24:02,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 114  (34.2):   8%|         | 113/1436 [06:48<1:24:02,  3.81s/it]\u001b[A\n",
      "Average Metric: 39 / 114  (34.2):   8%|         | 114/1436 [06:48<1:20:30,  3.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 115  (33.9):   8%|         | 114/1436 [06:51<1:20:30,  3.65s/it]\u001b[A\n",
      "Average Metric: 39 / 115  (33.9):   8%|         | 115/1436 [06:51<1:16:37,  3.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 116  (33.6):   8%|         | 115/1436 [06:56<1:16:37,  3.48s/it]\u001b[A\n",
      "Average Metric: 39 / 116  (33.6):   8%|         | 116/1436 [06:56<1:27:16,  3.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 39 / 117  (33.3):   8%|         | 116/1436 [07:01<1:27:16,  3.97s/it]\u001b[A\n",
      "Average Metric: 39 / 117  (33.3):   8%|         | 117/1436 [07:01<1:34:41,  4.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 40 / 118  (33.9):   8%|         | 117/1436 [07:06<1:34:41,  4.31s/it]\u001b[A\n",
      "Average Metric: 40 / 118  (33.9):   8%|         | 118/1436 [07:06<1:37:53,  4.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 119  (34.5):   8%|         | 118/1436 [07:10<1:37:53,  4.46s/it]\u001b[A\n",
      "Average Metric: 41 / 119  (34.5):   8%|         | 119/1436 [07:10<1:31:48,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 120  (34.2):   8%|         | 119/1436 [07:15<1:31:48,  4.18s/it]\u001b[A\n",
      "Average Metric: 41 / 120  (34.2):   8%|         | 120/1436 [07:15<1:38:45,  4.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 121  (33.9):   8%|         | 120/1436 [07:18<1:38:45,  4.50s/it]\u001b[A\n",
      "Average Metric: 41 / 121  (33.9):   8%|         | 121/1436 [07:18<1:28:20,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 122  (33.6):   8%|         | 121/1436 [07:21<1:28:20,  4.03s/it]\u001b[A\n",
      "Average Metric: 41 / 122  (33.6):   8%|         | 122/1436 [07:21<1:20:58,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 123  (33.3):   8%|         | 122/1436 [07:26<1:20:58,  3.70s/it]\u001b[A\n",
      "Average Metric: 41 / 123  (33.3):   9%|         | 123/1436 [07:26<1:31:07,  4.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 124  (33.1):   9%|         | 123/1436 [07:31<1:31:07,  4.16s/it]\u001b[A\n",
      "Average Metric: 41 / 124  (33.1):   9%|         | 124/1436 [07:31<1:32:55,  4.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 41 / 125  (32.8):   9%|         | 124/1436 [07:32<1:32:55,  4.25s/it]\u001b[A\n",
      "Average Metric: 41 / 125  (32.8):   9%|         | 125/1436 [07:32<1:16:23,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 126  (33.3):   9%|         | 125/1436 [07:36<1:16:23,  3.50s/it]\u001b[A\n",
      "Average Metric: 42 / 126  (33.3):   9%|         | 126/1436 [07:36<1:16:10,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 127  (33.1):   9%|         | 126/1436 [07:40<1:16:10,  3.49s/it]\u001b[A\n",
      "Average Metric: 42 / 127  (33.1):   9%|         | 127/1436 [07:40<1:23:34,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 128  (32.8):   9%|         | 127/1436 [07:45<1:23:34,  3.83s/it]\u001b[A\n",
      "Average Metric: 42 / 128  (32.8):   9%|         | 128/1436 [07:45<1:26:53,  3.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 129  (32.6):   9%|         | 128/1436 [07:50<1:26:53,  3.99s/it]\u001b[A\n",
      "Average Metric: 42 / 129  (32.6):   9%|         | 129/1436 [07:50<1:34:52,  4.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 42 / 130  (32.3):   9%|         | 129/1436 [07:53<1:34:52,  4.36s/it]\u001b[A\n",
      "Average Metric: 42 / 130  (32.3):   9%|         | 130/1436 [07:53<1:23:32,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 43 / 131  (32.8):   9%|         | 130/1436 [07:55<1:23:32,  3.84s/it]\u001b[A\n",
      "Average Metric: 43 / 131  (32.8):   9%|         | 131/1436 [07:55<1:12:12,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 43 / 132  (32.6):   9%|         | 131/1436 [07:59<1:12:12,  3.32s/it]\u001b[A\n",
      "Average Metric: 43 / 132  (32.6):   9%|         | 132/1436 [07:59<1:15:24,  3.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 43 / 133  (32.3):   9%|         | 132/1436 [08:03<1:15:24,  3.47s/it]\u001b[A\n",
      "Average Metric: 43 / 133  (32.3):   9%|         | 133/1436 [08:03<1:23:01,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 134  (32.8):   9%|         | 133/1436 [08:05<1:23:01,  3.82s/it]\u001b[A\n",
      "Average Metric: 44 / 134  (32.8):   9%|         | 134/1436 [08:05<1:09:57,  3.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 135  (32.6):   9%|         | 134/1436 [08:09<1:09:57,  3.22s/it]\u001b[A\n",
      "Average Metric: 44 / 135  (32.6):   9%|         | 135/1436 [08:09<1:15:37,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 136  (32.4):   9%|         | 135/1436 [08:14<1:15:37,  3.49s/it]\u001b[A\n",
      "Average Metric: 44 / 136  (32.4):   9%|         | 136/1436 [08:14<1:27:29,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 137  (32.1):   9%|         | 136/1436 [08:19<1:27:29,  4.04s/it]\u001b[A\n",
      "Average Metric: 44 / 137  (32.1):  10%|         | 137/1436 [08:19<1:27:48,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 138  (31.9):  10%|         | 137/1436 [08:24<1:27:48,  4.06s/it]\u001b[A\n",
      "Average Metric: 44 / 138  (31.9):  10%|         | 138/1436 [08:24<1:36:00,  4.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 139  (31.7):  10%|         | 138/1436 [08:27<1:36:00,  4.44s/it]\u001b[A\n",
      "Average Metric: 44 / 139  (31.7):  10%|         | 139/1436 [08:27<1:24:23,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 140  (31.4):  10%|         | 139/1436 [08:31<1:24:23,  3.90s/it]\u001b[A\n",
      "Average Metric: 44 / 140  (31.4):  10%|         | 140/1436 [08:31<1:25:42,  3.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 44 / 141  (31.2):  10%|         | 140/1436 [08:32<1:25:42,  3.97s/it]\u001b[A\n",
      "Average Metric: 44 / 141  (31.2):  10%|         | 141/1436 [08:32<1:10:11,  3.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 45 / 142  (31.7):  10%|         | 141/1436 [08:34<1:10:11,  3.25s/it]\u001b[A\n",
      "Average Metric: 45 / 142  (31.7):  10%|         | 142/1436 [08:34<1:02:42,  2.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 45 / 143  (31.5):  10%|         | 142/1436 [08:38<1:02:42,  2.91s/it]\u001b[A\n",
      "Average Metric: 45 / 143  (31.5):  10%|         | 143/1436 [08:38<1:04:45,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 45 / 144  (31.2):  10%|         | 143/1436 [08:43<1:04:45,  3.01s/it]\u001b[A\n",
      "Average Metric: 45 / 144  (31.2):  10%|         | 144/1436 [08:43<1:18:12,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 45 / 145  (31.0):  10%|         | 144/1436 [08:47<1:18:12,  3.63s/it]\u001b[A\n",
      "Average Metric: 45 / 145  (31.0):  10%|         | 145/1436 [08:47<1:23:42,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 46 / 146  (31.5):  10%|         | 145/1436 [08:52<1:23:42,  3.89s/it]\u001b[A\n",
      "Average Metric: 46 / 146  (31.5):  10%|         | 146/1436 [08:52<1:27:40,  4.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 46 / 147  (31.3):  10%|         | 146/1436 [08:54<1:27:40,  4.08s/it]\u001b[A\n",
      "Average Metric: 46 / 147  (31.3):  10%|         | 147/1436 [08:54<1:14:29,  3.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 46 / 148  (31.1):  10%|         | 147/1436 [08:59<1:14:29,  3.47s/it]\u001b[A\n",
      "Average Metric: 46 / 148  (31.1):  10%|         | 148/1436 [08:59<1:26:28,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 149  (31.5):  10%|         | 148/1436 [09:03<1:26:28,  4.03s/it]\u001b[A\n",
      "Average Metric: 47 / 149  (31.5):  10%|         | 149/1436 [09:03<1:28:18,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 150  (31.3):  10%|         | 149/1436 [09:09<1:28:18,  4.12s/it]\u001b[A\n",
      "Average Metric: 47 / 150  (31.3):  10%|         | 150/1436 [09:09<1:36:01,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 151  (31.1):  10%|         | 150/1436 [09:14<1:36:01,  4.48s/it]\u001b[A\n",
      "Average Metric: 47 / 151  (31.1):  11%|         | 151/1436 [09:14<1:41:29,  4.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 152  (30.9):  11%|         | 151/1436 [09:17<1:41:29,  4.74s/it]\u001b[A\n",
      "Average Metric: 47 / 152  (30.9):  11%|         | 152/1436 [09:17<1:29:07,  4.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 153  (30.7):  11%|         | 152/1436 [09:21<1:29:07,  4.16s/it]\u001b[A\n",
      "Average Metric: 47 / 153  (30.7):  11%|         | 153/1436 [09:21<1:27:33,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 154  (30.5):  11%|         | 153/1436 [09:26<1:27:33,  4.09s/it]\u001b[A\n",
      "Average Metric: 47 / 154  (30.5):  11%|         | 154/1436 [09:26<1:33:49,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 155  (30.3):  11%|         | 154/1436 [09:31<1:33:49,  4.39s/it]\u001b[A\n",
      "Average Metric: 47 / 155  (30.3):  11%|         | 155/1436 [09:31<1:38:40,  4.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 156  (30.1):  11%|         | 155/1436 [09:34<1:38:40,  4.62s/it]\u001b[A\n",
      "Average Metric: 47 / 156  (30.1):  11%|         | 156/1436 [09:34<1:25:48,  4.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 157  (29.9):  11%|         | 156/1436 [09:35<1:25:48,  4.02s/it]\u001b[A\n",
      "Average Metric: 47 / 157  (29.9):  11%|         | 157/1436 [09:35<1:08:30,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 158  (29.7):  11%|         | 157/1436 [09:40<1:08:30,  3.21s/it]\u001b[A\n",
      "Average Metric: 47 / 158  (29.7):  11%|         | 158/1436 [09:40<1:21:18,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 159  (29.6):  11%|         | 158/1436 [09:43<1:21:18,  3.82s/it]\u001b[A\n",
      "Average Metric: 47 / 159  (29.6):  11%|         | 159/1436 [09:43<1:13:38,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 160  (29.4):  11%|         | 159/1436 [09:45<1:13:38,  3.46s/it]\u001b[A\n",
      "Average Metric: 47 / 160  (29.4):  11%|         | 160/1436 [09:45<1:07:32,  3.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 47 / 161  (29.2):  11%|         | 160/1436 [09:51<1:07:32,  3.18s/it]\u001b[A\n",
      "Average Metric: 47 / 161  (29.2):  11%|         | 161/1436 [09:51<1:20:40,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 48 / 162  (29.6):  11%|         | 161/1436 [09:54<1:20:40,  3.80s/it]\u001b[A\n",
      "Average Metric: 48 / 162  (29.6):  11%|        | 162/1436 [09:54<1:15:26,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 49 / 163  (30.1):  11%|        | 162/1436 [09:55<1:15:26,  3.55s/it]\u001b[A\n",
      "Average Metric: 49 / 163  (30.1):  11%|        | 163/1436 [09:55<1:02:06,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 50 / 164  (30.5):  11%|        | 163/1436 [10:00<1:02:06,  2.93s/it]\u001b[A\n",
      "Average Metric: 50 / 164  (30.5):  11%|        | 164/1436 [10:00<1:16:53,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 50 / 165  (30.3):  11%|        | 164/1436 [10:04<1:16:53,  3.63s/it]\u001b[A\n",
      "Average Metric: 50 / 165  (30.3):  11%|        | 165/1436 [10:04<1:14:05,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 50 / 166  (30.1):  11%|        | 165/1436 [10:06<1:14:05,  3.50s/it]\u001b[A\n",
      "Average Metric: 50 / 166  (30.1):  12%|        | 166/1436 [10:06<1:06:16,  3.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 50 / 167  (29.9):  12%|        | 166/1436 [10:10<1:06:16,  3.13s/it]\u001b[A\n",
      "Average Metric: 50 / 167  (29.9):  12%|        | 167/1436 [10:10<1:14:31,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 50 / 168  (29.8):  12%|        | 167/1436 [10:12<1:14:31,  3.52s/it]\u001b[A\n",
      "Average Metric: 50 / 168  (29.8):  12%|        | 168/1436 [10:12<1:02:58,  2.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 51 / 169  (30.2):  12%|        | 168/1436 [10:15<1:02:58,  2.98s/it]\u001b[A\n",
      "Average Metric: 51 / 169  (30.2):  12%|        | 169/1436 [10:15<1:00:26,  2.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 51 / 170  (30.0):  12%|        | 169/1436 [10:18<1:00:26,  2.86s/it]\u001b[A\n",
      "Average Metric: 51 / 170  (30.0):  12%|        | 170/1436 [10:18<1:04:28,  3.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 52 / 171  (30.4):  12%|        | 170/1436 [10:21<1:04:28,  3.06s/it]\u001b[A\n",
      "Average Metric: 52 / 171  (30.4):  12%|        | 171/1436 [10:21<1:06:40,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 53 / 172  (30.8):  12%|        | 171/1436 [10:25<1:06:40,  3.16s/it]\u001b[A\n",
      "Average Metric: 53 / 172  (30.8):  12%|        | 172/1436 [10:25<1:10:58,  3.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 53 / 173  (30.6):  12%|        | 172/1436 [10:29<1:10:58,  3.37s/it]\u001b[A\n",
      "Average Metric: 53 / 173  (30.6):  12%|        | 173/1436 [10:29<1:14:06,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 54 / 174  (31.0):  12%|        | 173/1436 [10:31<1:14:06,  3.52s/it]\u001b[A\n",
      "Average Metric: 54 / 174  (31.0):  12%|        | 174/1436 [10:31<1:05:16,  3.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 55 / 175  (31.4):  12%|        | 174/1436 [10:36<1:05:16,  3.10s/it]\u001b[A\n",
      "Average Metric: 55 / 175  (31.4):  12%|        | 175/1436 [10:36<1:13:15,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 176  (31.8):  12%|        | 175/1436 [10:40<1:13:15,  3.49s/it]\u001b[A\n",
      "Average Metric: 56 / 176  (31.8):  12%|        | 176/1436 [10:40<1:20:34,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 177  (31.6):  12%|        | 176/1436 [10:44<1:20:34,  3.84s/it]\u001b[A\n",
      "Average Metric: 56 / 177  (31.6):  12%|        | 177/1436 [10:44<1:16:24,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 178  (31.5):  12%|        | 177/1436 [10:47<1:16:24,  3.64s/it]\u001b[A\n",
      "Average Metric: 56 / 178  (31.5):  12%|        | 178/1436 [10:47<1:12:51,  3.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 179  (31.3):  12%|        | 178/1436 [10:52<1:12:51,  3.48s/it]\u001b[A\n",
      "Average Metric: 56 / 179  (31.3):  12%|        | 179/1436 [10:52<1:22:02,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 180  (31.1):  12%|        | 179/1436 [10:57<1:22:02,  3.92s/it]\u001b[A\n",
      "Average Metric: 56 / 180  (31.1):  13%|        | 180/1436 [10:57<1:30:25,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 181  (30.9):  13%|        | 180/1436 [11:02<1:30:25,  4.32s/it]\u001b[A\n",
      "Average Metric: 56 / 181  (30.9):  13%|        | 181/1436 [11:02<1:36:39,  4.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 182  (30.8):  13%|        | 181/1436 [11:04<1:36:39,  4.62s/it]\u001b[A\n",
      "Average Metric: 56 / 182  (30.8):  13%|        | 182/1436 [11:04<1:20:22,  3.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 183  (30.6):  13%|        | 182/1436 [11:09<1:20:22,  3.85s/it]\u001b[A\n",
      "Average Metric: 56 / 183  (30.6):  13%|        | 183/1436 [11:09<1:26:02,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 184  (30.4):  13%|        | 183/1436 [11:14<1:26:02,  4.12s/it]\u001b[A\n",
      "Average Metric: 56 / 184  (30.4):  13%|        | 184/1436 [11:14<1:32:03,  4.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 56 / 185  (30.3):  13%|        | 184/1436 [11:17<1:32:03,  4.41s/it]\u001b[A\n",
      "Average Metric: 56 / 185  (30.3):  13%|        | 185/1436 [11:17<1:23:21,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 186  (30.6):  13%|        | 185/1436 [11:20<1:23:21,  4.00s/it]\u001b[A\n",
      "Average Metric: 57 / 186  (30.6):  13%|        | 186/1436 [11:20<1:18:39,  3.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 187  (30.5):  13%|        | 186/1436 [11:25<1:18:39,  3.78s/it]\u001b[A\n",
      "Average Metric: 57 / 187  (30.5):  13%|        | 187/1436 [11:25<1:26:51,  4.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 188  (30.3):  13%|        | 187/1436 [11:28<1:26:51,  4.17s/it]\u001b[A\n",
      "Average Metric: 57 / 188  (30.3):  13%|        | 188/1436 [11:28<1:14:41,  3.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 189  (30.2):  13%|        | 188/1436 [11:31<1:14:41,  3.59s/it]\u001b[A\n",
      "Average Metric: 57 / 189  (30.2):  13%|        | 189/1436 [11:31<1:14:58,  3.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 190  (30.0):  13%|        | 189/1436 [11:35<1:14:58,  3.61s/it]\u001b[A\n",
      "Average Metric: 57 / 190  (30.0):  13%|        | 190/1436 [11:35<1:17:50,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 191  (29.8):  13%|        | 190/1436 [11:40<1:17:50,  3.75s/it]\u001b[A\n",
      "Average Metric: 57 / 191  (29.8):  13%|        | 191/1436 [11:40<1:25:00,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 192  (29.7):  13%|        | 191/1436 [11:44<1:25:00,  4.10s/it]\u001b[A\n",
      "Average Metric: 57 / 192  (29.7):  13%|        | 192/1436 [11:44<1:20:29,  3.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 193  (29.5):  13%|        | 192/1436 [11:49<1:20:29,  3.88s/it]\u001b[A\n",
      "Average Metric: 57 / 193  (29.5):  13%|        | 193/1436 [11:49<1:28:18,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 57 / 194  (29.4):  13%|        | 193/1436 [11:51<1:28:18,  4.26s/it]\u001b[A\n",
      "Average Metric: 57 / 194  (29.4):  14%|        | 194/1436 [11:51<1:14:05,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 58 / 195  (29.7):  14%|        | 194/1436 [11:54<1:14:05,  3.58s/it]\u001b[A\n",
      "Average Metric: 58 / 195  (29.7):  14%|        | 195/1436 [11:54<1:10:25,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 59 / 196  (30.1):  14%|        | 195/1436 [11:56<1:10:25,  3.41s/it]\u001b[A\n",
      "Average Metric: 59 / 196  (30.1):  14%|        | 196/1436 [11:56<1:03:15,  3.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 59 / 197  (29.9):  14%|        | 196/1436 [12:00<1:03:15,  3.06s/it]\u001b[A\n",
      "Average Metric: 59 / 197  (29.9):  14%|        | 197/1436 [12:00<1:08:43,  3.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 59 / 198  (29.8):  14%|        | 197/1436 [12:03<1:08:43,  3.33s/it]\u001b[A\n",
      "Average Metric: 59 / 198  (29.8):  14%|        | 198/1436 [12:03<1:08:12,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 60 / 199  (30.2):  14%|        | 198/1436 [12:07<1:08:12,  3.31s/it]\u001b[A\n",
      "Average Metric: 60 / 199  (30.2):  14%|        | 199/1436 [12:07<1:13:36,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 60 / 200  (30.0):  14%|        | 199/1436 [12:13<1:13:36,  3.57s/it]\u001b[A\n",
      "Average Metric: 60 / 200  (30.0):  14%|        | 200/1436 [12:13<1:23:29,  4.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 60 / 201  (29.9):  14%|        | 200/1436 [12:18<1:23:29,  4.05s/it]\u001b[A\n",
      "Average Metric: 60 / 201  (29.9):  14%|        | 201/1436 [12:18<1:30:24,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 61 / 202  (30.2):  14%|        | 201/1436 [12:22<1:30:24,  4.39s/it]\u001b[A\n",
      "Average Metric: 61 / 202  (30.2):  14%|        | 202/1436 [12:22<1:27:50,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 61 / 203  (30.0):  14%|        | 202/1436 [12:27<1:27:50,  4.27s/it]\u001b[A\n",
      "Average Metric: 61 / 203  (30.0):  14%|        | 203/1436 [12:27<1:33:28,  4.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 62 / 204  (30.4):  14%|        | 203/1436 [12:29<1:33:28,  4.55s/it]\u001b[A\n",
      "Average Metric: 62 / 204  (30.4):  14%|        | 204/1436 [12:29<1:19:12,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 63 / 205  (30.7):  14%|        | 204/1436 [12:32<1:19:12,  3.86s/it]\u001b[A\n",
      "Average Metric: 63 / 205  (30.7):  14%|        | 205/1436 [12:32<1:14:37,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 206  (31.1):  14%|        | 205/1436 [12:36<1:14:37,  3.64s/it]\u001b[A\n",
      "Average Metric: 64 / 206  (31.1):  14%|        | 206/1436 [12:36<1:15:45,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 207  (30.9):  14%|        | 206/1436 [12:41<1:15:45,  3.70s/it]\u001b[A\n",
      "Average Metric: 64 / 207  (30.9):  14%|        | 207/1436 [12:41<1:24:42,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 208  (30.8):  14%|        | 207/1436 [12:47<1:24:42,  4.14s/it]\u001b[A\n",
      "Average Metric: 64 / 208  (30.8):  14%|        | 208/1436 [12:47<1:31:08,  4.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 209  (30.6):  14%|        | 208/1436 [12:49<1:31:08,  4.45s/it]\u001b[A\n",
      "Average Metric: 64 / 209  (30.6):  15%|        | 209/1436 [12:49<1:20:37,  3.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 210  (30.5):  15%|        | 209/1436 [12:55<1:20:37,  3.94s/it]\u001b[A\n",
      "Average Metric: 64 / 210  (30.5):  15%|        | 210/1436 [12:55<1:28:24,  4.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 211  (30.3):  15%|        | 210/1436 [12:59<1:28:24,  4.33s/it]\u001b[A\n",
      "Average Metric: 64 / 211  (30.3):  15%|        | 211/1436 [12:59<1:26:43,  4.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 212  (30.2):  15%|        | 211/1436 [13:04<1:26:43,  4.25s/it]\u001b[A\n",
      "Average Metric: 64 / 212  (30.2):  15%|        | 212/1436 [13:04<1:32:34,  4.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 64 / 213  (30.0):  15%|        | 212/1436 [13:08<1:32:34,  4.54s/it]\u001b[A\n",
      "Average Metric: 64 / 213  (30.0):  15%|        | 213/1436 [13:08<1:28:49,  4.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 65 / 214  (30.4):  15%|        | 213/1436 [13:10<1:28:49,  4.36s/it]\u001b[A\n",
      "Average Metric: 65 / 214  (30.4):  15%|        | 214/1436 [13:10<1:18:07,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 66 / 215  (30.7):  15%|        | 214/1436 [13:12<1:18:07,  3.84s/it]\u001b[A\n",
      "Average Metric: 66 / 215  (30.7):  15%|        | 215/1436 [13:12<1:04:18,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 66 / 216  (30.6):  15%|        | 215/1436 [13:15<1:04:18,  3.16s/it]\u001b[A\n",
      "Average Metric: 66 / 216  (30.6):  15%|        | 216/1436 [13:15<1:05:13,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 66 / 217  (30.4):  15%|        | 216/1436 [13:19<1:05:13,  3.21s/it]\u001b[A\n",
      "Average Metric: 66 / 217  (30.4):  15%|        | 217/1436 [13:19<1:06:09,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 66 / 218  (30.3):  15%|        | 217/1436 [13:23<1:06:09,  3.26s/it]\u001b[A\n",
      "Average Metric: 66 / 218  (30.3):  15%|        | 218/1436 [13:23<1:11:38,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 66 / 219  (30.1):  15%|        | 218/1436 [13:27<1:11:38,  3.53s/it]\u001b[A\n",
      "Average Metric: 66 / 219  (30.1):  15%|        | 219/1436 [13:27<1:13:46,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 67 / 220  (30.5):  15%|        | 219/1436 [13:28<1:13:46,  3.64s/it]\u001b[A\n",
      "Average Metric: 67 / 220  (30.5):  15%|        | 220/1436 [13:28<59:50,  2.95s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 67 / 221  (30.3):  15%|        | 220/1436 [13:33<59:50,  2.95s/it]\u001b[A\n",
      "Average Metric: 67 / 221  (30.3):  15%|        | 221/1436 [13:33<1:12:59,  3.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 67 / 222  (30.2):  15%|        | 221/1436 [13:38<1:12:59,  3.60s/it]\u001b[A\n",
      "Average Metric: 67 / 222  (30.2):  15%|        | 222/1436 [13:38<1:22:12,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 68 / 223  (30.5):  15%|        | 222/1436 [13:41<1:22:12,  4.06s/it]\u001b[A\n",
      "Average Metric: 68 / 223  (30.5):  16%|        | 223/1436 [13:41<1:13:05,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 68 / 224  (30.4):  16%|        | 223/1436 [13:46<1:13:05,  3.62s/it]\u001b[A\n",
      "Average Metric: 68 / 224  (30.4):  16%|        | 224/1436 [13:46<1:22:09,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 68 / 225  (30.2):  16%|        | 224/1436 [13:51<1:22:09,  4.07s/it]\u001b[A\n",
      "Average Metric: 68 / 225  (30.2):  16%|        | 225/1436 [13:51<1:28:30,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 68 / 226  (30.1):  16%|        | 225/1436 [13:53<1:28:30,  4.39s/it]\u001b[A\n",
      "Average Metric: 68 / 226  (30.1):  16%|        | 226/1436 [13:53<1:16:07,  3.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 68 / 227  (30.0):  16%|        | 226/1436 [13:59<1:16:07,  3.78s/it]\u001b[A\n",
      "Average Metric: 68 / 227  (30.0):  16%|        | 227/1436 [13:59<1:24:15,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 68 / 228  (29.8):  16%|        | 227/1436 [14:03<1:24:15,  4.18s/it]\u001b[A\n",
      "Average Metric: 68 / 228  (29.8):  16%|        | 228/1436 [14:03<1:27:00,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 69 / 229  (30.1):  16%|        | 228/1436 [14:06<1:27:00,  4.32s/it]\u001b[A\n",
      "Average Metric: 69 / 229  (30.1):  16%|        | 229/1436 [14:06<1:15:50,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 69 / 230  (30.0):  16%|        | 229/1436 [14:08<1:15:50,  3.77s/it]\u001b[A\n",
      "Average Metric: 69 / 230  (30.0):  16%|        | 230/1436 [14:08<1:08:26,  3.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 70 / 231  (30.3):  16%|        | 230/1436 [14:11<1:08:26,  3.40s/it]\u001b[A\n",
      "Average Metric: 70 / 231  (30.3):  16%|        | 231/1436 [14:11<1:01:54,  3.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 70 / 232  (30.2):  16%|        | 231/1436 [14:16<1:01:54,  3.08s/it]\u001b[A\n",
      "Average Metric: 70 / 232  (30.2):  16%|        | 232/1436 [14:16<1:13:51,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 70 / 233  (30.0):  16%|        | 232/1436 [14:21<1:13:51,  3.68s/it]\u001b[A\n",
      "Average Metric: 70 / 233  (30.0):  16%|        | 233/1436 [14:21<1:22:09,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 70 / 234  (29.9):  16%|        | 233/1436 [14:26<1:22:09,  4.10s/it]\u001b[A\n",
      "Average Metric: 70 / 234  (29.9):  16%|        | 234/1436 [14:26<1:28:00,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 71 / 235  (30.2):  16%|        | 234/1436 [14:29<1:28:00,  4.39s/it]\u001b[A\n",
      "Average Metric: 71 / 235  (30.2):  16%|        | 235/1436 [14:29<1:21:25,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 71 / 236  (30.1):  16%|        | 235/1436 [14:33<1:21:25,  4.07s/it]\u001b[A\n",
      "Average Metric: 71 / 236  (30.1):  16%|        | 236/1436 [14:33<1:17:27,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 71 / 237  (30.0):  16%|        | 236/1436 [14:37<1:17:27,  3.87s/it]\u001b[A\n",
      "Average Metric: 71 / 237  (30.0):  17%|        | 237/1436 [14:37<1:19:13,  3.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 71 / 238  (29.8):  17%|        | 237/1436 [14:40<1:19:13,  3.96s/it]\u001b[A\n",
      "Average Metric: 71 / 238  (29.8):  17%|        | 238/1436 [14:40<1:15:48,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 72 / 239  (30.1):  17%|        | 238/1436 [14:42<1:15:48,  3.80s/it]\u001b[A\n",
      "Average Metric: 72 / 239  (30.1):  17%|        | 239/1436 [14:42<1:04:48,  3.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 73 / 240  (30.4):  17%|        | 239/1436 [14:44<1:04:48,  3.25s/it]\u001b[A\n",
      "Average Metric: 73 / 240  (30.4):  17%|        | 240/1436 [14:44<57:29,  2.88s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 73 / 241  (30.3):  17%|        | 240/1436 [14:49<57:29,  2.88s/it]\u001b[A\n",
      "Average Metric: 73 / 241  (30.3):  17%|        | 241/1436 [14:49<1:11:04,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 74 / 242  (30.6):  17%|        | 241/1436 [14:51<1:11:04,  3.57s/it]\u001b[A\n",
      "Average Metric: 74 / 242  (30.6):  17%|        | 242/1436 [14:51<1:02:22,  3.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 74 / 243  (30.5):  17%|        | 242/1436 [14:54<1:02:22,  3.13s/it]\u001b[A\n",
      "Average Metric: 74 / 243  (30.5):  17%|        | 243/1436 [14:54<57:27,  2.89s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 74 / 244  (30.3):  17%|        | 243/1436 [14:58<57:27,  2.89s/it]\u001b[A\n",
      "Average Metric: 74 / 244  (30.3):  17%|        | 244/1436 [14:58<1:06:24,  3.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 75 / 245  (30.6):  17%|        | 244/1436 [15:02<1:06:24,  3.34s/it]\u001b[A\n",
      "Average Metric: 75 / 245  (30.6):  17%|        | 245/1436 [15:02<1:07:10,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 76 / 246  (30.9):  17%|        | 245/1436 [15:06<1:07:10,  3.38s/it]\u001b[A\n",
      "Average Metric: 76 / 246  (30.9):  17%|        | 246/1436 [15:06<1:13:10,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 76 / 247  (30.8):  17%|        | 246/1436 [15:11<1:13:10,  3.69s/it]\u001b[A\n",
      "Average Metric: 76 / 247  (30.8):  17%|        | 247/1436 [15:11<1:22:06,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 76 / 248  (30.6):  17%|        | 247/1436 [15:15<1:22:06,  4.14s/it]\u001b[A\n",
      "Average Metric: 76 / 248  (30.6):  17%|        | 248/1436 [15:15<1:18:40,  3.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 76 / 249  (30.5):  17%|        | 248/1436 [15:20<1:18:40,  3.97s/it]\u001b[A\n",
      "Average Metric: 76 / 249  (30.5):  17%|        | 249/1436 [15:20<1:26:10,  4.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 76 / 250  (30.4):  17%|        | 249/1436 [15:24<1:26:10,  4.36s/it]\u001b[A\n",
      "Average Metric: 76 / 250  (30.4):  17%|        | 250/1436 [15:24<1:20:52,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 77 / 251  (30.7):  17%|        | 250/1436 [15:26<1:20:52,  4.09s/it]\u001b[A\n",
      "Average Metric: 77 / 251  (30.7):  17%|        | 251/1436 [15:26<1:11:06,  3.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 78 / 252  (31.0):  17%|        | 251/1436 [15:29<1:11:06,  3.60s/it]\u001b[A\n",
      "Average Metric: 78 / 252  (31.0):  18%|        | 252/1436 [15:29<1:07:18,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 79 / 253  (31.2):  18%|        | 252/1436 [15:33<1:07:18,  3.41s/it]\u001b[A\n",
      "Average Metric: 79 / 253  (31.2):  18%|        | 253/1436 [15:33<1:13:08,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 79 / 254  (31.1):  18%|        | 253/1436 [15:37<1:13:08,  3.71s/it]\u001b[A\n",
      "Average Metric: 79 / 254  (31.1):  18%|        | 254/1436 [15:37<1:14:59,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 79 / 255  (31.0):  18%|        | 254/1436 [15:41<1:14:59,  3.81s/it]\u001b[A\n",
      "Average Metric: 79 / 255  (31.0):  18%|        | 255/1436 [15:41<1:13:15,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 80 / 256  (31.2):  18%|        | 255/1436 [15:44<1:13:15,  3.72s/it]\u001b[A\n",
      "Average Metric: 80 / 256  (31.2):  18%|        | 256/1436 [15:44<1:12:06,  3.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 80 / 257  (31.1):  18%|        | 256/1436 [15:48<1:12:06,  3.67s/it]\u001b[A\n",
      "Average Metric: 80 / 257  (31.1):  18%|        | 257/1436 [15:48<1:09:03,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 80 / 258  (31.0):  18%|        | 257/1436 [15:52<1:09:03,  3.51s/it]\u001b[A\n",
      "Average Metric: 80 / 258  (31.0):  18%|        | 258/1436 [15:52<1:16:35,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 80 / 259  (30.9):  18%|        | 258/1436 [15:54<1:16:35,  3.90s/it]\u001b[A\n",
      "Average Metric: 80 / 259  (30.9):  18%|        | 259/1436 [15:54<1:03:07,  3.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 80 / 260  (30.8):  18%|        | 259/1436 [15:56<1:03:07,  3.22s/it]\u001b[A\n",
      "Average Metric: 80 / 260  (30.8):  18%|        | 260/1436 [15:56<54:49,  2.80s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 81 / 261  (31.0):  18%|        | 260/1436 [15:58<54:49,  2.80s/it]\u001b[A\n",
      "Average Metric: 81 / 261  (31.0):  18%|        | 261/1436 [15:58<48:49,  2.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 81 / 262  (30.9):  18%|        | 261/1436 [15:59<48:49,  2.49s/it]\u001b[A\n",
      "Average Metric: 81 / 262  (30.9):  18%|        | 262/1436 [15:59<44:02,  2.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 81 / 263  (30.8):  18%|        | 262/1436 [16:03<44:02,  2.25s/it]\u001b[A\n",
      "Average Metric: 81 / 263  (30.8):  18%|        | 263/1436 [16:03<53:44,  2.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 81 / 264  (30.7):  18%|        | 263/1436 [16:07<53:44,  2.75s/it]\u001b[A\n",
      "Average Metric: 81 / 264  (30.7):  18%|        | 264/1436 [16:07<57:08,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 81 / 265  (30.6):  18%|        | 264/1436 [16:10<57:08,  2.93s/it]\u001b[A\n",
      "Average Metric: 81 / 265  (30.6):  18%|        | 265/1436 [16:10<1:00:25,  3.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 82 / 266  (30.8):  18%|        | 265/1436 [16:12<1:00:25,  3.10s/it]\u001b[A\n",
      "Average Metric: 82 / 266  (30.8):  19%|        | 266/1436 [16:12<51:12,  2.63s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 83 / 267  (31.1):  19%|        | 266/1436 [16:13<51:12,  2.63s/it]\u001b[A\n",
      "Average Metric: 83 / 267  (31.1):  19%|        | 267/1436 [16:13<46:25,  2.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 84 / 268  (31.3):  19%|        | 267/1436 [16:15<46:25,  2.38s/it]\u001b[A\n",
      "Average Metric: 84 / 268  (31.3):  19%|        | 268/1436 [16:15<44:03,  2.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 84 / 269  (31.2):  19%|        | 268/1436 [16:18<44:03,  2.26s/it]\u001b[A\n",
      "Average Metric: 84 / 269  (31.2):  19%|        | 269/1436 [16:18<43:50,  2.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 85 / 270  (31.5):  19%|        | 269/1436 [16:22<43:50,  2.25s/it]\u001b[A\n",
      "Average Metric: 85 / 270  (31.5):  19%|        | 270/1436 [16:22<55:00,  2.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 86 / 271  (31.7):  19%|        | 270/1436 [16:24<55:00,  2.83s/it]\u001b[A\n",
      "Average Metric: 86 / 271  (31.7):  19%|        | 271/1436 [16:24<48:55,  2.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 86 / 272  (31.6):  19%|        | 271/1436 [16:28<48:55,  2.52s/it]\u001b[A\n",
      "Average Metric: 86 / 272  (31.6):  19%|        | 272/1436 [16:28<58:07,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 87 / 273  (31.9):  19%|        | 272/1436 [16:32<58:07,  3.00s/it]\u001b[A\n",
      "Average Metric: 87 / 273  (31.9):  19%|        | 273/1436 [16:32<1:08:04,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 88 / 274  (32.1):  19%|        | 273/1436 [16:34<1:08:04,  3.51s/it]\u001b[A\n",
      "Average Metric: 88 / 274  (32.1):  19%|        | 274/1436 [16:34<54:57,  2.84s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 88 / 275  (32.0):  19%|        | 274/1436 [16:39<54:57,  2.84s/it]\u001b[A\n",
      "Average Metric: 88 / 275  (32.0):  19%|        | 275/1436 [16:39<1:07:56,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 89 / 276  (32.2):  19%|        | 275/1436 [16:41<1:07:56,  3.51s/it]\u001b[A\n",
      "Average Metric: 89 / 276  (32.2):  19%|        | 276/1436 [16:41<59:52,  3.10s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 89 / 277  (32.1):  19%|        | 276/1436 [16:44<59:52,  3.10s/it]\u001b[A\n",
      "Average Metric: 89 / 277  (32.1):  19%|        | 277/1436 [16:44<59:24,  3.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 89 / 278  (32.0):  19%|        | 277/1436 [16:47<59:24,  3.08s/it]\u001b[A\n",
      "Average Metric: 89 / 278  (32.0):  19%|        | 278/1436 [16:47<1:00:00,  3.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 90 / 279  (32.3):  19%|        | 278/1436 [16:49<1:00:00,  3.11s/it]\u001b[A\n",
      "Average Metric: 90 / 279  (32.3):  19%|        | 279/1436 [16:49<54:19,  2.82s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 90 / 280  (32.1):  19%|        | 279/1436 [16:54<54:19,  2.82s/it]\u001b[A\n",
      "Average Metric: 90 / 280  (32.1):  19%|        | 280/1436 [16:54<1:06:17,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 90 / 281  (32.0):  19%|        | 280/1436 [16:59<1:06:17,  3.44s/it]\u001b[A\n",
      "Average Metric: 90 / 281  (32.0):  20%|        | 281/1436 [16:59<1:15:44,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 90 / 282  (31.9):  20%|        | 281/1436 [17:04<1:15:44,  3.93s/it]\u001b[A\n",
      "Average Metric: 90 / 282  (31.9):  20%|        | 282/1436 [17:04<1:20:15,  4.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 90 / 283  (31.8):  20%|        | 282/1436 [17:07<1:20:15,  4.17s/it]\u001b[A\n",
      "Average Metric: 90 / 283  (31.8):  20%|        | 283/1436 [17:07<1:13:28,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 90 / 284  (31.7):  20%|        | 283/1436 [17:12<1:13:28,  3.82s/it]\u001b[A\n",
      "Average Metric: 90 / 284  (31.7):  20%|        | 284/1436 [17:12<1:21:40,  4.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 91 / 285  (31.9):  20%|        | 284/1436 [17:14<1:21:40,  4.25s/it]\u001b[A\n",
      "Average Metric: 91 / 285  (31.9):  20%|        | 285/1436 [17:14<1:07:14,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 91 / 286  (31.8):  20%|        | 285/1436 [17:16<1:07:14,  3.51s/it]\u001b[A\n",
      "Average Metric: 91 / 286  (31.8):  20%|        | 286/1436 [17:16<1:01:13,  3.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 91 / 287  (31.7):  20%|        | 286/1436 [17:20<1:01:13,  3.19s/it]\u001b[A\n",
      "Average Metric: 91 / 287  (31.7):  20%|        | 287/1436 [17:20<1:02:23,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 91 / 288  (31.6):  20%|        | 287/1436 [17:24<1:02:23,  3.26s/it]\u001b[A\n",
      "Average Metric: 91 / 288  (31.6):  20%|        | 288/1436 [17:24<1:07:29,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 289  (31.8):  20%|        | 288/1436 [17:26<1:07:29,  3.53s/it]\u001b[A\n",
      "Average Metric: 92 / 289  (31.8):  20%|        | 289/1436 [17:26<1:01:00,  3.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 290  (31.7):  20%|        | 289/1436 [17:29<1:01:00,  3.19s/it]\u001b[A\n",
      "Average Metric: 92 / 290  (31.7):  20%|        | 290/1436 [17:29<56:53,  2.98s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 291  (31.6):  20%|        | 290/1436 [17:32<56:53,  2.98s/it]\u001b[A\n",
      "Average Metric: 92 / 291  (31.6):  20%|        | 291/1436 [17:32<56:34,  2.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 292  (31.5):  20%|        | 291/1436 [17:36<56:34,  2.96s/it]\u001b[A\n",
      "Average Metric: 92 / 292  (31.5):  20%|        | 292/1436 [17:36<1:05:16,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 293  (31.4):  20%|        | 292/1436 [17:40<1:05:16,  3.42s/it]\u001b[A\n",
      "Average Metric: 92 / 293  (31.4):  20%|        | 293/1436 [17:40<1:09:04,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 294  (31.3):  20%|        | 293/1436 [17:46<1:09:04,  3.63s/it]\u001b[A\n",
      "Average Metric: 92 / 294  (31.3):  20%|        | 294/1436 [17:46<1:18:07,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 295  (31.2):  20%|        | 294/1436 [17:51<1:18:07,  4.10s/it]\u001b[A\n",
      "Average Metric: 92 / 295  (31.2):  21%|        | 295/1436 [17:51<1:24:24,  4.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 92 / 296  (31.1):  21%|        | 295/1436 [17:56<1:24:24,  4.44s/it]\u001b[A\n",
      "Average Metric: 92 / 296  (31.1):  21%|        | 296/1436 [17:56<1:28:51,  4.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 93 / 297  (31.3):  21%|        | 296/1436 [17:59<1:28:51,  4.68s/it]\u001b[A\n",
      "Average Metric: 93 / 297  (31.3):  21%|        | 297/1436 [17:59<1:16:44,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 94 / 298  (31.5):  21%|        | 297/1436 [18:00<1:16:44,  4.04s/it]\u001b[A\n",
      "Average Metric: 94 / 298  (31.5):  21%|        | 298/1436 [18:00<1:02:22,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 95 / 299  (31.8):  21%|        | 298/1436 [18:03<1:02:22,  3.29s/it]\u001b[A\n",
      "Average Metric: 95 / 299  (31.8):  21%|        | 299/1436 [18:03<1:00:48,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 95 / 300  (31.7):  21%|        | 299/1436 [18:07<1:00:48,  3.21s/it]\u001b[A\n",
      "Average Metric: 95 / 300  (31.7):  21%|        | 300/1436 [18:07<1:05:53,  3.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 95 / 301  (31.6):  21%|        | 300/1436 [18:11<1:05:53,  3.48s/it]\u001b[A\n",
      "Average Metric: 95 / 301  (31.6):  21%|        | 301/1436 [18:11<1:04:58,  3.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 96 / 302  (31.8):  21%|        | 301/1436 [18:13<1:04:58,  3.43s/it]\u001b[A\n",
      "Average Metric: 96 / 302  (31.8):  21%|        | 302/1436 [18:13<59:05,  3.13s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 96 / 303  (31.7):  21%|        | 302/1436 [18:18<59:05,  3.13s/it]\u001b[A\n",
      "Average Metric: 96 / 303  (31.7):  21%|        | 303/1436 [18:18<1:11:06,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 304  (31.9):  21%|        | 303/1436 [18:22<1:11:06,  3.77s/it]\u001b[A\n",
      "Average Metric: 97 / 304  (31.9):  21%|        | 304/1436 [18:22<1:09:05,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 305  (31.8):  21%|        | 304/1436 [18:27<1:09:05,  3.66s/it]\u001b[A\n",
      "Average Metric: 97 / 305  (31.8):  21%|        | 305/1436 [18:27<1:18:20,  4.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 306  (31.7):  21%|        | 305/1436 [18:32<1:18:20,  4.16s/it]\u001b[A\n",
      "Average Metric: 97 / 306  (31.7):  21%|       | 306/1436 [18:32<1:23:45,  4.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 307  (31.6):  21%|       | 306/1436 [18:37<1:23:45,  4.45s/it]\u001b[A\n",
      "Average Metric: 97 / 307  (31.6):  21%|       | 307/1436 [18:37<1:27:28,  4.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 308  (31.5):  21%|       | 307/1436 [18:39<1:27:28,  4.65s/it]\u001b[A\n",
      "Average Metric: 97 / 308  (31.5):  21%|       | 308/1436 [18:39<1:12:56,  3.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 309  (31.4):  21%|       | 308/1436 [18:43<1:12:56,  3.88s/it]\u001b[A\n",
      "Average Metric: 97 / 309  (31.4):  22%|       | 309/1436 [18:43<1:11:11,  3.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 310  (31.3):  22%|       | 309/1436 [18:46<1:11:11,  3.79s/it]\u001b[A\n",
      "Average Metric: 97 / 310  (31.3):  22%|       | 310/1436 [18:46<1:04:56,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 97 / 311  (31.2):  22%|       | 310/1436 [18:51<1:04:56,  3.46s/it]\u001b[A\n",
      "Average Metric: 97 / 311  (31.2):  22%|       | 311/1436 [18:51<1:15:20,  4.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 98 / 312  (31.4):  22%|       | 311/1436 [18:53<1:15:20,  4.02s/it]\u001b[A\n",
      "Average Metric: 98 / 312  (31.4):  22%|       | 312/1436 [18:53<1:06:21,  3.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 98 / 313  (31.3):  22%|       | 312/1436 [18:57<1:06:21,  3.54s/it]\u001b[A\n",
      "Average Metric: 98 / 313  (31.3):  22%|       | 313/1436 [18:57<1:05:29,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 98 / 314  (31.2):  22%|       | 313/1436 [19:02<1:05:29,  3.50s/it]\u001b[A\n",
      "Average Metric: 98 / 314  (31.2):  22%|       | 314/1436 [19:02<1:15:34,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 98 / 315  (31.1):  22%|       | 314/1436 [19:06<1:15:34,  4.04s/it]\u001b[A\n",
      "Average Metric: 98 / 315  (31.1):  22%|       | 315/1436 [19:06<1:17:06,  4.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 99 / 316  (31.3):  22%|       | 315/1436 [19:08<1:17:06,  4.13s/it]\u001b[A\n",
      "Average Metric: 99 / 316  (31.3):  22%|       | 316/1436 [19:08<1:02:30,  3.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 99 / 317  (31.2):  22%|       | 316/1436 [19:13<1:02:30,  3.35s/it]\u001b[A\n",
      "Average Metric: 99 / 317  (31.2):  22%|       | 317/1436 [19:13<1:13:00,  3.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 100 / 318  (31.4):  22%|       | 317/1436 [19:16<1:13:00,  3.91s/it]\u001b[A\n",
      "Average Metric: 100 / 318  (31.4):  22%|       | 318/1436 [19:16<1:05:13,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 100 / 319  (31.3):  22%|       | 318/1436 [19:20<1:05:13,  3.50s/it]\u001b[A\n",
      "Average Metric: 100 / 319  (31.3):  22%|       | 319/1436 [19:20<1:07:16,  3.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 100 / 320  (31.2):  22%|       | 319/1436 [19:23<1:07:16,  3.61s/it]\u001b[A\n",
      "Average Metric: 100 / 320  (31.2):  22%|       | 320/1436 [19:23<1:03:24,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 101 / 321  (31.5):  22%|       | 320/1436 [19:25<1:03:24,  3.41s/it]\u001b[A\n",
      "Average Metric: 101 / 321  (31.5):  22%|       | 321/1436 [19:25<57:39,  3.10s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 102 / 322  (31.7):  22%|       | 321/1436 [19:30<57:39,  3.10s/it]\u001b[A\n",
      "Average Metric: 102 / 322  (31.7):  22%|       | 322/1436 [19:30<1:07:12,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 102 / 323  (31.6):  22%|       | 322/1436 [19:35<1:07:12,  3.62s/it]\u001b[A\n",
      "Average Metric: 102 / 323  (31.6):  22%|       | 323/1436 [19:35<1:16:05,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 102 / 324  (31.5):  22%|       | 323/1436 [19:40<1:16:05,  4.10s/it]\u001b[A\n",
      "Average Metric: 102 / 324  (31.5):  23%|       | 324/1436 [19:40<1:22:21,  4.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 102 / 325  (31.4):  23%|       | 324/1436 [19:44<1:22:21,  4.44s/it]\u001b[A\n",
      "Average Metric: 102 / 325  (31.4):  23%|       | 325/1436 [19:44<1:16:51,  4.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 103 / 326  (31.6):  23%|       | 325/1436 [19:46<1:16:51,  4.15s/it]\u001b[A\n",
      "Average Metric: 103 / 326  (31.6):  23%|       | 326/1436 [19:46<1:07:44,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 104 / 327  (31.8):  23%|       | 326/1436 [19:49<1:07:44,  3.66s/it]\u001b[A\n",
      "Average Metric: 104 / 327  (31.8):  23%|       | 327/1436 [19:49<1:02:41,  3.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 105 / 328  (32.0):  23%|       | 327/1436 [19:52<1:02:41,  3.39s/it]\u001b[A\n",
      "Average Metric: 105 / 328  (32.0):  23%|       | 328/1436 [19:52<57:37,  3.12s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 105 / 329  (31.9):  23%|       | 328/1436 [19:54<57:37,  3.12s/it]\u001b[A\n",
      "Average Metric: 105 / 329  (31.9):  23%|       | 329/1436 [19:54<53:53,  2.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 105 / 330  (31.8):  23%|       | 329/1436 [19:57<53:53,  2.92s/it]\u001b[A\n",
      "Average Metric: 105 / 330  (31.8):  23%|       | 330/1436 [19:57<55:27,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 106 / 331  (32.0):  23%|       | 330/1436 [19:59<55:27,  3.01s/it]\u001b[A\n",
      "Average Metric: 106 / 331  (32.0):  23%|       | 331/1436 [19:59<49:35,  2.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 332  (32.2):  23%|       | 331/1436 [20:03<49:35,  2.69s/it]\u001b[A\n",
      "Average Metric: 107 / 332  (32.2):  23%|       | 332/1436 [20:03<54:02,  2.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 333  (32.1):  23%|       | 332/1436 [20:08<54:02,  2.94s/it]\u001b[A\n",
      "Average Metric: 107 / 333  (32.1):  23%|       | 333/1436 [20:08<1:05:16,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 334  (32.0):  23%|       | 333/1436 [20:13<1:05:16,  3.55s/it]\u001b[A\n",
      "Average Metric: 107 / 334  (32.0):  23%|       | 334/1436 [20:13<1:13:50,  4.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 335  (31.9):  23%|       | 334/1436 [20:18<1:13:50,  4.02s/it]\u001b[A\n",
      "Average Metric: 107 / 335  (31.9):  23%|       | 335/1436 [20:18<1:19:43,  4.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 336  (31.8):  23%|       | 335/1436 [20:23<1:19:43,  4.34s/it]\u001b[A\n",
      "Average Metric: 107 / 336  (31.8):  23%|       | 336/1436 [20:23<1:23:49,  4.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 107 / 337  (31.8):  23%|       | 336/1436 [20:27<1:23:49,  4.57s/it]\u001b[A\n",
      "Average Metric: 107 / 337  (31.8):  23%|       | 337/1436 [20:27<1:20:51,  4.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 108 / 338  (32.0):  23%|       | 337/1436 [20:28<1:20:51,  4.41s/it]\u001b[A\n",
      "Average Metric: 108 / 338  (32.0):  24%|       | 338/1436 [20:28<1:04:15,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 108 / 339  (31.9):  24%|       | 338/1436 [20:31<1:04:15,  3.51s/it]\u001b[A\n",
      "Average Metric: 108 / 339  (31.9):  24%|       | 339/1436 [20:31<57:59,  3.17s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 108 / 340  (31.8):  24%|       | 339/1436 [20:34<57:59,  3.17s/it]\u001b[A\n",
      "Average Metric: 108 / 340  (31.8):  24%|       | 340/1436 [20:34<59:46,  3.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 108 / 341  (31.7):  24%|       | 340/1436 [20:36<59:46,  3.27s/it]\u001b[A\n",
      "Average Metric: 108 / 341  (31.7):  24%|       | 341/1436 [20:36<51:50,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 108 / 342  (31.6):  24%|       | 341/1436 [20:38<51:50,  2.84s/it]\u001b[A\n",
      "Average Metric: 108 / 342  (31.6):  24%|       | 342/1436 [20:38<46:47,  2.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 109 / 343  (31.8):  24%|       | 342/1436 [20:42<46:47,  2.57s/it]\u001b[A\n",
      "Average Metric: 109 / 343  (31.8):  24%|       | 343/1436 [20:42<54:29,  2.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 109 / 344  (31.7):  24%|       | 343/1436 [20:44<54:29,  2.99s/it]\u001b[A\n",
      "Average Metric: 109 / 344  (31.7):  24%|       | 344/1436 [20:44<50:08,  2.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 110 / 345  (31.9):  24%|       | 344/1436 [20:47<50:08,  2.76s/it]\u001b[A\n",
      "Average Metric: 110 / 345  (31.9):  24%|       | 345/1436 [20:47<49:37,  2.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 346  (32.1):  24%|       | 345/1436 [20:49<49:37,  2.73s/it]\u001b[A\n",
      "Average Metric: 111 / 346  (32.1):  24%|       | 346/1436 [20:49<44:56,  2.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 347  (32.0):  24%|       | 346/1436 [20:54<44:56,  2.47s/it]\u001b[A\n",
      "Average Metric: 111 / 347  (32.0):  24%|       | 347/1436 [20:54<59:54,  3.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 348  (31.9):  24%|       | 347/1436 [20:58<59:54,  3.30s/it]\u001b[A\n",
      "Average Metric: 111 / 348  (31.9):  24%|       | 348/1436 [20:58<1:05:50,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 349  (31.8):  24%|       | 348/1436 [21:02<1:05:50,  3.63s/it]\u001b[A\n",
      "Average Metric: 111 / 349  (31.8):  24%|       | 349/1436 [21:02<1:08:12,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 350  (31.7):  24%|       | 349/1436 [21:08<1:08:12,  3.76s/it]\u001b[A\n",
      "Average Metric: 111 / 350  (31.7):  24%|       | 350/1436 [21:08<1:15:23,  4.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 351  (31.6):  24%|       | 350/1436 [21:13<1:15:23,  4.17s/it]\u001b[A\n",
      "Average Metric: 111 / 351  (31.6):  24%|       | 351/1436 [21:13<1:20:39,  4.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 352  (31.5):  24%|       | 351/1436 [21:18<1:20:39,  4.46s/it]\u001b[A\n",
      "Average Metric: 111 / 352  (31.5):  25%|       | 352/1436 [21:18<1:23:59,  4.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 353  (31.4):  25%|       | 352/1436 [21:19<1:23:59,  4.65s/it]\u001b[A\n",
      "Average Metric: 111 / 353  (31.4):  25%|       | 353/1436 [21:19<1:07:15,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 354  (31.4):  25%|       | 353/1436 [21:24<1:07:15,  3.73s/it]\u001b[A\n",
      "Average Metric: 111 / 354  (31.4):  25%|       | 354/1436 [21:24<1:12:46,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 111 / 355  (31.3):  25%|       | 354/1436 [21:30<1:12:46,  4.04s/it]\u001b[A\n",
      "Average Metric: 111 / 355  (31.3):  25%|       | 355/1436 [21:30<1:19:55,  4.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 356  (31.5):  25%|       | 355/1436 [21:34<1:19:55,  4.44s/it]\u001b[A\n",
      "Average Metric: 112 / 356  (31.5):  25%|       | 356/1436 [21:34<1:20:36,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 357  (31.4):  25%|       | 356/1436 [21:38<1:20:36,  4.48s/it]\u001b[A\n",
      "Average Metric: 112 / 357  (31.4):  25%|       | 357/1436 [21:38<1:16:09,  4.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 358  (31.3):  25%|       | 357/1436 [21:41<1:16:09,  4.24s/it]\u001b[A\n",
      "Average Metric: 112 / 358  (31.3):  25%|       | 358/1436 [21:41<1:08:14,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 359  (31.2):  25%|       | 358/1436 [21:44<1:08:14,  3.80s/it]\u001b[A\n",
      "Average Metric: 112 / 359  (31.2):  25%|       | 359/1436 [21:44<1:04:54,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 360  (31.1):  25%|       | 359/1436 [21:48<1:04:54,  3.62s/it]\u001b[A\n",
      "Average Metric: 112 / 360  (31.1):  25%|       | 360/1436 [21:48<1:06:54,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 361  (31.0):  25%|       | 360/1436 [21:53<1:06:54,  3.73s/it]\u001b[A\n",
      "Average Metric: 112 / 361  (31.0):  25%|       | 361/1436 [21:53<1:15:31,  4.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 362  (30.9):  25%|       | 361/1436 [21:58<1:15:31,  4.21s/it]\u001b[A\n",
      "Average Metric: 112 / 362  (30.9):  25%|       | 362/1436 [21:58<1:18:35,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 363  (30.9):  25%|       | 362/1436 [22:03<1:18:35,  4.39s/it]\u001b[A\n",
      "Average Metric: 112 / 363  (30.9):  25%|       | 363/1436 [22:03<1:23:41,  4.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 112 / 364  (30.8):  25%|       | 363/1436 [22:07<1:23:41,  4.68s/it]\u001b[A\n",
      "Average Metric: 112 / 364  (30.8):  25%|       | 364/1436 [22:07<1:21:09,  4.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 113 / 365  (31.0):  25%|       | 364/1436 [22:09<1:21:09,  4.54s/it]\u001b[A\n",
      "Average Metric: 113 / 365  (31.0):  25%|       | 365/1436 [22:09<1:06:41,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 114 / 366  (31.1):  25%|       | 365/1436 [22:12<1:06:41,  3.74s/it]\u001b[A\n",
      "Average Metric: 114 / 366  (31.1):  25%|       | 366/1436 [22:12<1:02:57,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 114 / 367  (31.1):  25%|       | 366/1436 [22:16<1:02:57,  3.53s/it]\u001b[A\n",
      "Average Metric: 114 / 367  (31.1):  26%|       | 367/1436 [22:16<1:05:42,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 115 / 368  (31.2):  26%|       | 367/1436 [22:20<1:05:42,  3.69s/it]\u001b[A\n",
      "Average Metric: 115 / 368  (31.2):  26%|       | 368/1436 [22:20<1:03:20,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 115 / 369  (31.2):  26%|       | 368/1436 [22:25<1:03:20,  3.56s/it]\u001b[A\n",
      "Average Metric: 115 / 369  (31.2):  26%|       | 369/1436 [22:25<1:13:14,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 116 / 370  (31.4):  26%|       | 369/1436 [22:30<1:13:14,  4.12s/it]\u001b[A\n",
      "Average Metric: 116 / 370  (31.4):  26%|       | 370/1436 [22:30<1:19:30,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 117 / 371  (31.5):  26%|       | 370/1436 [22:32<1:19:30,  4.48s/it]\u001b[A\n",
      "Average Metric: 117 / 371  (31.5):  26%|       | 371/1436 [22:32<1:04:09,  3.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 118 / 372  (31.7):  26%|       | 371/1436 [22:35<1:04:09,  3.61s/it]\u001b[A\n",
      "Average Metric: 118 / 372  (31.7):  26%|       | 372/1436 [22:35<1:03:03,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 119 / 373  (31.9):  26%|       | 372/1436 [22:37<1:03:03,  3.56s/it]\u001b[A\n",
      "Average Metric: 119 / 373  (31.9):  26%|       | 373/1436 [22:37<54:46,  3.09s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 120 / 374  (32.1):  26%|       | 373/1436 [22:39<54:46,  3.09s/it]\u001b[A\n",
      "Average Metric: 120 / 374  (32.1):  26%|       | 374/1436 [22:39<48:48,  2.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 121 / 375  (32.3):  26%|       | 374/1436 [22:42<48:48,  2.76s/it]\u001b[A\n",
      "Average Metric: 121 / 375  (32.3):  26%|       | 375/1436 [22:42<47:45,  2.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 122 / 376  (32.4):  26%|       | 375/1436 [22:44<47:45,  2.70s/it]\u001b[A\n",
      "Average Metric: 122 / 376  (32.4):  26%|       | 376/1436 [22:44<43:39,  2.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 377  (32.6):  26%|       | 376/1436 [22:45<43:39,  2.47s/it]\u001b[A\n",
      "Average Metric: 123 / 377  (32.6):  26%|       | 377/1436 [22:45<38:31,  2.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 378  (32.5):  26%|       | 377/1436 [22:51<38:31,  2.18s/it]\u001b[A\n",
      "Average Metric: 123 / 378  (32.5):  26%|       | 378/1436 [22:51<54:37,  3.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 379  (32.5):  26%|       | 378/1436 [22:53<54:37,  3.10s/it]\u001b[A\n",
      "Average Metric: 123 / 379  (32.5):  26%|       | 379/1436 [22:53<48:03,  2.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 380  (32.4):  26%|       | 379/1436 [22:58<48:03,  2.73s/it]\u001b[A\n",
      "Average Metric: 123 / 380  (32.4):  26%|       | 380/1436 [22:58<1:02:02,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 381  (32.3):  26%|       | 380/1436 [23:02<1:02:02,  3.53s/it]\u001b[A\n",
      "Average Metric: 123 / 381  (32.3):  27%|       | 381/1436 [23:02<1:02:53,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 382  (32.2):  27%|       | 381/1436 [23:07<1:02:53,  3.58s/it]\u001b[A\n",
      "Average Metric: 123 / 382  (32.2):  27%|       | 382/1436 [23:07<1:13:37,  4.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 383  (32.1):  27%|       | 382/1436 [23:13<1:13:37,  4.19s/it]\u001b[A\n",
      "Average Metric: 123 / 383  (32.1):  27%|       | 383/1436 [23:13<1:19:57,  4.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 384  (32.0):  27%|       | 383/1436 [23:16<1:19:57,  4.56s/it]\u001b[A\n",
      "Average Metric: 123 / 384  (32.0):  27%|       | 384/1436 [23:16<1:12:12,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 385  (31.9):  27%|       | 384/1436 [23:21<1:12:12,  4.12s/it]\u001b[A\n",
      "Average Metric: 123 / 385  (31.9):  27%|       | 385/1436 [23:21<1:19:31,  4.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 386  (31.9):  27%|       | 385/1436 [23:26<1:19:31,  4.54s/it]\u001b[A\n",
      "Average Metric: 123 / 386  (31.9):  27%|       | 386/1436 [23:26<1:19:30,  4.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 123 / 387  (31.8):  27%|       | 386/1436 [23:29<1:19:30,  4.54s/it]\u001b[A\n",
      "Average Metric: 123 / 387  (31.8):  27%|       | 387/1436 [23:29<1:12:21,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 124 / 388  (32.0):  27%|       | 387/1436 [23:34<1:12:21,  4.14s/it]\u001b[A\n",
      "Average Metric: 124 / 388  (32.0):  27%|       | 388/1436 [23:34<1:18:53,  4.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 125 / 389  (32.1):  27%|       | 388/1436 [23:37<1:18:53,  4.52s/it]\u001b[A\n",
      "Average Metric: 125 / 389  (32.1):  27%|       | 389/1436 [23:37<1:07:32,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 126 / 390  (32.3):  27%|       | 389/1436 [23:40<1:07:32,  3.87s/it]\u001b[A\n",
      "Average Metric: 126 / 390  (32.3):  27%|       | 390/1436 [23:40<1:02:10,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 126 / 391  (32.2):  27%|       | 390/1436 [23:45<1:02:10,  3.57s/it]\u001b[A\n",
      "Average Metric: 126 / 391  (32.2):  27%|       | 391/1436 [23:45<1:11:11,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 126 / 392  (32.1):  27%|       | 391/1436 [23:48<1:11:11,  4.09s/it]\u001b[A\n",
      "Average Metric: 126 / 392  (32.1):  27%|       | 392/1436 [23:48<1:04:00,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 126 / 393  (32.1):  27%|       | 392/1436 [23:51<1:04:00,  3.68s/it]\u001b[A\n",
      "Average Metric: 126 / 393  (32.1):  27%|       | 393/1436 [23:51<1:04:36,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 127 / 394  (32.2):  27%|       | 393/1436 [23:55<1:04:36,  3.72s/it]\u001b[A\n",
      "Average Metric: 127 / 394  (32.2):  27%|       | 394/1436 [23:55<1:05:12,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 127 / 395  (32.2):  27%|       | 394/1436 [23:57<1:05:12,  3.76s/it]\u001b[A\n",
      "Average Metric: 127 / 395  (32.2):  28%|       | 395/1436 [23:57<55:40,  3.21s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 127 / 396  (32.1):  28%|       | 395/1436 [24:00<55:40,  3.21s/it]\u001b[A\n",
      "Average Metric: 127 / 396  (32.1):  28%|       | 396/1436 [24:00<54:46,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 128 / 397  (32.2):  28%|       | 396/1436 [24:03<54:46,  3.16s/it]\u001b[A\n",
      "Average Metric: 128 / 397  (32.2):  28%|       | 397/1436 [24:03<54:17,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 128 / 398  (32.2):  28%|       | 397/1436 [24:07<54:17,  3.14s/it]\u001b[A\n",
      "Average Metric: 128 / 398  (32.2):  28%|       | 398/1436 [24:07<57:55,  3.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 129 / 399  (32.3):  28%|       | 398/1436 [24:10<57:55,  3.35s/it]\u001b[A\n",
      "Average Metric: 129 / 399  (32.3):  28%|       | 399/1436 [24:10<54:08,  3.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 400  (32.5):  28%|       | 399/1436 [24:13<54:08,  3.13s/it]\u001b[A\n",
      "Average Metric: 130 / 400  (32.5):  28%|       | 400/1436 [24:13<56:46,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 130 / 401  (32.4):  28%|       | 400/1436 [24:17<56:46,  3.29s/it]\u001b[A\n",
      "Average Metric: 130 / 401  (32.4):  28%|       | 401/1436 [24:17<57:55,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 131 / 402  (32.6):  28%|       | 401/1436 [24:18<57:55,  3.36s/it]\u001b[A\n",
      "Average Metric: 131 / 402  (32.6):  28%|       | 402/1436 [24:18<48:08,  2.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 131 / 403  (32.5):  28%|       | 402/1436 [24:22<48:08,  2.79s/it]\u001b[A\n",
      "Average Metric: 131 / 403  (32.5):  28%|       | 403/1436 [24:22<51:56,  3.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 404  (32.7):  28%|       | 403/1436 [24:25<51:56,  3.02s/it]\u001b[A\n",
      "Average Metric: 132 / 404  (32.7):  28%|       | 404/1436 [24:25<53:57,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 405  (32.6):  28%|       | 404/1436 [24:29<53:57,  3.14s/it]\u001b[A\n",
      "Average Metric: 132 / 405  (32.6):  28%|       | 405/1436 [24:29<56:00,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 406  (32.5):  28%|       | 405/1436 [24:31<56:00,  3.26s/it]\u001b[A\n",
      "Average Metric: 132 / 406  (32.5):  28%|       | 406/1436 [24:31<47:39,  2.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 407  (32.4):  28%|       | 406/1436 [24:33<47:39,  2.78s/it]\u001b[A\n",
      "Average Metric: 132 / 407  (32.4):  28%|       | 407/1436 [24:33<45:30,  2.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 408  (32.4):  28%|       | 407/1436 [24:38<45:30,  2.65s/it]\u001b[A\n",
      "Average Metric: 132 / 408  (32.4):  28%|       | 408/1436 [24:38<57:57,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 132 / 409  (32.3):  28%|       | 408/1436 [24:40<57:57,  3.38s/it]\u001b[A\n",
      "Average Metric: 132 / 409  (32.3):  28%|       | 409/1436 [24:40<52:49,  3.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 133 / 410  (32.4):  28%|       | 409/1436 [24:42<52:49,  3.09s/it]\u001b[A\n",
      "Average Metric: 133 / 410  (32.4):  29%|       | 410/1436 [24:42<42:58,  2.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 133 / 411  (32.4):  29%|       | 410/1436 [24:44<42:58,  2.51s/it]\u001b[A\n",
      "Average Metric: 133 / 411  (32.4):  29%|       | 411/1436 [24:44<41:11,  2.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 134 / 412  (32.5):  29%|       | 411/1436 [24:47<41:11,  2.41s/it]\u001b[A\n",
      "Average Metric: 134 / 412  (32.5):  29%|       | 412/1436 [24:47<42:35,  2.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 135 / 413  (32.7):  29%|       | 412/1436 [24:50<42:35,  2.50s/it]\u001b[A\n",
      "Average Metric: 135 / 413  (32.7):  29%|       | 413/1436 [24:50<46:28,  2.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 135 / 414  (32.6):  29%|       | 413/1436 [24:52<46:28,  2.73s/it]\u001b[A\n",
      "Average Metric: 135 / 414  (32.6):  29%|       | 414/1436 [24:52<44:17,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 136 / 415  (32.8):  29%|       | 414/1436 [24:54<44:17,  2.60s/it]\u001b[A\n",
      "Average Metric: 136 / 415  (32.8):  29%|       | 415/1436 [24:54<41:44,  2.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 136 / 416  (32.7):  29%|       | 415/1436 [24:57<41:44,  2.45s/it]\u001b[A\n",
      "Average Metric: 136 / 416  (32.7):  29%|       | 416/1436 [24:57<42:15,  2.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 136 / 417  (32.6):  29%|       | 416/1436 [25:02<42:15,  2.49s/it]\u001b[A\n",
      "Average Metric: 136 / 417  (32.6):  29%|       | 417/1436 [25:02<56:15,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 136 / 418  (32.5):  29%|       | 417/1436 [25:06<56:15,  3.31s/it]\u001b[A\n",
      "Average Metric: 136 / 418  (32.5):  29%|       | 418/1436 [25:06<1:00:12,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 419  (32.7):  29%|       | 418/1436 [25:11<1:00:12,  3.55s/it]\u001b[A\n",
      "Average Metric: 137 / 419  (32.7):  29%|       | 419/1436 [25:11<1:07:48,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 420  (32.6):  29%|       | 419/1436 [25:16<1:07:48,  4.00s/it]\u001b[A\n",
      "Average Metric: 137 / 420  (32.6):  29%|       | 420/1436 [25:16<1:14:27,  4.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 421  (32.5):  29%|       | 420/1436 [25:20<1:14:27,  4.40s/it]\u001b[A\n",
      "Average Metric: 137 / 421  (32.5):  29%|       | 421/1436 [25:20<1:12:26,  4.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 422  (32.5):  29%|       | 421/1436 [25:23<1:12:26,  4.28s/it]\u001b[A\n",
      "Average Metric: 137 / 422  (32.5):  29%|       | 422/1436 [25:23<1:03:38,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 423  (32.4):  29%|       | 422/1436 [25:25<1:03:38,  3.77s/it]\u001b[A\n",
      "Average Metric: 137 / 423  (32.4):  29%|       | 423/1436 [25:25<55:20,  3.28s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 424  (32.3):  29%|       | 423/1436 [25:29<55:20,  3.28s/it]\u001b[A\n",
      "Average Metric: 137 / 424  (32.3):  30%|       | 424/1436 [25:29<58:18,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 137 / 425  (32.2):  30%|       | 424/1436 [25:33<58:18,  3.46s/it]\u001b[A\n",
      "Average Metric: 137 / 425  (32.2):  30%|       | 425/1436 [25:33<1:01:15,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 138 / 426  (32.4):  30%|       | 425/1436 [25:35<1:01:15,  3.64s/it]\u001b[A\n",
      "Average Metric: 138 / 426  (32.4):  30%|       | 426/1436 [25:35<50:47,  3.02s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 138 / 427  (32.3):  30%|       | 426/1436 [25:37<50:47,  3.02s/it]\u001b[A\n",
      "Average Metric: 138 / 427  (32.3):  30%|       | 427/1436 [25:37<44:43,  2.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 139 / 428  (32.5):  30%|       | 427/1436 [25:39<44:43,  2.66s/it]\u001b[A\n",
      "Average Metric: 139 / 428  (32.5):  30%|       | 428/1436 [25:39<42:21,  2.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 139 / 429  (32.4):  30%|       | 428/1436 [25:42<42:21,  2.52s/it]\u001b[A\n",
      "Average Metric: 139 / 429  (32.4):  30%|       | 429/1436 [25:42<45:29,  2.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 140 / 430  (32.6):  30%|       | 429/1436 [25:46<45:29,  2.71s/it]\u001b[A\n",
      "Average Metric: 140 / 430  (32.6):  30%|       | 430/1436 [25:47<55:04,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 140 / 431  (32.5):  30%|       | 430/1436 [25:49<55:04,  3.28s/it]\u001b[A\n",
      "Average Metric: 140 / 431  (32.5):  30%|       | 431/1436 [25:49<53:28,  3.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 141 / 432  (32.6):  30%|       | 431/1436 [25:51<53:28,  3.19s/it]\u001b[A\n",
      "Average Metric: 141 / 432  (32.6):  30%|       | 432/1436 [25:51<45:42,  2.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 142 / 433  (32.8):  30%|       | 432/1436 [25:53<45:42,  2.73s/it]\u001b[A\n",
      "Average Metric: 142 / 433  (32.8):  30%|       | 433/1436 [25:53<41:08,  2.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 143 / 434  (32.9):  30%|       | 433/1436 [25:57<41:08,  2.46s/it]\u001b[A\n",
      "Average Metric: 143 / 434  (32.9):  30%|       | 434/1436 [25:57<48:50,  2.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 143 / 435  (32.9):  30%|       | 434/1436 [26:02<48:50,  2.92s/it]\u001b[A\n",
      "Average Metric: 143 / 435  (32.9):  30%|       | 435/1436 [26:02<59:10,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 144 / 436  (33.0):  30%|       | 435/1436 [26:06<59:10,  3.55s/it]\u001b[A\n",
      "Average Metric: 144 / 436  (33.0):  30%|       | 436/1436 [26:06<1:01:05,  3.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 144 / 437  (33.0):  30%|       | 436/1436 [26:11<1:01:05,  3.67s/it]\u001b[A\n",
      "Average Metric: 144 / 437  (33.0):  30%|       | 437/1436 [26:11<1:08:52,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 145 / 438  (33.1):  30%|       | 437/1436 [26:16<1:08:52,  4.14s/it]\u001b[A\n",
      "Average Metric: 145 / 438  (33.1):  31%|       | 438/1436 [26:16<1:11:49,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 146 / 439  (33.3):  31%|       | 438/1436 [26:19<1:11:49,  4.32s/it]\u001b[A\n",
      "Average Metric: 146 / 439  (33.3):  31%|       | 439/1436 [26:19<1:06:42,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 146 / 440  (33.2):  31%|       | 439/1436 [26:22<1:06:42,  4.01s/it]\u001b[A\n",
      "Average Metric: 146 / 440  (33.2):  31%|       | 440/1436 [26:22<59:23,  3.58s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 441  (33.3):  31%|       | 440/1436 [26:25<59:23,  3.58s/it]\u001b[A\n",
      "Average Metric: 147 / 441  (33.3):  31%|       | 441/1436 [26:25<58:51,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 442  (33.3):  31%|       | 441/1436 [26:28<58:51,  3.55s/it]\u001b[A\n",
      "Average Metric: 147 / 442  (33.3):  31%|       | 442/1436 [26:28<54:28,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 443  (33.2):  31%|       | 442/1436 [26:32<54:28,  3.29s/it]\u001b[A\n",
      "Average Metric: 147 / 443  (33.2):  31%|       | 443/1436 [26:32<58:32,  3.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 444  (33.1):  31%|       | 443/1436 [26:37<58:32,  3.54s/it]\u001b[A\n",
      "Average Metric: 147 / 444  (33.1):  31%|       | 444/1436 [26:37<1:07:01,  4.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 445  (33.0):  31%|       | 444/1436 [26:43<1:07:01,  4.05s/it]\u001b[A\n",
      "Average Metric: 147 / 445  (33.0):  31%|       | 445/1436 [26:43<1:12:52,  4.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 446  (33.0):  31%|       | 445/1436 [26:45<1:12:52,  4.41s/it]\u001b[A\n",
      "Average Metric: 147 / 446  (33.0):  31%|       | 446/1436 [26:45<1:04:02,  3.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 147 / 447  (32.9):  31%|       | 446/1436 [26:50<1:04:02,  3.88s/it]\u001b[A\n",
      "Average Metric: 147 / 447  (32.9):  31%|       | 447/1436 [26:50<1:10:45,  4.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 148 / 448  (33.0):  31%|       | 447/1436 [26:53<1:10:45,  4.29s/it]\u001b[A\n",
      "Average Metric: 148 / 448  (33.0):  31%|       | 448/1436 [26:53<1:04:15,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 148 / 449  (33.0):  31%|       | 448/1436 [26:56<1:04:15,  3.90s/it]\u001b[A\n",
      "Average Metric: 148 / 449  (33.0):  31%|      | 449/1436 [26:56<55:14,  3.36s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 148 / 450  (32.9):  31%|      | 449/1436 [26:58<55:14,  3.36s/it]\u001b[A\n",
      "Average Metric: 148 / 450  (32.9):  31%|      | 450/1436 [26:58<48:55,  2.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 149 / 451  (33.0):  31%|      | 450/1436 [27:00<48:55,  2.98s/it]\u001b[A\n",
      "Average Metric: 149 / 451  (33.0):  31%|      | 451/1436 [27:00<46:13,  2.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 150 / 452  (33.2):  31%|      | 451/1436 [27:01<46:13,  2.82s/it]\u001b[A\n",
      "Average Metric: 150 / 452  (33.2):  31%|      | 452/1436 [27:01<39:04,  2.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 150 / 453  (33.1):  31%|      | 452/1436 [27:03<39:04,  2.38s/it]\u001b[A\n",
      "Average Metric: 150 / 453  (33.1):  32%|      | 453/1436 [27:03<34:22,  2.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 150 / 454  (33.0):  32%|      | 453/1436 [27:06<34:22,  2.10s/it]\u001b[A\n",
      "Average Metric: 150 / 454  (33.0):  32%|      | 454/1436 [27:06<37:24,  2.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 150 / 455  (33.0):  32%|      | 454/1436 [27:08<37:24,  2.29s/it]\u001b[A\n",
      "Average Metric: 150 / 455  (33.0):  32%|      | 455/1436 [27:08<38:43,  2.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 151 / 456  (33.1):  32%|      | 455/1436 [27:11<38:43,  2.37s/it]\u001b[A\n",
      "Average Metric: 151 / 456  (33.1):  32%|      | 456/1436 [27:11<41:28,  2.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 152 / 457  (33.3):  32%|      | 456/1436 [27:16<41:28,  2.54s/it]\u001b[A\n",
      "Average Metric: 152 / 457  (33.3):  32%|      | 457/1436 [27:16<51:17,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 152 / 458  (33.2):  32%|      | 457/1436 [27:19<51:17,  3.14s/it]\u001b[A\n",
      "Average Metric: 152 / 458  (33.2):  32%|      | 458/1436 [27:19<53:21,  3.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 153 / 459  (33.3):  32%|      | 458/1436 [27:22<53:21,  3.27s/it]\u001b[A\n",
      "Average Metric: 153 / 459  (33.3):  32%|      | 459/1436 [27:22<52:31,  3.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 153 / 460  (33.3):  32%|      | 459/1436 [27:27<52:31,  3.23s/it]\u001b[A\n",
      "Average Metric: 153 / 460  (33.3):  32%|      | 460/1436 [27:27<59:14,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 153 / 461  (33.2):  32%|      | 460/1436 [27:32<59:14,  3.64s/it]\u001b[A\n",
      "Average Metric: 153 / 461  (33.2):  32%|      | 461/1436 [27:32<1:06:53,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 153 / 462  (33.1):  32%|      | 461/1436 [27:34<1:06:53,  4.12s/it]\u001b[A\n",
      "Average Metric: 153 / 462  (33.1):  32%|      | 462/1436 [27:34<56:55,  3.51s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 154 / 463  (33.3):  32%|      | 462/1436 [27:37<56:55,  3.51s/it]\u001b[A\n",
      "Average Metric: 154 / 463  (33.3):  32%|      | 463/1436 [27:37<54:49,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 154 / 464  (33.2):  32%|      | 463/1436 [27:40<54:49,  3.38s/it]\u001b[A\n",
      "Average Metric: 154 / 464  (33.2):  32%|      | 464/1436 [27:40<50:58,  3.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 154 / 465  (33.1):  32%|      | 464/1436 [27:45<50:58,  3.15s/it]\u001b[A\n",
      "Average Metric: 154 / 465  (33.1):  32%|      | 465/1436 [27:45<1:01:09,  3.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 155 / 466  (33.3):  32%|      | 465/1436 [27:50<1:01:09,  3.78s/it]\u001b[A\n",
      "Average Metric: 155 / 466  (33.3):  32%|      | 466/1436 [27:50<1:06:01,  4.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 155 / 467  (33.2):  32%|      | 466/1436 [27:53<1:06:01,  4.08s/it]\u001b[A\n",
      "Average Metric: 155 / 467  (33.2):  33%|      | 467/1436 [27:53<1:02:33,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 155 / 468  (33.1):  33%|      | 467/1436 [27:58<1:02:33,  3.87s/it]\u001b[A\n",
      "Average Metric: 155 / 468  (33.1):  33%|      | 468/1436 [27:58<1:04:23,  3.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 155 / 469  (33.0):  33%|      | 468/1436 [28:02<1:04:23,  3.99s/it]\u001b[A\n",
      "Average Metric: 155 / 469  (33.0):  33%|      | 469/1436 [28:02<1:08:33,  4.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 155 / 470  (33.0):  33%|      | 469/1436 [28:06<1:08:33,  4.25s/it]\u001b[A\n",
      "Average Metric: 155 / 470  (33.0):  33%|      | 470/1436 [28:06<1:04:26,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 155 / 471  (32.9):  33%|      | 470/1436 [28:10<1:04:26,  4.00s/it]\u001b[A\n",
      "Average Metric: 155 / 471  (32.9):  33%|      | 471/1436 [28:10<1:04:57,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 155 / 472  (32.8):  33%|      | 471/1436 [28:15<1:04:57,  4.04s/it]\u001b[A\n",
      "Average Metric: 155 / 472  (32.8):  33%|      | 472/1436 [28:15<1:07:37,  4.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 156 / 473  (33.0):  33%|      | 472/1436 [28:17<1:07:37,  4.21s/it]\u001b[A\n",
      "Average Metric: 156 / 473  (33.0):  33%|      | 473/1436 [28:17<57:07,  3.56s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 157 / 474  (33.1):  33%|      | 473/1436 [28:19<57:07,  3.56s/it]\u001b[A\n",
      "Average Metric: 157 / 474  (33.1):  33%|      | 474/1436 [28:19<49:10,  3.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 157 / 475  (33.1):  33%|      | 474/1436 [28:21<49:10,  3.07s/it]\u001b[A\n",
      "Average Metric: 157 / 475  (33.1):  33%|      | 475/1436 [28:21<44:11,  2.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 476  (33.2):  33%|      | 475/1436 [28:22<44:11,  2.76s/it]\u001b[A\n",
      "Average Metric: 158 / 476  (33.2):  33%|      | 476/1436 [28:22<39:07,  2.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 477  (33.1):  33%|      | 476/1436 [28:28<39:07,  2.45s/it]\u001b[A\n",
      "Average Metric: 158 / 477  (33.1):  33%|      | 477/1436 [28:28<52:19,  3.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 478  (33.1):  33%|      | 477/1436 [28:30<52:19,  3.27s/it]\u001b[A\n",
      "Average Metric: 158 / 478  (33.1):  33%|      | 478/1436 [28:30<47:16,  2.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 479  (33.0):  33%|      | 478/1436 [28:34<47:16,  2.96s/it]\u001b[A\n",
      "Average Metric: 158 / 479  (33.0):  33%|      | 479/1436 [28:34<52:52,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 480  (32.9):  33%|      | 479/1436 [28:38<52:52,  3.31s/it]\u001b[A\n",
      "Average Metric: 158 / 480  (32.9):  33%|      | 480/1436 [28:38<57:05,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 481  (32.8):  33%|      | 480/1436 [28:43<57:05,  3.58s/it]\u001b[A\n",
      "Average Metric: 158 / 481  (32.8):  33%|      | 481/1436 [28:43<1:04:08,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 158 / 482  (32.8):  33%|      | 481/1436 [28:48<1:04:08,  4.03s/it]\u001b[A\n",
      "Average Metric: 158 / 482  (32.8):  34%|      | 482/1436 [28:48<1:07:47,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 159 / 483  (32.9):  34%|      | 482/1436 [28:51<1:07:47,  4.26s/it]\u001b[A\n",
      "Average Metric: 159 / 483  (32.9):  34%|      | 483/1436 [28:51<1:02:10,  3.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 160 / 484  (33.1):  34%|      | 483/1436 [28:55<1:02:10,  3.91s/it]\u001b[A\n",
      "Average Metric: 160 / 484  (33.1):  34%|      | 484/1436 [28:55<1:01:27,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 160 / 485  (33.0):  34%|      | 484/1436 [28:58<1:01:27,  3.87s/it]\u001b[A\n",
      "Average Metric: 160 / 485  (33.0):  34%|      | 485/1436 [28:58<59:27,  3.75s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 160 / 486  (32.9):  34%|      | 485/1436 [29:00<59:27,  3.75s/it]\u001b[A\n",
      "Average Metric: 160 / 486  (32.9):  34%|      | 486/1436 [29:00<48:36,  3.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 160 / 487  (32.9):  34%|      | 486/1436 [29:05<48:36,  3.07s/it]\u001b[A\n",
      "Average Metric: 160 / 487  (32.9):  34%|      | 487/1436 [29:05<59:13,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 160 / 488  (32.8):  34%|      | 487/1436 [29:10<59:13,  3.74s/it]\u001b[A\n",
      "Average Metric: 160 / 488  (32.8):  34%|      | 488/1436 [29:10<1:04:48,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 161 / 489  (32.9):  34%|      | 488/1436 [29:13<1:04:48,  4.10s/it]\u001b[A\n",
      "Average Metric: 161 / 489  (32.9):  34%|      | 489/1436 [29:13<1:00:30,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 161 / 490  (32.9):  34%|      | 489/1436 [29:18<1:00:30,  3.83s/it]\u001b[A\n",
      "Average Metric: 161 / 490  (32.9):  34%|      | 490/1436 [29:18<1:02:59,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 161 / 491  (32.8):  34%|      | 490/1436 [29:20<1:02:59,  4.00s/it]\u001b[A\n",
      "Average Metric: 161 / 491  (32.8):  34%|      | 491/1436 [29:20<56:34,  3.59s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 492  (32.9):  34%|      | 491/1436 [29:22<56:34,  3.59s/it]\u001b[A\n",
      "Average Metric: 162 / 492  (32.9):  34%|      | 492/1436 [29:22<49:22,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 493  (32.9):  34%|      | 492/1436 [29:25<49:22,  3.14s/it]\u001b[A\n",
      "Average Metric: 162 / 493  (32.9):  34%|      | 493/1436 [29:25<47:47,  3.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 494  (32.8):  34%|      | 493/1436 [29:29<47:47,  3.04s/it]\u001b[A\n",
      "Average Metric: 162 / 494  (32.8):  34%|      | 494/1436 [29:29<49:17,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 495  (32.7):  34%|      | 494/1436 [29:34<49:17,  3.14s/it]\u001b[A\n",
      "Average Metric: 162 / 495  (32.7):  34%|      | 495/1436 [29:34<58:36,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 496  (32.7):  34%|      | 495/1436 [29:39<58:36,  3.74s/it]\u001b[A\n",
      "Average Metric: 162 / 496  (32.7):  35%|      | 496/1436 [29:39<1:05:17,  4.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 497  (32.6):  35%|      | 496/1436 [29:42<1:05:17,  4.17s/it]\u001b[A\n",
      "Average Metric: 162 / 497  (32.6):  35%|      | 497/1436 [29:42<59:02,  3.77s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 162 / 498  (32.5):  35%|      | 497/1436 [29:44<59:02,  3.77s/it]\u001b[A\n",
      "Average Metric: 162 / 498  (32.5):  35%|      | 498/1436 [29:44<51:16,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 163 / 499  (32.7):  35%|      | 498/1436 [29:49<51:16,  3.28s/it]\u001b[A\n",
      "Average Metric: 163 / 499  (32.7):  35%|      | 499/1436 [29:49<59:52,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 163 / 500  (32.6):  35%|      | 499/1436 [29:53<59:52,  3.83s/it]\u001b[A\n",
      "Average Metric: 163 / 500  (32.6):  35%|      | 500/1436 [29:53<59:21,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 164 / 501  (32.7):  35%|      | 500/1436 [29:54<59:21,  3.80s/it]\u001b[A\n",
      "Average Metric: 164 / 501  (32.7):  35%|      | 501/1436 [29:54<47:32,  3.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 164 / 502  (32.7):  35%|      | 501/1436 [29:59<47:32,  3.05s/it]\u001b[A\n",
      "Average Metric: 164 / 502  (32.7):  35%|      | 502/1436 [29:59<57:43,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 503  (32.8):  35%|      | 502/1436 [30:03<57:43,  3.71s/it]\u001b[A\n",
      "Average Metric: 165 / 503  (32.8):  35%|      | 503/1436 [30:03<55:27,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 504  (32.7):  35%|      | 503/1436 [30:07<55:27,  3.57s/it]\u001b[A\n",
      "Average Metric: 165 / 504  (32.7):  35%|      | 504/1436 [30:07<58:35,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 505  (32.7):  35%|      | 504/1436 [30:10<58:35,  3.77s/it]\u001b[A\n",
      "Average Metric: 165 / 505  (32.7):  35%|      | 505/1436 [30:10<54:04,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 506  (32.6):  35%|      | 505/1436 [30:15<54:04,  3.49s/it]\u001b[A\n",
      "Average Metric: 165 / 506  (32.6):  35%|      | 506/1436 [30:15<1:01:18,  3.95s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 507  (32.5):  35%|      | 506/1436 [30:18<1:01:18,  3.95s/it]\u001b[A\n",
      "Average Metric: 165 / 507  (32.5):  35%|      | 507/1436 [30:18<57:53,  3.74s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 508  (32.5):  35%|      | 507/1436 [30:21<57:53,  3.74s/it]\u001b[A\n",
      "Average Metric: 165 / 508  (32.5):  35%|      | 508/1436 [30:21<52:46,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 165 / 509  (32.4):  35%|      | 508/1436 [30:24<52:46,  3.41s/it]\u001b[A\n",
      "Average Metric: 165 / 509  (32.4):  35%|      | 509/1436 [30:24<54:14,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 166 / 510  (32.5):  35%|      | 509/1436 [30:29<54:14,  3.51s/it]\u001b[A\n",
      "Average Metric: 166 / 510  (32.5):  36%|      | 510/1436 [30:29<1:01:29,  3.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 166 / 511  (32.5):  36%|      | 510/1436 [30:33<1:01:29,  3.98s/it]\u001b[A\n",
      "Average Metric: 166 / 511  (32.5):  36%|      | 511/1436 [30:33<58:41,  3.81s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 166 / 512  (32.4):  36%|      | 511/1436 [30:38<58:41,  3.81s/it]\u001b[A\n",
      "Average Metric: 166 / 512  (32.4):  36%|      | 512/1436 [30:38<1:05:03,  4.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 513  (32.6):  36%|      | 512/1436 [30:40<1:05:03,  4.22s/it]\u001b[A\n",
      "Average Metric: 167 / 513  (32.6):  36%|      | 513/1436 [30:40<53:27,  3.47s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 514  (32.5):  36%|      | 513/1436 [30:45<53:27,  3.47s/it]\u001b[A\n",
      "Average Metric: 167 / 514  (32.5):  36%|      | 514/1436 [30:45<1:01:53,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 515  (32.4):  36%|      | 514/1436 [30:49<1:01:53,  4.03s/it]\u001b[A\n",
      "Average Metric: 167 / 515  (32.4):  36%|      | 515/1436 [30:49<1:01:30,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 516  (32.4):  36%|      | 515/1436 [30:51<1:01:30,  4.01s/it]\u001b[A\n",
      "Average Metric: 167 / 516  (32.4):  36%|      | 516/1436 [30:51<54:26,  3.55s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 517  (32.3):  36%|      | 516/1436 [30:54<54:26,  3.55s/it]\u001b[A\n",
      "Average Metric: 167 / 517  (32.3):  36%|      | 517/1436 [30:54<51:47,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 518  (32.2):  36%|      | 517/1436 [30:57<51:47,  3.38s/it]\u001b[A\n",
      "Average Metric: 167 / 518  (32.2):  36%|      | 518/1436 [30:57<50:07,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 519  (32.2):  36%|      | 518/1436 [30:59<50:07,  3.28s/it]\u001b[A\n",
      "Average Metric: 167 / 519  (32.2):  36%|      | 519/1436 [30:59<44:21,  2.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 167 / 520  (32.1):  36%|      | 519/1436 [31:03<44:21,  2.90s/it]\u001b[A\n",
      "Average Metric: 167 / 520  (32.1):  36%|      | 520/1436 [31:03<49:08,  3.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 168 / 521  (32.2):  36%|      | 520/1436 [31:06<49:08,  3.22s/it]\u001b[A\n",
      "Average Metric: 168 / 521  (32.2):  36%|      | 521/1436 [31:06<46:56,  3.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 168 / 522  (32.2):  36%|      | 521/1436 [31:11<46:56,  3.08s/it]\u001b[A\n",
      "Average Metric: 168 / 522  (32.2):  36%|      | 522/1436 [31:11<56:10,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 168 / 523  (32.1):  36%|      | 522/1436 [31:15<56:10,  3.69s/it]\u001b[A\n",
      "Average Metric: 168 / 523  (32.1):  36%|      | 523/1436 [31:15<57:39,  3.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 168 / 524  (32.1):  36%|      | 523/1436 [31:20<57:39,  3.79s/it]\u001b[A\n",
      "Average Metric: 168 / 524  (32.1):  36%|      | 524/1436 [31:20<1:02:52,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 168 / 525  (32.0):  36%|      | 524/1436 [31:22<1:02:52,  4.14s/it]\u001b[A\n",
      "Average Metric: 168 / 525  (32.0):  37%|      | 525/1436 [31:22<53:53,  3.55s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 169 / 526  (32.1):  37%|      | 525/1436 [31:24<53:53,  3.55s/it]\u001b[A\n",
      "Average Metric: 169 / 526  (32.1):  37%|      | 526/1436 [31:24<43:27,  2.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 527  (32.3):  37%|      | 526/1436 [31:26<43:27,  2.87s/it]\u001b[A\n",
      "Average Metric: 170 / 527  (32.3):  37%|      | 527/1436 [31:26<41:41,  2.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 528  (32.2):  37%|      | 527/1436 [31:31<41:41,  2.75s/it]\u001b[A\n",
      "Average Metric: 170 / 528  (32.2):  37%|      | 528/1436 [31:31<52:20,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 529  (32.1):  37%|      | 528/1436 [31:34<52:20,  3.46s/it]\u001b[A\n",
      "Average Metric: 170 / 529  (32.1):  37%|      | 529/1436 [31:34<47:15,  3.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 530  (32.1):  37%|      | 529/1436 [31:38<47:15,  3.13s/it]\u001b[A\n",
      "Average Metric: 170 / 530  (32.1):  37%|      | 530/1436 [31:38<51:06,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 531  (32.0):  37%|      | 530/1436 [31:40<51:06,  3.38s/it]\u001b[A\n",
      "Average Metric: 170 / 531  (32.0):  37%|      | 531/1436 [31:40<48:01,  3.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 532  (32.0):  37%|      | 531/1436 [31:45<48:01,  3.18s/it]\u001b[A\n",
      "Average Metric: 170 / 532  (32.0):  37%|      | 532/1436 [31:45<55:11,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 533  (31.9):  37%|      | 532/1436 [31:50<55:11,  3.66s/it]\u001b[A\n",
      "Average Metric: 170 / 533  (31.9):  37%|      | 533/1436 [31:50<1:02:12,  4.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 534  (31.8):  37%|      | 533/1436 [31:56<1:02:12,  4.13s/it]\u001b[A\n",
      "Average Metric: 170 / 534  (31.8):  37%|      | 534/1436 [31:56<1:07:23,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 535  (31.8):  37%|      | 534/1436 [32:01<1:07:23,  4.48s/it]\u001b[A\n",
      "Average Metric: 170 / 535  (31.8):  37%|      | 535/1436 [32:01<1:10:58,  4.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 170 / 536  (31.7):  37%|      | 535/1436 [32:03<1:10:58,  4.73s/it]\u001b[A\n",
      "Average Metric: 170 / 536  (31.7):  37%|      | 536/1436 [32:03<57:55,  3.86s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 537  (31.8):  37%|      | 536/1436 [32:07<57:55,  3.86s/it]\u001b[A\n",
      "Average Metric: 171 / 537  (31.8):  37%|      | 537/1436 [32:07<59:01,  3.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 538  (31.8):  37%|      | 537/1436 [32:12<59:01,  3.94s/it]\u001b[A\n",
      "Average Metric: 171 / 538  (31.8):  37%|      | 538/1436 [32:12<1:04:39,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 539  (31.7):  37%|      | 538/1436 [32:14<1:04:39,  4.32s/it]\u001b[A\n",
      "Average Metric: 171 / 539  (31.7):  38%|      | 539/1436 [32:14<55:10,  3.69s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 540  (31.7):  38%|      | 539/1436 [32:19<55:10,  3.69s/it]\u001b[A\n",
      "Average Metric: 171 / 540  (31.7):  38%|      | 540/1436 [32:19<1:01:06,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 541  (31.6):  38%|      | 540/1436 [32:23<1:01:06,  4.09s/it]\u001b[A\n",
      "Average Metric: 171 / 541  (31.6):  38%|      | 541/1436 [32:23<59:08,  3.96s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 542  (31.5):  38%|      | 541/1436 [32:26<59:08,  3.96s/it]\u001b[A\n",
      "Average Metric: 171 / 542  (31.5):  38%|      | 542/1436 [32:26<55:43,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 543  (31.5):  38%|      | 542/1436 [32:30<55:43,  3.74s/it]\u001b[A\n",
      "Average Metric: 171 / 543  (31.5):  38%|      | 543/1436 [32:30<54:56,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 544  (31.4):  38%|      | 543/1436 [32:34<54:56,  3.69s/it]\u001b[A\n",
      "Average Metric: 171 / 544  (31.4):  38%|      | 544/1436 [32:34<57:06,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 545  (31.4):  38%|      | 544/1436 [32:39<57:06,  3.84s/it]\u001b[A\n",
      "Average Metric: 171 / 545  (31.4):  38%|      | 545/1436 [32:39<1:00:42,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 546  (31.3):  38%|      | 545/1436 [32:43<1:00:42,  4.09s/it]\u001b[A\n",
      "Average Metric: 171 / 546  (31.3):  38%|      | 546/1436 [32:43<1:01:30,  4.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 171 / 547  (31.3):  38%|      | 546/1436 [32:46<1:01:30,  4.15s/it]\u001b[A\n",
      "Average Metric: 171 / 547  (31.3):  38%|      | 547/1436 [32:46<57:30,  3.88s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 548  (31.4):  38%|      | 547/1436 [32:51<57:30,  3.88s/it]\u001b[A\n",
      "Average Metric: 172 / 548  (31.4):  38%|      | 548/1436 [32:51<1:01:51,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 549  (31.3):  38%|      | 548/1436 [32:56<1:01:51,  4.18s/it]\u001b[A\n",
      "Average Metric: 172 / 549  (31.3):  38%|      | 549/1436 [32:56<1:06:13,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 550  (31.3):  38%|      | 549/1436 [32:59<1:06:13,  4.48s/it]\u001b[A\n",
      "Average Metric: 172 / 550  (31.3):  38%|      | 550/1436 [32:59<58:46,  3.98s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 551  (31.2):  38%|      | 550/1436 [33:02<58:46,  3.98s/it]\u001b[A\n",
      "Average Metric: 172 / 551  (31.2):  38%|      | 551/1436 [33:02<52:20,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 552  (31.2):  38%|      | 551/1436 [33:07<52:20,  3.55s/it]\u001b[A\n",
      "Average Metric: 172 / 552  (31.2):  38%|      | 552/1436 [33:07<58:57,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 553  (31.1):  38%|      | 552/1436 [33:11<58:57,  4.00s/it]\u001b[A\n",
      "Average Metric: 172 / 553  (31.1):  39%|      | 553/1436 [33:11<1:02:08,  4.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 554  (31.0):  39%|      | 553/1436 [33:13<1:02:08,  4.22s/it]\u001b[A\n",
      "Average Metric: 172 / 554  (31.0):  39%|      | 554/1436 [33:13<51:33,  3.51s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 555  (31.0):  39%|      | 554/1436 [33:18<51:33,  3.51s/it]\u001b[A\n",
      "Average Metric: 172 / 555  (31.0):  39%|      | 555/1436 [33:18<58:26,  3.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 172 / 556  (30.9):  39%|      | 555/1436 [33:22<58:26,  3.98s/it]\u001b[A\n",
      "Average Metric: 172 / 556  (30.9):  39%|      | 556/1436 [33:22<55:01,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 173 / 557  (31.1):  39%|      | 556/1436 [33:27<55:01,  3.75s/it]\u001b[A\n",
      "Average Metric: 173 / 557  (31.1):  39%|      | 557/1436 [33:27<1:01:28,  4.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 173 / 558  (31.0):  39%|      | 557/1436 [33:30<1:01:28,  4.20s/it]\u001b[A\n",
      "Average Metric: 173 / 558  (31.0):  39%|      | 558/1436 [33:30<58:16,  3.98s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 174 / 559  (31.1):  39%|      | 558/1436 [33:35<58:16,  3.98s/it]\u001b[A\n",
      "Average Metric: 174 / 559  (31.1):  39%|      | 559/1436 [33:35<1:00:11,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 174 / 560  (31.1):  39%|      | 559/1436 [33:39<1:00:11,  4.12s/it]\u001b[A\n",
      "Average Metric: 174 / 560  (31.1):  39%|      | 560/1436 [33:39<1:00:17,  4.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 175 / 561  (31.2):  39%|      | 560/1436 [33:41<1:00:17,  4.13s/it]\u001b[A\n",
      "Average Metric: 175 / 561  (31.2):  39%|      | 561/1436 [33:41<50:15,  3.45s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 175 / 562  (31.1):  39%|      | 561/1436 [33:45<50:15,  3.45s/it]\u001b[A\n",
      "Average Metric: 175 / 562  (31.1):  39%|      | 562/1436 [33:45<52:40,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 175 / 563  (31.1):  39%|      | 562/1436 [33:50<52:40,  3.62s/it]\u001b[A\n",
      "Average Metric: 175 / 563  (31.1):  39%|      | 563/1436 [33:50<59:06,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 175 / 564  (31.0):  39%|      | 563/1436 [33:55<59:06,  4.06s/it]\u001b[A\n",
      "Average Metric: 175 / 564  (31.0):  39%|      | 564/1436 [33:55<1:03:28,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 176 / 565  (31.2):  39%|      | 564/1436 [33:58<1:03:28,  4.37s/it]\u001b[A\n",
      "Average Metric: 176 / 565  (31.2):  39%|      | 565/1436 [33:58<58:23,  4.02s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 176 / 566  (31.1):  39%|      | 565/1436 [34:03<58:23,  4.02s/it]\u001b[A\n",
      "Average Metric: 176 / 566  (31.1):  39%|      | 566/1436 [34:03<1:03:38,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 177 / 567  (31.2):  39%|      | 566/1436 [34:06<1:03:38,  4.39s/it]\u001b[A\n",
      "Average Metric: 177 / 567  (31.2):  39%|      | 567/1436 [34:06<57:48,  3.99s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 177 / 568  (31.2):  39%|      | 567/1436 [34:10<57:48,  3.99s/it]\u001b[A\n",
      "Average Metric: 177 / 568  (31.2):  40%|      | 568/1436 [34:10<57:30,  3.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 177 / 569  (31.1):  40%|      | 568/1436 [34:15<57:30,  3.98s/it]\u001b[A\n",
      "Average Metric: 177 / 569  (31.1):  40%|      | 569/1436 [34:15<58:48,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 177 / 570  (31.1):  40%|      | 569/1436 [34:18<58:48,  4.07s/it]\u001b[A\n",
      "Average Metric: 177 / 570  (31.1):  40%|      | 570/1436 [34:18<54:58,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 177 / 571  (31.0):  40%|      | 570/1436 [34:22<54:58,  3.81s/it]\u001b[A\n",
      "Average Metric: 177 / 571  (31.0):  40%|      | 571/1436 [34:22<57:39,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 178 / 572  (31.1):  40%|      | 571/1436 [34:26<57:39,  4.00s/it]\u001b[A\n",
      "Average Metric: 178 / 572  (31.1):  40%|      | 572/1436 [34:26<54:02,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 178 / 573  (31.1):  40%|      | 572/1436 [34:30<54:02,  3.75s/it]\u001b[A\n",
      "Average Metric: 178 / 573  (31.1):  40%|      | 573/1436 [34:30<56:15,  3.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 178 / 574  (31.0):  40%|      | 573/1436 [34:34<56:15,  3.91s/it]\u001b[A\n",
      "Average Metric: 178 / 574  (31.0):  40%|      | 574/1436 [34:34<55:51,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 179 / 575  (31.1):  40%|      | 574/1436 [34:37<55:51,  3.89s/it]\u001b[A\n",
      "Average Metric: 179 / 575  (31.1):  40%|      | 575/1436 [34:37<52:58,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 180 / 576  (31.2):  40%|      | 575/1436 [34:42<52:58,  3.69s/it]\u001b[A\n",
      "Average Metric: 180 / 576  (31.2):  40%|      | 576/1436 [34:42<59:25,  4.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 180 / 577  (31.2):  40%|      | 576/1436 [34:44<59:25,  4.15s/it]\u001b[A\n",
      "Average Metric: 180 / 577  (31.2):  40%|      | 577/1436 [34:44<50:00,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 578  (31.3):  40%|      | 577/1436 [34:47<50:00,  3.49s/it]\u001b[A\n",
      "Average Metric: 181 / 578  (31.3):  40%|      | 578/1436 [34:47<45:49,  3.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 579  (31.3):  40%|      | 578/1436 [34:51<45:49,  3.20s/it]\u001b[A\n",
      "Average Metric: 181 / 579  (31.3):  40%|      | 579/1436 [34:51<51:17,  3.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 580  (31.2):  40%|      | 579/1436 [34:55<51:17,  3.59s/it]\u001b[A\n",
      "Average Metric: 181 / 580  (31.2):  40%|      | 580/1436 [34:55<51:22,  3.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 581  (31.2):  40%|      | 580/1436 [34:59<51:22,  3.60s/it]\u001b[A\n",
      "Average Metric: 181 / 581  (31.2):  40%|      | 581/1436 [34:59<54:47,  3.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 582  (31.1):  40%|      | 581/1436 [35:02<54:47,  3.85s/it]\u001b[A\n",
      "Average Metric: 181 / 582  (31.1):  41%|      | 582/1436 [35:02<50:53,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 583  (31.0):  41%|      | 582/1436 [35:07<50:53,  3.58s/it]\u001b[A\n",
      "Average Metric: 181 / 583  (31.0):  41%|      | 583/1436 [35:07<55:47,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 584  (31.0):  41%|      | 583/1436 [35:12<55:47,  3.92s/it]\u001b[A\n",
      "Average Metric: 181 / 584  (31.0):  41%|      | 584/1436 [35:12<59:29,  4.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 585  (30.9):  41%|      | 584/1436 [35:16<59:29,  4.19s/it]\u001b[A\n",
      "Average Metric: 181 / 585  (30.9):  41%|      | 585/1436 [35:16<58:40,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 586  (30.9):  41%|      | 585/1436 [35:21<58:40,  4.14s/it]\u001b[A\n",
      "Average Metric: 181 / 586  (30.9):  41%|      | 586/1436 [35:21<1:03:10,  4.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 587  (30.8):  41%|      | 586/1436 [35:26<1:03:10,  4.46s/it]\u001b[A\n",
      "Average Metric: 181 / 587  (30.8):  41%|      | 587/1436 [35:26<1:05:00,  4.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 588  (30.8):  41%|      | 587/1436 [35:28<1:05:00,  4.59s/it]\u001b[A\n",
      "Average Metric: 181 / 588  (30.8):  41%|      | 588/1436 [35:28<55:57,  3.96s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 589  (30.7):  41%|      | 588/1436 [35:32<55:57,  3.96s/it]\u001b[A\n",
      "Average Metric: 181 / 589  (30.7):  41%|      | 589/1436 [35:32<56:55,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 590  (30.7):  41%|      | 589/1436 [35:35<56:55,  4.03s/it]\u001b[A\n",
      "Average Metric: 181 / 590  (30.7):  41%|      | 590/1436 [35:35<52:41,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 591  (30.6):  41%|      | 590/1436 [35:37<52:41,  3.74s/it]\u001b[A\n",
      "Average Metric: 181 / 591  (30.6):  41%|      | 591/1436 [35:37<43:50,  3.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 592  (30.6):  41%|      | 591/1436 [35:40<43:50,  3.11s/it]\u001b[A\n",
      "Average Metric: 181 / 592  (30.6):  41%|      | 592/1436 [35:40<43:59,  3.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 593  (30.5):  41%|      | 592/1436 [35:43<43:59,  3.13s/it]\u001b[A\n",
      "Average Metric: 181 / 593  (30.5):  41%|     | 593/1436 [35:43<41:01,  2.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 594  (30.5):  41%|     | 593/1436 [35:46<41:01,  2.92s/it]\u001b[A\n",
      "Average Metric: 181 / 594  (30.5):  41%|     | 594/1436 [35:46<40:51,  2.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 181 / 595  (30.4):  41%|     | 594/1436 [35:51<40:51,  2.91s/it]\u001b[A\n",
      "Average Metric: 181 / 595  (30.4):  41%|     | 595/1436 [35:51<49:54,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 182 / 596  (30.5):  41%|     | 595/1436 [35:53<49:54,  3.56s/it]\u001b[A\n",
      "Average Metric: 182 / 596  (30.5):  42%|     | 596/1436 [35:53<45:37,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 183 / 597  (30.7):  42%|     | 596/1436 [35:56<45:37,  3.26s/it]\u001b[A\n",
      "Average Metric: 183 / 597  (30.7):  42%|     | 597/1436 [35:56<43:56,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 183 / 598  (30.6):  42%|     | 597/1436 [36:00<43:56,  3.14s/it]\u001b[A\n",
      "Average Metric: 183 / 598  (30.6):  42%|     | 598/1436 [36:00<46:32,  3.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 183 / 599  (30.6):  42%|     | 598/1436 [36:04<46:32,  3.33s/it]\u001b[A\n",
      "Average Metric: 183 / 599  (30.6):  42%|     | 599/1436 [36:04<50:26,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 184 / 600  (30.7):  42%|     | 599/1436 [36:09<50:26,  3.62s/it]\u001b[A\n",
      "Average Metric: 184 / 600  (30.7):  42%|     | 600/1436 [36:09<54:46,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 184 / 601  (30.6):  42%|     | 600/1436 [36:14<54:46,  3.93s/it]\u001b[A\n",
      "Average Metric: 184 / 601  (30.6):  42%|     | 601/1436 [36:14<1:00:26,  4.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 184 / 602  (30.6):  42%|     | 601/1436 [36:16<1:00:26,  4.34s/it]\u001b[A\n",
      "Average Metric: 184 / 602  (30.6):  42%|     | 602/1436 [36:16<51:14,  3.69s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 184 / 603  (30.5):  42%|     | 602/1436 [36:21<51:14,  3.69s/it]\u001b[A\n",
      "Average Metric: 184 / 603  (30.5):  42%|     | 603/1436 [36:21<54:08,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 185 / 604  (30.6):  42%|     | 603/1436 [36:25<54:08,  3.90s/it]\u001b[A\n",
      "Average Metric: 185 / 604  (30.6):  42%|     | 604/1436 [36:25<55:27,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 605  (30.7):  42%|     | 604/1436 [36:29<55:27,  4.00s/it]\u001b[A\n",
      "Average Metric: 186 / 605  (30.7):  42%|     | 605/1436 [36:29<54:22,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 606  (30.7):  42%|     | 605/1436 [36:32<54:22,  3.93s/it]\u001b[A\n",
      "Average Metric: 186 / 606  (30.7):  42%|     | 606/1436 [36:32<50:25,  3.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 607  (30.6):  42%|     | 606/1436 [36:37<50:25,  3.65s/it]\u001b[A\n",
      "Average Metric: 186 / 607  (30.6):  42%|     | 607/1436 [36:37<57:46,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 608  (30.6):  42%|     | 607/1436 [36:41<57:46,  4.18s/it]\u001b[A\n",
      "Average Metric: 186 / 608  (30.6):  42%|     | 608/1436 [36:41<56:28,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 609  (30.5):  42%|     | 608/1436 [36:45<56:28,  4.09s/it]\u001b[A\n",
      "Average Metric: 186 / 609  (30.5):  42%|     | 609/1436 [36:45<55:51,  4.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 610  (30.5):  42%|     | 609/1436 [36:48<55:51,  4.05s/it]\u001b[A\n",
      "Average Metric: 186 / 610  (30.5):  42%|     | 610/1436 [36:48<49:57,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 611  (30.4):  42%|     | 610/1436 [36:50<49:57,  3.63s/it]\u001b[A\n",
      "Average Metric: 186 / 611  (30.4):  43%|     | 611/1436 [36:50<44:49,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 612  (30.4):  43%|     | 611/1436 [36:55<44:49,  3.26s/it]\u001b[A\n",
      "Average Metric: 186 / 612  (30.4):  43%|     | 612/1436 [36:55<52:49,  3.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 186 / 613  (30.3):  43%|     | 612/1436 [37:00<52:49,  3.85s/it]\u001b[A\n",
      "Average Metric: 186 / 613  (30.3):  43%|     | 613/1436 [37:00<58:26,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 614  (30.5):  43%|     | 613/1436 [37:05<58:26,  4.26s/it]\u001b[A\n",
      "Average Metric: 187 / 614  (30.5):  43%|     | 614/1436 [37:05<57:59,  4.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 615  (30.4):  43%|     | 614/1436 [37:10<57:59,  4.23s/it]\u001b[A\n",
      "Average Metric: 187 / 615  (30.4):  43%|     | 615/1436 [37:10<1:02:20,  4.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 616  (30.4):  43%|     | 615/1436 [37:15<1:02:20,  4.56s/it]\u001b[A\n",
      "Average Metric: 187 / 616  (30.4):  43%|     | 616/1436 [37:15<1:05:24,  4.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 617  (30.3):  43%|     | 616/1436 [37:21<1:05:24,  4.79s/it]\u001b[A\n",
      "Average Metric: 187 / 617  (30.3):  43%|     | 617/1436 [37:21<1:07:29,  4.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 618  (30.3):  43%|     | 617/1436 [37:26<1:07:29,  4.94s/it]\u001b[A\n",
      "Average Metric: 187 / 618  (30.3):  43%|     | 618/1436 [37:26<1:08:31,  5.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 187 / 619  (30.2):  43%|     | 618/1436 [37:29<1:08:31,  5.03s/it]\u001b[A\n",
      "Average Metric: 187 / 619  (30.2):  43%|     | 619/1436 [37:29<1:02:16,  4.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 188 / 620  (30.3):  43%|     | 619/1436 [37:33<1:02:16,  4.57s/it]\u001b[A\n",
      "Average Metric: 188 / 620  (30.3):  43%|     | 620/1436 [37:33<57:33,  4.23s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 188 / 621  (30.3):  43%|     | 620/1436 [37:36<57:33,  4.23s/it]\u001b[A\n",
      "Average Metric: 188 / 621  (30.3):  43%|     | 621/1436 [37:36<54:23,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 188 / 622  (30.2):  43%|     | 621/1436 [37:41<54:23,  4.00s/it]\u001b[A\n",
      "Average Metric: 188 / 622  (30.2):  43%|     | 622/1436 [37:41<59:22,  4.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 189 / 623  (30.3):  43%|     | 622/1436 [37:43<59:22,  4.38s/it]\u001b[A\n",
      "Average Metric: 189 / 623  (30.3):  43%|     | 623/1436 [37:43<46:15,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 189 / 624  (30.3):  43%|     | 623/1436 [37:44<46:15,  3.41s/it]\u001b[A\n",
      "Average Metric: 189 / 624  (30.3):  43%|     | 624/1436 [37:44<37:43,  2.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 189 / 625  (30.2):  43%|     | 624/1436 [37:46<37:43,  2.79s/it]\u001b[A\n",
      "Average Metric: 189 / 625  (30.2):  44%|     | 625/1436 [37:46<34:07,  2.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 189 / 626  (30.2):  44%|     | 625/1436 [37:48<34:07,  2.53s/it]\u001b[A\n",
      "Average Metric: 189 / 626  (30.2):  44%|     | 626/1436 [37:48<30:56,  2.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 189 / 627  (30.1):  44%|     | 626/1436 [37:50<30:56,  2.29s/it]\u001b[A\n",
      "Average Metric: 189 / 627  (30.1):  44%|     | 627/1436 [37:50<32:30,  2.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 190 / 628  (30.3):  44%|     | 627/1436 [37:53<32:30,  2.41s/it]\u001b[A\n",
      "Average Metric: 190 / 628  (30.3):  44%|     | 628/1436 [37:53<34:29,  2.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 191 / 629  (30.4):  44%|     | 628/1436 [37:55<34:29,  2.56s/it]\u001b[A\n",
      "Average Metric: 191 / 629  (30.4):  44%|     | 629/1436 [37:55<30:22,  2.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 192 / 630  (30.5):  44%|     | 629/1436 [37:57<30:22,  2.26s/it]\u001b[A\n",
      "Average Metric: 192 / 630  (30.5):  44%|     | 630/1436 [37:57<29:03,  2.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 192 / 631  (30.4):  44%|     | 630/1436 [38:01<29:03,  2.16s/it]\u001b[A\n",
      "Average Metric: 192 / 631  (30.4):  44%|     | 631/1436 [38:01<38:02,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 193 / 632  (30.5):  44%|     | 631/1436 [38:03<38:02,  2.84s/it]\u001b[A\n",
      "Average Metric: 193 / 632  (30.5):  44%|     | 632/1436 [38:03<36:10,  2.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 193 / 633  (30.5):  44%|     | 632/1436 [38:07<36:10,  2.70s/it]\u001b[A\n",
      "Average Metric: 193 / 633  (30.5):  44%|     | 633/1436 [38:07<37:33,  2.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 194 / 634  (30.6):  44%|     | 633/1436 [38:08<37:33,  2.81s/it]\u001b[A\n",
      "Average Metric: 194 / 634  (30.6):  44%|     | 634/1436 [38:08<32:45,  2.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 635  (30.7):  44%|     | 634/1436 [38:12<32:45,  2.45s/it]\u001b[A\n",
      "Average Metric: 195 / 635  (30.7):  44%|     | 635/1436 [38:12<37:26,  2.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 636  (30.7):  44%|     | 635/1436 [38:17<37:26,  2.80s/it]\u001b[A\n",
      "Average Metric: 195 / 636  (30.7):  44%|     | 636/1436 [38:17<46:43,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 637  (30.6):  44%|     | 636/1436 [38:19<46:43,  3.50s/it]\u001b[A\n",
      "Average Metric: 195 / 637  (30.6):  44%|     | 637/1436 [38:19<42:34,  3.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 638  (30.6):  44%|     | 637/1436 [38:25<42:34,  3.20s/it]\u001b[A\n",
      "Average Metric: 195 / 638  (30.6):  44%|     | 638/1436 [38:25<50:13,  3.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 639  (30.5):  44%|     | 638/1436 [38:28<50:13,  3.78s/it]\u001b[A\n",
      "Average Metric: 195 / 639  (30.5):  44%|     | 639/1436 [38:28<49:04,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 640  (30.5):  44%|     | 639/1436 [38:33<49:04,  3.69s/it]\u001b[A\n",
      "Average Metric: 195 / 640  (30.5):  45%|     | 640/1436 [38:33<54:51,  4.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 641  (30.4):  45%|     | 640/1436 [38:38<54:51,  4.13s/it]\u001b[A\n",
      "Average Metric: 195 / 641  (30.4):  45%|     | 641/1436 [38:38<58:53,  4.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 642  (30.4):  45%|     | 641/1436 [38:44<58:53,  4.44s/it]\u001b[A\n",
      "Average Metric: 195 / 642  (30.4):  45%|     | 642/1436 [38:44<1:01:41,  4.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 643  (30.3):  45%|     | 642/1436 [38:47<1:01:41,  4.66s/it]\u001b[A\n",
      "Average Metric: 195 / 643  (30.3):  45%|     | 643/1436 [38:47<55:23,  4.19s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 195 / 644  (30.3):  45%|     | 643/1436 [38:52<55:23,  4.19s/it]\u001b[A\n",
      "Average Metric: 195 / 644  (30.3):  45%|     | 644/1436 [38:52<59:26,  4.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 645  (30.4):  45%|     | 644/1436 [38:55<59:26,  4.50s/it]\u001b[A\n",
      "Average Metric: 196 / 645  (30.4):  45%|     | 645/1436 [38:55<52:54,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 646  (30.3):  45%|     | 645/1436 [38:58<52:54,  4.01s/it]\u001b[A\n",
      "Average Metric: 196 / 646  (30.3):  45%|     | 646/1436 [38:58<48:30,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 647  (30.3):  45%|     | 646/1436 [39:03<48:30,  3.68s/it]\u001b[A\n",
      "Average Metric: 196 / 647  (30.3):  45%|     | 647/1436 [39:03<54:33,  4.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 648  (30.2):  45%|     | 647/1436 [39:07<54:33,  4.15s/it]\u001b[A\n",
      "Average Metric: 196 / 648  (30.2):  45%|     | 648/1436 [39:07<53:24,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 649  (30.2):  45%|     | 648/1436 [39:09<53:24,  4.07s/it]\u001b[A\n",
      "Average Metric: 196 / 649  (30.2):  45%|     | 649/1436 [39:09<48:07,  3.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 650  (30.2):  45%|     | 649/1436 [39:13<48:07,  3.67s/it]\u001b[A\n",
      "Average Metric: 196 / 650  (30.2):  45%|     | 650/1436 [39:13<46:33,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 651  (30.1):  45%|     | 650/1436 [39:15<46:33,  3.55s/it]\u001b[A\n",
      "Average Metric: 196 / 651  (30.1):  45%|     | 651/1436 [39:15<42:44,  3.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 196 / 652  (30.1):  45%|     | 651/1436 [39:20<42:44,  3.27s/it]\u001b[A\n",
      "Average Metric: 196 / 652  (30.1):  45%|     | 652/1436 [39:20<48:25,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 197 / 653  (30.2):  45%|     | 652/1436 [39:23<48:25,  3.71s/it]\u001b[A\n",
      "Average Metric: 197 / 653  (30.2):  45%|     | 653/1436 [39:23<45:28,  3.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 198 / 654  (30.3):  45%|     | 653/1436 [39:27<45:28,  3.48s/it]\u001b[A\n",
      "Average Metric: 198 / 654  (30.3):  46%|     | 654/1436 [39:27<48:57,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 198 / 655  (30.2):  46%|     | 654/1436 [39:33<48:57,  3.76s/it]\u001b[A\n",
      "Average Metric: 198 / 655  (30.2):  46%|     | 655/1436 [39:33<55:05,  4.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 198 / 656  (30.2):  46%|     | 655/1436 [39:38<55:05,  4.23s/it]\u001b[A\n",
      "Average Metric: 198 / 656  (30.2):  46%|     | 656/1436 [39:38<57:49,  4.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 199 / 657  (30.3):  46%|     | 656/1436 [39:39<57:49,  4.45s/it]\u001b[A\n",
      "Average Metric: 199 / 657  (30.3):  46%|     | 657/1436 [39:39<44:22,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 199 / 658  (30.2):  46%|     | 657/1436 [39:42<44:22,  3.42s/it]\u001b[A\n",
      "Average Metric: 199 / 658  (30.2):  46%|     | 658/1436 [39:42<44:13,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 199 / 659  (30.2):  46%|     | 658/1436 [39:45<44:13,  3.41s/it]\u001b[A\n",
      "Average Metric: 199 / 659  (30.2):  46%|     | 659/1436 [39:45<42:28,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 200 / 660  (30.3):  46%|     | 659/1436 [39:48<42:28,  3.28s/it]\u001b[A\n",
      "Average Metric: 200 / 660  (30.3):  46%|     | 660/1436 [39:48<42:45,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 200 / 661  (30.3):  46%|     | 660/1436 [39:52<42:45,  3.31s/it]\u001b[A\n",
      "Average Metric: 200 / 661  (30.3):  46%|     | 661/1436 [39:52<42:17,  3.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 201 / 662  (30.4):  46%|     | 661/1436 [39:54<42:17,  3.27s/it]\u001b[A\n",
      "Average Metric: 201 / 662  (30.4):  46%|     | 662/1436 [39:54<39:44,  3.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 202 / 663  (30.5):  46%|     | 662/1436 [39:58<39:44,  3.08s/it]\u001b[A\n",
      "Average Metric: 202 / 663  (30.5):  46%|     | 663/1436 [39:58<42:24,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 202 / 664  (30.4):  46%|     | 663/1436 [40:03<42:24,  3.29s/it]\u001b[A\n",
      "Average Metric: 202 / 664  (30.4):  46%|     | 664/1436 [40:03<49:25,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 202 / 665  (30.4):  46%|     | 664/1436 [40:06<49:25,  3.84s/it]\u001b[A\n",
      "Average Metric: 202 / 665  (30.4):  46%|     | 665/1436 [40:06<46:51,  3.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 202 / 666  (30.3):  46%|     | 665/1436 [40:12<46:51,  3.65s/it]\u001b[A\n",
      "Average Metric: 202 / 666  (30.3):  46%|     | 666/1436 [40:12<53:23,  4.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 202 / 667  (30.3):  46%|     | 666/1436 [40:14<53:23,  4.16s/it]\u001b[A\n",
      "Average Metric: 202 / 667  (30.3):  46%|     | 667/1436 [40:14<46:57,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 203 / 668  (30.4):  46%|     | 667/1436 [40:17<46:57,  3.66s/it]\u001b[A\n",
      "Average Metric: 203 / 668  (30.4):  47%|     | 668/1436 [40:17<44:58,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 203 / 669  (30.3):  47%|     | 668/1436 [40:22<44:58,  3.51s/it]\u001b[A\n",
      "Average Metric: 203 / 669  (30.3):  47%|     | 669/1436 [40:22<48:04,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 203 / 670  (30.3):  47%|     | 669/1436 [40:25<48:04,  3.76s/it]\u001b[A\n",
      "Average Metric: 203 / 670  (30.3):  47%|     | 670/1436 [40:25<46:13,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 203 / 671  (30.3):  47%|     | 670/1436 [40:29<46:13,  3.62s/it]\u001b[A\n",
      "Average Metric: 203 / 671  (30.3):  47%|     | 671/1436 [40:29<47:25,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 203 / 672  (30.2):  47%|     | 671/1436 [40:34<47:25,  3.72s/it]\u001b[A\n",
      "Average Metric: 203 / 672  (30.2):  47%|     | 672/1436 [40:34<51:29,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 204 / 673  (30.3):  47%|     | 672/1436 [40:36<51:29,  4.04s/it]\u001b[A\n",
      "Average Metric: 204 / 673  (30.3):  47%|     | 673/1436 [40:36<43:32,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 204 / 674  (30.3):  47%|     | 673/1436 [40:40<43:32,  3.42s/it]\u001b[A\n",
      "Average Metric: 204 / 674  (30.3):  47%|     | 674/1436 [40:40<44:44,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 204 / 675  (30.2):  47%|     | 674/1436 [40:42<44:44,  3.52s/it]\u001b[A\n",
      "Average Metric: 204 / 675  (30.2):  47%|     | 675/1436 [40:42<42:24,  3.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 676  (30.3):  47%|     | 675/1436 [40:47<42:24,  3.34s/it]\u001b[A\n",
      "Average Metric: 205 / 676  (30.3):  47%|     | 676/1436 [40:47<48:28,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 677  (30.3):  47%|     | 676/1436 [40:53<48:28,  3.83s/it]\u001b[A\n",
      "Average Metric: 205 / 677  (30.3):  47%|     | 677/1436 [40:53<53:22,  4.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 678  (30.2):  47%|     | 677/1436 [40:56<53:22,  4.22s/it]\u001b[A\n",
      "Average Metric: 205 / 678  (30.2):  47%|     | 678/1436 [40:56<49:10,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 679  (30.2):  47%|     | 678/1436 [41:01<49:10,  3.89s/it]\u001b[A\n",
      "Average Metric: 205 / 679  (30.2):  47%|     | 679/1436 [41:01<53:46,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 680  (30.1):  47%|     | 679/1436 [41:05<53:46,  4.26s/it]\u001b[A\n",
      "Average Metric: 205 / 680  (30.1):  47%|     | 680/1436 [41:05<53:39,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 681  (30.1):  47%|     | 680/1436 [41:08<53:39,  4.26s/it]\u001b[A\n",
      "Average Metric: 205 / 681  (30.1):  47%|     | 681/1436 [41:08<47:01,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 682  (30.1):  47%|     | 681/1436 [41:13<47:01,  3.74s/it]\u001b[A\n",
      "Average Metric: 205 / 682  (30.1):  47%|     | 682/1436 [41:13<51:32,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 205 / 683  (30.0):  47%|     | 682/1436 [41:18<51:32,  4.10s/it]\u001b[A\n",
      "Average Metric: 205 / 683  (30.0):  48%|     | 683/1436 [41:18<56:23,  4.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 206 / 684  (30.1):  48%|     | 683/1436 [41:23<56:23,  4.49s/it]\u001b[A\n",
      "Average Metric: 206 / 684  (30.1):  48%|     | 684/1436 [41:23<58:49,  4.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 206 / 685  (30.1):  48%|     | 684/1436 [41:29<58:49,  4.69s/it]\u001b[A\n",
      "Average Metric: 206 / 685  (30.1):  48%|     | 685/1436 [41:29<1:01:35,  4.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 206 / 686  (30.0):  48%|     | 685/1436 [41:34<1:01:35,  4.92s/it]\u001b[A\n",
      "Average Metric: 206 / 686  (30.0):  48%|     | 686/1436 [41:34<1:03:22,  5.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 687  (30.1):  48%|     | 686/1436 [41:37<1:03:22,  5.07s/it]\u001b[A\n",
      "Average Metric: 207 / 687  (30.1):  48%|     | 687/1436 [41:37<54:20,  4.35s/it]  \u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 688  (30.1):  48%|     | 687/1436 [41:39<54:20,  4.35s/it]\u001b[A\n",
      "Average Metric: 207 / 688  (30.1):  48%|     | 688/1436 [41:39<47:35,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 689  (30.0):  48%|     | 688/1436 [41:43<47:35,  3.82s/it]\u001b[A\n",
      "Average Metric: 207 / 689  (30.0):  48%|     | 689/1436 [41:43<48:09,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 690  (30.0):  48%|     | 689/1436 [41:49<48:09,  3.87s/it]\u001b[A\n",
      "Average Metric: 207 / 690  (30.0):  48%|     | 690/1436 [41:49<53:40,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 691  (30.0):  48%|     | 690/1436 [41:53<53:40,  4.32s/it]\u001b[A\n",
      "Average Metric: 207 / 691  (30.0):  48%|     | 691/1436 [41:53<53:43,  4.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 692  (29.9):  48%|     | 691/1436 [41:55<53:43,  4.33s/it]\u001b[A\n",
      "Average Metric: 207 / 692  (29.9):  48%|     | 692/1436 [41:55<45:07,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 693  (29.9):  48%|     | 692/1436 [41:57<45:07,  3.64s/it]\u001b[A\n",
      "Average Metric: 207 / 693  (29.9):  48%|     | 693/1436 [41:57<39:43,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 207 / 694  (29.8):  48%|     | 693/1436 [42:01<39:43,  3.21s/it]\u001b[A\n",
      "Average Metric: 207 / 694  (29.8):  48%|     | 694/1436 [42:01<41:32,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 208 / 695  (29.9):  48%|     | 694/1436 [42:05<41:32,  3.36s/it]\u001b[A\n",
      "Average Metric: 208 / 695  (29.9):  48%|     | 695/1436 [42:05<45:51,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 208 / 696  (29.9):  48%|     | 695/1436 [42:10<45:51,  3.71s/it]\u001b[A\n",
      "Average Metric: 208 / 696  (29.9):  48%|     | 696/1436 [42:10<48:33,  3.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 208 / 697  (29.8):  48%|     | 696/1436 [42:15<48:33,  3.94s/it]\u001b[A\n",
      "Average Metric: 208 / 697  (29.8):  49%|     | 697/1436 [42:15<53:24,  4.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 208 / 698  (29.8):  49%|     | 697/1436 [42:17<53:24,  4.34s/it]\u001b[A\n",
      "Average Metric: 208 / 698  (29.8):  49%|     | 698/1436 [42:17<45:15,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 208 / 699  (29.8):  49%|     | 698/1436 [42:21<45:15,  3.68s/it]\u001b[A\n",
      "Average Metric: 208 / 699  (29.8):  49%|     | 699/1436 [42:21<45:09,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 209 / 700  (29.9):  49%|     | 699/1436 [42:23<45:09,  3.68s/it]\u001b[A\n",
      "Average Metric: 209 / 700  (29.9):  49%|     | 700/1436 [42:23<40:32,  3.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 210 / 701  (30.0):  49%|     | 700/1436 [42:26<40:32,  3.30s/it]\u001b[A\n",
      "Average Metric: 210 / 701  (30.0):  49%|     | 701/1436 [42:26<38:05,  3.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 211 / 702  (30.1):  49%|     | 701/1436 [42:31<38:05,  3.11s/it]\u001b[A\n",
      "Average Metric: 211 / 702  (30.1):  49%|     | 702/1436 [42:31<44:49,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 211 / 703  (30.0):  49%|     | 702/1436 [42:35<44:49,  3.66s/it]\u001b[A\n",
      "Average Metric: 211 / 703  (30.0):  49%|     | 703/1436 [42:35<47:02,  3.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 211 / 704  (30.0):  49%|     | 703/1436 [42:38<47:02,  3.85s/it]\u001b[A\n",
      "Average Metric: 211 / 704  (30.0):  49%|     | 704/1436 [42:38<42:48,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 211 / 705  (29.9):  49%|     | 704/1436 [42:43<42:48,  3.51s/it]\u001b[A\n",
      "Average Metric: 211 / 705  (29.9):  49%|     | 705/1436 [42:43<48:51,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 211 / 706  (29.9):  49%|     | 705/1436 [42:46<48:51,  4.01s/it]\u001b[A\n",
      "Average Metric: 211 / 706  (29.9):  49%|     | 706/1436 [42:46<43:20,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 211 / 707  (29.8):  49%|     | 706/1436 [42:51<43:20,  3.56s/it]\u001b[A\n",
      "Average Metric: 211 / 707  (29.8):  49%|     | 707/1436 [42:51<49:27,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 708  (29.9):  49%|     | 707/1436 [42:53<49:27,  4.07s/it]\u001b[A\n",
      "Average Metric: 212 / 708  (29.9):  49%|     | 708/1436 [42:53<41:23,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 709  (29.9):  49%|     | 708/1436 [42:58<41:23,  3.41s/it]\u001b[A\n",
      "Average Metric: 212 / 709  (29.9):  49%|     | 709/1436 [42:58<47:59,  3.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 710  (29.9):  49%|     | 709/1436 [43:02<47:59,  3.96s/it]\u001b[A\n",
      "Average Metric: 212 / 710  (29.9):  49%|     | 710/1436 [43:02<45:58,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 711  (29.8):  49%|     | 710/1436 [43:05<45:58,  3.80s/it]\u001b[A\n",
      "Average Metric: 212 / 711  (29.8):  50%|     | 711/1436 [43:05<46:01,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 712  (29.8):  50%|     | 711/1436 [43:11<46:01,  3.81s/it]\u001b[A\n",
      "Average Metric: 212 / 712  (29.8):  50%|     | 712/1436 [43:11<51:33,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 713  (29.7):  50%|     | 712/1436 [43:15<51:33,  4.27s/it]\u001b[A\n",
      "Average Metric: 212 / 713  (29.7):  50%|     | 713/1436 [43:15<52:32,  4.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 714  (29.7):  50%|     | 713/1436 [43:19<52:32,  4.36s/it]\u001b[A\n",
      "Average Metric: 212 / 714  (29.7):  50%|     | 714/1436 [43:19<51:45,  4.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 212 / 715  (29.7):  50%|     | 714/1436 [43:24<51:45,  4.30s/it]\u001b[A\n",
      "Average Metric: 212 / 715  (29.7):  50%|     | 715/1436 [43:24<52:26,  4.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 213 / 716  (29.7):  50%|     | 715/1436 [43:27<52:26,  4.36s/it]\u001b[A\n",
      "Average Metric: 213 / 716  (29.7):  50%|     | 716/1436 [43:27<49:07,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 214 / 717  (29.8):  50%|     | 716/1436 [43:29<49:07,  4.09s/it]\u001b[A\n",
      "Average Metric: 214 / 717  (29.8):  50%|     | 717/1436 [43:29<41:01,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 214 / 718  (29.8):  50%|     | 717/1436 [43:31<41:01,  3.42s/it]\u001b[A\n",
      "Average Metric: 214 / 718  (29.8):  50%|     | 718/1436 [43:31<35:21,  2.95s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 214 / 719  (29.8):  50%|     | 718/1436 [43:33<35:21,  2.95s/it]\u001b[A\n",
      "Average Metric: 214 / 719  (29.8):  50%|     | 719/1436 [43:33<30:57,  2.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 214 / 720  (29.7):  50%|     | 719/1436 [43:37<30:57,  2.59s/it]\u001b[A\n",
      "Average Metric: 214 / 720  (29.7):  50%|     | 720/1436 [43:37<34:40,  2.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 215 / 721  (29.8):  50%|     | 720/1436 [43:40<34:40,  2.91s/it]\u001b[A\n",
      "Average Metric: 215 / 721  (29.8):  50%|     | 721/1436 [43:40<35:26,  2.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 216 / 722  (29.9):  50%|     | 721/1436 [43:41<35:26,  2.97s/it]\u001b[A\n",
      "Average Metric: 216 / 722  (29.9):  50%|     | 722/1436 [43:41<30:08,  2.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 217 / 723  (30.0):  50%|     | 722/1436 [43:44<30:08,  2.53s/it]\u001b[A\n",
      "Average Metric: 217 / 723  (30.0):  50%|     | 723/1436 [43:45<33:03,  2.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 217 / 724  (30.0):  50%|     | 723/1436 [43:49<33:03,  2.78s/it]\u001b[A\n",
      "Average Metric: 217 / 724  (30.0):  50%|     | 724/1436 [43:49<40:04,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 218 / 725  (30.1):  50%|     | 724/1436 [43:51<40:04,  3.38s/it]\u001b[A\n",
      "Average Metric: 218 / 725  (30.1):  50%|     | 725/1436 [43:51<34:13,  2.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 218 / 726  (30.0):  50%|     | 725/1436 [43:55<34:13,  2.89s/it]\u001b[A\n",
      "Average Metric: 218 / 726  (30.0):  51%|     | 726/1436 [43:55<36:40,  3.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 218 / 727  (30.0):  51%|     | 726/1436 [43:58<36:40,  3.10s/it]\u001b[A\n",
      "Average Metric: 218 / 727  (30.0):  51%|     | 727/1436 [43:58<38:38,  3.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 728  (30.1):  51%|     | 727/1436 [44:02<38:38,  3.27s/it]\u001b[A\n",
      "Average Metric: 219 / 728  (30.1):  51%|     | 728/1436 [44:02<39:10,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 729  (30.0):  51%|     | 728/1436 [44:06<39:10,  3.32s/it]\u001b[A\n",
      "Average Metric: 219 / 729  (30.0):  51%|     | 729/1436 [44:06<42:52,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 730  (30.0):  51%|     | 729/1436 [44:11<42:52,  3.64s/it]\u001b[A\n",
      "Average Metric: 219 / 730  (30.0):  51%|     | 730/1436 [44:11<48:09,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 731  (30.0):  51%|     | 730/1436 [44:16<48:09,  4.09s/it]\u001b[A\n",
      "Average Metric: 219 / 731  (30.0):  51%|     | 731/1436 [44:16<48:41,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 732  (29.9):  51%|     | 731/1436 [44:18<48:41,  4.14s/it]\u001b[A\n",
      "Average Metric: 219 / 732  (29.9):  51%|     | 732/1436 [44:18<42:35,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 733  (29.9):  51%|     | 732/1436 [44:19<42:35,  3.63s/it]\u001b[A\n",
      "Average Metric: 219 / 733  (29.9):  51%|     | 733/1436 [44:19<34:46,  2.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 734  (29.8):  51%|     | 733/1436 [44:23<34:46,  2.97s/it]\u001b[A\n",
      "Average Metric: 219 / 734  (29.8):  51%|     | 734/1436 [44:23<35:32,  3.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 219 / 735  (29.8):  51%|     | 734/1436 [44:25<35:32,  3.04s/it]\u001b[A\n",
      "Average Metric: 219 / 735  (29.8):  51%|     | 735/1436 [44:25<33:43,  2.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 220 / 736  (29.9):  51%|     | 735/1436 [44:29<33:43,  2.89s/it]\u001b[A\n",
      "Average Metric: 220 / 736  (29.9):  51%|    | 736/1436 [44:29<37:35,  3.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 220 / 737  (29.9):  51%|    | 736/1436 [44:31<37:35,  3.22s/it]\u001b[A\n",
      "Average Metric: 220 / 737  (29.9):  51%|    | 737/1436 [44:31<33:04,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 220 / 738  (29.8):  51%|    | 737/1436 [44:33<33:04,  2.84s/it]\u001b[A\n",
      "Average Metric: 220 / 738  (29.8):  51%|    | 738/1436 [44:33<30:14,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 221 / 739  (29.9):  51%|    | 738/1436 [44:35<30:14,  2.60s/it]\u001b[A\n",
      "Average Metric: 221 / 739  (29.9):  51%|    | 739/1436 [44:35<27:21,  2.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 740  (30.0):  51%|    | 739/1436 [44:37<27:21,  2.36s/it]\u001b[A\n",
      "Average Metric: 222 / 740  (30.0):  52%|    | 740/1436 [44:37<27:06,  2.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 741  (30.0):  52%|    | 740/1436 [44:40<27:06,  2.34s/it]\u001b[A\n",
      "Average Metric: 222 / 741  (30.0):  52%|    | 741/1436 [44:40<29:44,  2.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 742  (29.9):  52%|    | 741/1436 [44:43<29:44,  2.57s/it]\u001b[A\n",
      "Average Metric: 222 / 742  (29.9):  52%|    | 742/1436 [44:43<31:04,  2.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 743  (29.9):  52%|    | 742/1436 [44:47<31:04,  2.69s/it]\u001b[A\n",
      "Average Metric: 222 / 743  (29.9):  52%|    | 743/1436 [44:47<33:39,  2.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 744  (29.8):  52%|    | 743/1436 [44:52<33:39,  2.91s/it]\u001b[A\n",
      "Average Metric: 222 / 744  (29.8):  52%|    | 744/1436 [44:52<41:29,  3.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 745  (29.8):  52%|    | 744/1436 [44:56<41:29,  3.60s/it]\u001b[A\n",
      "Average Metric: 222 / 745  (29.8):  52%|    | 745/1436 [44:56<43:40,  3.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 746  (29.8):  52%|    | 745/1436 [44:58<43:40,  3.79s/it]\u001b[A\n",
      "Average Metric: 222 / 746  (29.8):  52%|    | 746/1436 [44:58<36:26,  3.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 222 / 747  (29.7):  52%|    | 746/1436 [45:02<36:26,  3.17s/it]\u001b[A\n",
      "Average Metric: 222 / 747  (29.7):  52%|    | 747/1436 [45:02<38:49,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 223 / 748  (29.8):  52%|    | 747/1436 [45:05<38:49,  3.38s/it]\u001b[A\n",
      "Average Metric: 223 / 748  (29.8):  52%|    | 748/1436 [45:05<39:53,  3.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 224 / 749  (29.9):  52%|    | 748/1436 [45:09<39:53,  3.48s/it]\u001b[A\n",
      "Average Metric: 224 / 749  (29.9):  52%|    | 749/1436 [45:09<39:17,  3.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 224 / 750  (29.9):  52%|    | 749/1436 [45:14<39:17,  3.43s/it]\u001b[A\n",
      "Average Metric: 224 / 750  (29.9):  52%|    | 750/1436 [45:14<44:49,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 224 / 751  (29.8):  52%|    | 750/1436 [45:19<44:49,  3.92s/it]\u001b[A\n",
      "Average Metric: 224 / 751  (29.8):  52%|    | 751/1436 [45:19<49:50,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 225 / 752  (29.9):  52%|    | 751/1436 [45:23<49:50,  4.37s/it]\u001b[A\n",
      "Average Metric: 225 / 752  (29.9):  52%|    | 752/1436 [45:23<48:29,  4.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 225 / 753  (29.9):  52%|    | 752/1436 [45:28<48:29,  4.25s/it]\u001b[A\n",
      "Average Metric: 225 / 753  (29.9):  52%|    | 753/1436 [45:28<51:26,  4.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 226 / 754  (30.0):  52%|    | 753/1436 [45:31<51:26,  4.52s/it]\u001b[A\n",
      "Average Metric: 226 / 754  (30.0):  53%|    | 754/1436 [45:31<44:44,  3.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 226 / 755  (29.9):  53%|    | 754/1436 [45:35<44:44,  3.94s/it]\u001b[A\n",
      "Average Metric: 226 / 755  (29.9):  53%|    | 755/1436 [45:35<46:21,  4.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 226 / 756  (29.9):  53%|    | 755/1436 [45:38<46:21,  4.08s/it]\u001b[A\n",
      "Average Metric: 226 / 756  (29.9):  53%|    | 756/1436 [45:38<42:26,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 226 / 757  (29.9):  53%|    | 756/1436 [45:42<42:26,  3.75s/it]\u001b[A\n",
      "Average Metric: 226 / 757  (29.9):  53%|    | 757/1436 [45:42<42:32,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 226 / 758  (29.8):  53%|    | 757/1436 [45:47<42:32,  3.76s/it]\u001b[A\n",
      "Average Metric: 226 / 758  (29.8):  53%|    | 758/1436 [45:47<46:11,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 227 / 759  (29.9):  53%|    | 758/1436 [45:50<46:11,  4.09s/it]\u001b[A\n",
      "Average Metric: 227 / 759  (29.9):  53%|    | 759/1436 [45:50<41:07,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 228 / 760  (30.0):  53%|    | 759/1436 [45:53<41:07,  3.64s/it]\u001b[A\n",
      "Average Metric: 228 / 760  (30.0):  53%|    | 760/1436 [45:53<39:38,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 228 / 761  (30.0):  53%|    | 760/1436 [45:57<39:38,  3.52s/it]\u001b[A\n",
      "Average Metric: 228 / 761  (30.0):  53%|    | 761/1436 [45:57<43:13,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 228 / 762  (29.9):  53%|    | 761/1436 [46:01<43:13,  3.84s/it]\u001b[A\n",
      "Average Metric: 228 / 762  (29.9):  53%|    | 762/1436 [46:01<41:03,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 763  (30.0):  53%|    | 762/1436 [46:02<41:03,  3.66s/it]\u001b[A\n",
      "Average Metric: 229 / 763  (30.0):  53%|    | 763/1436 [46:02<33:48,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 764  (30.0):  53%|    | 763/1436 [46:07<33:48,  3.01s/it]\u001b[A\n",
      "Average Metric: 229 / 764  (30.0):  53%|    | 764/1436 [46:07<41:00,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 765  (29.9):  53%|    | 764/1436 [46:12<41:00,  3.66s/it]\u001b[A\n",
      "Average Metric: 229 / 765  (29.9):  53%|    | 765/1436 [46:12<46:02,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 766  (29.9):  53%|    | 765/1436 [46:15<46:02,  4.12s/it]\u001b[A\n",
      "Average Metric: 229 / 766  (29.9):  53%|    | 766/1436 [46:15<39:46,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 767  (29.9):  53%|    | 766/1436 [46:18<39:46,  3.56s/it]\u001b[A\n",
      "Average Metric: 229 / 767  (29.9):  53%|    | 767/1436 [46:18<38:11,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 768  (29.8):  53%|    | 767/1436 [46:22<38:11,  3.42s/it]\u001b[A\n",
      "Average Metric: 229 / 768  (29.8):  53%|    | 768/1436 [46:22<40:29,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 769  (29.8):  53%|    | 768/1436 [46:24<40:29,  3.64s/it]\u001b[A\n",
      "Average Metric: 229 / 769  (29.8):  54%|    | 769/1436 [46:24<36:26,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 770  (29.7):  54%|    | 769/1436 [46:30<36:26,  3.28s/it]\u001b[A\n",
      "Average Metric: 229 / 770  (29.7):  54%|    | 770/1436 [46:30<43:09,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 229 / 771  (29.7):  54%|    | 770/1436 [46:34<43:09,  3.89s/it]\u001b[A\n",
      "Average Metric: 229 / 771  (29.7):  54%|    | 771/1436 [46:34<43:30,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 230 / 772  (29.8):  54%|    | 771/1436 [46:38<43:30,  3.93s/it]\u001b[A\n",
      "Average Metric: 230 / 772  (29.8):  54%|    | 772/1436 [46:38<44:27,  4.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 230 / 773  (29.8):  54%|    | 772/1436 [46:40<44:27,  4.02s/it]\u001b[A\n",
      "Average Metric: 230 / 773  (29.8):  54%|    | 773/1436 [46:40<38:18,  3.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 230 / 774  (29.7):  54%|    | 773/1436 [46:42<38:18,  3.47s/it]\u001b[A\n",
      "Average Metric: 230 / 774  (29.7):  54%|    | 774/1436 [46:42<33:33,  3.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 230 / 775  (29.7):  54%|    | 774/1436 [46:45<33:33,  3.04s/it]\u001b[A\n",
      "Average Metric: 230 / 775  (29.7):  54%|    | 775/1436 [46:45<31:56,  2.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 230 / 776  (29.6):  54%|    | 775/1436 [46:50<31:56,  2.90s/it]\u001b[A\n",
      "Average Metric: 230 / 776  (29.6):  54%|    | 776/1436 [46:50<39:22,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 230 / 777  (29.6):  54%|    | 776/1436 [46:55<39:22,  3.58s/it]\u001b[A\n",
      "Average Metric: 230 / 777  (29.6):  54%|    | 777/1436 [46:55<43:59,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 231 / 778  (29.7):  54%|    | 777/1436 [47:00<43:59,  4.00s/it]\u001b[A\n",
      "Average Metric: 231 / 778  (29.7):  54%|    | 778/1436 [47:00<46:51,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 231 / 779  (29.7):  54%|    | 778/1436 [47:03<46:51,  4.27s/it]\u001b[A\n",
      "Average Metric: 231 / 779  (29.7):  54%|    | 779/1436 [47:03<41:59,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 231 / 780  (29.6):  54%|    | 779/1436 [47:06<41:59,  3.83s/it]\u001b[A\n",
      "Average Metric: 231 / 780  (29.6):  54%|    | 780/1436 [47:06<41:09,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 231 / 781  (29.6):  54%|    | 780/1436 [47:12<41:09,  3.76s/it]\u001b[A\n",
      "Average Metric: 231 / 781  (29.6):  54%|    | 781/1436 [47:12<46:16,  4.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 232 / 782  (29.7):  54%|    | 781/1436 [47:14<46:16,  4.24s/it]\u001b[A\n",
      "Average Metric: 232 / 782  (29.7):  54%|    | 782/1436 [47:14<39:10,  3.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 232 / 783  (29.6):  54%|    | 782/1436 [47:19<39:10,  3.59s/it]\u001b[A\n",
      "Average Metric: 232 / 783  (29.6):  55%|    | 783/1436 [47:19<44:47,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 784  (29.7):  55%|    | 783/1436 [47:22<44:47,  4.12s/it]\u001b[A\n",
      "Average Metric: 233 / 784  (29.7):  55%|    | 784/1436 [47:22<39:27,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 785  (29.7):  55%|    | 784/1436 [47:25<39:27,  3.63s/it]\u001b[A\n",
      "Average Metric: 233 / 785  (29.7):  55%|    | 785/1436 [47:25<38:05,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 786  (29.6):  55%|    | 785/1436 [47:30<38:05,  3.51s/it]\u001b[A\n",
      "Average Metric: 233 / 786  (29.6):  55%|    | 786/1436 [47:30<43:54,  4.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 787  (29.6):  55%|    | 786/1436 [47:35<43:54,  4.05s/it]\u001b[A\n",
      "Average Metric: 233 / 787  (29.6):  55%|    | 787/1436 [47:35<46:46,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 788  (29.6):  55%|    | 787/1436 [47:38<46:46,  4.32s/it]\u001b[A\n",
      "Average Metric: 233 / 788  (29.6):  55%|    | 788/1436 [47:38<43:28,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 789  (29.5):  55%|    | 788/1436 [47:44<43:28,  4.03s/it]\u001b[A\n",
      "Average Metric: 233 / 789  (29.5):  55%|    | 789/1436 [47:44<47:42,  4.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 790  (29.5):  55%|    | 789/1436 [47:47<47:42,  4.42s/it]\u001b[A\n",
      "Average Metric: 233 / 790  (29.5):  55%|    | 790/1436 [47:47<45:01,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 791  (29.5):  55%|    | 790/1436 [47:52<45:01,  4.18s/it]\u001b[A\n",
      "Average Metric: 233 / 791  (29.5):  55%|    | 791/1436 [47:52<46:02,  4.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 792  (29.4):  55%|    | 791/1436 [47:57<46:02,  4.28s/it]\u001b[A\n",
      "Average Metric: 233 / 792  (29.4):  55%|    | 792/1436 [47:57<48:52,  4.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 233 / 793  (29.4):  55%|    | 792/1436 [48:02<48:52,  4.55s/it]\u001b[A\n",
      "Average Metric: 233 / 793  (29.4):  55%|    | 793/1436 [48:02<50:56,  4.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 794  (29.5):  55%|    | 793/1436 [48:06<50:56,  4.75s/it]\u001b[A\n",
      "Average Metric: 234 / 794  (29.5):  55%|    | 794/1436 [48:06<48:13,  4.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 795  (29.4):  55%|    | 794/1436 [48:09<48:13,  4.51s/it]\u001b[A\n",
      "Average Metric: 234 / 795  (29.4):  55%|    | 795/1436 [48:09<41:50,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 796  (29.4):  55%|    | 795/1436 [48:12<41:50,  3.92s/it]\u001b[A\n",
      "Average Metric: 234 / 796  (29.4):  55%|    | 796/1436 [48:12<39:12,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 797  (29.4):  55%|    | 796/1436 [48:16<39:12,  3.68s/it]\u001b[A\n",
      "Average Metric: 234 / 797  (29.4):  56%|    | 797/1436 [48:16<41:34,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 798  (29.3):  56%|    | 797/1436 [48:21<41:34,  3.90s/it]\u001b[A\n",
      "Average Metric: 234 / 798  (29.3):  56%|    | 798/1436 [48:21<45:30,  4.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 799  (29.3):  56%|    | 798/1436 [48:24<45:30,  4.28s/it]\u001b[A\n",
      "Average Metric: 234 / 799  (29.3):  56%|    | 799/1436 [48:24<40:31,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 800  (29.2):  56%|    | 799/1436 [48:28<40:31,  3.82s/it]\u001b[A\n",
      "Average Metric: 234 / 800  (29.2):  56%|    | 800/1436 [48:28<39:53,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 801  (29.2):  56%|    | 800/1436 [48:33<39:53,  3.76s/it]\u001b[A\n",
      "Average Metric: 234 / 801  (29.2):  56%|    | 801/1436 [48:33<44:12,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 802  (29.2):  56%|    | 801/1436 [48:38<44:12,  4.18s/it]\u001b[A\n",
      "Average Metric: 234 / 802  (29.2):  56%|    | 802/1436 [48:38<47:11,  4.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 803  (29.1):  56%|    | 802/1436 [48:43<47:11,  4.47s/it]\u001b[A\n",
      "Average Metric: 234 / 803  (29.1):  56%|    | 803/1436 [48:43<49:16,  4.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 234 / 804  (29.1):  56%|    | 803/1436 [48:46<49:16,  4.67s/it]\u001b[A\n",
      "Average Metric: 234 / 804  (29.1):  56%|    | 804/1436 [48:46<44:12,  4.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 235 / 805  (29.2):  56%|    | 804/1436 [48:49<44:12,  4.20s/it]\u001b[A\n",
      "Average Metric: 235 / 805  (29.2):  56%|    | 805/1436 [48:49<38:57,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 236 / 806  (29.3):  56%|    | 805/1436 [48:53<38:57,  3.70s/it]\u001b[A\n",
      "Average Metric: 236 / 806  (29.3):  56%|    | 806/1436 [48:53<38:49,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 236 / 807  (29.2):  56%|    | 806/1436 [48:55<38:49,  3.70s/it]\u001b[A\n",
      "Average Metric: 236 / 807  (29.2):  56%|    | 807/1436 [48:55<35:51,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 237 / 808  (29.3):  56%|    | 807/1436 [48:58<35:51,  3.42s/it]\u001b[A\n",
      "Average Metric: 237 / 808  (29.3):  56%|    | 808/1436 [48:58<34:39,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 237 / 809  (29.3):  56%|    | 808/1436 [49:04<34:39,  3.31s/it]\u001b[A\n",
      "Average Metric: 237 / 809  (29.3):  56%|    | 809/1436 [49:04<40:39,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 237 / 810  (29.3):  56%|    | 809/1436 [49:08<40:39,  3.89s/it]\u001b[A\n",
      "Average Metric: 237 / 810  (29.3):  56%|    | 810/1436 [49:08<40:51,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 237 / 811  (29.2):  56%|    | 810/1436 [49:10<40:51,  3.92s/it]\u001b[A\n",
      "Average Metric: 237 / 811  (29.2):  56%|    | 811/1436 [49:10<35:27,  3.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 237 / 812  (29.2):  56%|    | 811/1436 [49:15<35:27,  3.40s/it]\u001b[A\n",
      "Average Metric: 237 / 812  (29.2):  57%|    | 812/1436 [49:15<41:23,  3.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 237 / 813  (29.2):  57%|    | 812/1436 [49:20<41:23,  3.98s/it]\u001b[A\n",
      "Average Metric: 237 / 813  (29.2):  57%|    | 813/1436 [49:20<42:47,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 237 / 814  (29.1):  57%|    | 813/1436 [49:23<42:47,  4.12s/it]\u001b[A\n",
      "Average Metric: 237 / 814  (29.1):  57%|    | 814/1436 [49:23<40:13,  3.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 815  (29.2):  57%|    | 814/1436 [49:25<40:13,  3.88s/it]\u001b[A\n",
      "Average Metric: 238 / 815  (29.2):  57%|    | 815/1436 [49:25<34:53,  3.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 816  (29.2):  57%|    | 815/1436 [49:28<34:53,  3.37s/it]\u001b[A\n",
      "Average Metric: 238 / 816  (29.2):  57%|    | 816/1436 [49:28<33:01,  3.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 817  (29.1):  57%|    | 816/1436 [49:32<33:01,  3.20s/it]\u001b[A\n",
      "Average Metric: 238 / 817  (29.1):  57%|    | 817/1436 [49:32<35:11,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 818  (29.1):  57%|    | 817/1436 [49:34<35:11,  3.41s/it]\u001b[A\n",
      "Average Metric: 238 / 818  (29.1):  57%|    | 818/1436 [49:34<30:37,  2.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 238 / 819  (29.1):  57%|    | 818/1436 [49:39<30:37,  2.97s/it]\u001b[A\n",
      "Average Metric: 238 / 819  (29.1):  57%|    | 819/1436 [49:39<37:16,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 239 / 820  (29.1):  57%|    | 819/1436 [49:43<37:16,  3.63s/it]\u001b[A\n",
      "Average Metric: 239 / 820  (29.1):  57%|    | 820/1436 [49:43<39:21,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 240 / 821  (29.2):  57%|    | 820/1436 [49:46<39:21,  3.83s/it]\u001b[A\n",
      "Average Metric: 240 / 821  (29.2):  57%|    | 821/1436 [49:46<35:23,  3.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 240 / 822  (29.2):  57%|    | 821/1436 [49:49<35:23,  3.45s/it]\u001b[A\n",
      "Average Metric: 240 / 822  (29.2):  57%|    | 822/1436 [49:49<35:05,  3.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 240 / 823  (29.2):  57%|    | 822/1436 [49:52<35:05,  3.43s/it]\u001b[A\n",
      "Average Metric: 240 / 823  (29.2):  57%|    | 823/1436 [49:52<34:28,  3.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 240 / 824  (29.1):  57%|    | 823/1436 [49:56<34:28,  3.37s/it]\u001b[A\n",
      "Average Metric: 240 / 824  (29.1):  57%|    | 824/1436 [49:56<34:12,  3.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 240 / 825  (29.1):  57%|    | 824/1436 [50:01<34:12,  3.35s/it]\u001b[A\n",
      "Average Metric: 240 / 825  (29.1):  57%|    | 825/1436 [50:01<39:57,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 241 / 826  (29.2):  57%|    | 825/1436 [50:03<39:57,  3.92s/it]\u001b[A\n",
      "Average Metric: 241 / 826  (29.2):  58%|    | 826/1436 [50:03<32:41,  3.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 241 / 827  (29.1):  58%|    | 826/1436 [50:05<32:41,  3.22s/it]\u001b[A\n",
      "Average Metric: 241 / 827  (29.1):  58%|    | 827/1436 [50:05<29:09,  2.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 241 / 828  (29.1):  58%|    | 827/1436 [50:07<29:09,  2.87s/it]\u001b[A\n",
      "Average Metric: 241 / 828  (29.1):  58%|    | 828/1436 [50:07<27:10,  2.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 241 / 829  (29.1):  58%|    | 828/1436 [50:09<27:10,  2.68s/it]\u001b[A\n",
      "Average Metric: 241 / 829  (29.1):  58%|    | 829/1436 [50:09<24:36,  2.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 242 / 830  (29.2):  58%|    | 829/1436 [50:12<24:36,  2.43s/it]\u001b[A\n",
      "Average Metric: 242 / 830  (29.2):  58%|    | 830/1436 [50:12<26:13,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 242 / 831  (29.1):  58%|    | 830/1436 [50:15<26:13,  2.60s/it]\u001b[A\n",
      "Average Metric: 242 / 831  (29.1):  58%|    | 831/1436 [50:15<28:42,  2.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 243 / 832  (29.2):  58%|    | 831/1436 [50:17<28:42,  2.85s/it]\u001b[A\n",
      "Average Metric: 243 / 832  (29.2):  58%|    | 832/1436 [50:17<25:44,  2.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 243 / 833  (29.2):  58%|    | 832/1436 [50:21<25:44,  2.56s/it]\u001b[A\n",
      "Average Metric: 243 / 833  (29.2):  58%|    | 833/1436 [50:21<30:10,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 243 / 834  (29.1):  58%|    | 833/1436 [50:26<30:10,  3.00s/it]\u001b[A\n",
      "Average Metric: 243 / 834  (29.1):  58%|    | 834/1436 [50:26<36:46,  3.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 244 / 835  (29.2):  58%|    | 834/1436 [50:30<36:46,  3.67s/it]\u001b[A\n",
      "Average Metric: 244 / 835  (29.2):  58%|    | 835/1436 [50:30<36:07,  3.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 244 / 836  (29.2):  58%|    | 835/1436 [50:34<36:07,  3.61s/it]\u001b[A\n",
      "Average Metric: 244 / 836  (29.2):  58%|    | 836/1436 [50:34<36:47,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 244 / 837  (29.2):  58%|    | 836/1436 [50:39<36:47,  3.68s/it]\u001b[A\n",
      "Average Metric: 244 / 837  (29.2):  58%|    | 837/1436 [50:39<41:21,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 244 / 838  (29.1):  58%|    | 837/1436 [50:44<41:21,  4.14s/it]\u001b[A\n",
      "Average Metric: 244 / 838  (29.1):  58%|    | 838/1436 [50:44<44:32,  4.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 244 / 839  (29.1):  58%|    | 838/1436 [50:49<44:32,  4.47s/it]\u001b[A\n",
      "Average Metric: 244 / 839  (29.1):  58%|    | 839/1436 [50:49<46:42,  4.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 244 / 840  (29.0):  58%|    | 839/1436 [50:54<46:42,  4.69s/it]\u001b[A\n",
      "Average Metric: 244 / 840  (29.0):  58%|    | 840/1436 [50:54<48:15,  4.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 244 / 841  (29.0):  58%|    | 840/1436 [50:58<48:15,  4.86s/it]\u001b[A\n",
      "Average Metric: 244 / 841  (29.0):  59%|    | 841/1436 [50:58<44:20,  4.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 245 / 842  (29.1):  59%|    | 841/1436 [51:02<44:20,  4.47s/it]\u001b[A\n",
      "Average Metric: 245 / 842  (29.1):  59%|    | 842/1436 [51:02<42:20,  4.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 245 / 843  (29.1):  59%|    | 842/1436 [51:07<42:20,  4.28s/it]\u001b[A\n",
      "Average Metric: 245 / 843  (29.1):  59%|    | 843/1436 [51:07<44:11,  4.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 245 / 844  (29.0):  59%|    | 843/1436 [51:11<44:11,  4.47s/it]\u001b[A\n",
      "Average Metric: 245 / 844  (29.0):  59%|    | 844/1436 [51:11<44:32,  4.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 245 / 845  (29.0):  59%|    | 844/1436 [51:15<44:32,  4.51s/it]\u001b[A\n",
      "Average Metric: 245 / 845  (29.0):  59%|    | 845/1436 [51:15<42:02,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 246 / 846  (29.1):  59%|    | 845/1436 [51:19<42:02,  4.27s/it]\u001b[A\n",
      "Average Metric: 246 / 846  (29.1):  59%|    | 846/1436 [51:19<40:33,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 247 / 847  (29.2):  59%|    | 846/1436 [51:22<40:33,  4.12s/it]\u001b[A\n",
      "Average Metric: 247 / 847  (29.2):  59%|    | 847/1436 [51:22<38:55,  3.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 247 / 848  (29.1):  59%|    | 847/1436 [51:28<38:55,  3.96s/it]\u001b[A\n",
      "Average Metric: 247 / 848  (29.1):  59%|    | 848/1436 [51:28<42:23,  4.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 248 / 849  (29.2):  59%|    | 848/1436 [51:30<42:23,  4.32s/it]\u001b[A\n",
      "Average Metric: 248 / 849  (29.2):  59%|    | 849/1436 [51:30<36:27,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 249 / 850  (29.3):  59%|    | 849/1436 [51:32<36:27,  3.73s/it]\u001b[A\n",
      "Average Metric: 249 / 850  (29.3):  59%|    | 850/1436 [51:32<31:09,  3.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 250 / 851  (29.4):  59%|    | 850/1436 [51:34<31:09,  3.19s/it]\u001b[A\n",
      "Average Metric: 250 / 851  (29.4):  59%|    | 851/1436 [51:34<27:55,  2.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 250 / 852  (29.3):  59%|    | 851/1436 [51:39<27:55,  2.86s/it]\u001b[A\n",
      "Average Metric: 250 / 852  (29.3):  59%|    | 852/1436 [51:39<34:20,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 251 / 853  (29.4):  59%|    | 852/1436 [51:42<34:20,  3.53s/it]\u001b[A\n",
      "Average Metric: 251 / 853  (29.4):  59%|    | 853/1436 [51:42<33:05,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 251 / 854  (29.4):  59%|    | 853/1436 [51:47<33:05,  3.41s/it]\u001b[A\n",
      "Average Metric: 251 / 854  (29.4):  59%|    | 854/1436 [51:47<37:52,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 251 / 855  (29.4):  59%|    | 854/1436 [51:52<37:52,  3.90s/it]\u001b[A\n",
      "Average Metric: 251 / 855  (29.4):  60%|    | 855/1436 [51:52<41:12,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 252 / 856  (29.4):  60%|    | 855/1436 [51:54<41:12,  4.26s/it]\u001b[A\n",
      "Average Metric: 252 / 856  (29.4):  60%|    | 856/1436 [51:54<32:44,  3.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 253 / 857  (29.5):  60%|    | 856/1436 [51:56<32:44,  3.39s/it]\u001b[A\n",
      "Average Metric: 253 / 857  (29.5):  60%|    | 857/1436 [51:56<30:56,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 253 / 858  (29.5):  60%|    | 857/1436 [52:00<30:56,  3.21s/it]\u001b[A\n",
      "Average Metric: 253 / 858  (29.5):  60%|    | 858/1436 [52:00<33:11,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 253 / 859  (29.5):  60%|    | 858/1436 [52:05<33:11,  3.44s/it]\u001b[A\n",
      "Average Metric: 253 / 859  (29.5):  60%|    | 859/1436 [52:05<34:49,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 253 / 860  (29.4):  60%|    | 859/1436 [52:08<34:49,  3.62s/it]\u001b[A\n",
      "Average Metric: 253 / 860  (29.4):  60%|    | 860/1436 [52:08<35:22,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 254 / 861  (29.5):  60%|    | 860/1436 [52:12<35:22,  3.69s/it]\u001b[A\n",
      "Average Metric: 254 / 861  (29.5):  60%|    | 861/1436 [52:12<34:14,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 254 / 862  (29.5):  60%|    | 861/1436 [52:17<34:14,  3.57s/it]\u001b[A\n",
      "Average Metric: 254 / 862  (29.5):  60%|    | 862/1436 [52:17<38:45,  4.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 254 / 863  (29.4):  60%|    | 862/1436 [52:22<38:45,  4.05s/it]\u001b[A\n",
      "Average Metric: 254 / 863  (29.4):  60%|    | 863/1436 [52:22<41:59,  4.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 254 / 864  (29.4):  60%|    | 863/1436 [52:27<41:59,  4.40s/it]\u001b[A\n",
      "Average Metric: 254 / 864  (29.4):  60%|    | 864/1436 [52:27<44:14,  4.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 255 / 865  (29.5):  60%|    | 864/1436 [52:29<44:14,  4.64s/it]\u001b[A\n",
      "Average Metric: 255 / 865  (29.5):  60%|    | 865/1436 [52:29<35:53,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 255 / 866  (29.4):  60%|    | 865/1436 [52:33<35:53,  3.77s/it]\u001b[A\n",
      "Average Metric: 255 / 866  (29.4):  60%|    | 866/1436 [52:33<37:18,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 255 / 867  (29.4):  60%|    | 866/1436 [52:38<37:18,  3.93s/it]\u001b[A\n",
      "Average Metric: 255 / 867  (29.4):  60%|    | 867/1436 [52:38<40:39,  4.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 255 / 868  (29.4):  60%|    | 867/1436 [52:41<40:39,  4.29s/it]\u001b[A\n",
      "Average Metric: 255 / 868  (29.4):  60%|    | 868/1436 [52:41<36:04,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 255 / 869  (29.3):  60%|    | 868/1436 [52:46<36:04,  3.81s/it]\u001b[A\n",
      "Average Metric: 255 / 869  (29.3):  61%|    | 869/1436 [52:46<37:53,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 870  (29.4):  61%|    | 869/1436 [52:50<37:53,  4.01s/it]\u001b[A\n",
      "Average Metric: 256 / 870  (29.4):  61%|    | 870/1436 [52:50<40:10,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 871  (29.4):  61%|    | 870/1436 [52:53<40:10,  4.26s/it]\u001b[A\n",
      "Average Metric: 256 / 871  (29.4):  61%|    | 871/1436 [52:53<35:16,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 872  (29.4):  61%|    | 871/1436 [52:58<35:16,  3.75s/it]\u001b[A\n",
      "Average Metric: 256 / 872  (29.4):  61%|    | 872/1436 [52:58<39:07,  4.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 873  (29.3):  61%|    | 872/1436 [53:03<39:07,  4.16s/it]\u001b[A\n",
      "Average Metric: 256 / 873  (29.3):  61%|    | 873/1436 [53:03<41:51,  4.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 874  (29.3):  61%|    | 873/1436 [53:07<41:51,  4.46s/it]\u001b[A\n",
      "Average Metric: 256 / 874  (29.3):  61%|    | 874/1436 [53:07<40:54,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 875  (29.3):  61%|    | 874/1436 [53:12<40:54,  4.37s/it]\u001b[A\n",
      "Average Metric: 256 / 875  (29.3):  61%|    | 875/1436 [53:13<42:53,  4.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 876  (29.2):  61%|    | 875/1436 [53:15<42:53,  4.59s/it]\u001b[A\n",
      "Average Metric: 256 / 876  (29.2):  61%|    | 876/1436 [53:15<37:03,  3.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 877  (29.2):  61%|    | 876/1436 [53:19<37:03,  3.97s/it]\u001b[A\n",
      "Average Metric: 256 / 877  (29.2):  61%|    | 877/1436 [53:19<38:10,  4.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 256 / 878  (29.2):  61%|    | 877/1436 [53:24<38:10,  4.10s/it]\u001b[A\n",
      "Average Metric: 256 / 878  (29.2):  61%|    | 878/1436 [53:24<40:17,  4.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 257 / 879  (29.2):  61%|    | 878/1436 [53:26<40:17,  4.33s/it]\u001b[A\n",
      "Average Metric: 257 / 879  (29.2):  61%|    | 879/1436 [53:26<33:01,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 257 / 880  (29.2):  61%|    | 879/1436 [53:28<33:01,  3.56s/it]\u001b[A\n",
      "Average Metric: 257 / 880  (29.2):  61%|   | 880/1436 [53:28<29:31,  3.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 881  (29.3):  61%|   | 880/1436 [53:30<29:31,  3.19s/it]\u001b[A\n",
      "Average Metric: 258 / 881  (29.3):  61%|   | 881/1436 [53:30<25:13,  2.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 882  (29.3):  61%|   | 881/1436 [53:32<25:13,  2.73s/it]\u001b[A\n",
      "Average Metric: 258 / 882  (29.3):  61%|   | 882/1436 [53:32<23:58,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 258 / 883  (29.2):  61%|   | 882/1436 [53:36<23:58,  2.60s/it]\u001b[A\n",
      "Average Metric: 258 / 883  (29.2):  61%|   | 883/1436 [53:36<25:34,  2.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 259 / 884  (29.3):  61%|   | 883/1436 [53:37<25:34,  2.77s/it]\u001b[A\n",
      "Average Metric: 259 / 884  (29.3):  62%|   | 884/1436 [53:37<22:19,  2.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 259 / 885  (29.3):  62%|   | 884/1436 [53:40<22:19,  2.43s/it]\u001b[A\n",
      "Average Metric: 259 / 885  (29.3):  62%|   | 885/1436 [53:40<22:31,  2.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 260 / 886  (29.3):  62%|   | 885/1436 [53:42<22:31,  2.45s/it]\u001b[A\n",
      "Average Metric: 260 / 886  (29.3):  62%|   | 886/1436 [53:42<21:31,  2.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 261 / 887  (29.4):  62%|   | 886/1436 [53:47<21:31,  2.35s/it]\u001b[A\n",
      "Average Metric: 261 / 887  (29.4):  62%|   | 887/1436 [53:47<29:05,  3.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 888  (29.5):  62%|   | 887/1436 [53:51<29:05,  3.18s/it]\u001b[A\n",
      "Average Metric: 262 / 888  (29.5):  62%|   | 888/1436 [53:51<32:05,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 889  (29.5):  62%|   | 888/1436 [53:56<32:05,  3.51s/it]\u001b[A\n",
      "Average Metric: 262 / 889  (29.5):  62%|   | 889/1436 [53:56<36:24,  3.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 890  (29.4):  62%|   | 889/1436 [54:01<36:24,  3.99s/it]\u001b[A\n",
      "Average Metric: 262 / 890  (29.4):  62%|   | 890/1436 [54:01<37:30,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 891  (29.4):  62%|   | 890/1436 [54:04<37:30,  4.12s/it]\u001b[A\n",
      "Average Metric: 262 / 891  (29.4):  62%|   | 891/1436 [54:04<35:34,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 892  (29.4):  62%|   | 891/1436 [54:06<35:34,  3.92s/it]\u001b[A\n",
      "Average Metric: 262 / 892  (29.4):  62%|   | 892/1436 [54:06<29:35,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 893  (29.3):  62%|   | 892/1436 [54:10<29:35,  3.26s/it]\u001b[A\n",
      "Average Metric: 262 / 893  (29.3):  62%|   | 893/1436 [54:10<32:41,  3.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 894  (29.3):  62%|   | 893/1436 [54:13<32:41,  3.61s/it]\u001b[A\n",
      "Average Metric: 262 / 894  (29.3):  62%|   | 894/1436 [54:13<30:55,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 895  (29.3):  62%|   | 894/1436 [54:15<30:55,  3.42s/it]\u001b[A\n",
      "Average Metric: 262 / 895  (29.3):  62%|   | 895/1436 [54:15<26:27,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 896  (29.2):  62%|   | 895/1436 [54:19<26:27,  2.93s/it]\u001b[A\n",
      "Average Metric: 262 / 896  (29.2):  62%|   | 896/1436 [54:19<27:56,  3.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 897  (29.2):  62%|   | 896/1436 [54:22<27:56,  3.10s/it]\u001b[A\n",
      "Average Metric: 262 / 897  (29.2):  62%|   | 897/1436 [54:22<29:38,  3.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 898  (29.2):  62%|   | 897/1436 [54:27<29:38,  3.30s/it]\u001b[A\n",
      "Average Metric: 262 / 898  (29.2):  63%|   | 898/1436 [54:27<34:29,  3.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 899  (29.1):  63%|   | 898/1436 [54:31<34:29,  3.85s/it]\u001b[A\n",
      "Average Metric: 262 / 899  (29.1):  63%|   | 899/1436 [54:31<32:25,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 900  (29.1):  63%|   | 899/1436 [54:36<32:25,  3.62s/it]\u001b[A\n",
      "Average Metric: 262 / 900  (29.1):  63%|   | 900/1436 [54:36<36:42,  4.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 901  (29.1):  63%|   | 900/1436 [54:39<36:42,  4.11s/it]\u001b[A\n",
      "Average Metric: 262 / 901  (29.1):  63%|   | 901/1436 [54:39<34:29,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 902  (29.0):  63%|   | 901/1436 [54:42<34:29,  3.87s/it]\u001b[A\n",
      "Average Metric: 262 / 902  (29.0):  63%|   | 902/1436 [54:42<30:50,  3.47s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 262 / 903  (29.0):  63%|   | 902/1436 [54:46<30:50,  3.47s/it]\u001b[A\n",
      "Average Metric: 262 / 903  (29.0):  63%|   | 903/1436 [54:46<33:20,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 904  (29.1):  63%|   | 903/1436 [54:50<33:20,  3.75s/it]\u001b[A\n",
      "Average Metric: 263 / 904  (29.1):  63%|   | 904/1436 [54:50<33:45,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 905  (29.1):  63%|   | 904/1436 [54:55<33:45,  3.81s/it]\u001b[A\n",
      "Average Metric: 263 / 905  (29.1):  63%|   | 905/1436 [54:55<37:30,  4.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 906  (29.0):  63%|   | 905/1436 [55:00<37:30,  4.24s/it]\u001b[A\n",
      "Average Metric: 263 / 906  (29.0):  63%|   | 906/1436 [55:00<38:37,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 263 / 907  (29.0):  63%|   | 906/1436 [55:03<38:37,  4.37s/it]\u001b[A\n",
      "Average Metric: 263 / 907  (29.0):  63%|   | 907/1436 [55:03<35:00,  3.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 264 / 908  (29.1):  63%|   | 907/1436 [55:05<35:00,  3.97s/it]\u001b[A\n",
      "Average Metric: 264 / 908  (29.1):  63%|   | 908/1436 [55:05<30:45,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 264 / 909  (29.0):  63%|   | 908/1436 [55:11<30:45,  3.49s/it]\u001b[A\n",
      "Average Metric: 264 / 909  (29.0):  63%|   | 909/1436 [55:11<35:11,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 265 / 910  (29.1):  63%|   | 909/1436 [55:13<35:11,  4.01s/it]\u001b[A\n",
      "Average Metric: 265 / 910  (29.1):  63%|   | 910/1436 [55:13<32:16,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 911  (29.2):  63%|   | 910/1436 [55:17<32:16,  3.68s/it]\u001b[A\n",
      "Average Metric: 266 / 911  (29.2):  63%|   | 911/1436 [55:17<31:30,  3.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 912  (29.2):  63%|   | 911/1436 [55:22<31:30,  3.60s/it]\u001b[A\n",
      "Average Metric: 266 / 912  (29.2):  64%|   | 912/1436 [55:22<34:52,  3.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 913  (29.1):  64%|   | 912/1436 [55:24<34:52,  3.99s/it]\u001b[A\n",
      "Average Metric: 266 / 913  (29.1):  64%|   | 913/1436 [55:24<31:07,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 914  (29.1):  64%|   | 913/1436 [55:28<31:07,  3.57s/it]\u001b[A\n",
      "Average Metric: 266 / 914  (29.1):  64%|   | 914/1436 [55:28<31:03,  3.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 915  (29.1):  64%|   | 914/1436 [55:32<31:03,  3.57s/it]\u001b[A\n",
      "Average Metric: 266 / 915  (29.1):  64%|   | 915/1436 [55:32<32:17,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 916  (29.0):  64%|   | 915/1436 [55:34<32:17,  3.72s/it]\u001b[A\n",
      "Average Metric: 266 / 916  (29.0):  64%|   | 916/1436 [55:34<28:47,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 917  (29.0):  64%|   | 916/1436 [55:38<28:47,  3.32s/it]\u001b[A\n",
      "Average Metric: 266 / 917  (29.0):  64%|   | 917/1436 [55:38<28:19,  3.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 918  (29.0):  64%|   | 917/1436 [55:40<28:19,  3.27s/it]\u001b[A\n",
      "Average Metric: 266 / 918  (29.0):  64%|   | 918/1436 [55:40<25:19,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 266 / 919  (28.9):  64%|   | 918/1436 [55:42<25:19,  2.93s/it]\u001b[A\n",
      "Average Metric: 266 / 919  (28.9):  64%|   | 919/1436 [55:42<22:36,  2.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 267 / 920  (29.0):  64%|   | 919/1436 [55:45<22:36,  2.62s/it]\u001b[A\n",
      "Average Metric: 267 / 920  (29.0):  64%|   | 920/1436 [55:45<25:21,  2.95s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 268 / 921  (29.1):  64%|   | 920/1436 [55:50<25:21,  2.95s/it]\u001b[A\n",
      "Average Metric: 268 / 921  (29.1):  64%|   | 921/1436 [55:50<29:33,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 268 / 922  (29.1):  64%|   | 921/1436 [55:55<29:33,  3.44s/it]\u001b[A\n",
      "Average Metric: 268 / 922  (29.1):  64%|   | 922/1436 [55:55<32:52,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 268 / 923  (29.0):  64%|   | 922/1436 [55:58<32:52,  3.84s/it]\u001b[A\n",
      "Average Metric: 268 / 923  (29.0):  64%|   | 923/1436 [55:58<30:16,  3.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 268 / 924  (29.0):  64%|   | 923/1436 [56:03<30:16,  3.54s/it]\u001b[A\n",
      "Average Metric: 268 / 924  (29.0):  64%|   | 924/1436 [56:03<34:29,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 268 / 925  (29.0):  64%|   | 924/1436 [56:06<34:29,  4.04s/it]\u001b[A\n",
      "Average Metric: 268 / 925  (29.0):  64%|   | 925/1436 [56:06<31:54,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 268 / 926  (28.9):  64%|   | 925/1436 [56:10<31:54,  3.75s/it]\u001b[A\n",
      "Average Metric: 268 / 926  (28.9):  64%|   | 926/1436 [56:10<32:48,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 269 / 927  (29.0):  64%|   | 926/1436 [56:13<32:48,  3.86s/it]\u001b[A\n",
      "Average Metric: 269 / 927  (29.0):  65%|   | 927/1436 [56:13<30:56,  3.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 269 / 928  (29.0):  65%|   | 927/1436 [56:16<30:56,  3.65s/it]\u001b[A\n",
      "Average Metric: 269 / 928  (29.0):  65%|   | 928/1436 [56:16<28:51,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 270 / 929  (29.1):  65%|   | 928/1436 [56:17<28:51,  3.41s/it]\u001b[A\n",
      "Average Metric: 270 / 929  (29.1):  65%|   | 929/1436 [56:17<23:27,  2.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 270 / 930  (29.0):  65%|   | 929/1436 [56:21<23:27,  2.78s/it]\u001b[A\n",
      "Average Metric: 270 / 930  (29.0):  65%|   | 930/1436 [56:21<26:34,  3.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 270 / 931  (29.0):  65%|   | 930/1436 [56:24<26:34,  3.15s/it]\u001b[A\n",
      "Average Metric: 270 / 931  (29.0):  65%|   | 931/1436 [56:24<24:25,  2.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 270 / 932  (29.0):  65%|   | 931/1436 [56:27<24:25,  2.90s/it]\u001b[A\n",
      "Average Metric: 270 / 932  (29.0):  65%|   | 932/1436 [56:27<25:32,  3.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 933  (29.0):  65%|   | 932/1436 [56:31<25:32,  3.04s/it]\u001b[A\n",
      "Average Metric: 271 / 933  (29.0):  65%|   | 933/1436 [56:31<29:17,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 934  (29.0):  65%|   | 933/1436 [56:36<29:17,  3.49s/it]\u001b[A\n",
      "Average Metric: 271 / 934  (29.0):  65%|   | 934/1436 [56:36<31:31,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 935  (29.0):  65%|   | 934/1436 [56:41<31:31,  3.77s/it]\u001b[A\n",
      "Average Metric: 271 / 935  (29.0):  65%|   | 935/1436 [56:41<35:07,  4.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 936  (29.0):  65%|   | 935/1436 [56:46<35:07,  4.21s/it]\u001b[A\n",
      "Average Metric: 271 / 936  (29.0):  65%|   | 936/1436 [56:46<37:29,  4.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 937  (28.9):  65%|   | 936/1436 [56:52<37:29,  4.50s/it]\u001b[A\n",
      "Average Metric: 271 / 937  (28.9):  65%|   | 937/1436 [56:52<39:15,  4.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 938  (28.9):  65%|   | 937/1436 [56:57<39:15,  4.72s/it]\u001b[A\n",
      "Average Metric: 271 / 938  (28.9):  65%|   | 938/1436 [56:57<40:37,  4.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 939  (28.9):  65%|   | 938/1436 [57:02<40:37,  4.89s/it]\u001b[A\n",
      "Average Metric: 271 / 939  (28.9):  65%|   | 939/1436 [57:02<41:34,  5.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 271 / 940  (28.8):  65%|   | 939/1436 [57:04<41:34,  5.02s/it]\u001b[A\n",
      "Average Metric: 271 / 940  (28.8):  65%|   | 940/1436 [57:04<34:36,  4.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 272 / 941  (28.9):  65%|   | 940/1436 [57:06<34:36,  4.19s/it]\u001b[A\n",
      "Average Metric: 272 / 941  (28.9):  66%|   | 941/1436 [57:06<28:55,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 272 / 942  (28.9):  66%|   | 941/1436 [57:10<28:55,  3.51s/it]\u001b[A\n",
      "Average Metric: 272 / 942  (28.9):  66%|   | 942/1436 [57:10<29:20,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 272 / 943  (28.8):  66%|   | 942/1436 [57:13<29:20,  3.56s/it]\u001b[A\n",
      "Average Metric: 272 / 943  (28.8):  66%|   | 943/1436 [57:13<28:49,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 944  (28.9):  66%|   | 943/1436 [57:18<28:49,  3.51s/it]\u001b[A\n",
      "Average Metric: 273 / 944  (28.9):  66%|   | 944/1436 [57:18<31:12,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 945  (28.9):  66%|   | 944/1436 [57:23<31:12,  3.81s/it]\u001b[A\n",
      "Average Metric: 273 / 945  (28.9):  66%|   | 945/1436 [57:23<34:30,  4.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 946  (28.9):  66%|   | 945/1436 [57:28<34:30,  4.22s/it]\u001b[A\n",
      "Average Metric: 273 / 946  (28.9):  66%|   | 946/1436 [57:28<36:54,  4.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 947  (28.8):  66%|   | 946/1436 [57:32<36:54,  4.52s/it]\u001b[A\n",
      "Average Metric: 273 / 947  (28.8):  66%|   | 947/1436 [57:32<34:51,  4.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 948  (28.8):  66%|   | 947/1436 [57:37<34:51,  4.28s/it]\u001b[A\n",
      "Average Metric: 273 / 948  (28.8):  66%|   | 948/1436 [57:37<36:24,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 273 / 949  (28.8):  66%|   | 948/1436 [57:42<36:24,  4.48s/it]\u001b[A\n",
      "Average Metric: 273 / 949  (28.8):  66%|   | 949/1436 [57:42<38:09,  4.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 274 / 950  (28.8):  66%|   | 949/1436 [57:46<38:09,  4.70s/it]\u001b[A\n",
      "Average Metric: 274 / 950  (28.8):  66%|   | 950/1436 [57:46<36:50,  4.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 274 / 951  (28.8):  66%|   | 950/1436 [57:52<36:50,  4.55s/it]\u001b[A\n",
      "Average Metric: 274 / 951  (28.8):  66%|   | 951/1436 [57:52<38:21,  4.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 274 / 952  (28.8):  66%|   | 951/1436 [57:57<38:21,  4.75s/it]\u001b[A\n",
      "Average Metric: 274 / 952  (28.8):  66%|   | 952/1436 [57:57<39:24,  4.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 275 / 953  (28.9):  66%|   | 952/1436 [58:01<39:24,  4.89s/it]\u001b[A\n",
      "Average Metric: 275 / 953  (28.9):  66%|   | 953/1436 [58:01<38:29,  4.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 275 / 954  (28.8):  66%|   | 953/1436 [58:05<38:29,  4.78s/it]\u001b[A\n",
      "Average Metric: 275 / 954  (28.8):  66%|   | 954/1436 [58:05<35:03,  4.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 275 / 955  (28.8):  66%|   | 954/1436 [58:07<35:03,  4.36s/it]\u001b[A\n",
      "Average Metric: 275 / 955  (28.8):  67%|   | 955/1436 [58:07<29:37,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 275 / 956  (28.8):  67%|   | 955/1436 [58:09<29:37,  3.70s/it]\u001b[A\n",
      "Average Metric: 275 / 956  (28.8):  67%|   | 956/1436 [58:09<25:26,  3.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 275 / 957  (28.7):  67%|   | 956/1436 [58:12<25:26,  3.18s/it]\u001b[A\n",
      "Average Metric: 275 / 957  (28.7):  67%|   | 957/1436 [58:12<24:54,  3.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 276 / 958  (28.8):  67%|   | 957/1436 [58:15<24:54,  3.12s/it]\u001b[A\n",
      "Average Metric: 276 / 958  (28.8):  67%|   | 958/1436 [58:15<25:17,  3.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 276 / 959  (28.8):  67%|   | 958/1436 [58:20<25:17,  3.17s/it]\u001b[A\n",
      "Average Metric: 276 / 959  (28.8):  67%|   | 959/1436 [58:20<28:11,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 277 / 960  (28.9):  67%|   | 959/1436 [58:22<28:11,  3.55s/it]\u001b[A\n",
      "Average Metric: 277 / 960  (28.9):  67%|   | 960/1436 [58:22<25:32,  3.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 278 / 961  (28.9):  67%|   | 960/1436 [58:23<25:32,  3.22s/it]\u001b[A\n",
      "Average Metric: 278 / 961  (28.9):  67%|   | 961/1436 [58:23<21:22,  2.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 278 / 962  (28.9):  67%|   | 961/1436 [58:26<21:22,  2.70s/it]\u001b[A\n",
      "Average Metric: 278 / 962  (28.9):  67%|   | 962/1436 [58:26<21:21,  2.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 279 / 963  (29.0):  67%|   | 962/1436 [58:29<21:21,  2.70s/it]\u001b[A\n",
      "Average Metric: 279 / 963  (29.0):  67%|   | 963/1436 [58:29<20:57,  2.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 280 / 964  (29.0):  67%|   | 963/1436 [58:30<20:57,  2.66s/it]\u001b[A\n",
      "Average Metric: 280 / 964  (29.0):  67%|   | 964/1436 [58:30<18:38,  2.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 280 / 965  (29.0):  67%|   | 964/1436 [58:34<18:38,  2.37s/it]\u001b[A\n",
      "Average Metric: 280 / 965  (29.0):  67%|   | 965/1436 [58:34<22:07,  2.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 280 / 966  (29.0):  67%|   | 965/1436 [58:37<22:07,  2.82s/it]\u001b[A\n",
      "Average Metric: 280 / 966  (29.0):  67%|   | 966/1436 [58:37<20:59,  2.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 281 / 967  (29.1):  67%|   | 966/1436 [58:38<20:59,  2.68s/it]\u001b[A\n",
      "Average Metric: 281 / 967  (29.1):  67%|   | 967/1436 [58:38<17:48,  2.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 281 / 968  (29.0):  67%|   | 967/1436 [58:43<17:48,  2.28s/it]\u001b[A\n",
      "Average Metric: 281 / 968  (29.0):  67%|   | 968/1436 [58:43<24:26,  3.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 281 / 969  (29.0):  67%|   | 968/1436 [58:48<24:26,  3.13s/it]\u001b[A\n",
      "Average Metric: 281 / 969  (29.0):  67%|   | 969/1436 [58:48<29:03,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 281 / 970  (29.0):  67%|   | 969/1436 [58:52<29:03,  3.73s/it]\u001b[A\n",
      "Average Metric: 281 / 970  (29.0):  68%|   | 970/1436 [58:52<28:57,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 281 / 971  (28.9):  68%|   | 970/1436 [58:57<28:57,  3.73s/it]\u001b[A\n",
      "Average Metric: 281 / 971  (28.9):  68%|   | 971/1436 [58:57<31:02,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 282 / 972  (29.0):  68%|   | 971/1436 [59:01<31:02,  4.00s/it]\u001b[A\n",
      "Average Metric: 282 / 972  (29.0):  68%|   | 972/1436 [59:01<32:43,  4.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 282 / 973  (29.0):  68%|   | 972/1436 [59:05<32:43,  4.23s/it]\u001b[A\n",
      "Average Metric: 282 / 973  (29.0):  68%|   | 973/1436 [59:05<31:35,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 282 / 974  (29.0):  68%|   | 973/1436 [59:10<31:35,  4.09s/it]\u001b[A\n",
      "Average Metric: 282 / 974  (29.0):  68%|   | 974/1436 [59:10<32:14,  4.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 282 / 975  (28.9):  68%|   | 974/1436 [59:15<32:14,  4.19s/it]\u001b[A\n",
      "Average Metric: 282 / 975  (28.9):  68%|   | 975/1436 [59:15<34:37,  4.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 282 / 976  (28.9):  68%|   | 975/1436 [59:20<34:37,  4.51s/it]\u001b[A\n",
      "Average Metric: 282 / 976  (28.9):  68%|   | 976/1436 [59:20<36:12,  4.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 283 / 977  (29.0):  68%|   | 976/1436 [59:22<36:12,  4.72s/it]\u001b[A\n",
      "Average Metric: 283 / 977  (29.0):  68%|   | 977/1436 [59:22<28:48,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 283 / 978  (28.9):  68%|   | 977/1436 [59:24<28:48,  3.77s/it]\u001b[A\n",
      "Average Metric: 283 / 978  (28.9):  68%|   | 978/1436 [59:24<25:03,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 283 / 979  (28.9):  68%|   | 978/1436 [59:27<25:03,  3.28s/it]\u001b[A\n",
      "Average Metric: 283 / 979  (28.9):  68%|   | 979/1436 [59:27<25:13,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 284 / 980  (29.0):  68%|   | 979/1436 [59:32<25:13,  3.31s/it]\u001b[A\n",
      "Average Metric: 284 / 980  (29.0):  68%|   | 980/1436 [59:32<29:23,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 285 / 981  (29.1):  68%|   | 980/1436 [59:37<29:23,  3.87s/it]\u001b[A\n",
      "Average Metric: 285 / 981  (29.1):  68%|   | 981/1436 [59:37<30:58,  4.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 285 / 982  (29.0):  68%|   | 981/1436 [59:42<30:58,  4.08s/it]\u001b[A\n",
      "Average Metric: 285 / 982  (29.0):  68%|   | 982/1436 [59:42<33:41,  4.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 286 / 983  (29.1):  68%|   | 982/1436 [59:45<33:41,  4.45s/it]\u001b[A\n",
      "Average Metric: 286 / 983  (29.1):  68%|   | 983/1436 [59:45<29:46,  3.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 286 / 984  (29.1):  68%|   | 983/1436 [59:47<29:46,  3.94s/it]\u001b[A\n",
      "Average Metric: 286 / 984  (29.1):  69%|   | 984/1436 [59:47<24:44,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 286 / 985  (29.0):  69%|   | 984/1436 [59:51<24:44,  3.28s/it]\u001b[A\n",
      "Average Metric: 286 / 985  (29.0):  69%|   | 985/1436 [59:51<26:59,  3.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 287 / 986  (29.1):  69%|   | 985/1436 [59:53<26:59,  3.59s/it]\u001b[A\n",
      "Average Metric: 287 / 986  (29.1):  69%|   | 986/1436 [59:53<23:48,  3.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 288 / 987  (29.2):  69%|   | 986/1436 [59:56<23:48,  3.17s/it]\u001b[A\n",
      "Average Metric: 288 / 987  (29.2):  69%|   | 987/1436 [59:56<22:16,  2.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 288 / 988  (29.1):  69%|   | 987/1436 [59:58<22:16,  2.98s/it]\u001b[A\n",
      "Average Metric: 288 / 988  (29.1):  69%|   | 988/1436 [59:58<19:41,  2.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 289 / 989  (29.2):  69%|   | 988/1436 [59:59<19:41,  2.64s/it]\u001b[A\n",
      "Average Metric: 289 / 989  (29.2):  69%|   | 989/1436 [59:59<16:42,  2.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 290 / 990  (29.3):  69%|   | 989/1436 [1:00:01<16:42,  2.24s/it]\u001b[A\n",
      "Average Metric: 290 / 990  (29.3):  69%|   | 990/1436 [1:00:01<15:22,  2.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 290 / 991  (29.3):  69%|   | 990/1436 [1:00:03<15:22,  2.07s/it]\u001b[A\n",
      "Average Metric: 290 / 991  (29.3):  69%|   | 991/1436 [1:00:03<16:42,  2.25s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 291 / 992  (29.3):  69%|   | 991/1436 [1:00:05<16:42,  2.25s/it]\u001b[A\n",
      "Average Metric: 291 / 992  (29.3):  69%|   | 992/1436 [1:00:05<15:24,  2.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 291 / 993  (29.3):  69%|   | 992/1436 [1:00:08<15:24,  2.08s/it]\u001b[A\n",
      "Average Metric: 291 / 993  (29.3):  69%|   | 993/1436 [1:00:08<16:49,  2.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 292 / 994  (29.4):  69%|   | 993/1436 [1:00:09<16:49,  2.28s/it]\u001b[A\n",
      "Average Metric: 292 / 994  (29.4):  69%|   | 994/1436 [1:00:09<15:38,  2.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 292 / 995  (29.3):  69%|   | 994/1436 [1:00:13<15:38,  2.12s/it]\u001b[A\n",
      "Average Metric: 292 / 995  (29.3):  69%|   | 995/1436 [1:00:13<18:06,  2.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 293 / 996  (29.4):  69%|   | 995/1436 [1:00:16<18:06,  2.46s/it]\u001b[A\n",
      "Average Metric: 293 / 996  (29.4):  69%|   | 996/1436 [1:00:16<19:11,  2.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 293 / 997  (29.4):  69%|   | 996/1436 [1:00:18<19:11,  2.62s/it]\u001b[A\n",
      "Average Metric: 293 / 997  (29.4):  69%|   | 997/1436 [1:00:18<19:05,  2.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 294 / 998  (29.5):  69%|   | 997/1436 [1:00:19<19:05,  2.61s/it]\u001b[A\n",
      "Average Metric: 294 / 998  (29.5):  69%|   | 998/1436 [1:00:19<15:45,  2.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 295 / 999  (29.5):  69%|   | 998/1436 [1:00:20<15:45,  2.16s/it]\u001b[A\n",
      "Average Metric: 295 / 999  (29.5):  70%|   | 999/1436 [1:00:20<13:21,  1.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 1000  (29.6):  70%|   | 999/1436 [1:00:24<13:21,  1.83s/it]\u001b[A\n",
      "Average Metric: 296 / 1000  (29.6):  70%|   | 1000/1436 [1:00:24<16:10,  2.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 1001  (29.6):  70%|   | 1000/1436 [1:00:27<16:10,  2.23s/it]\u001b[A\n",
      "Average Metric: 296 / 1001  (29.6):  70%|   | 1001/1436 [1:00:27<18:39,  2.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 1002  (29.5):  70%|   | 1001/1436 [1:00:30<18:39,  2.57s/it]\u001b[A\n",
      "Average Metric: 296 / 1002  (29.5):  70%|   | 1002/1436 [1:00:30<18:46,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 1003  (29.5):  70%|   | 1002/1436 [1:00:35<18:46,  2.60s/it]\u001b[A\n",
      "Average Metric: 296 / 1003  (29.5):  70%|   | 1003/1436 [1:00:35<24:46,  3.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 296 / 1004  (29.5):  70%|   | 1003/1436 [1:00:38<24:46,  3.43s/it]\u001b[A\n",
      "Average Metric: 296 / 1004  (29.5):  70%|   | 1004/1436 [1:00:38<24:49,  3.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 297 / 1005  (29.6):  70%|   | 1004/1436 [1:00:43<24:49,  3.45s/it]\u001b[A\n",
      "Average Metric: 297 / 1005  (29.6):  70%|   | 1005/1436 [1:00:43<26:21,  3.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 297 / 1006  (29.5):  70%|   | 1005/1436 [1:00:48<26:21,  3.67s/it]\u001b[A\n",
      "Average Metric: 297 / 1006  (29.5):  70%|   | 1006/1436 [1:00:48<30:04,  4.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 297 / 1007  (29.5):  70%|   | 1006/1436 [1:00:52<30:04,  4.20s/it]\u001b[A\n",
      "Average Metric: 297 / 1007  (29.5):  70%|   | 1007/1436 [1:00:52<29:05,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 297 / 1008  (29.5):  70%|   | 1007/1436 [1:00:57<29:05,  4.07s/it]\u001b[A\n",
      "Average Metric: 297 / 1008  (29.5):  70%|   | 1008/1436 [1:00:57<31:34,  4.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 297 / 1009  (29.4):  70%|   | 1008/1436 [1:01:02<31:34,  4.43s/it]\u001b[A\n",
      "Average Metric: 297 / 1009  (29.4):  70%|   | 1009/1436 [1:01:02<33:13,  4.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 298 / 1010  (29.5):  70%|   | 1009/1436 [1:01:07<33:13,  4.67s/it]\u001b[A\n",
      "Average Metric: 298 / 1010  (29.5):  70%|   | 1010/1436 [1:01:07<33:03,  4.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1011  (29.6):  70%|   | 1010/1436 [1:01:08<33:03,  4.66s/it]\u001b[A\n",
      "Average Metric: 299 / 1011  (29.6):  70%|   | 1011/1436 [1:01:08<26:15,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1012  (29.5):  70%|   | 1011/1436 [1:01:13<26:15,  3.71s/it]\u001b[A\n",
      "Average Metric: 299 / 1012  (29.5):  70%|   | 1012/1436 [1:01:13<29:05,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1013  (29.5):  70%|   | 1012/1436 [1:01:16<29:05,  4.12s/it]\u001b[A\n",
      "Average Metric: 299 / 1013  (29.5):  71%|   | 1013/1436 [1:01:16<24:58,  3.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1014  (29.5):  71%|   | 1013/1436 [1:01:21<24:58,  3.54s/it]\u001b[A\n",
      "Average Metric: 299 / 1014  (29.5):  71%|   | 1014/1436 [1:01:21<28:08,  4.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1015  (29.5):  71%|   | 1014/1436 [1:01:23<28:08,  4.00s/it]\u001b[A\n",
      "Average Metric: 299 / 1015  (29.5):  71%|   | 1015/1436 [1:01:23<24:57,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1016  (29.4):  71%|   | 1015/1436 [1:01:25<24:57,  3.56s/it]\u001b[A\n",
      "Average Metric: 299 / 1016  (29.4):  71%|   | 1016/1436 [1:01:25<20:59,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1017  (29.4):  71%|   | 1016/1436 [1:01:29<20:59,  3.00s/it]\u001b[A\n",
      "Average Metric: 299 / 1017  (29.4):  71%|   | 1017/1436 [1:01:29<22:17,  3.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1018  (29.4):  71%|   | 1017/1436 [1:01:32<22:17,  3.19s/it]\u001b[A\n",
      "Average Metric: 299 / 1018  (29.4):  71%|   | 1018/1436 [1:01:32<22:03,  3.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1019  (29.3):  71%|   | 1018/1436 [1:01:34<22:03,  3.17s/it]\u001b[A\n",
      "Average Metric: 299 / 1019  (29.3):  71%|   | 1019/1436 [1:01:34<19:25,  2.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 299 / 1020  (29.3):  71%|   | 1019/1436 [1:01:36<19:25,  2.80s/it]\u001b[A\n",
      "Average Metric: 299 / 1020  (29.3):  71%|   | 1020/1436 [1:01:36<17:33,  2.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 300 / 1021  (29.4):  71%|   | 1020/1436 [1:01:37<17:33,  2.53s/it]\u001b[A\n",
      "Average Metric: 300 / 1021  (29.4):  71%|   | 1021/1436 [1:01:37<15:09,  2.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 301 / 1022  (29.5):  71%|   | 1021/1436 [1:01:42<15:09,  2.19s/it]\u001b[A\n",
      "Average Metric: 301 / 1022  (29.5):  71%|   | 1022/1436 [1:01:42<20:45,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 302 / 1023  (29.5):  71%|   | 1022/1436 [1:01:44<20:45,  3.01s/it]\u001b[A\n",
      "Average Metric: 302 / 1023  (29.5):  71%|   | 1023/1436 [1:01:44<19:02,  2.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 302 / 1024  (29.5):  71%|   | 1023/1436 [1:01:47<19:02,  2.77s/it]\u001b[A\n",
      "Average Metric: 302 / 1024  (29.5):  71%|  | 1024/1436 [1:01:47<18:34,  2.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 303 / 1025  (29.6):  71%|  | 1024/1436 [1:01:50<18:34,  2.71s/it]\u001b[A\n",
      "Average Metric: 303 / 1025  (29.6):  71%|  | 1025/1436 [1:01:50<20:05,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 303 / 1026  (29.5):  71%|  | 1025/1436 [1:01:55<20:05,  2.93s/it]\u001b[A\n",
      "Average Metric: 303 / 1026  (29.5):  71%|  | 1026/1436 [1:01:55<24:21,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 304 / 1027  (29.6):  71%|  | 1026/1436 [1:01:59<24:21,  3.56s/it]\u001b[A\n",
      "Average Metric: 304 / 1027  (29.6):  72%|  | 1027/1436 [1:01:59<24:50,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 305 / 1028  (29.7):  72%|  | 1027/1436 [1:02:03<24:50,  3.64s/it]\u001b[A\n",
      "Average Metric: 305 / 1028  (29.7):  72%|  | 1028/1436 [1:02:03<25:12,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 306 / 1029  (29.7):  72%|  | 1028/1436 [1:02:07<25:12,  3.71s/it]\u001b[A\n",
      "Average Metric: 306 / 1029  (29.7):  72%|  | 1029/1436 [1:02:07<25:49,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 307 / 1030  (29.8):  72%|  | 1029/1436 [1:02:09<25:49,  3.81s/it]\u001b[A\n",
      "Average Metric: 307 / 1030  (29.8):  72%|  | 1030/1436 [1:02:09<22:12,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 307 / 1031  (29.8):  72%|  | 1030/1436 [1:02:12<22:12,  3.28s/it]\u001b[A\n",
      "Average Metric: 307 / 1031  (29.8):  72%|  | 1031/1436 [1:02:12<22:23,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 307 / 1032  (29.7):  72%|  | 1031/1436 [1:02:16<22:23,  3.32s/it]\u001b[A\n",
      "Average Metric: 307 / 1032  (29.7):  72%|  | 1032/1436 [1:02:16<22:06,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 307 / 1033  (29.7):  72%|  | 1032/1436 [1:02:21<22:06,  3.28s/it]\u001b[A\n",
      "Average Metric: 307 / 1033  (29.7):  72%|  | 1033/1436 [1:02:21<25:48,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 307 / 1034  (29.7):  72%|  | 1033/1436 [1:02:26<25:48,  3.84s/it]\u001b[A\n",
      "Average Metric: 307 / 1034  (29.7):  72%|  | 1034/1436 [1:02:26<28:06,  4.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 307 / 1035  (29.7):  72%|  | 1034/1436 [1:02:30<28:06,  4.20s/it]\u001b[A\n",
      "Average Metric: 307 / 1035  (29.7):  72%|  | 1035/1436 [1:02:30<27:39,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 308 / 1036  (29.7):  72%|  | 1035/1436 [1:02:33<27:39,  4.14s/it]\u001b[A\n",
      "Average Metric: 308 / 1036  (29.7):  72%|  | 1036/1436 [1:02:33<25:37,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 308 / 1037  (29.7):  72%|  | 1036/1436 [1:02:38<25:37,  3.84s/it]\u001b[A\n",
      "Average Metric: 308 / 1037  (29.7):  72%|  | 1037/1436 [1:02:38<28:18,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 308 / 1038  (29.7):  72%|  | 1037/1436 [1:02:43<28:18,  4.26s/it]\u001b[A\n",
      "Average Metric: 308 / 1038  (29.7):  72%|  | 1038/1436 [1:02:43<30:12,  4.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 308 / 1039  (29.6):  72%|  | 1038/1436 [1:02:49<30:12,  4.55s/it]\u001b[A\n",
      "Average Metric: 308 / 1039  (29.6):  72%|  | 1039/1436 [1:02:49<31:30,  4.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 308 / 1040  (29.6):  72%|  | 1039/1436 [1:02:54<31:30,  4.76s/it]\u001b[A\n",
      "Average Metric: 308 / 1040  (29.6):  72%|  | 1040/1436 [1:02:54<32:22,  4.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 309 / 1041  (29.7):  72%|  | 1040/1436 [1:02:57<32:22,  4.90s/it]\u001b[A\n",
      "Average Metric: 309 / 1041  (29.7):  72%|  | 1041/1436 [1:02:57<29:30,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 309 / 1042  (29.7):  72%|  | 1041/1436 [1:03:03<29:30,  4.48s/it]\u001b[A\n",
      "Average Metric: 309 / 1042  (29.7):  73%|  | 1042/1436 [1:03:03<30:56,  4.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 309 / 1043  (29.6):  73%|  | 1042/1436 [1:03:07<30:56,  4.71s/it]\u001b[A\n",
      "Average Metric: 309 / 1043  (29.6):  73%|  | 1043/1436 [1:03:07<29:26,  4.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 310 / 1044  (29.7):  73%|  | 1043/1436 [1:03:09<29:26,  4.50s/it]\u001b[A\n",
      "Average Metric: 310 / 1044  (29.7):  73%|  | 1044/1436 [1:03:09<25:36,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 311 / 1045  (29.8):  73%|  | 1044/1436 [1:03:13<25:36,  3.92s/it]\u001b[A\n",
      "Average Metric: 311 / 1045  (29.8):  73%|  | 1045/1436 [1:03:13<25:27,  3.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 1046  (29.8):  73%|  | 1045/1436 [1:03:15<25:27,  3.91s/it]\u001b[A\n",
      "Average Metric: 312 / 1046  (29.8):  73%|  | 1046/1436 [1:03:15<22:08,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 1047  (29.8):  73%|  | 1046/1436 [1:03:20<22:08,  3.41s/it]\u001b[A\n",
      "Average Metric: 312 / 1047  (29.8):  73%|  | 1047/1436 [1:03:20<25:29,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 1048  (29.8):  73%|  | 1047/1436 [1:03:26<25:29,  3.93s/it]\u001b[A\n",
      "Average Metric: 312 / 1048  (29.8):  73%|  | 1048/1436 [1:03:26<27:46,  4.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 1049  (29.7):  73%|  | 1048/1436 [1:03:31<27:46,  4.29s/it]\u001b[A\n",
      "Average Metric: 312 / 1049  (29.7):  73%|  | 1049/1436 [1:03:31<29:19,  4.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 1050  (29.7):  73%|  | 1049/1436 [1:03:36<29:19,  4.55s/it]\u001b[A\n",
      "Average Metric: 312 / 1050  (29.7):  73%|  | 1050/1436 [1:03:36<30:24,  4.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 1051  (29.7):  73%|  | 1050/1436 [1:03:41<30:24,  4.73s/it]\u001b[A\n",
      "Average Metric: 312 / 1051  (29.7):  73%|  | 1051/1436 [1:03:41<31:09,  4.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 312 / 1052  (29.7):  73%|  | 1051/1436 [1:03:46<31:09,  4.86s/it]\u001b[A\n",
      "Average Metric: 312 / 1052  (29.7):  73%|  | 1052/1436 [1:03:46<31:37,  4.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 313 / 1053  (29.7):  73%|  | 1052/1436 [1:03:50<31:37,  4.94s/it]\u001b[A\n",
      "Average Metric: 313 / 1053  (29.7):  73%|  | 1053/1436 [1:03:50<28:50,  4.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 314 / 1054  (29.8):  73%|  | 1053/1436 [1:03:52<28:50,  4.52s/it]\u001b[A\n",
      "Average Metric: 314 / 1054  (29.8):  73%|  | 1054/1436 [1:03:52<24:01,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 315 / 1055  (29.9):  73%|  | 1054/1436 [1:03:56<24:01,  3.77s/it]\u001b[A\n",
      "Average Metric: 315 / 1055  (29.9):  73%|  | 1055/1436 [1:03:56<24:43,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1056  (29.9):  73%|  | 1055/1436 [1:03:58<24:43,  3.89s/it]\u001b[A\n",
      "Average Metric: 316 / 1056  (29.9):  74%|  | 1056/1436 [1:03:58<22:00,  3.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1057  (29.9):  74%|  | 1056/1436 [1:04:01<22:00,  3.48s/it]\u001b[A\n",
      "Average Metric: 316 / 1057  (29.9):  74%|  | 1057/1436 [1:04:01<20:57,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1058  (29.9):  74%|  | 1057/1436 [1:04:03<20:57,  3.32s/it]\u001b[A\n",
      "Average Metric: 316 / 1058  (29.9):  74%|  | 1058/1436 [1:04:03<17:35,  2.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1059  (29.8):  74%|  | 1058/1436 [1:04:08<17:35,  2.79s/it]\u001b[A\n",
      "Average Metric: 316 / 1059  (29.8):  74%|  | 1059/1436 [1:04:08<22:06,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1060  (29.8):  74%|  | 1059/1436 [1:04:11<22:06,  3.52s/it]\u001b[A\n",
      "Average Metric: 316 / 1060  (29.8):  74%|  | 1060/1436 [1:04:11<20:55,  3.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1061  (29.8):  74%|  | 1060/1436 [1:04:15<20:55,  3.34s/it]\u001b[A\n",
      "Average Metric: 316 / 1061  (29.8):  74%|  | 1061/1436 [1:04:15<21:44,  3.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1062  (29.8):  74%|  | 1061/1436 [1:04:20<21:44,  3.48s/it]\u001b[A\n",
      "Average Metric: 316 / 1062  (29.8):  74%|  | 1062/1436 [1:04:20<24:58,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1063  (29.7):  74%|  | 1062/1436 [1:04:23<24:58,  4.01s/it]\u001b[A\n",
      "Average Metric: 316 / 1063  (29.7):  74%|  | 1063/1436 [1:04:23<23:25,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1064  (29.7):  74%|  | 1063/1436 [1:04:29<23:25,  3.77s/it]\u001b[A\n",
      "Average Metric: 316 / 1064  (29.7):  74%|  | 1064/1436 [1:04:29<26:16,  4.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 316 / 1065  (29.7):  74%|  | 1064/1436 [1:04:34<26:16,  4.24s/it]\u001b[A\n",
      "Average Metric: 316 / 1065  (29.7):  74%|  | 1065/1436 [1:04:34<28:14,  4.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 317 / 1066  (29.7):  74%|  | 1065/1436 [1:04:36<28:14,  4.57s/it]\u001b[A\n",
      "Average Metric: 317 / 1066  (29.7):  74%|  | 1066/1436 [1:04:36<23:49,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 318 / 1067  (29.8):  74%|  | 1066/1436 [1:04:37<23:49,  3.86s/it]\u001b[A\n",
      "Average Metric: 318 / 1067  (29.8):  74%|  | 1067/1436 [1:04:37<19:01,  3.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 318 / 1068  (29.8):  74%|  | 1067/1436 [1:04:41<19:01,  3.09s/it]\u001b[A\n",
      "Average Metric: 318 / 1068  (29.8):  74%|  | 1068/1436 [1:04:41<20:28,  3.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 318 / 1069  (29.7):  74%|  | 1068/1436 [1:04:43<20:28,  3.34s/it]\u001b[A\n",
      "Average Metric: 318 / 1069  (29.7):  74%|  | 1069/1436 [1:04:43<17:12,  2.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 318 / 1070  (29.7):  74%|  | 1069/1436 [1:04:45<17:12,  2.81s/it]\u001b[A\n",
      "Average Metric: 318 / 1070  (29.7):  75%|  | 1070/1436 [1:04:45<16:30,  2.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 318 / 1071  (29.7):  75%|  | 1070/1436 [1:04:47<16:30,  2.71s/it]\u001b[A\n",
      "Average Metric: 318 / 1071  (29.7):  75%|  | 1071/1436 [1:04:47<14:53,  2.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 319 / 1072  (29.8):  75%|  | 1071/1436 [1:04:49<14:53,  2.45s/it]\u001b[A\n",
      "Average Metric: 319 / 1072  (29.8):  75%|  | 1072/1436 [1:04:49<14:13,  2.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 1073  (29.8):  75%|  | 1072/1436 [1:04:52<14:13,  2.34s/it]\u001b[A\n",
      "Average Metric: 320 / 1073  (29.8):  75%|  | 1073/1436 [1:04:52<14:58,  2.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 1074  (29.8):  75%|  | 1073/1436 [1:04:57<14:58,  2.48s/it]\u001b[A\n",
      "Average Metric: 320 / 1074  (29.8):  75%|  | 1074/1436 [1:04:57<19:47,  3.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 1075  (29.8):  75%|  | 1074/1436 [1:04:59<19:47,  3.28s/it]\u001b[A\n",
      "Average Metric: 320 / 1075  (29.8):  75%|  | 1075/1436 [1:04:59<17:46,  2.95s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 1076  (29.7):  75%|  | 1075/1436 [1:05:02<17:46,  2.95s/it]\u001b[A\n",
      "Average Metric: 320 / 1076  (29.7):  75%|  | 1076/1436 [1:05:02<17:33,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 1077  (29.7):  75%|  | 1076/1436 [1:05:06<17:33,  2.93s/it]\u001b[A\n",
      "Average Metric: 320 / 1077  (29.7):  75%|  | 1077/1436 [1:05:06<18:16,  3.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 1078  (29.7):  75%|  | 1077/1436 [1:05:09<18:16,  3.05s/it]\u001b[A\n",
      "Average Metric: 320 / 1078  (29.7):  75%|  | 1078/1436 [1:05:09<19:26,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 320 / 1079  (29.7):  75%|  | 1078/1436 [1:05:13<19:26,  3.26s/it]\u001b[A\n",
      "Average Metric: 320 / 1079  (29.7):  75%|  | 1079/1436 [1:05:13<20:30,  3.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 321 / 1080  (29.7):  75%|  | 1079/1436 [1:05:17<20:30,  3.45s/it]\u001b[A\n",
      "Average Metric: 321 / 1080  (29.7):  75%|  | 1080/1436 [1:05:17<20:08,  3.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 322 / 1081  (29.8):  75%|  | 1080/1436 [1:05:18<20:08,  3.39s/it]\u001b[A\n",
      "Average Metric: 322 / 1081  (29.8):  75%|  | 1081/1436 [1:05:18<16:53,  2.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 322 / 1082  (29.8):  75%|  | 1081/1436 [1:05:20<16:53,  2.85s/it]\u001b[A\n",
      "Average Metric: 322 / 1082  (29.8):  75%|  | 1082/1436 [1:05:20<15:44,  2.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 322 / 1083  (29.7):  75%|  | 1082/1436 [1:05:23<15:44,  2.67s/it]\u001b[A\n",
      "Average Metric: 322 / 1083  (29.7):  75%|  | 1083/1436 [1:05:23<15:16,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 322 / 1084  (29.7):  75%|  | 1083/1436 [1:05:26<15:16,  2.60s/it]\u001b[A\n",
      "Average Metric: 322 / 1084  (29.7):  75%|  | 1084/1436 [1:05:26<16:12,  2.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 323 / 1085  (29.8):  75%|  | 1084/1436 [1:05:28<16:12,  2.76s/it]\u001b[A\n",
      "Average Metric: 323 / 1085  (29.8):  76%|  | 1085/1436 [1:05:28<15:19,  2.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 323 / 1086  (29.7):  76%|  | 1085/1436 [1:05:33<15:19,  2.62s/it]\u001b[A\n",
      "Average Metric: 323 / 1086  (29.7):  76%|  | 1086/1436 [1:05:33<18:26,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 324 / 1087  (29.8):  76%|  | 1086/1436 [1:05:35<18:26,  3.16s/it]\u001b[A\n",
      "Average Metric: 324 / 1087  (29.8):  76%|  | 1087/1436 [1:05:35<16:32,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 324 / 1088  (29.8):  76%|  | 1087/1436 [1:05:39<16:32,  2.84s/it]\u001b[A\n",
      "Average Metric: 324 / 1088  (29.8):  76%|  | 1088/1436 [1:05:39<18:48,  3.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 324 / 1089  (29.8):  76%|  | 1088/1436 [1:05:43<18:48,  3.24s/it]\u001b[A\n",
      "Average Metric: 324 / 1089  (29.8):  76%|  | 1089/1436 [1:05:43<20:22,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 325 / 1090  (29.8):  76%|  | 1089/1436 [1:05:45<20:22,  3.52s/it]\u001b[A\n",
      "Average Metric: 325 / 1090  (29.8):  76%|  | 1090/1436 [1:05:45<17:59,  3.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 325 / 1091  (29.8):  76%|  | 1090/1436 [1:05:49<17:59,  3.12s/it]\u001b[A\n",
      "Average Metric: 325 / 1091  (29.8):  76%|  | 1091/1436 [1:05:49<18:08,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1092  (29.9):  76%|  | 1091/1436 [1:05:51<18:08,  3.16s/it]\u001b[A\n",
      "Average Metric: 326 / 1092  (29.9):  76%|  | 1092/1436 [1:05:51<16:25,  2.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1093  (29.8):  76%|  | 1092/1436 [1:05:56<16:25,  2.86s/it]\u001b[A\n",
      "Average Metric: 326 / 1093  (29.8):  76%|  | 1093/1436 [1:05:56<19:42,  3.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1094  (29.8):  76%|  | 1093/1436 [1:06:00<19:42,  3.45s/it]\u001b[A\n",
      "Average Metric: 326 / 1094  (29.8):  76%|  | 1094/1436 [1:06:00<21:58,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1095  (29.8):  76%|  | 1094/1436 [1:06:04<21:58,  3.86s/it]\u001b[A\n",
      "Average Metric: 326 / 1095  (29.8):  76%|  | 1095/1436 [1:06:04<21:44,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1096  (29.7):  76%|  | 1095/1436 [1:06:05<21:44,  3.83s/it]\u001b[A\n",
      "Average Metric: 326 / 1096  (29.7):  76%|  | 1096/1436 [1:06:05<17:24,  3.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1097  (29.7):  76%|  | 1096/1436 [1:06:11<17:24,  3.07s/it]\u001b[A\n",
      "Average Metric: 326 / 1097  (29.7):  76%|  | 1097/1436 [1:06:11<21:04,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1098  (29.7):  76%|  | 1097/1436 [1:06:16<21:04,  3.73s/it]\u001b[A\n",
      "Average Metric: 326 / 1098  (29.7):  76%|  | 1098/1436 [1:06:16<23:36,  4.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1099  (29.7):  76%|  | 1098/1436 [1:06:20<23:36,  4.19s/it]\u001b[A\n",
      "Average Metric: 326 / 1099  (29.7):  77%|  | 1099/1436 [1:06:20<23:27,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1100  (29.6):  77%|  | 1099/1436 [1:06:25<23:27,  4.18s/it]\u001b[A\n",
      "Average Metric: 326 / 1100  (29.6):  77%|  | 1100/1436 [1:06:25<24:17,  4.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1101  (29.6):  77%|  | 1100/1436 [1:06:29<24:17,  4.34s/it]\u001b[A\n",
      "Average Metric: 326 / 1101  (29.6):  77%|  | 1101/1436 [1:06:29<23:22,  4.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 326 / 1102  (29.6):  77%|  | 1101/1436 [1:06:31<23:22,  4.19s/it]\u001b[A\n",
      "Average Metric: 326 / 1102  (29.6):  77%|  | 1102/1436 [1:06:31<20:00,  3.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 327 / 1103  (29.6):  77%|  | 1102/1436 [1:06:32<20:00,  3.59s/it]\u001b[A\n",
      "Average Metric: 327 / 1103  (29.6):  77%|  | 1103/1436 [1:06:32<16:01,  2.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 328 / 1104  (29.7):  77%|  | 1103/1436 [1:06:34<16:01,  2.89s/it]\u001b[A\n",
      "Average Metric: 328 / 1104  (29.7):  77%|  | 1104/1436 [1:06:34<13:57,  2.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 329 / 1105  (29.8):  77%|  | 1104/1436 [1:06:36<13:57,  2.52s/it]\u001b[A\n",
      "Average Metric: 329 / 1105  (29.8):  77%|  | 1105/1436 [1:06:36<12:36,  2.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 329 / 1106  (29.7):  77%|  | 1105/1436 [1:06:37<12:36,  2.29s/it]\u001b[A\n",
      "Average Metric: 329 / 1106  (29.7):  77%|  | 1106/1436 [1:06:37<11:59,  2.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 329 / 1107  (29.7):  77%|  | 1106/1436 [1:06:41<11:59,  2.18s/it]\u001b[A\n",
      "Average Metric: 329 / 1107  (29.7):  77%|  | 1107/1436 [1:06:41<13:26,  2.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 329 / 1108  (29.7):  77%|  | 1107/1436 [1:06:42<13:26,  2.45s/it]\u001b[A\n",
      "Average Metric: 329 / 1108  (29.7):  77%|  | 1108/1436 [1:06:42<11:37,  2.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 330 / 1109  (29.8):  77%|  | 1108/1436 [1:06:45<11:37,  2.13s/it]\u001b[A\n",
      "Average Metric: 330 / 1109  (29.8):  77%|  | 1109/1436 [1:06:45<12:50,  2.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 330 / 1110  (29.7):  77%|  | 1109/1436 [1:06:46<12:50,  2.36s/it]\u001b[A\n",
      "Average Metric: 330 / 1110  (29.7):  77%|  | 1110/1436 [1:06:46<11:02,  2.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 330 / 1111  (29.7):  77%|  | 1110/1436 [1:06:48<11:02,  2.03s/it]\u001b[A\n",
      "Average Metric: 330 / 1111  (29.7):  77%|  | 1111/1436 [1:06:48<11:11,  2.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 330 / 1112  (29.7):  77%|  | 1111/1436 [1:06:53<11:11,  2.07s/it]\u001b[A\n",
      "Average Metric: 330 / 1112  (29.7):  77%|  | 1112/1436 [1:06:53<16:02,  2.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 330 / 1113  (29.6):  77%|  | 1112/1436 [1:06:55<16:02,  2.97s/it]\u001b[A\n",
      "Average Metric: 330 / 1113  (29.6):  78%|  | 1113/1436 [1:06:55<13:34,  2.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 331 / 1114  (29.7):  78%|  | 1113/1436 [1:06:56<13:34,  2.52s/it]\u001b[A\n",
      "Average Metric: 331 / 1114  (29.7):  78%|  | 1114/1436 [1:06:56<12:07,  2.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 331 / 1115  (29.7):  78%|  | 1114/1436 [1:07:02<12:07,  2.26s/it]\u001b[A\n",
      "Average Metric: 331 / 1115  (29.7):  78%|  | 1115/1436 [1:07:02<16:41,  3.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 332 / 1116  (29.7):  78%|  | 1115/1436 [1:07:06<16:41,  3.12s/it]\u001b[A\n",
      "Average Metric: 332 / 1116  (29.7):  78%|  | 1116/1436 [1:07:06<18:38,  3.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 332 / 1117  (29.7):  78%|  | 1116/1436 [1:07:09<18:38,  3.50s/it]\u001b[A\n",
      "Average Metric: 332 / 1117  (29.7):  78%|  | 1117/1436 [1:07:09<17:55,  3.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 332 / 1118  (29.7):  78%|  | 1117/1436 [1:07:11<17:55,  3.37s/it]\u001b[A\n",
      "Average Metric: 332 / 1118  (29.7):  78%|  | 1118/1436 [1:07:11<16:21,  3.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 333 / 1119  (29.8):  78%|  | 1118/1436 [1:07:14<16:21,  3.09s/it]\u001b[A\n",
      "Average Metric: 333 / 1119  (29.8):  78%|  | 1119/1436 [1:07:14<16:02,  3.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 334 / 1120  (29.8):  78%|  | 1119/1436 [1:07:17<16:02,  3.04s/it]\u001b[A\n",
      "Average Metric: 334 / 1120  (29.8):  78%|  | 1120/1436 [1:07:17<15:57,  3.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1121  (29.9):  78%|  | 1120/1436 [1:07:18<15:57,  3.03s/it]\u001b[A\n",
      "Average Metric: 335 / 1121  (29.9):  78%|  | 1121/1436 [1:07:18<12:48,  2.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1122  (29.9):  78%|  | 1121/1436 [1:07:21<12:48,  2.44s/it]\u001b[A\n",
      "Average Metric: 335 / 1122  (29.9):  78%|  | 1122/1436 [1:07:21<12:23,  2.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1123  (29.8):  78%|  | 1122/1436 [1:07:25<12:23,  2.37s/it]\u001b[A\n",
      "Average Metric: 335 / 1123  (29.8):  78%|  | 1123/1436 [1:07:25<15:38,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1124  (29.8):  78%|  | 1123/1436 [1:07:30<15:38,  3.00s/it]\u001b[A\n",
      "Average Metric: 335 / 1124  (29.8):  78%|  | 1124/1436 [1:07:30<19:01,  3.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1125  (29.8):  78%|  | 1124/1436 [1:07:34<19:01,  3.66s/it]\u001b[A\n",
      "Average Metric: 335 / 1125  (29.8):  78%|  | 1125/1436 [1:07:34<19:10,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1126  (29.8):  78%|  | 1125/1436 [1:07:38<19:10,  3.70s/it]\u001b[A\n",
      "Average Metric: 335 / 1126  (29.8):  78%|  | 1126/1436 [1:07:38<19:03,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1127  (29.7):  78%|  | 1126/1436 [1:07:41<19:03,  3.69s/it]\u001b[A\n",
      "Average Metric: 335 / 1127  (29.7):  78%|  | 1127/1436 [1:07:41<18:55,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1128  (29.7):  78%|  | 1127/1436 [1:07:47<18:55,  3.68s/it]\u001b[A\n",
      "Average Metric: 335 / 1128  (29.7):  79%|  | 1128/1436 [1:07:47<21:17,  4.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1129  (29.7):  79%|  | 1128/1436 [1:07:52<21:17,  4.15s/it]\u001b[A\n",
      "Average Metric: 335 / 1129  (29.7):  79%|  | 1129/1436 [1:07:52<22:56,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1130  (29.6):  79%|  | 1129/1436 [1:07:57<22:56,  4.48s/it]\u001b[A\n",
      "Average Metric: 335 / 1130  (29.6):  79%|  | 1130/1436 [1:07:57<23:52,  4.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1131  (29.6):  79%|  | 1130/1436 [1:08:02<23:52,  4.68s/it]\u001b[A\n",
      "Average Metric: 335 / 1131  (29.6):  79%|  | 1131/1436 [1:08:02<24:32,  4.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1132  (29.6):  79%|  | 1131/1436 [1:08:05<24:32,  4.83s/it]\u001b[A\n",
      "Average Metric: 335 / 1132  (29.6):  79%|  | 1132/1436 [1:08:05<21:59,  4.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1133  (29.6):  79%|  | 1132/1436 [1:08:09<21:59,  4.34s/it]\u001b[A\n",
      "Average Metric: 335 / 1133  (29.6):  79%|  | 1133/1436 [1:08:09<20:30,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1134  (29.5):  79%|  | 1133/1436 [1:08:12<20:30,  4.06s/it]\u001b[A\n",
      "Average Metric: 335 / 1134  (29.5):  79%|  | 1134/1436 [1:08:12<18:43,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1135  (29.5):  79%|  | 1134/1436 [1:08:16<18:43,  3.72s/it]\u001b[A\n",
      "Average Metric: 335 / 1135  (29.5):  79%|  | 1135/1436 [1:08:16<18:40,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1136  (29.5):  79%|  | 1135/1436 [1:08:21<18:40,  3.72s/it]\u001b[A\n",
      "Average Metric: 335 / 1136  (29.5):  79%|  | 1136/1436 [1:08:21<20:44,  4.15s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1137  (29.5):  79%|  | 1136/1436 [1:08:25<20:44,  4.15s/it]\u001b[A\n",
      "Average Metric: 335 / 1137  (29.5):  79%|  | 1137/1436 [1:08:25<20:22,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 335 / 1138  (29.4):  79%|  | 1137/1436 [1:08:27<20:22,  4.09s/it]\u001b[A\n",
      "Average Metric: 335 / 1138  (29.4):  79%|  | 1138/1436 [1:08:27<17:09,  3.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 336 / 1139  (29.5):  79%|  | 1138/1436 [1:08:29<17:09,  3.45s/it]\u001b[A\n",
      "Average Metric: 336 / 1139  (29.5):  79%|  | 1139/1436 [1:08:29<15:04,  3.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 337 / 1140  (29.6):  79%|  | 1139/1436 [1:08:30<15:04,  3.04s/it]\u001b[A\n",
      "Average Metric: 337 / 1140  (29.6):  79%|  | 1140/1436 [1:08:30<13:04,  2.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 338 / 1141  (29.6):  79%|  | 1140/1436 [1:08:33<13:04,  2.65s/it]\u001b[A\n",
      "Average Metric: 338 / 1141  (29.6):  79%|  | 1141/1436 [1:08:33<12:43,  2.59s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 339 / 1142  (29.7):  79%|  | 1141/1436 [1:08:35<12:43,  2.59s/it]\u001b[A\n",
      "Average Metric: 339 / 1142  (29.7):  80%|  | 1142/1436 [1:08:35<11:24,  2.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 340 / 1143  (29.7):  80%|  | 1142/1436 [1:08:37<11:24,  2.33s/it]\u001b[A\n",
      "Average Metric: 340 / 1143  (29.7):  80%|  | 1143/1436 [1:08:37<11:39,  2.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1144  (29.8):  80%|  | 1143/1436 [1:08:40<11:39,  2.39s/it]\u001b[A\n",
      "Average Metric: 341 / 1144  (29.8):  80%|  | 1144/1436 [1:08:40<12:51,  2.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1145  (29.8):  80%|  | 1144/1436 [1:08:44<12:51,  2.64s/it]\u001b[A\n",
      "Average Metric: 341 / 1145  (29.8):  80%|  | 1145/1436 [1:08:44<14:36,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1146  (29.8):  80%|  | 1145/1436 [1:08:49<14:36,  3.01s/it]\u001b[A\n",
      "Average Metric: 341 / 1146  (29.8):  80%|  | 1146/1436 [1:08:49<17:43,  3.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1147  (29.7):  80%|  | 1146/1436 [1:08:52<17:43,  3.67s/it]\u001b[A\n",
      "Average Metric: 341 / 1147  (29.7):  80%|  | 1147/1436 [1:08:52<15:55,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1148  (29.7):  80%|  | 1147/1436 [1:08:54<15:55,  3.31s/it]\u001b[A\n",
      "Average Metric: 341 / 1148  (29.7):  80%|  | 1148/1436 [1:08:54<14:24,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1149  (29.7):  80%|  | 1148/1436 [1:08:57<14:24,  3.00s/it]\u001b[A\n",
      "Average Metric: 341 / 1149  (29.7):  80%|  | 1149/1436 [1:08:57<13:46,  2.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1150  (29.7):  80%|  | 1149/1436 [1:09:00<13:46,  2.88s/it]\u001b[A\n",
      "Average Metric: 341 / 1150  (29.7):  80%|  | 1150/1436 [1:09:00<13:50,  2.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1151  (29.6):  80%|  | 1150/1436 [1:09:04<13:50,  2.90s/it]\u001b[A\n",
      "Average Metric: 341 / 1151  (29.6):  80%|  | 1151/1436 [1:09:04<16:21,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 341 / 1152  (29.6):  80%|  | 1151/1436 [1:09:10<16:21,  3.44s/it]\u001b[A\n",
      "Average Metric: 341 / 1152  (29.6):  80%|  | 1152/1436 [1:09:10<18:43,  3.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 1153  (29.7):  80%|  | 1152/1436 [1:09:12<18:43,  3.96s/it]\u001b[A\n",
      "Average Metric: 342 / 1153  (29.7):  80%|  | 1153/1436 [1:09:12<16:37,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 1154  (29.6):  80%|  | 1153/1436 [1:09:17<16:37,  3.52s/it]\u001b[A\n",
      "Average Metric: 342 / 1154  (29.6):  80%|  | 1154/1436 [1:09:17<18:56,  4.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 1155  (29.6):  80%|  | 1154/1436 [1:09:21<18:56,  4.03s/it]\u001b[A\n",
      "Average Metric: 342 / 1155  (29.6):  80%|  | 1155/1436 [1:09:21<18:37,  3.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 1156  (29.6):  80%|  | 1155/1436 [1:09:23<18:37,  3.98s/it]\u001b[A\n",
      "Average Metric: 342 / 1156  (29.6):  81%|  | 1156/1436 [1:09:23<15:40,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 1157  (29.6):  81%|  | 1156/1436 [1:09:26<15:40,  3.36s/it]\u001b[A\n",
      "Average Metric: 342 / 1157  (29.6):  81%|  | 1157/1436 [1:09:26<15:42,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 342 / 1158  (29.5):  81%|  | 1157/1436 [1:09:32<15:42,  3.38s/it]\u001b[A\n",
      "Average Metric: 342 / 1158  (29.5):  81%|  | 1158/1436 [1:09:32<18:11,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 343 / 1159  (29.6):  81%|  | 1158/1436 [1:09:35<18:11,  3.93s/it]\u001b[A\n",
      "Average Metric: 343 / 1159  (29.6):  81%|  | 1159/1436 [1:09:35<17:00,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 344 / 1160  (29.7):  81%|  | 1159/1436 [1:09:37<17:00,  3.68s/it]\u001b[A\n",
      "Average Metric: 344 / 1160  (29.7):  81%|  | 1160/1436 [1:09:37<14:27,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 345 / 1161  (29.7):  81%|  | 1160/1436 [1:09:42<14:27,  3.14s/it]\u001b[A\n",
      "Average Metric: 345 / 1161  (29.7):  81%|  | 1161/1436 [1:09:42<16:48,  3.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 345 / 1162  (29.7):  81%|  | 1161/1436 [1:09:45<16:48,  3.67s/it]\u001b[A\n",
      "Average Metric: 345 / 1162  (29.7):  81%|  | 1162/1436 [1:09:45<16:49,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 346 / 1163  (29.8):  81%|  | 1162/1436 [1:09:47<16:49,  3.68s/it]\u001b[A\n",
      "Average Metric: 346 / 1163  (29.8):  81%|  | 1163/1436 [1:09:47<14:41,  3.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 1164  (29.8):  81%|  | 1163/1436 [1:09:53<14:41,  3.23s/it]\u001b[A\n",
      "Average Metric: 347 / 1164  (29.8):  81%|  | 1164/1436 [1:09:53<17:23,  3.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 1165  (29.8):  81%|  | 1164/1436 [1:09:58<17:23,  3.83s/it]\u001b[A\n",
      "Average Metric: 347 / 1165  (29.8):  81%|  | 1165/1436 [1:09:58<19:15,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 1166  (29.8):  81%|  | 1165/1436 [1:09:59<19:15,  4.27s/it]\u001b[A\n",
      "Average Metric: 347 / 1166  (29.8):  81%|  | 1166/1436 [1:09:59<15:05,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 347 / 1167  (29.7):  81%|  | 1166/1436 [1:10:04<15:05,  3.36s/it]\u001b[A\n",
      "Average Metric: 347 / 1167  (29.7):  81%| | 1167/1436 [1:10:04<17:36,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 348 / 1168  (29.8):  81%| | 1167/1436 [1:10:09<17:36,  3.93s/it]\u001b[A\n",
      "Average Metric: 348 / 1168  (29.8):  81%| | 1168/1436 [1:10:09<18:14,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 348 / 1169  (29.8):  81%| | 1168/1436 [1:10:12<18:14,  4.09s/it]\u001b[A\n",
      "Average Metric: 348 / 1169  (29.8):  81%| | 1169/1436 [1:10:12<17:26,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 349 / 1170  (29.8):  81%| | 1169/1436 [1:10:17<17:26,  3.92s/it]\u001b[A\n",
      "Average Metric: 349 / 1170  (29.8):  81%| | 1170/1436 [1:10:17<18:38,  4.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 349 / 1171  (29.8):  81%| | 1170/1436 [1:10:22<18:38,  4.21s/it]\u001b[A\n",
      "Average Metric: 349 / 1171  (29.8):  82%| | 1171/1436 [1:10:22<18:54,  4.28s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 349 / 1172  (29.8):  82%| | 1171/1436 [1:10:27<18:54,  4.28s/it]\u001b[A\n",
      "Average Metric: 349 / 1172  (29.8):  82%| | 1172/1436 [1:10:27<19:59,  4.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 350 / 1173  (29.8):  82%| | 1172/1436 [1:10:29<19:59,  4.54s/it]\u001b[A\n",
      "Average Metric: 350 / 1173  (29.8):  82%| | 1173/1436 [1:10:29<16:45,  3.82s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 351 / 1174  (29.9):  82%| | 1173/1436 [1:10:31<16:45,  3.82s/it]\u001b[A\n",
      "Average Metric: 351 / 1174  (29.9):  82%| | 1174/1436 [1:10:31<14:29,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 352 / 1175  (30.0):  82%| | 1174/1436 [1:10:33<14:29,  3.32s/it]\u001b[A\n",
      "Average Metric: 352 / 1175  (30.0):  82%| | 1175/1436 [1:10:33<12:25,  2.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 353 / 1176  (30.0):  82%| | 1175/1436 [1:10:36<12:25,  2.86s/it]\u001b[A\n",
      "Average Metric: 353 / 1176  (30.0):  82%| | 1176/1436 [1:10:36<12:24,  2.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 354 / 1177  (30.1):  82%| | 1176/1436 [1:10:38<12:24,  2.86s/it]\u001b[A\n",
      "Average Metric: 354 / 1177  (30.1):  82%| | 1177/1436 [1:10:38<11:56,  2.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 354 / 1178  (30.1):  82%| | 1177/1436 [1:10:44<11:56,  2.77s/it]\u001b[A\n",
      "Average Metric: 354 / 1178  (30.1):  82%| | 1178/1436 [1:10:44<15:16,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 355 / 1179  (30.1):  82%| | 1178/1436 [1:10:48<15:16,  3.55s/it]\u001b[A\n",
      "Average Metric: 355 / 1179  (30.1):  82%| | 1179/1436 [1:10:48<15:33,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 355 / 1180  (30.1):  82%| | 1179/1436 [1:10:53<15:33,  3.63s/it]\u001b[A\n",
      "Average Metric: 355 / 1180  (30.1):  82%| | 1180/1436 [1:10:53<17:35,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 356 / 1181  (30.1):  82%| | 1180/1436 [1:10:56<17:35,  4.12s/it]\u001b[A\n",
      "Average Metric: 356 / 1181  (30.1):  82%| | 1181/1436 [1:10:56<16:44,  3.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 357 / 1182  (30.2):  82%| | 1181/1436 [1:10:58<16:44,  3.94s/it]\u001b[A\n",
      "Average Metric: 357 / 1182  (30.2):  82%| | 1182/1436 [1:10:58<13:23,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 357 / 1183  (30.2):  82%| | 1182/1436 [1:11:03<13:23,  3.16s/it]\u001b[A\n",
      "Average Metric: 357 / 1183  (30.2):  82%| | 1183/1436 [1:11:03<16:02,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 358 / 1184  (30.2):  82%| | 1183/1436 [1:11:07<16:02,  3.80s/it]\u001b[A\n",
      "Average Metric: 358 / 1184  (30.2):  82%| | 1184/1436 [1:11:07<15:49,  3.77s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 359 / 1185  (30.3):  82%| | 1184/1436 [1:11:08<15:49,  3.77s/it]\u001b[A\n",
      "Average Metric: 359 / 1185  (30.3):  83%| | 1185/1436 [1:11:08<12:47,  3.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 359 / 1186  (30.3):  83%| | 1185/1436 [1:11:11<12:47,  3.06s/it]\u001b[A\n",
      "Average Metric: 359 / 1186  (30.3):  83%| | 1186/1436 [1:11:11<11:51,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1187  (30.3):  83%| | 1186/1436 [1:11:13<11:51,  2.84s/it]\u001b[A\n",
      "Average Metric: 360 / 1187  (30.3):  83%| | 1187/1436 [1:11:13<11:44,  2.83s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1188  (30.3):  83%| | 1187/1436 [1:11:15<11:44,  2.83s/it]\u001b[A\n",
      "Average Metric: 360 / 1188  (30.3):  83%| | 1188/1436 [1:11:15<09:53,  2.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1189  (30.3):  83%| | 1188/1436 [1:11:17<09:53,  2.39s/it]\u001b[A\n",
      "Average Metric: 360 / 1189  (30.3):  83%| | 1189/1436 [1:11:17<10:17,  2.50s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1190  (30.3):  83%| | 1189/1436 [1:11:23<10:17,  2.50s/it]\u001b[A\n",
      "Average Metric: 360 / 1190  (30.3):  83%| | 1190/1436 [1:11:23<13:37,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1191  (30.2):  83%| | 1190/1436 [1:11:25<13:37,  3.32s/it]\u001b[A\n",
      "Average Metric: 360 / 1191  (30.2):  83%| | 1191/1436 [1:11:25<12:19,  3.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1192  (30.2):  83%| | 1191/1436 [1:11:30<12:19,  3.02s/it]\u001b[A\n",
      "Average Metric: 360 / 1192  (30.2):  83%| | 1192/1436 [1:11:30<14:27,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1193  (30.2):  83%| | 1192/1436 [1:11:34<14:27,  3.56s/it]\u001b[A\n",
      "Average Metric: 360 / 1193  (30.2):  83%| | 1193/1436 [1:11:34<15:33,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1194  (30.2):  83%| | 1193/1436 [1:11:37<15:33,  3.84s/it]\u001b[A\n",
      "Average Metric: 360 / 1194  (30.2):  83%| | 1194/1436 [1:11:37<14:26,  3.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1195  (30.1):  83%| | 1194/1436 [1:11:42<14:26,  3.58s/it]\u001b[A\n",
      "Average Metric: 360 / 1195  (30.1):  83%| | 1195/1436 [1:11:42<16:15,  4.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1196  (30.1):  83%| | 1195/1436 [1:11:48<16:15,  4.05s/it]\u001b[A\n",
      "Average Metric: 360 / 1196  (30.1):  83%| | 1196/1436 [1:11:48<17:28,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1197  (30.1):  83%| | 1196/1436 [1:11:52<17:28,  4.37s/it]\u001b[A\n",
      "Average Metric: 360 / 1197  (30.1):  83%| | 1197/1436 [1:11:52<17:24,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1198  (30.1):  83%| | 1197/1436 [1:11:56<17:24,  4.37s/it]\u001b[A\n",
      "Average Metric: 360 / 1198  (30.1):  83%| | 1198/1436 [1:11:56<17:11,  4.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 360 / 1199  (30.0):  83%| | 1198/1436 [1:12:01<17:11,  4.33s/it]\u001b[A\n",
      "Average Metric: 360 / 1199  (30.0):  83%| | 1199/1436 [1:12:01<18:01,  4.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 361 / 1200  (30.1):  83%| | 1199/1436 [1:12:03<18:01,  4.56s/it]\u001b[A\n",
      "Average Metric: 361 / 1200  (30.1):  84%| | 1200/1436 [1:12:03<14:47,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 362 / 1201  (30.1):  84%| | 1200/1436 [1:12:05<14:47,  3.76s/it]\u001b[A\n",
      "Average Metric: 362 / 1201  (30.1):  84%| | 1201/1436 [1:12:05<12:52,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 363 / 1202  (30.2):  84%| | 1201/1436 [1:12:07<12:52,  3.29s/it]\u001b[A\n",
      "Average Metric: 363 / 1202  (30.2):  84%| | 1202/1436 [1:12:07<10:52,  2.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 364 / 1203  (30.3):  84%| | 1202/1436 [1:12:08<10:52,  2.79s/it]\u001b[A\n",
      "Average Metric: 364 / 1203  (30.3):  84%| | 1203/1436 [1:12:09<09:23,  2.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 365 / 1204  (30.3):  84%| | 1203/1436 [1:12:11<09:23,  2.42s/it]\u001b[A\n",
      "Average Metric: 365 / 1204  (30.3):  84%| | 1204/1436 [1:12:11<09:27,  2.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 366 / 1205  (30.4):  84%| | 1204/1436 [1:12:13<09:27,  2.45s/it]\u001b[A\n",
      "Average Metric: 366 / 1205  (30.4):  84%| | 1205/1436 [1:12:13<08:24,  2.19s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 367 / 1206  (30.4):  84%| | 1205/1436 [1:12:17<08:24,  2.19s/it]\u001b[A\n",
      "Average Metric: 367 / 1206  (30.4):  84%| | 1206/1436 [1:12:17<10:38,  2.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 367 / 1207  (30.4):  84%| | 1206/1436 [1:12:22<10:38,  2.78s/it]\u001b[A\n",
      "Average Metric: 367 / 1207  (30.4):  84%| | 1207/1436 [1:12:22<13:05,  3.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 367 / 1208  (30.4):  84%| | 1207/1436 [1:12:23<13:05,  3.43s/it]\u001b[A\n",
      "Average Metric: 367 / 1208  (30.4):  84%| | 1208/1436 [1:12:23<10:47,  2.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 367 / 1209  (30.4):  84%| | 1208/1436 [1:12:27<10:47,  2.84s/it]\u001b[A\n",
      "Average Metric: 367 / 1209  (30.4):  84%| | 1209/1436 [1:12:27<12:12,  3.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 368 / 1210  (30.4):  84%| | 1209/1436 [1:12:29<12:12,  3.23s/it]\u001b[A\n",
      "Average Metric: 368 / 1210  (30.4):  84%| | 1210/1436 [1:12:29<10:15,  2.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 1211  (30.5):  84%| | 1210/1436 [1:12:33<10:15,  2.73s/it]\u001b[A\n",
      "Average Metric: 369 / 1211  (30.5):  84%| | 1211/1436 [1:12:33<11:36,  3.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 1212  (30.4):  84%| | 1211/1436 [1:12:37<11:36,  3.09s/it]\u001b[A\n",
      "Average Metric: 369 / 1212  (30.4):  84%| | 1212/1436 [1:12:37<12:24,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 1213  (30.4):  84%| | 1212/1436 [1:12:40<12:24,  3.32s/it]\u001b[A\n",
      "Average Metric: 369 / 1213  (30.4):  84%| | 1213/1436 [1:12:40<12:26,  3.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 1214  (30.4):  84%| | 1213/1436 [1:12:45<12:26,  3.35s/it]\u001b[A\n",
      "Average Metric: 369 / 1214  (30.4):  85%| | 1214/1436 [1:12:45<14:20,  3.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 1215  (30.4):  85%| | 1214/1436 [1:12:49<14:20,  3.88s/it]\u001b[A\n",
      "Average Metric: 369 / 1215  (30.4):  85%| | 1215/1436 [1:12:49<14:37,  3.97s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 1216  (30.3):  85%| | 1215/1436 [1:12:53<14:37,  3.97s/it]\u001b[A\n",
      "Average Metric: 369 / 1216  (30.3):  85%| | 1216/1436 [1:12:53<14:11,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 369 / 1217  (30.3):  85%| | 1216/1436 [1:12:56<14:11,  3.87s/it]\u001b[A\n",
      "Average Metric: 369 / 1217  (30.3):  85%| | 1217/1436 [1:12:56<13:30,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 370 / 1218  (30.4):  85%| | 1217/1436 [1:12:58<13:30,  3.70s/it]\u001b[A\n",
      "Average Metric: 370 / 1218  (30.4):  85%| | 1218/1436 [1:12:58<11:28,  3.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 370 / 1219  (30.4):  85%| | 1218/1436 [1:13:03<11:28,  3.16s/it]\u001b[A\n",
      "Average Metric: 370 / 1219  (30.4):  85%| | 1219/1436 [1:13:03<13:24,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 370 / 1220  (30.3):  85%| | 1219/1436 [1:13:07<13:24,  3.71s/it]\u001b[A\n",
      "Average Metric: 370 / 1220  (30.3):  85%| | 1220/1436 [1:13:07<13:30,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 371 / 1221  (30.4):  85%| | 1220/1436 [1:13:10<13:30,  3.75s/it]\u001b[A\n",
      "Average Metric: 371 / 1221  (30.4):  85%| | 1221/1436 [1:13:10<13:00,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 371 / 1222  (30.4):  85%| | 1221/1436 [1:13:13<13:00,  3.63s/it]\u001b[A\n",
      "Average Metric: 371 / 1222  (30.4):  85%| | 1222/1436 [1:13:13<12:10,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 372 / 1223  (30.4):  85%| | 1222/1436 [1:13:16<12:10,  3.41s/it]\u001b[A\n",
      "Average Metric: 372 / 1223  (30.4):  85%| | 1223/1436 [1:13:16<10:56,  3.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 372 / 1224  (30.4):  85%| | 1223/1436 [1:13:19<10:56,  3.08s/it]\u001b[A\n",
      "Average Metric: 372 / 1224  (30.4):  85%| | 1224/1436 [1:13:19<11:00,  3.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 1225  (30.4):  85%| | 1224/1436 [1:13:22<11:00,  3.12s/it]\u001b[A\n",
      "Average Metric: 373 / 1225  (30.4):  85%| | 1225/1436 [1:13:22<11:16,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 1226  (30.4):  85%| | 1225/1436 [1:13:27<11:16,  3.21s/it]\u001b[A\n",
      "Average Metric: 373 / 1226  (30.4):  85%| | 1226/1436 [1:13:27<13:16,  3.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 1227  (30.4):  85%| | 1226/1436 [1:13:31<13:16,  3.79s/it]\u001b[A\n",
      "Average Metric: 373 / 1227  (30.4):  85%| | 1227/1436 [1:13:31<13:23,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 373 / 1228  (30.4):  85%| | 1227/1436 [1:13:34<13:23,  3.84s/it]\u001b[A\n",
      "Average Metric: 373 / 1228  (30.4):  86%| | 1228/1436 [1:13:34<11:56,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 374 / 1229  (30.4):  86%| | 1228/1436 [1:13:39<11:56,  3.44s/it]\u001b[A\n",
      "Average Metric: 374 / 1229  (30.4):  86%| | 1229/1436 [1:13:39<13:20,  3.87s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 374 / 1230  (30.4):  86%| | 1229/1436 [1:13:40<13:20,  3.87s/it]\u001b[A\n",
      "Average Metric: 374 / 1230  (30.4):  86%| | 1230/1436 [1:13:40<11:00,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 375 / 1231  (30.5):  86%| | 1230/1436 [1:13:45<11:00,  3.21s/it]\u001b[A\n",
      "Average Metric: 375 / 1231  (30.5):  86%| | 1231/1436 [1:13:45<12:36,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 376 / 1232  (30.5):  86%| | 1231/1436 [1:13:48<12:36,  3.69s/it]\u001b[A\n",
      "Average Metric: 376 / 1232  (30.5):  86%| | 1232/1436 [1:13:48<11:57,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 376 / 1233  (30.5):  86%| | 1232/1436 [1:13:54<11:57,  3.52s/it]\u001b[A\n",
      "Average Metric: 376 / 1233  (30.5):  86%| | 1233/1436 [1:13:54<13:39,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 377 / 1234  (30.6):  86%| | 1233/1436 [1:13:57<13:39,  4.04s/it]\u001b[A\n",
      "Average Metric: 377 / 1234  (30.6):  86%| | 1234/1436 [1:13:57<12:38,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 377 / 1235  (30.5):  86%| | 1234/1436 [1:14:02<12:38,  3.76s/it]\u001b[A\n",
      "Average Metric: 377 / 1235  (30.5):  86%| | 1235/1436 [1:14:02<14:10,  4.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 377 / 1236  (30.5):  86%| | 1235/1436 [1:14:07<14:10,  4.23s/it]\u001b[A\n",
      "Average Metric: 377 / 1236  (30.5):  86%| | 1236/1436 [1:14:07<14:26,  4.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 378 / 1237  (30.6):  86%| | 1236/1436 [1:14:10<14:26,  4.33s/it]\u001b[A\n",
      "Average Metric: 378 / 1237  (30.6):  86%| | 1237/1436 [1:14:10<13:43,  4.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 379 / 1238  (30.6):  86%| | 1237/1436 [1:14:12<13:43,  4.14s/it]\u001b[A\n",
      "Average Metric: 379 / 1238  (30.6):  86%| | 1238/1436 [1:14:12<11:10,  3.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 380 / 1239  (30.7):  86%| | 1238/1436 [1:14:15<11:10,  3.39s/it]\u001b[A\n",
      "Average Metric: 380 / 1239  (30.7):  86%| | 1239/1436 [1:14:15<10:38,  3.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 381 / 1240  (30.7):  86%| | 1239/1436 [1:14:17<10:38,  3.24s/it]\u001b[A\n",
      "Average Metric: 381 / 1240  (30.7):  86%| | 1240/1436 [1:14:17<09:17,  2.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 381 / 1241  (30.7):  86%| | 1240/1436 [1:14:20<09:17,  2.85s/it]\u001b[A\n",
      "Average Metric: 381 / 1241  (30.7):  86%| | 1241/1436 [1:14:20<09:16,  2.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 382 / 1242  (30.8):  86%| | 1241/1436 [1:14:23<09:16,  2.85s/it]\u001b[A\n",
      "Average Metric: 382 / 1242  (30.8):  86%| | 1242/1436 [1:14:23<09:22,  2.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 382 / 1243  (30.7):  86%| | 1242/1436 [1:14:27<09:22,  2.90s/it]\u001b[A\n",
      "Average Metric: 382 / 1243  (30.7):  87%| | 1243/1436 [1:14:27<11:14,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 382 / 1244  (30.7):  87%| | 1243/1436 [1:14:31<11:14,  3.49s/it]\u001b[A\n",
      "Average Metric: 382 / 1244  (30.7):  87%| | 1244/1436 [1:14:31<10:49,  3.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 382 / 1245  (30.7):  87%| | 1244/1436 [1:14:34<10:49,  3.38s/it]\u001b[A\n",
      "Average Metric: 382 / 1245  (30.7):  87%| | 1245/1436 [1:14:34<10:53,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 382 / 1246  (30.7):  87%| | 1245/1436 [1:14:36<10:53,  3.42s/it]\u001b[A\n",
      "Average Metric: 382 / 1246  (30.7):  87%| | 1246/1436 [1:14:36<09:39,  3.05s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 382 / 1247  (30.6):  87%| | 1246/1436 [1:14:41<09:39,  3.05s/it]\u001b[A\n",
      "Average Metric: 382 / 1247  (30.6):  87%| | 1247/1436 [1:14:41<10:42,  3.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 382 / 1248  (30.6):  87%| | 1247/1436 [1:14:45<10:42,  3.40s/it]\u001b[A\n",
      "Average Metric: 382 / 1248  (30.6):  87%| | 1248/1436 [1:14:45<11:25,  3.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 383 / 1249  (30.7):  87%| | 1248/1436 [1:14:48<11:25,  3.65s/it]\u001b[A\n",
      "Average Metric: 383 / 1249  (30.7):  87%| | 1249/1436 [1:14:48<10:51,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 383 / 1250  (30.6):  87%| | 1249/1436 [1:14:51<10:51,  3.49s/it]\u001b[A\n",
      "Average Metric: 383 / 1250  (30.6):  87%| | 1250/1436 [1:14:51<10:26,  3.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 383 / 1251  (30.6):  87%| | 1250/1436 [1:14:54<10:26,  3.37s/it]\u001b[A\n",
      "Average Metric: 383 / 1251  (30.6):  87%| | 1251/1436 [1:14:54<09:51,  3.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 383 / 1252  (30.6):  87%| | 1251/1436 [1:14:57<09:51,  3.20s/it]\u001b[A\n",
      "Average Metric: 383 / 1252  (30.6):  87%| | 1252/1436 [1:14:57<10:04,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 384 / 1253  (30.6):  87%| | 1252/1436 [1:15:00<10:04,  3.29s/it]\u001b[A\n",
      "Average Metric: 384 / 1253  (30.6):  87%| | 1253/1436 [1:15:00<09:57,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 384 / 1254  (30.6):  87%| | 1253/1436 [1:15:02<09:57,  3.26s/it]\u001b[A\n",
      "Average Metric: 384 / 1254  (30.6):  87%| | 1254/1436 [1:15:02<08:43,  2.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 384 / 1255  (30.6):  87%| | 1254/1436 [1:15:08<08:43,  2.88s/it]\u001b[A\n",
      "Average Metric: 384 / 1255  (30.6):  87%| | 1255/1436 [1:15:08<10:54,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 385 / 1256  (30.7):  87%| | 1255/1436 [1:15:12<10:54,  3.62s/it]\u001b[A\n",
      "Average Metric: 385 / 1256  (30.7):  87%| | 1256/1436 [1:15:12<11:40,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 385 / 1257  (30.6):  87%| | 1256/1436 [1:15:17<11:40,  3.89s/it]\u001b[A\n",
      "Average Metric: 385 / 1257  (30.6):  88%| | 1257/1436 [1:15:17<12:47,  4.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 385 / 1258  (30.6):  88%| | 1257/1436 [1:15:22<12:47,  4.29s/it]\u001b[A\n",
      "Average Metric: 385 / 1258  (30.6):  88%| | 1258/1436 [1:15:22<12:32,  4.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 385 / 1259  (30.6):  88%| | 1258/1436 [1:15:27<12:32,  4.23s/it]\u001b[A\n",
      "Average Metric: 385 / 1259  (30.6):  88%| | 1259/1436 [1:15:27<13:21,  4.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 385 / 1260  (30.6):  88%| | 1259/1436 [1:15:32<13:21,  4.53s/it]\u001b[A\n",
      "Average Metric: 385 / 1260  (30.6):  88%| | 1260/1436 [1:15:32<13:48,  4.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 385 / 1261  (30.5):  88%| | 1260/1436 [1:15:34<13:48,  4.71s/it]\u001b[A\n",
      "Average Metric: 385 / 1261  (30.5):  88%| | 1261/1436 [1:15:34<11:24,  3.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 385 / 1262  (30.5):  88%| | 1261/1436 [1:15:37<11:24,  3.91s/it]\u001b[A\n",
      "Average Metric: 385 / 1262  (30.5):  88%| | 1262/1436 [1:15:37<10:16,  3.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 386 / 1263  (30.6):  88%| | 1262/1436 [1:15:40<10:16,  3.54s/it]\u001b[A\n",
      "Average Metric: 386 / 1263  (30.6):  88%| | 1263/1436 [1:15:40<10:15,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 387 / 1264  (30.6):  88%| | 1263/1436 [1:15:42<10:15,  3.55s/it]\u001b[A\n",
      "Average Metric: 387 / 1264  (30.6):  88%| | 1264/1436 [1:15:42<08:47,  3.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1265  (30.7):  88%| | 1264/1436 [1:15:46<08:47,  3.07s/it]\u001b[A\n",
      "Average Metric: 388 / 1265  (30.7):  88%| | 1265/1436 [1:15:46<09:48,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1266  (30.6):  88%| | 1265/1436 [1:15:49<09:48,  3.44s/it]\u001b[A\n",
      "Average Metric: 388 / 1266  (30.6):  88%| | 1266/1436 [1:15:49<08:42,  3.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1267  (30.6):  88%| | 1266/1436 [1:15:54<08:42,  3.07s/it]\u001b[A\n",
      "Average Metric: 388 / 1267  (30.6):  88%| | 1267/1436 [1:15:54<10:21,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1268  (30.6):  88%| | 1267/1436 [1:15:57<10:21,  3.68s/it]\u001b[A\n",
      "Average Metric: 388 / 1268  (30.6):  88%| | 1268/1436 [1:15:57<09:45,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1269  (30.6):  88%| | 1268/1436 [1:16:00<09:45,  3.49s/it]\u001b[A\n",
      "Average Metric: 388 / 1269  (30.6):  88%| | 1269/1436 [1:16:00<09:22,  3.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1270  (30.6):  88%| | 1269/1436 [1:16:04<09:22,  3.37s/it]\u001b[A\n",
      "Average Metric: 388 / 1270  (30.6):  88%| | 1270/1436 [1:16:04<10:17,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1271  (30.5):  88%| | 1270/1436 [1:16:10<10:17,  3.72s/it]\u001b[A\n",
      "Average Metric: 388 / 1271  (30.5):  89%| | 1271/1436 [1:16:10<11:28,  4.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1272  (30.5):  89%| | 1271/1436 [1:16:15<11:28,  4.17s/it]\u001b[A\n",
      "Average Metric: 388 / 1272  (30.5):  89%| | 1272/1436 [1:16:15<12:16,  4.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1273  (30.5):  89%| | 1272/1436 [1:16:20<12:16,  4.49s/it]\u001b[A\n",
      "Average Metric: 388 / 1273  (30.5):  89%| | 1273/1436 [1:16:20<12:16,  4.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1274  (30.5):  89%| | 1273/1436 [1:16:25<12:16,  4.52s/it]\u001b[A\n",
      "Average Metric: 388 / 1274  (30.5):  89%| | 1274/1436 [1:16:25<12:46,  4.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1275  (30.4):  89%| | 1274/1436 [1:16:27<12:46,  4.73s/it]\u001b[A\n",
      "Average Metric: 388 / 1275  (30.4):  89%| | 1275/1436 [1:16:27<11:02,  4.12s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 388 / 1276  (30.4):  89%| | 1275/1436 [1:16:33<11:02,  4.12s/it]\u001b[A\n",
      "Average Metric: 388 / 1276  (30.4):  89%| | 1276/1436 [1:16:33<11:51,  4.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 389 / 1277  (30.5):  89%| | 1276/1436 [1:16:36<11:51,  4.45s/it]\u001b[A\n",
      "Average Metric: 389 / 1277  (30.5):  89%| | 1277/1436 [1:16:36<10:48,  4.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 389 / 1278  (30.4):  89%| | 1277/1436 [1:16:39<10:48,  4.08s/it]\u001b[A\n",
      "Average Metric: 389 / 1278  (30.4):  89%| | 1278/1436 [1:16:39<09:52,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 389 / 1279  (30.4):  89%| | 1278/1436 [1:16:44<09:52,  3.75s/it]\u001b[A\n",
      "Average Metric: 389 / 1279  (30.4):  89%| | 1279/1436 [1:16:44<11:02,  4.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 389 / 1280  (30.4):  89%| | 1279/1436 [1:16:49<11:02,  4.22s/it]\u001b[A\n",
      "Average Metric: 389 / 1280  (30.4):  89%| | 1280/1436 [1:16:49<11:46,  4.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 389 / 1281  (30.4):  89%| | 1280/1436 [1:16:55<11:46,  4.53s/it]\u001b[A\n",
      "Average Metric: 389 / 1281  (30.4):  89%| | 1281/1436 [1:16:55<12:14,  4.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 390 / 1282  (30.4):  89%| | 1281/1436 [1:16:56<12:14,  4.74s/it]\u001b[A\n",
      "Average Metric: 390 / 1282  (30.4):  89%| | 1282/1436 [1:16:56<09:46,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 390 / 1283  (30.4):  89%| | 1282/1436 [1:17:01<09:46,  3.81s/it]\u001b[A\n",
      "Average Metric: 390 / 1283  (30.4):  89%| | 1283/1436 [1:17:01<10:22,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 391 / 1284  (30.5):  89%| | 1283/1436 [1:17:04<10:22,  4.07s/it]\u001b[A\n",
      "Average Metric: 391 / 1284  (30.5):  89%| | 1284/1436 [1:17:04<09:10,  3.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 392 / 1285  (30.5):  89%| | 1284/1436 [1:17:06<09:10,  3.62s/it]\u001b[A\n",
      "Average Metric: 392 / 1285  (30.5):  89%| | 1285/1436 [1:17:06<08:17,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 392 / 1286  (30.5):  89%| | 1285/1436 [1:17:11<08:17,  3.29s/it]\u001b[A\n",
      "Average Metric: 392 / 1286  (30.5):  90%| | 1286/1436 [1:17:11<09:35,  3.84s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 392 / 1287  (30.5):  90%| | 1286/1436 [1:17:17<09:35,  3.84s/it]\u001b[A\n",
      "Average Metric: 392 / 1287  (30.5):  90%| | 1287/1436 [1:17:17<10:39,  4.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 392 / 1288  (30.4):  90%| | 1287/1436 [1:17:22<10:39,  4.29s/it]\u001b[A\n",
      "Average Metric: 392 / 1288  (30.4):  90%| | 1288/1436 [1:17:22<11:21,  4.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 393 / 1289  (30.5):  90%| | 1288/1436 [1:17:26<11:21,  4.61s/it]\u001b[A\n",
      "Average Metric: 393 / 1289  (30.5):  90%| | 1289/1436 [1:17:26<10:48,  4.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 394 / 1290  (30.5):  90%| | 1289/1436 [1:17:29<10:48,  4.41s/it]\u001b[A\n",
      "Average Metric: 394 / 1290  (30.5):  90%| | 1290/1436 [1:17:29<09:45,  4.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 395 / 1291  (30.6):  90%| | 1290/1436 [1:17:31<09:45,  4.01s/it]\u001b[A\n",
      "Average Metric: 395 / 1291  (30.6):  90%| | 1291/1436 [1:17:31<08:21,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 396 / 1292  (30.7):  90%| | 1291/1436 [1:17:33<08:21,  3.46s/it]\u001b[A\n",
      "Average Metric: 396 / 1292  (30.7):  90%| | 1292/1436 [1:17:33<07:24,  3.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 397 / 1293  (30.7):  90%| | 1292/1436 [1:17:36<07:24,  3.09s/it]\u001b[A\n",
      "Average Metric: 397 / 1293  (30.7):  90%| | 1293/1436 [1:17:36<06:56,  2.91s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 397 / 1294  (30.7):  90%| | 1293/1436 [1:17:37<06:56,  2.91s/it]\u001b[A\n",
      "Average Metric: 397 / 1294  (30.7):  90%| | 1294/1436 [1:17:37<05:52,  2.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 397 / 1295  (30.7):  90%| | 1294/1436 [1:17:41<05:52,  2.49s/it]\u001b[A\n",
      "Average Metric: 397 / 1295  (30.7):  90%| | 1295/1436 [1:17:41<06:36,  2.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 397 / 1296  (30.6):  90%| | 1295/1436 [1:17:46<06:36,  2.81s/it]\u001b[A\n",
      "Average Metric: 397 / 1296  (30.6):  90%| | 1296/1436 [1:17:46<08:12,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 397 / 1297  (30.6):  90%| | 1296/1436 [1:17:49<08:12,  3.52s/it]\u001b[A\n",
      "Average Metric: 397 / 1297  (30.6):  90%| | 1297/1436 [1:17:49<07:26,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 1298  (30.7):  90%| | 1297/1436 [1:17:52<07:26,  3.21s/it]\u001b[A\n",
      "Average Metric: 398 / 1298  (30.7):  90%| | 1298/1436 [1:17:52<07:53,  3.43s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 1299  (30.6):  90%| | 1298/1436 [1:17:57<07:53,  3.43s/it]\u001b[A\n",
      "Average Metric: 398 / 1299  (30.6):  90%| | 1299/1436 [1:17:57<08:23,  3.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 1300  (30.6):  90%| | 1299/1436 [1:18:02<08:23,  3.68s/it]\u001b[A\n",
      "Average Metric: 398 / 1300  (30.6):  91%| | 1300/1436 [1:18:02<09:09,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 1301  (30.6):  91%| | 1300/1436 [1:18:05<09:09,  4.04s/it]\u001b[A\n",
      "Average Metric: 398 / 1301  (30.6):  91%| | 1301/1436 [1:18:05<08:34,  3.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 1302  (30.6):  91%| | 1301/1436 [1:18:07<08:34,  3.81s/it]\u001b[A\n",
      "Average Metric: 398 / 1302  (30.6):  91%| | 1302/1436 [1:18:07<07:38,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 1303  (30.5):  91%| | 1302/1436 [1:18:10<07:38,  3.42s/it]\u001b[A\n",
      "Average Metric: 398 / 1303  (30.5):  91%| | 1303/1436 [1:18:10<07:09,  3.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 398 / 1304  (30.5):  91%| | 1303/1436 [1:18:12<07:09,  3.23s/it]\u001b[A\n",
      "Average Metric: 398 / 1304  (30.5):  91%| | 1304/1436 [1:18:12<06:25,  2.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 1305  (30.6):  91%| | 1304/1436 [1:18:16<06:25,  2.92s/it]\u001b[A\n",
      "Average Metric: 399 / 1305  (30.6):  91%| | 1305/1436 [1:18:16<06:37,  3.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 399 / 1306  (30.6):  91%| | 1305/1436 [1:18:20<06:37,  3.03s/it]\u001b[A\n",
      "Average Metric: 399 / 1306  (30.6):  91%| | 1306/1436 [1:18:20<07:17,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 400 / 1307  (30.6):  91%| | 1306/1436 [1:18:23<07:17,  3.36s/it]\u001b[A\n",
      "Average Metric: 400 / 1307  (30.6):  91%| | 1307/1436 [1:18:23<06:57,  3.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 400 / 1308  (30.6):  91%| | 1307/1436 [1:18:26<06:57,  3.24s/it]\u001b[A\n",
      "Average Metric: 400 / 1308  (30.6):  91%| | 1308/1436 [1:18:26<07:05,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 400 / 1309  (30.6):  91%| | 1308/1436 [1:18:31<07:05,  3.32s/it]\u001b[A\n",
      "Average Metric: 400 / 1309  (30.6):  91%| | 1309/1436 [1:18:31<07:53,  3.73s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 401 / 1310  (30.6):  91%| | 1309/1436 [1:18:32<07:53,  3.73s/it]\u001b[A\n",
      "Average Metric: 401 / 1310  (30.6):  91%| | 1310/1436 [1:18:32<06:07,  2.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 402 / 1311  (30.7):  91%| | 1310/1436 [1:18:33<06:07,  2.92s/it]\u001b[A\n",
      "Average Metric: 402 / 1311  (30.7):  91%|| 1311/1436 [1:18:33<05:02,  2.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 402 / 1312  (30.6):  91%|| 1311/1436 [1:18:35<05:02,  2.42s/it]\u001b[A\n",
      "Average Metric: 402 / 1312  (30.6):  91%|| 1312/1436 [1:18:35<04:29,  2.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 402 / 1313  (30.6):  91%|| 1312/1436 [1:18:37<04:29,  2.18s/it]\u001b[A\n",
      "Average Metric: 402 / 1313  (30.6):  91%|| 1313/1436 [1:18:37<04:30,  2.20s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 403 / 1314  (30.7):  91%|| 1313/1436 [1:18:41<04:30,  2.20s/it]\u001b[A\n",
      "Average Metric: 403 / 1314  (30.7):  92%|| 1314/1436 [1:18:41<05:28,  2.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 404 / 1315  (30.7):  92%|| 1314/1436 [1:18:43<05:28,  2.70s/it]\u001b[A\n",
      "Average Metric: 404 / 1315  (30.7):  92%|| 1315/1436 [1:18:43<04:46,  2.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 405 / 1316  (30.8):  92%|| 1315/1436 [1:18:45<04:46,  2.37s/it]\u001b[A\n",
      "Average Metric: 405 / 1316  (30.8):  92%|| 1316/1436 [1:18:45<04:38,  2.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 405 / 1317  (30.8):  92%|| 1316/1436 [1:18:48<04:38,  2.32s/it]\u001b[A\n",
      "Average Metric: 405 / 1317  (30.8):  92%|| 1317/1436 [1:18:48<05:04,  2.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 405 / 1318  (30.7):  92%|| 1317/1436 [1:18:53<05:04,  2.56s/it]\u001b[A\n",
      "Average Metric: 405 / 1318  (30.7):  92%|| 1318/1436 [1:18:53<06:40,  3.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 405 / 1319  (30.7):  92%|| 1318/1436 [1:18:58<06:40,  3.39s/it]\u001b[A\n",
      "Average Metric: 405 / 1319  (30.7):  92%|| 1319/1436 [1:18:58<07:17,  3.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 405 / 1320  (30.7):  92%|| 1319/1436 [1:19:03<07:17,  3.74s/it]\u001b[A\n",
      "Average Metric: 405 / 1320  (30.7):  92%|| 1320/1436 [1:19:03<08:08,  4.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 1321  (30.7):  92%|| 1320/1436 [1:19:05<08:08,  4.21s/it]\u001b[A\n",
      "Average Metric: 406 / 1321  (30.7):  92%|| 1321/1436 [1:19:05<06:54,  3.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 406 / 1322  (30.7):  92%|| 1321/1436 [1:19:10<06:54,  3.60s/it]\u001b[A\n",
      "Average Metric: 406 / 1322  (30.7):  92%|| 1322/1436 [1:19:10<07:30,  3.95s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 407 / 1323  (30.8):  92%|| 1322/1436 [1:19:13<07:30,  3.95s/it]\u001b[A\n",
      "Average Metric: 407 / 1323  (30.8):  92%|| 1323/1436 [1:19:13<06:41,  3.55s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 407 / 1324  (30.7):  92%|| 1323/1436 [1:19:18<06:41,  3.55s/it]\u001b[A\n",
      "Average Metric: 407 / 1324  (30.7):  92%|| 1324/1436 [1:19:18<07:32,  4.04s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 407 / 1325  (30.7):  92%|| 1324/1436 [1:19:21<07:32,  4.04s/it]\u001b[A\n",
      "Average Metric: 407 / 1325  (30.7):  92%|| 1325/1436 [1:19:21<06:53,  3.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 407 / 1326  (30.7):  92%|| 1325/1436 [1:19:23<06:53,  3.72s/it]\u001b[A\n",
      "Average Metric: 407 / 1326  (30.7):  92%|| 1326/1436 [1:19:23<06:14,  3.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 408 / 1327  (30.7):  92%|| 1326/1436 [1:19:28<06:14,  3.41s/it]\u001b[A\n",
      "Average Metric: 408 / 1327  (30.7):  92%|| 1327/1436 [1:19:28<07:00,  3.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 408 / 1328  (30.7):  92%|| 1327/1436 [1:19:32<07:00,  3.86s/it]\u001b[A\n",
      "Average Metric: 408 / 1328  (30.7):  92%|| 1328/1436 [1:19:32<06:38,  3.69s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 409 / 1329  (30.8):  92%|| 1328/1436 [1:19:35<06:38,  3.69s/it]\u001b[A\n",
      "Average Metric: 409 / 1329  (30.8):  93%|| 1329/1436 [1:19:35<06:28,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 409 / 1330  (30.8):  93%|| 1329/1436 [1:19:40<06:28,  3.63s/it]\u001b[A\n",
      "Average Metric: 409 / 1330  (30.8):  93%|| 1330/1436 [1:19:40<07:12,  4.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 410 / 1331  (30.8):  93%|| 1330/1436 [1:19:44<07:12,  4.08s/it]\u001b[A\n",
      "Average Metric: 410 / 1331  (30.8):  93%|| 1331/1436 [1:19:44<06:58,  3.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1332  (30.9):  93%|| 1331/1436 [1:19:46<06:58,  3.99s/it]\u001b[A\n",
      "Average Metric: 411 / 1332  (30.9):  93%|| 1332/1436 [1:19:46<06:05,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1333  (30.8):  93%|| 1332/1436 [1:19:48<06:05,  3.51s/it]\u001b[A\n",
      "Average Metric: 411 / 1333  (30.8):  93%|| 1333/1436 [1:19:48<05:15,  3.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1334  (30.8):  93%|| 1333/1436 [1:19:54<05:15,  3.06s/it]\u001b[A\n",
      "Average Metric: 411 / 1334  (30.8):  93%|| 1334/1436 [1:19:54<06:18,  3.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1335  (30.8):  93%|| 1334/1436 [1:19:59<06:18,  3.71s/it]\u001b[A\n",
      "Average Metric: 411 / 1335  (30.8):  93%|| 1335/1436 [1:19:59<07:00,  4.16s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1336  (30.8):  93%|| 1335/1436 [1:20:03<07:00,  4.16s/it]\u001b[A\n",
      "Average Metric: 411 / 1336  (30.8):  93%|| 1336/1436 [1:20:03<06:47,  4.07s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 411 / 1337  (30.7):  93%|| 1336/1436 [1:20:07<06:47,  4.07s/it]\u001b[A\n",
      "Average Metric: 411 / 1337  (30.7):  93%|| 1337/1436 [1:20:07<06:53,  4.18s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 412 / 1338  (30.8):  93%|| 1337/1436 [1:20:12<06:53,  4.18s/it]\u001b[A\n",
      "Average Metric: 412 / 1338  (30.8):  93%|| 1338/1436 [1:20:12<06:55,  4.24s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 413 / 1339  (30.8):  93%|| 1338/1436 [1:20:16<06:55,  4.24s/it]\u001b[A\n",
      "Average Metric: 413 / 1339  (30.8):  93%|| 1339/1436 [1:20:16<06:53,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 414 / 1340  (30.9):  93%|| 1339/1436 [1:20:20<06:53,  4.26s/it]\u001b[A\n",
      "Average Metric: 414 / 1340  (30.9):  93%|| 1340/1436 [1:20:20<06:36,  4.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 414 / 1341  (30.9):  93%|| 1340/1436 [1:20:24<06:36,  4.13s/it]\u001b[A\n",
      "Average Metric: 414 / 1341  (30.9):  93%|| 1341/1436 [1:20:24<06:28,  4.09s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 414 / 1342  (30.8):  93%|| 1341/1436 [1:20:29<06:28,  4.09s/it]\u001b[A\n",
      "Average Metric: 414 / 1342  (30.8):  93%|| 1342/1436 [1:20:29<06:50,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 414 / 1343  (30.8):  93%|| 1342/1436 [1:20:33<06:50,  4.37s/it]\u001b[A\n",
      "Average Metric: 414 / 1343  (30.8):  94%|| 1343/1436 [1:20:33<06:31,  4.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 414 / 1344  (30.8):  94%|| 1343/1436 [1:20:38<06:31,  4.21s/it]\u001b[A\n",
      "Average Metric: 414 / 1344  (30.8):  94%|| 1344/1436 [1:20:38<06:54,  4.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 414 / 1345  (30.8):  94%|| 1344/1436 [1:20:43<06:54,  4.51s/it]\u001b[A\n",
      "Average Metric: 414 / 1345  (30.8):  94%|| 1345/1436 [1:20:43<07:08,  4.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 415 / 1346  (30.8):  94%|| 1345/1436 [1:20:46<07:08,  4.71s/it]\u001b[A\n",
      "Average Metric: 415 / 1346  (30.8):  94%|| 1346/1436 [1:20:46<06:15,  4.17s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 415 / 1347  (30.8):  94%|| 1346/1436 [1:20:47<06:15,  4.17s/it]\u001b[A\n",
      "Average Metric: 415 / 1347  (30.8):  94%|| 1347/1436 [1:20:47<05:02,  3.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 416 / 1348  (30.9):  94%|| 1347/1436 [1:20:51<05:02,  3.40s/it]\u001b[A\n",
      "Average Metric: 416 / 1348  (30.9):  94%|| 1348/1436 [1:20:51<04:51,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 417 / 1349  (30.9):  94%|| 1348/1436 [1:20:53<04:51,  3.31s/it]\u001b[A\n",
      "Average Metric: 417 / 1349  (30.9):  94%|| 1349/1436 [1:20:53<04:19,  2.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 418 / 1350  (31.0):  94%|| 1349/1436 [1:20:54<04:19,  2.98s/it]\u001b[A\n",
      "Average Metric: 418 / 1350  (31.0):  94%|| 1350/1436 [1:20:54<03:31,  2.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 418 / 1351  (30.9):  94%|| 1350/1436 [1:20:57<03:31,  2.46s/it]\u001b[A\n",
      "Average Metric: 418 / 1351  (30.9):  94%|| 1351/1436 [1:20:57<03:48,  2.68s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 419 / 1352  (31.0):  94%|| 1351/1436 [1:21:02<03:48,  2.68s/it]\u001b[A\n",
      "Average Metric: 419 / 1352  (31.0):  94%|| 1352/1436 [1:21:02<04:29,  3.21s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 420 / 1353  (31.0):  94%|| 1352/1436 [1:21:03<04:29,  3.21s/it]\u001b[A\n",
      "Average Metric: 420 / 1353  (31.0):  94%|| 1353/1436 [1:21:03<03:33,  2.57s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 420 / 1354  (31.0):  94%|| 1353/1436 [1:21:06<03:33,  2.57s/it]\u001b[A\n",
      "Average Metric: 420 / 1354  (31.0):  94%|| 1354/1436 [1:21:06<03:44,  2.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 420 / 1355  (31.0):  94%|| 1354/1436 [1:21:08<03:44,  2.74s/it]\u001b[A\n",
      "Average Metric: 420 / 1355  (31.0):  94%|| 1355/1436 [1:21:08<03:31,  2.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 420 / 1356  (31.0):  94%|| 1355/1436 [1:21:10<03:31,  2.61s/it]\u001b[A\n",
      "Average Metric: 420 / 1356  (31.0):  94%|| 1356/1436 [1:21:10<03:04,  2.30s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 421 / 1357  (31.0):  94%|| 1356/1436 [1:21:12<03:04,  2.30s/it]\u001b[A\n",
      "Average Metric: 421 / 1357  (31.0):  94%|| 1357/1436 [1:21:12<02:59,  2.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 422 / 1358  (31.1):  94%|| 1357/1436 [1:21:16<02:59,  2.27s/it]\u001b[A\n",
      "Average Metric: 422 / 1358  (31.1):  95%|| 1358/1436 [1:21:16<03:48,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 422 / 1359  (31.1):  95%|| 1358/1436 [1:21:22<03:48,  2.93s/it]\u001b[A\n",
      "Average Metric: 422 / 1359  (31.1):  95%|| 1359/1436 [1:21:22<04:39,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 423 / 1360  (31.1):  95%|| 1359/1436 [1:21:23<04:39,  3.64s/it]\u001b[A\n",
      "Average Metric: 423 / 1360  (31.1):  95%|| 1360/1436 [1:21:23<03:42,  2.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 423 / 1361  (31.1):  95%|| 1360/1436 [1:21:28<03:42,  2.93s/it]\u001b[A\n",
      "Average Metric: 423 / 1361  (31.1):  95%|| 1361/1436 [1:21:28<04:32,  3.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 423 / 1362  (31.1):  95%|| 1361/1436 [1:21:32<04:32,  3.64s/it]\u001b[A\n",
      "Average Metric: 423 / 1362  (31.1):  95%|| 1362/1436 [1:21:32<04:20,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1363  (31.1):  95%|| 1362/1436 [1:21:35<04:20,  3.53s/it]\u001b[A\n",
      "Average Metric: 424 / 1363  (31.1):  95%|| 1363/1436 [1:21:35<04:14,  3.49s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1364  (31.1):  95%|| 1363/1436 [1:21:38<04:14,  3.49s/it]\u001b[A\n",
      "Average Metric: 424 / 1364  (31.1):  95%|| 1364/1436 [1:21:38<04:02,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1365  (31.1):  95%|| 1364/1436 [1:21:41<04:02,  3.36s/it]\u001b[A\n",
      "Average Metric: 424 / 1365  (31.1):  95%|| 1365/1436 [1:21:41<03:58,  3.36s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1366  (31.0):  95%|| 1365/1436 [1:21:47<03:58,  3.36s/it]\u001b[A\n",
      "Average Metric: 424 / 1366  (31.0):  95%|| 1366/1436 [1:21:47<04:33,  3.90s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 424 / 1367  (31.0):  95%|| 1366/1436 [1:21:51<04:33,  3.90s/it]\u001b[A\n",
      "Average Metric: 424 / 1367  (31.0):  95%|| 1367/1436 [1:21:51<04:30,  3.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 425 / 1368  (31.1):  95%|| 1367/1436 [1:21:53<04:30,  3.93s/it]\u001b[A\n",
      "Average Metric: 425 / 1368  (31.1):  95%|| 1368/1436 [1:21:53<03:52,  3.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 425 / 1369  (31.0):  95%|| 1368/1436 [1:21:56<03:52,  3.42s/it]\u001b[A\n",
      "Average Metric: 425 / 1369  (31.0):  95%|| 1369/1436 [1:21:56<03:40,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 425 / 1370  (31.0):  95%|| 1369/1436 [1:22:00<03:40,  3.29s/it]\u001b[A\n",
      "Average Metric: 425 / 1370  (31.0):  95%|| 1370/1436 [1:22:00<03:53,  3.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 426 / 1371  (31.1):  95%|| 1370/1436 [1:22:02<03:53,  3.54s/it]\u001b[A\n",
      "Average Metric: 426 / 1371  (31.1):  95%|| 1371/1436 [1:22:02<03:15,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 427 / 1372  (31.1):  95%|| 1371/1436 [1:22:04<03:15,  3.01s/it]\u001b[A\n",
      "Average Metric: 427 / 1372  (31.1):  96%|| 1372/1436 [1:22:04<03:05,  2.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 427 / 1373  (31.1):  96%|| 1372/1436 [1:22:09<03:05,  2.89s/it]\u001b[A\n",
      "Average Metric: 427 / 1373  (31.1):  96%|| 1373/1436 [1:22:09<03:44,  3.56s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 428 / 1374  (31.1):  96%|| 1373/1436 [1:22:13<03:44,  3.56s/it]\u001b[A\n",
      "Average Metric: 428 / 1374  (31.1):  96%|| 1374/1436 [1:22:13<03:38,  3.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 428 / 1375  (31.1):  96%|| 1374/1436 [1:22:16<03:38,  3.52s/it]\u001b[A\n",
      "Average Metric: 428 / 1375  (31.1):  96%|| 1375/1436 [1:22:16<03:35,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 429 / 1376  (31.2):  96%|| 1375/1436 [1:22:20<03:35,  3.53s/it]\u001b[A\n",
      "Average Metric: 429 / 1376  (31.2):  96%|| 1376/1436 [1:22:20<03:39,  3.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1377  (31.2):  96%|| 1376/1436 [1:22:24<03:39,  3.65s/it]\u001b[A\n",
      "Average Metric: 430 / 1377  (31.2):  96%|| 1377/1436 [1:22:24<03:33,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1378  (31.2):  96%|| 1377/1436 [1:22:29<03:33,  3.63s/it]\u001b[A\n",
      "Average Metric: 430 / 1378  (31.2):  96%|| 1378/1436 [1:22:29<03:59,  4.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1379  (31.2):  96%|| 1378/1436 [1:22:34<03:59,  4.13s/it]\u001b[A\n",
      "Average Metric: 430 / 1379  (31.2):  96%|| 1379/1436 [1:22:34<04:00,  4.22s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1380  (31.2):  96%|| 1379/1436 [1:22:38<04:00,  4.22s/it]\u001b[A\n",
      "Average Metric: 430 / 1380  (31.2):  96%|| 1380/1436 [1:22:38<04:02,  4.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1381  (31.1):  96%|| 1380/1436 [1:22:43<04:02,  4.33s/it]\u001b[A\n",
      "Average Metric: 430 / 1381  (31.1):  96%|| 1381/1436 [1:22:43<04:14,  4.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 430 / 1382  (31.1):  96%|| 1381/1436 [1:22:45<04:14,  4.62s/it]\u001b[A\n",
      "Average Metric: 430 / 1382  (31.1):  96%|| 1382/1436 [1:22:45<03:15,  3.61s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 431 / 1383  (31.2):  96%|| 1382/1436 [1:22:46<03:15,  3.61s/it]\u001b[A\n",
      "Average Metric: 431 / 1383  (31.2):  96%|| 1383/1436 [1:22:46<02:39,  3.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 432 / 1384  (31.2):  96%|| 1383/1436 [1:22:50<02:39,  3.01s/it]\u001b[A\n",
      "Average Metric: 432 / 1384  (31.2):  96%|| 1384/1436 [1:22:50<02:41,  3.10s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 433 / 1385  (31.3):  96%|| 1384/1436 [1:22:52<02:41,  3.10s/it]\u001b[A\n",
      "Average Metric: 433 / 1385  (31.3):  96%|| 1385/1436 [1:22:52<02:21,  2.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 433 / 1386  (31.2):  96%|| 1385/1436 [1:22:55<02:21,  2.78s/it]\u001b[A\n",
      "Average Metric: 433 / 1386  (31.2):  97%|| 1386/1436 [1:22:55<02:30,  3.02s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 434 / 1387  (31.3):  97%|| 1386/1436 [1:22:57<02:30,  3.02s/it]\u001b[A\n",
      "Average Metric: 434 / 1387  (31.3):  97%|| 1387/1436 [1:22:57<02:09,  2.64s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 434 / 1388  (31.3):  97%|| 1387/1436 [1:23:02<02:09,  2.64s/it]\u001b[A\n",
      "Average Metric: 434 / 1388  (31.3):  97%|| 1388/1436 [1:23:02<02:39,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 434 / 1389  (31.2):  97%|| 1388/1436 [1:23:04<02:39,  3.32s/it]\u001b[A\n",
      "Average Metric: 434 / 1389  (31.2):  97%|| 1389/1436 [1:23:04<02:18,  2.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 434 / 1390  (31.2):  97%|| 1389/1436 [1:23:06<02:18,  2.94s/it]\u001b[A\n",
      "Average Metric: 434 / 1390  (31.2):  97%|| 1390/1436 [1:23:06<01:59,  2.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 435 / 1391  (31.3):  97%|| 1390/1436 [1:23:09<01:59,  2.60s/it]\u001b[A\n",
      "Average Metric: 435 / 1391  (31.3):  97%|| 1391/1436 [1:23:09<02:06,  2.81s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 436 / 1392  (31.3):  97%|| 1391/1436 [1:23:11<02:06,  2.81s/it]\u001b[A\n",
      "Average Metric: 436 / 1392  (31.3):  97%|| 1392/1436 [1:23:11<01:53,  2.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1393  (31.4):  97%|| 1392/1436 [1:23:15<01:53,  2.58s/it]\u001b[A\n",
      "Average Metric: 437 / 1393  (31.4):  97%|| 1393/1436 [1:23:15<02:02,  2.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 437 / 1394  (31.3):  97%|| 1393/1436 [1:23:20<02:02,  2.86s/it]\u001b[A\n",
      "Average Metric: 437 / 1394  (31.3):  97%|| 1394/1436 [1:23:20<02:27,  3.51s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 438 / 1395  (31.4):  97%|| 1394/1436 [1:23:22<02:27,  3.51s/it]\u001b[A\n",
      "Average Metric: 438 / 1395  (31.4):  97%|| 1395/1436 [1:23:22<02:08,  3.14s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1396  (31.4):  97%|| 1395/1436 [1:23:25<02:08,  3.14s/it]\u001b[A\n",
      "Average Metric: 439 / 1396  (31.4):  97%|| 1396/1436 [1:23:25<02:00,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1397  (31.4):  97%|| 1396/1436 [1:23:29<02:00,  3.00s/it]\u001b[A\n",
      "Average Metric: 439 / 1397  (31.4):  97%|| 1397/1436 [1:23:29<02:13,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1398  (31.4):  97%|| 1397/1436 [1:23:34<02:13,  3.44s/it]\u001b[A\n",
      "Average Metric: 439 / 1398  (31.4):  97%|| 1398/1436 [1:23:34<02:27,  3.89s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1399  (31.4):  97%|| 1398/1436 [1:23:36<02:27,  3.89s/it]\u001b[A\n",
      "Average Metric: 439 / 1399  (31.4):  97%|| 1399/1436 [1:23:36<02:03,  3.34s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1400  (31.4):  97%|| 1399/1436 [1:23:41<02:03,  3.34s/it]\u001b[A\n",
      "Average Metric: 439 / 1400  (31.4):  97%|| 1400/1436 [1:23:41<02:14,  3.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1401  (31.3):  97%|| 1400/1436 [1:23:43<02:14,  3.75s/it]\u001b[A\n",
      "Average Metric: 439 / 1401  (31.3):  98%|| 1401/1436 [1:23:43<01:54,  3.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1402  (31.3):  98%|| 1401/1436 [1:23:44<01:54,  3.26s/it]\u001b[A\n",
      "Average Metric: 439 / 1402  (31.3):  98%|| 1402/1436 [1:23:44<01:32,  2.71s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1403  (31.3):  98%|| 1402/1436 [1:23:50<01:32,  2.71s/it]\u001b[A\n",
      "Average Metric: 439 / 1403  (31.3):  98%|| 1403/1436 [1:23:50<01:53,  3.45s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1404  (31.3):  98%|| 1403/1436 [1:23:54<01:53,  3.45s/it]\u001b[A\n",
      "Average Metric: 439 / 1404  (31.3):  98%|| 1404/1436 [1:23:54<01:56,  3.63s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1405  (31.2):  98%|| 1404/1436 [1:23:57<01:56,  3.63s/it]\u001b[A\n",
      "Average Metric: 439 / 1405  (31.2):  98%|| 1405/1436 [1:23:57<01:54,  3.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 439 / 1406  (31.2):  98%|| 1405/1436 [1:24:00<01:54,  3.70s/it]\u001b[A\n",
      "Average Metric: 439 / 1406  (31.2):  98%|| 1406/1436 [1:24:00<01:43,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 440 / 1407  (31.3):  98%|| 1406/1436 [1:24:04<01:43,  3.46s/it]\u001b[A\n",
      "Average Metric: 440 / 1407  (31.3):  98%|| 1407/1436 [1:24:04<01:39,  3.44s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 441 / 1408  (31.3):  98%|| 1407/1436 [1:24:07<01:39,  3.44s/it]\u001b[A\n",
      "Average Metric: 441 / 1408  (31.3):  98%|| 1408/1436 [1:24:07<01:32,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 442 / 1409  (31.4):  98%|| 1408/1436 [1:24:10<01:32,  3.31s/it]\u001b[A\n",
      "Average Metric: 442 / 1409  (31.4):  98%|| 1409/1436 [1:24:10<01:30,  3.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 443 / 1410  (31.4):  98%|| 1409/1436 [1:24:13<01:30,  3.37s/it]\u001b[A\n",
      "Average Metric: 443 / 1410  (31.4):  98%|| 1410/1436 [1:24:13<01:23,  3.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 443 / 1411  (31.4):  98%|| 1410/1436 [1:24:18<01:23,  3.23s/it]\u001b[A\n",
      "Average Metric: 443 / 1411  (31.4):  98%|| 1411/1436 [1:24:18<01:34,  3.78s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 444 / 1412  (31.4):  98%|| 1411/1436 [1:24:20<01:34,  3.78s/it]\u001b[A\n",
      "Average Metric: 444 / 1412  (31.4):  98%|| 1412/1436 [1:24:20<01:17,  3.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 445 / 1413  (31.5):  98%|| 1412/1436 [1:24:22<01:17,  3.23s/it]\u001b[A\n",
      "Average Metric: 445 / 1413  (31.5):  98%|| 1413/1436 [1:24:22<01:03,  2.75s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 446 / 1414  (31.5):  98%|| 1413/1436 [1:24:23<01:03,  2.75s/it]\u001b[A\n",
      "Average Metric: 446 / 1414  (31.5):  98%|| 1414/1436 [1:24:23<00:52,  2.38s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 446 / 1415  (31.5):  98%|| 1414/1436 [1:24:26<00:52,  2.38s/it]\u001b[A\n",
      "Average Metric: 446 / 1415  (31.5):  99%|| 1415/1436 [1:24:26<00:53,  2.52s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 446 / 1416  (31.5):  99%|| 1415/1436 [1:24:28<00:53,  2.52s/it]\u001b[A\n",
      "Average Metric: 446 / 1416  (31.5):  99%|| 1416/1436 [1:24:28<00:46,  2.35s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 446 / 1417  (31.5):  99%|| 1416/1436 [1:24:31<00:46,  2.35s/it]\u001b[A\n",
      "Average Metric: 446 / 1417  (31.5):  99%|| 1417/1436 [1:24:31<00:48,  2.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 446 / 1418  (31.5):  99%|| 1417/1436 [1:24:36<00:48,  2.53s/it]\u001b[A\n",
      "Average Metric: 446 / 1418  (31.5):  99%|| 1418/1436 [1:24:36<00:59,  3.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 447 / 1419  (31.5):  99%|| 1418/1436 [1:24:39<00:59,  3.32s/it]\u001b[A\n",
      "Average Metric: 447 / 1419  (31.5):  99%|| 1419/1436 [1:24:40<00:56,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 447 / 1420  (31.5):  99%|| 1419/1436 [1:24:45<00:56,  3.31s/it]\u001b[A\n",
      "Average Metric: 447 / 1420  (31.5):  99%|| 1420/1436 [1:24:45<01:03,  3.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 447 / 1421  (31.5):  99%|| 1420/1436 [1:24:47<01:03,  3.96s/it]\u001b[A\n",
      "Average Metric: 447 / 1421  (31.5):  99%|| 1421/1436 [1:24:47<00:51,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 447 / 1422  (31.4):  99%|| 1421/1436 [1:24:51<00:51,  3.46s/it]\u001b[A\n",
      "Average Metric: 447 / 1422  (31.4):  99%|| 1422/1436 [1:24:51<00:48,  3.46s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 447 / 1423  (31.4):  99%|| 1422/1436 [1:24:54<00:48,  3.46s/it]\u001b[A\n",
      "Average Metric: 447 / 1423  (31.4):  99%|| 1423/1436 [1:24:54<00:44,  3.40s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 447 / 1424  (31.4):  99%|| 1423/1436 [1:24:55<00:44,  3.40s/it]\u001b[A\n",
      "Average Metric: 447 / 1424  (31.4):  99%|| 1424/1436 [1:24:55<00:32,  2.74s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 447 / 1425  (31.4):  99%|| 1424/1436 [1:24:57<00:32,  2.74s/it]\u001b[A\n",
      "Average Metric: 447 / 1425  (31.4):  99%|| 1425/1436 [1:24:57<00:26,  2.41s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 448 / 1426  (31.4):  99%|| 1425/1436 [1:25:01<00:26,  2.41s/it]\u001b[A\n",
      "Average Metric: 448 / 1426  (31.4):  99%|| 1426/1436 [1:25:01<00:30,  3.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 449 / 1427  (31.5):  99%|| 1426/1436 [1:25:03<00:30,  3.00s/it]\u001b[A\n",
      "Average Metric: 449 / 1427  (31.5):  99%|| 1427/1436 [1:25:03<00:24,  2.70s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 450 / 1428  (31.5):  99%|| 1427/1436 [1:25:04<00:24,  2.70s/it]\u001b[A\n",
      "Average Metric: 450 / 1428  (31.5):  99%|| 1428/1436 [1:25:04<00:17,  2.23s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 450 / 1429  (31.5):  99%|| 1428/1436 [1:25:07<00:17,  2.23s/it]\u001b[A\n",
      "Average Metric: 450 / 1429  (31.5): 100%|| 1429/1436 [1:25:07<00:16,  2.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 451 / 1430  (31.5): 100%|| 1429/1436 [1:25:08<00:16,  2.33s/it]\u001b[A\n",
      "Average Metric: 451 / 1430  (31.5): 100%|| 1430/1436 [1:25:08<00:11,  1.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 451 / 1431  (31.5): 100%|| 1430/1436 [1:25:09<00:11,  1.99s/it]\u001b[A\n",
      "Average Metric: 451 / 1431  (31.5): 100%|| 1431/1436 [1:25:09<00:09,  1.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 451 / 1432  (31.5): 100%|| 1431/1436 [1:25:15<00:09,  1.80s/it]\u001b[A\n",
      "Average Metric: 451 / 1432  (31.5): 100%|| 1432/1436 [1:25:15<00:11,  2.79s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 452 / 1433  (31.5): 100%|| 1432/1436 [1:25:19<00:11,  2.79s/it]\u001b[A\n",
      "Average Metric: 452 / 1433  (31.5): 100%|| 1433/1436 [1:25:19<00:09,  3.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 452 / 1434  (31.5): 100%|| 1433/1436 [1:25:22<00:09,  3.31s/it]\u001b[A\n",
      "Average Metric: 452 / 1434  (31.5): 100%|| 1434/1436 [1:25:22<00:06,  3.29s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 452 / 1435  (31.5): 100%|| 1434/1436 [1:25:26<00:06,  3.29s/it]\u001b[A\n",
      "Average Metric: 452 / 1435  (31.5): 100%|| 1435/1436 [1:25:26<00:03,  3.54s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 452 / 1436  (31.5): 100%|| 1435/1436 [1:25:31<00:03,  3.54s/it]\u001b[A\n",
      "Average Metric: 452 / 1436  (31.5): 100%|| 1436/1436 [1:25:31<00:00,  3.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 452 / 1436  (31.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61857 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61857 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61857_row0_col0, #T_61857_row0_col1, #T_61857_row0_col2, #T_61857_row0_col3, #T_61857_row0_col4, #T_61857_row0_col5, #T_61857_row0_col6, #T_61857_row0_col7, #T_61857_row1_col0, #T_61857_row1_col1, #T_61857_row1_col2, #T_61857_row1_col3, #T_61857_row1_col4, #T_61857_row1_col5, #T_61857_row1_col6, #T_61857_row1_col7, #T_61857_row2_col0, #T_61857_row2_col1, #T_61857_row2_col2, #T_61857_row2_col3, #T_61857_row2_col4, #T_61857_row2_col5, #T_61857_row2_col6, #T_61857_row2_col7, #T_61857_row3_col0, #T_61857_row3_col1, #T_61857_row3_col2, #T_61857_row3_col3, #T_61857_row3_col4, #T_61857_row3_col5, #T_61857_row3_col6, #T_61857_row3_col7, #T_61857_row4_col0, #T_61857_row4_col1, #T_61857_row4_col2, #T_61857_row4_col3, #T_61857_row4_col4, #T_61857_row4_col5, #T_61857_row4_col6, #T_61857_row4_col7 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61857\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61857_level0_col0\" class=\"col_heading level0 col0\" >context</th>\n",
       "      <th id=\"T_61857_level0_col1\" class=\"col_heading level0 col1\" >question</th>\n",
       "      <th id=\"T_61857_level0_col2\" class=\"col_heading level0 col2\" >options</th>\n",
       "      <th id=\"T_61857_level0_col3\" class=\"col_heading level0 col3\" >answer_option</th>\n",
       "      <th id=\"T_61857_level0_col4\" class=\"col_heading level0 col4\" >example_answer</th>\n",
       "      <th id=\"T_61857_level0_col5\" class=\"col_heading level0 col5\" >rationale</th>\n",
       "      <th id=\"T_61857_level0_col6\" class=\"col_heading level0 col6\" >pred_answer</th>\n",
       "      <th id=\"T_61857_level0_col7\" class=\"col_heading level0 col7\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61857_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_61857_row0_col0\" class=\"data row0 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_61857_row0_col1\" class=\"data row0 col1\" >Where is Wendy from?</td>\n",
       "      <td id=\"T_61857_row0_col2\" class=\"data row0 col2\" >['China.', 'England.', 'America.', 'Australia.']</td>\n",
       "      <td id=\"T_61857_row0_col3\" class=\"data row0 col3\" >D</td>\n",
       "      <td id=\"T_61857_row0_col4\" class=\"data row0 col4\" >Australia.</td>\n",
       "      <td id=\"T_61857_row0_col5\" class=\"data row0 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_61857_row0_col6\" class=\"data row0 col6\" >Australia.</td>\n",
       "      <td id=\"T_61857_row0_col7\" class=\"data row0 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61857_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_61857_row1_col0\" class=\"data row1 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_61857_row1_col1\" class=\"data row1 col1\" >What colours does Nancy like?</td>\n",
       "      <td id=\"T_61857_row1_col2\" class=\"data row1 col2\" >['Red and blue.', 'Red and yellow.', 'Green and yellow.', 'Green and blue.']</td>\n",
       "      <td id=\"T_61857_row1_col3\" class=\"data row1 col3\" >D</td>\n",
       "      <td id=\"T_61857_row1_col4\" class=\"data row1 col4\" >Green and blue.</td>\n",
       "      <td id=\"T_61857_row1_col5\" class=\"data row1 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_61857_row1_col6\" class=\"data row1 col6\" >Green and blue.</td>\n",
       "      <td id=\"T_61857_row1_col7\" class=\"data row1 col7\" > [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61857_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_61857_row2_col0\" class=\"data row2 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_61857_row2_col1\" class=\"data row2 col1\" >What's Wendy's favourite sport?</td>\n",
       "      <td id=\"T_61857_row2_col2\" class=\"data row2 col2\" >['Running.', 'Basketball.', 'Football.', 'Table tennis.']</td>\n",
       "      <td id=\"T_61857_row2_col3\" class=\"data row2 col3\" >A</td>\n",
       "      <td id=\"T_61857_row2_col4\" class=\"data row2 col4\" >Running.</td>\n",
       "      <td id=\"T_61857_row2_col5\" class=\"data row2 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_61857_row2_col6\" class=\"data row2 col6\" >We don't have enough information to answer the question.</td>\n",
       "      <td id=\"T_61857_row2_col7\" class=\"data row2 col7\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61857_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_61857_row3_col0\" class=\"data row3 col0\" >My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We...</td>\n",
       "      <td id=\"T_61857_row3_col1\" class=\"data row3 col1\" >Which is TRUE ?</td>\n",
       "      <td id=\"T_61857_row3_col2\" class=\"data row3 col2\" >['Nancy and Wendy are 12 years old.', 'Wendy is a student and she is English.', 'Everyone in Class Four likes Wendy.', 'Nancy has a cat...</td>\n",
       "      <td id=\"T_61857_row3_col3\" class=\"data row3 col3\" >C</td>\n",
       "      <td id=\"T_61857_row3_col4\" class=\"data row3 col4\" >Everyone in Class Four likes Wendy.</td>\n",
       "      <td id=\"T_61857_row3_col5\" class=\"data row3 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_61857_row3_col6\" class=\"data row3 col6\" >Nancy has a dog and Wendy has a cat.</td>\n",
       "      <td id=\"T_61857_row3_col7\" class=\"data row3 col7\" > [False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61857_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_61857_row4_col0\" class=\"data row4 col0\" >June 5 is World Environment Day.This makes us pay more attention to our environment and the need to protect it. When Wang Baoxuan,a Beijing high...</td>\n",
       "      <td id=\"T_61857_row4_col1\" class=\"data row4 col1\" >What do Wang Baoxuan and his schoolmates do with the waste exercise books?</td>\n",
       "      <td id=\"T_61857_row4_col2\" class=\"data row4 col2\" >['Throw them away', 'Collect and sell them', 'Cut them into pieces', 'Give them to the students in Inner Mongolia']</td>\n",
       "      <td id=\"T_61857_row4_col3\" class=\"data row4 col3\" >B</td>\n",
       "      <td id=\"T_61857_row4_col4\" class=\"data row4 col4\" >Collect and sell them</td>\n",
       "      <td id=\"T_61857_row4_col5\" class=\"data row4 col5\" >Given the context, answer the question by choosing from given options. --- Follow the following format. Context: ${context} Question: ${question} Options: 4 options to select...</td>\n",
       "      <td id=\"T_61857_row4_col6\" class=\"data row4 col6\" >Collect and sell them.</td>\n",
       "      <td id=\"T_61857_row4_col7\" class=\"data row4 col7\" > [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3ff19427a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1431 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31.48"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=dspy_dataset[\"middle\"][\"test\"], num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(generate_answer_with_chain_of_thought, metric=metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 0/3498 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 1 / 1  (100.0):   0%|          | 1/3498 [00:03<3:14:09,  3.33s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 2  (100.0):   0%|          | 1/3498 [00:06<3:14:09,  3.33s/it]\u001b[A\n",
      "Average Metric: 2 / 2  (100.0):   0%|          | 2/3498 [00:06<3:01:01,  3.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 3  (66.7):   0%|          | 2/3498 [00:11<3:01:01,  3.11s/it] \u001b[A\n",
      "Average Metric: 2 / 3  (66.7):   0%|          | 3/3498 [00:11<3:48:15,  3.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 4  (50.0):   0%|          | 3/3498 [00:16<3:48:15,  3.92s/it]\u001b[A\n",
      "Average Metric: 2 / 4  (50.0):   0%|          | 4/3498 [00:16<4:20:44,  4.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 5  (40.0):   0%|          | 4/3498 [00:20<4:20:44,  4.48s/it]\u001b[A\n",
      "Average Metric: 2 / 5  (40.0):   0%|          | 5/3498 [00:20<4:14:34,  4.37s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 2 / 6  (33.3):   0%|          | 5/3498 [00:25<4:14:34,  4.37s/it]\u001b[A\n",
      "Average Metric: 2 / 6  (33.3):   0%|          | 6/3498 [00:25<4:31:45,  4.67s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 3 / 7  (42.9):   0%|          | 6/3498 [00:28<4:31:45,  4.67s/it]\u001b[A\n",
      "Average Metric: 3 / 7  (42.9):   0%|          | 7/3498 [00:28<3:57:10,  4.08s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 8  (50.0):   0%|          | 7/3498 [00:31<3:57:10,  4.08s/it]\u001b[A\n",
      "Average Metric: 4 / 8  (50.0):   0%|          | 8/3498 [00:31<3:40:56,  3.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 9  (44.4):   0%|          | 8/3498 [00:37<3:40:56,  3.80s/it]\u001b[A\n",
      "Average Metric: 4 / 9  (44.4):   0%|          | 9/3498 [00:37<4:08:20,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 10  (40.0):   0%|          | 9/3498 [00:39<4:08:20,  4.27s/it]\u001b[A\n",
      "Average Metric: 4 / 10  (40.0):   0%|          | 10/3498 [00:39<3:38:38,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 11  (36.4):   0%|          | 10/3498 [00:43<3:38:38,  3.76s/it]\u001b[A\n",
      "Average Metric: 4 / 11  (36.4):   0%|          | 11/3498 [00:43<3:43:31,  3.85s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 12  (33.3):   0%|          | 11/3498 [00:49<3:43:31,  3.85s/it]\u001b[A\n",
      "Average Metric: 4 / 12  (33.3):   0%|          | 12/3498 [00:49<4:07:13,  4.26s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 13  (30.8):   0%|          | 12/3498 [00:54<4:07:13,  4.26s/it]\u001b[A\n",
      "Average Metric: 4 / 13  (30.8):   0%|          | 13/3498 [00:54<4:26:13,  4.58s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 14  (28.6):   0%|          | 13/3498 [00:59<4:26:13,  4.58s/it]\u001b[A\n",
      "Average Metric: 4 / 14  (28.6):   0%|          | 14/3498 [00:59<4:38:46,  4.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 4 / 15  (26.7):   0%|          | 14/3498 [01:05<4:38:46,  4.80s/it]\u001b[A\n",
      "Average Metric: 4 / 15  (26.7):   0%|          | 15/3498 [01:05<4:48:08,  4.96s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 5 / 16  (31.2):   0%|          | 15/3498 [01:08<4:48:08,  4.96s/it]\u001b[A\n",
      "Average Metric: 5 / 16  (31.2):   0%|          | 16/3498 [01:08<4:14:38,  4.39s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 6 / 17  (35.3):   0%|          | 16/3498 [01:09<4:14:38,  4.39s/it]\u001b[A\n",
      "Average Metric: 6 / 17  (35.3):   0%|          | 17/3498 [01:09<3:28:55,  3.60s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 6 / 18  (33.3):   0%|          | 17/3498 [01:14<3:28:55,  3.60s/it]\u001b[A\n",
      "Average Metric: 6 / 18  (33.3):   1%|          | 18/3498 [01:14<3:38:04,  3.76s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 6 / 19  (31.6):   1%|          | 18/3498 [01:17<3:38:04,  3.76s/it]\u001b[A\n",
      "Average Metric: 6 / 19  (31.6):   1%|          | 19/3498 [01:17<3:24:24,  3.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 6 / 20  (30.0):   1%|          | 19/3498 [01:22<3:24:24,  3.53s/it]\u001b[A\n",
      "Average Metric: 6 / 20  (30.0):   1%|          | 20/3498 [01:22<3:55:17,  4.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 7 / 21  (33.3):   1%|          | 20/3498 [01:27<3:55:17,  4.06s/it]\u001b[A\n",
      "Average Metric: 7 / 21  (33.3):   1%|          | 21/3498 [01:27<4:15:55,  4.42s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 7 / 22  (31.8):   1%|          | 21/3498 [01:32<4:15:55,  4.42s/it]\u001b[A\n",
      "Average Metric: 7 / 22  (31.8):   1%|          | 22/3498 [01:32<4:30:02,  4.66s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 7 / 23  (30.4):   1%|          | 22/3498 [01:36<4:30:02,  4.66s/it]\u001b[A\n",
      "Average Metric: 7 / 23  (30.4):   1%|          | 23/3498 [01:36<4:07:18,  4.27s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 24  (33.3):   1%|          | 23/3498 [01:39<4:07:18,  4.27s/it]\u001b[A\n",
      "Average Metric: 8 / 24  (33.3):   1%|          | 24/3498 [01:39<3:48:47,  3.95s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 25  (32.0):   1%|          | 24/3498 [01:44<3:48:47,  3.95s/it]\u001b[A\n",
      "Average Metric: 8 / 25  (32.0):   1%|          | 25/3498 [01:44<4:09:18,  4.31s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 26  (30.8):   1%|          | 25/3498 [01:49<4:09:18,  4.31s/it]\u001b[A\n",
      "Average Metric: 8 / 26  (30.8):   1%|          | 26/3498 [01:49<4:22:08,  4.53s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 27  (29.6):   1%|          | 26/3498 [01:55<4:22:08,  4.53s/it]\u001b[A\n",
      "Average Metric: 8 / 27  (29.6):   1%|          | 27/3498 [01:55<4:37:34,  4.80s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 28  (28.6):   1%|          | 27/3498 [02:00<4:37:34,  4.80s/it]\u001b[A\n",
      "Average Metric: 8 / 28  (28.6):   1%|          | 28/3498 [02:00<4:48:18,  4.99s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 29  (27.6):   1%|          | 28/3498 [02:05<4:48:18,  4.99s/it]\u001b[A\n",
      "Average Metric: 8 / 29  (27.6):   1%|          | 29/3498 [02:05<4:55:39,  5.11s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 30  (26.7):   1%|          | 29/3498 [02:10<4:55:39,  5.11s/it]\u001b[A\n",
      "Average Metric: 8 / 30  (26.7):   1%|          | 30/3498 [02:10<4:40:48,  4.86s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "Average Metric: 8 / 31  (25.8):   1%|          | 30/3498 [02:15<4:40:48,  4.86s/it]\u001b[A\n",
      "Average Metric: 8 / 31  (25.8):   1%|          | 31/3498 [02:15<4:49:03,  5.00s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m metric \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mevaluate\u001b[38;5;241m.\u001b[39manswer_exact_match\n\u001b[0;32m----> 9\u001b[0m \u001b[43mevaluate_on_comprehension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_answer_with_chain_of_thought\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:111\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[0;34m(self, program, metric, devset, num_threads, display_progress, display_table, display, return_all_scores)\u001b[0m\n\u001b[1;32m    108\u001b[0m devset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(devset))\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_threads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_single_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_multi_thread(wrapped_program, devset, num_threads, display_progress)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:38\u001b[0m, in \u001b[0;36mEvaluate._execute_single_thread\u001b[0;34m(self, wrapped_program, devset, display_progress)\u001b[0m\n\u001b[1;32m     36\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(devset), dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m display_progress)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, arg \u001b[38;5;129;01min\u001b[39;00m devset:\n\u001b[0;32m---> 38\u001b[0m     example_idx, example, prediction, score \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     reordered_devset\u001b[38;5;241m.\u001b[39mappend((example_idx, example, prediction, score))\n\u001b[1;32m     40\u001b[0m     ncorrect \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:93\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# print(threading.get_ident(), dsp.settings.stack_by_thread[threading.get_ident()])\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# print(type(example), example)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     score \u001b[38;5;241m=\u001b[39m metric(example, prediction)  \u001b[38;5;66;03m# FIXME: TODO: What's the right order? Maybe force name-based kwargs!\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m example_idx, example, prediction, score\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dspy/primitives/program.py:25\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 21\u001b[0m, in \u001b[0;36mCoT.forward\u001b[0;34m(self, context, question, options)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, context, question, options):\n\u001b[0;32m---> 21\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     prediction\u001b[38;5;241m.\u001b[39manswer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(prediction\u001b[38;5;241m.\u001b[39manswer)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py:60\u001b[0m, in \u001b[0;36mPredict.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dspy/predict/chain_of_thought.py:55\u001b[0m, in \u001b[0;36mChainOfThought.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivated \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivated \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mlm, dsp\u001b[38;5;241m.\u001b[39mGPT3)):\n\u001b[1;32m     53\u001b[0m     signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextended_signature\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dspy/predict/predict.py:87\u001b[0m, in \u001b[0;36mPredict.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m dsp\u001b[38;5;241m.\u001b[39mExample(demos\u001b[38;5;241m=\u001b[39mdemos, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     x, C \u001b[38;5;241m=\u001b[39m \u001b[43mdsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mcontext(lm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm, query_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;66;03m# print(f\"using lm = {self.lm} !\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dsp/primitives/predict.py:78\u001b[0m, in \u001b[0;36m_generate.<locals>.do_generate\u001b[0;34m(example, stage, max_depth, original_example)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Generate and extract the fields.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m prompt \u001b[38;5;241m=\u001b[39m template(example)\n\u001b[0;32m---> 78\u001b[0m completions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m completions: \u001b[38;5;28mlist\u001b[39m[Example] \u001b[38;5;241m=\u001b[39m [template\u001b[38;5;241m.\u001b[39mextract(example, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m completions]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Find the completions that are most complete.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py:137\u001b[0m, in \u001b[0;36mHFModel.__call__\u001b[0;34m(self, prompt, only_completed, return_sorted, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.1\u001b[39m:\n\u001b[1;32m    135\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dsp/modules/lm.py:26\u001b[0m, in \u001b[0;36mLM.request\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py:91\u001b[0m, in \u001b[0;36mHFModel.basic_request\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m raw_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m     90\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m---> 91\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m history \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: response,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: raw_kwargs,\n\u001b[1;32m     98\u001b[0m }\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend(history)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dsp/modules/hf.py:116\u001b[0m, in \u001b[0;36mHFModel._generate\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# print(kwargs)\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_prompt_from_output:\n\u001b[1;32m    118\u001b[0m     input_length \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1718\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1702\u001b[0m         input_ids,\n\u001b[1;32m   1703\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1715\u001b[0m     )\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2579\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2579\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2580\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2582\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1044\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1041\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1044\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1057\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:929\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    919\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    920\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    921\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    926\u001b[0m         use_cache,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:654\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:302\u001b[0m, in \u001b[0;36mMistralAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attn_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(query_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    301\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m--> 302\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim):\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attn_output` should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mq_len,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_comprehension = Evaluate(devset=dspy_dataset[\"high\"][\"test\"], num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "\n",
    "evaluate_on_comprehension(generate_answer_with_chain_of_thought, metric=metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d8372e00adc4573914cd14a7435f9be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2f7cd716de84319be6b2fc47596e83b",
      "placeholder": "",
      "style": "IPY_MODEL_f756ff4c6a234b81aeffdbca9740120e",
      "value": "Map: 100%"
     }
    },
    "15a82a5784914ac08630e2f4071ba3bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1698a2b8f6e448e49e36c9c9962c7c95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17156cb5ed9d4b4f9fe52b4286016752": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c5bde4646194721a2a30f2cc07335a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e374f032d0a44e0bcd20e3f06c78c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c5bde4646194721a2a30f2cc07335a5",
      "placeholder": "",
      "style": "IPY_MODEL_f4dd0c0980fc4c19bdeef3c1630c5312",
      "value": " 2000/2000 [00:00&lt;00:00, 46490.25 examples/s]"
     }
    },
    "25fe02c768e54238bf20540dbf311fa7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2645512b9ade44f6a74576ff0d6fa447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e21bc0c967f40148fb882c8692d3278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35df6a1f32524ab1a0cb9dedcda968d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38f0319edfed473d8100d6ad3504ed75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2645512b9ade44f6a74576ff0d6fa447",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8167d6e1e3945e8993fb038c4ecc9ea",
      "value": 2000
     }
    },
    "4571611d877e4d03a2aa0ffa364d635d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45745800f73046a2b27efada4f8eb3e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15a82a5784914ac08630e2f4071ba3bc",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0752f1be3c2478c9464438fcadd0127",
      "value": 2000
     }
    },
    "46eea712001e449b806537819ff208f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7541ec8e9bc446a297e35442bc8cd2a9",
      "placeholder": "",
      "style": "IPY_MODEL_c7d92f41c2564ce9909d2fbb1ded4c24",
      "value": " 2000/2000 [00:00&lt;00:00, 18845.98 examples/s]"
     }
    },
    "4fbe9e916c58498f94d1dbc39030736d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9438276614d94569b36a1ccd8903927e",
      "placeholder": "",
      "style": "IPY_MODEL_9c8f103f3e92424e87ec527f06ce3783",
      "value": "Filter: 100%"
     }
    },
    "691b812bbacc46d3b9d8413d5ee8cbaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a905eb31b29343408c2923898845ac82",
       "IPY_MODEL_45745800f73046a2b27efada4f8eb3e6",
       "IPY_MODEL_f5a908ff6a5141e29c0f2adf1e4eb6f3"
      ],
      "layout": "IPY_MODEL_714f7dc65d0b4f5f96c23326732bb1cb"
     }
    },
    "714f7dc65d0b4f5f96c23326732bb1cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7541ec8e9bc446a297e35442bc8cd2a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77fd1da3e56a48ddb679433ed04fd954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4fbe9e916c58498f94d1dbc39030736d",
       "IPY_MODEL_8e2c8030ad78492ba390202aa7ef0d93",
       "IPY_MODEL_1e374f032d0a44e0bcd20e3f06c78c83"
      ],
      "layout": "IPY_MODEL_cb20de4cee8f4f74a92e3251a0202ea9"
     }
    },
    "7e02b08cb22c4674acdb19ca61794894": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f40feca3d4c41bf8bc62627ed1dc958": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8645eb09632f4a3eb9660a18b7a22f3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88827a69dace443e9db9aaee06730ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e1a494621894bfcad9418e6da0dff41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e2c8030ad78492ba390202aa7ef0d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acfd7180cd984b2089632238c0cf080e",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e1a494621894bfcad9418e6da0dff41",
      "value": 2000
     }
    },
    "8ec864e098ae4c09b41f74e37d011d40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9007cb683c264fa599648b008871d9a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93558e5be6694ff1a3bfab6f0aea7d97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9438276614d94569b36a1ccd8903927e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99919dbc154f4d289d2ae34f9bbecf54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c24d002c4d5d488c8ae49d158d3017af",
      "placeholder": "",
      "style": "IPY_MODEL_9d28d336e00d446bb7f7629b99c9b53d",
      "value": "Map: 100%"
     }
    },
    "9be50fdd5ace4151b9033fc53de6856b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c8f103f3e92424e87ec527f06ce3783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d28d336e00d446bb7f7629b99c9b53d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a00da28977b44a549906c98c14f7f97a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8167d6e1e3945e8993fb038c4ecc9ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a905eb31b29343408c2923898845ac82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f40feca3d4c41bf8bc62627ed1dc958",
      "placeholder": "",
      "style": "IPY_MODEL_35df6a1f32524ab1a0cb9dedcda968d9",
      "value": "Map: 100%"
     }
    },
    "acfd7180cd984b2089632238c0cf080e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0752f1be3c2478c9464438fcadd0127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c13234152b4c477d88dd85844b5e712e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17156cb5ed9d4b4f9fe52b4286016752",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c328a618bad746c6855ca796b076ae0c",
      "value": 2000
     }
    },
    "c24d002c4d5d488c8ae49d158d3017af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f7cd716de84319be6b2fc47596e83b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c328a618bad746c6855ca796b076ae0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c34bead716714285833a9ab9328b2b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1698a2b8f6e448e49e36c9c9962c7c95",
      "placeholder": "",
      "style": "IPY_MODEL_7e02b08cb22c4674acdb19ca61794894",
      "value": " 2000/2000 [00:00&lt;00:00, 5516.08 examples/s]"
     }
    },
    "c7d92f41c2564ce9909d2fbb1ded4c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95483cbfca84905b44b1aaa32480615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25fe02c768e54238bf20540dbf311fa7",
      "placeholder": "",
      "style": "IPY_MODEL_2e21bc0c967f40148fb882c8692d3278",
      "value": " 2000/2000 [00:00&lt;00:00, 8521.81 examples/s]"
     }
    },
    "cb20de4cee8f4f74a92e3251a0202ea9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb3bc20c19f54663a1b420c2b06365ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9007cb683c264fa599648b008871d9a8",
      "placeholder": "",
      "style": "IPY_MODEL_88827a69dace443e9db9aaee06730ee0",
      "value": "Map: 100%"
     }
    },
    "d5869c5b82e9415c8b9c22ab8b2d9d02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb3bc20c19f54663a1b420c2b06365ba",
       "IPY_MODEL_c13234152b4c477d88dd85844b5e712e",
       "IPY_MODEL_c95483cbfca84905b44b1aaa32480615"
      ],
      "layout": "IPY_MODEL_4571611d877e4d03a2aa0ffa364d635d"
     }
    },
    "d6d3f9489f62473a935de8e4f7ad5146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d8372e00adc4573914cd14a7435f9be",
       "IPY_MODEL_deebf2522b3246b193bd00a8eb613807",
       "IPY_MODEL_46eea712001e449b806537819ff208f8"
      ],
      "layout": "IPY_MODEL_93558e5be6694ff1a3bfab6f0aea7d97"
     }
    },
    "d7aadac4406b43d99549d088f9b6d24f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "deebf2522b3246b193bd00a8eb613807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ec864e098ae4c09b41f74e37d011d40",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8645eb09632f4a3eb9660a18b7a22f3f",
      "value": 2000
     }
    },
    "f4dd0c0980fc4c19bdeef3c1630c5312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5568b990cb8474d8ea7d880486a207b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99919dbc154f4d289d2ae34f9bbecf54",
       "IPY_MODEL_38f0319edfed473d8100d6ad3504ed75",
       "IPY_MODEL_c34bead716714285833a9ab9328b2b52"
      ],
      "layout": "IPY_MODEL_a00da28977b44a549906c98c14f7f97a"
     }
    },
    "f5a908ff6a5141e29c0f2adf1e4eb6f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9be50fdd5ace4151b9033fc53de6856b",
      "placeholder": "",
      "style": "IPY_MODEL_d7aadac4406b43d99549d088f9b6d24f",
      "value": " 2000/2000 [00:00&lt;00:00, 5667.09 examples/s]"
     }
    },
    "f756ff4c6a234b81aeffdbca9740120e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
